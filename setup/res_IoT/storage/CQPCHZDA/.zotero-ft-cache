Vers une approche comportementale de recommandation : apport de l’analyse des usages dans un processus de personnalisation
Ilham Esslimani
To cite this version:
Ilham Esslimani. Vers une approche comportementale de recommandation : apport de l’analyse des usages dans un processus de personnalisation. Interface homme-machine [cs.HC]. Universit´e Nancy II, 2010. Fran¸cais. <tel-00581436>
HAL Id: tel-00581436 https://tel.archives-ouvertes.fr/tel-00581436
Submitted on 31 Mar 2011

HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientiﬁc research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est destin´ee au d´epˆot et `a la diﬀusion de documents scientiﬁques de niveau recherche, publi´es ou non, ´emanant des ´etablissements d’enseignement et de recherche fran¸cais ou ´etrangers, des laboratoires publics ou priv´es.

UFR math´ematiques et informatique

E´cole doctorale IAEM Lorraine

D´epartement de formation doctorale en informatique

Vers une approche comportementale de recommandation : apport de l’analyse
des usages dans un processus de personnalisation

THE` SE
pr´esent´ee et soutenue publiquement le 11 d´ecembre 2010 pour l’obtention du
Doctorat de l’universit´e Nancy 2
(sp´ecialit´e informatique) par
Ilham Esslimani

Composition du jury

Rapporteurs :

Pr. C´ecile Paris, CSIRO ICT Centre, Australie Pr. Sylvie Calabretto, LIRIS INSA-Lyon

Examinateurs :

Pr. Monique Grandbastien, UHP-Nancy 1 Dr. Jean Philippe Blanchard, Cr´edit Agricole S.A, Paris

Directrice de th`ese : Pr. Anne Boyer, Universit´e Nancy 2

Laboratoire Lorrain de Recherche en Informatique et ses Applications — UMR 7503

Mis en page avec la classe thloria.

Remerciements
Je tiens à adresser tout d’abord mes remerciements à ma Directrice de thèse Anne Boyer pour son encadrement et ses conseils pendant ces années de thèse. Sa disponibilité, son soutien et son esprit pédagogique m’ont permis d’apprendre beaucoup de choses et de donner le meilleur de moi-même. En outre, sa constante bonne humeur a rendu très agréable nos échanges tout au long de la thèse. Je remercie également Armelle Brun pour tout le temps qu’elle m’a consacré, pour son esprit d’écoute, pour les échanges intéressants qu’on a eu pendant la thèse et pour tous les conseils qu’elle m’a prodigué. Qu’elle trouve ici l’expression de ma reconnaissance.
Je tiens à exprimer ma gratitude au Groupe Crédit Agricole (S.A) pour avoir soutenu ﬁnancièrement cette thèse et remercier en particulier Jean Philippe Blanchard pour sa collaboration et pour ses conseils avisés qui m’ont permis de mener à bien mon travail de thèse.
J’adresse mes remerciements également aux membres du jury Cécile Paris et Sylvie Calabretto pour avoir accepté d’être les rapporteurs de ma thèse, Monique Grandbastien et Jean Philippe Blanchard d’avoir été examinateurs de ma thèse.
Je remercie la société Sailendra et en particulier Régis Lhoste pour son assistance, son soutien et sa collaboration. Mes remerciements vont aussi à tous les membres de l’équipe KIWI que j’ai cotoyés au quotidien. J’ai beaucoup apprécié l’ambiance de travail et les moments agréables passés avec eux qui étaient riches tant sur le plan professionnel que personnel. Je remercie en outre toute l’équipe MAIA de m’avoir accueilli pendant ma première année de thèse. Mes remerciements s’adressent également à Antoinette Courrier pour son aide notamment pour toutes les procédures administratives qui étaient liées à ma thèse.
Je remercie toute ma famille : mes parents, mes sœurs et mes frères qui m’ont poussé jusqu’au bout pour eﬀectuer cette thèse. Je remercie inﬁniment mon mari pour son encouragement, son écoute et son soutien tout au long de ces années et grâce à qui j’ai pu surmonter des moments diﬃciles. Une pensée très particulière est adressée à Najet Boughanmi, Maha Idrissi Aouad, Geoffray Bonnin, Ahmad Hamad, Chérif Haydar et Rokia Bendaoud. Je remercie aussi tous les amis et les collègues que j’ai côtoyés pendant les années de thèse : Wahiba Touali, Ghaith Kaabi, Hanen Maghrebi, Ines Sakly, Stéphane Goria, Manel Sorba, Ilyess Ohayon, Maxime Rio, Mathieu Lefort, Nicolas Jones, Sylvain Castagnos, Cédric Bernier, Billel Nefzi, Karim Dahman, Yoann Bertrand, Cédric Rose, Walid Fdhila et Arnaud Glad. La liste n’étant pas exhaustive, mes remerciements les plus sincères sont adressés à toute personne que j’ai oubliée de citer ici et qui a contribué de près ou de loin à la réalisation de cette thèse.
1

2

Je dédie cette thèse à la mémoire de mon père. 3

4

Table des matières

Introduction générale

11

1 Contexte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2 Problématique de recherche . . . . . . . . . . . . . . . . . . . . . . . . 13

3 Approche proposée . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

3.1 Cadre industriel . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

3.2 Approche . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

3.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

3.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

4 Structure du document . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

Partie I Contexte

Chapitre 1

Etat de l’art

21

5

Table des matières 1.1 Origines et applications . . . . . . . . . . . . . . . . . . . . . . . . . . 21 1.2 Données . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 1.3 Techniques de recommandation . . . . . . . . . . . . . . . . . . . . . . 27 1.3.1 Technique basée sur le contenu . . . . . . . . . . . . . . . . . . 27 1.3.2 Méthodes basées sur la mémoire . . . . . . . . . . . . . . . . . 29 1.3.3 Méthodes basées sur un modèle . . . . . . . . . . . . . . . . . . 33 1.3.4 Techniques issues du Web Usage Mining . . . . . . . . . . . . . 39 1.3.5 Techniques hybrides . . . . . . . . . . . . . . . . . . . . . . . . 44 1.4 Verrous scientiﬁques . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 1.4.1 Manque de données . . . . . . . . . . . . . . . . . . . . . . . . . 47 1.4.2 Démarrage à froid . . . . . . . . . . . . . . . . . . . . . . . . . 49 1.4.3 Sélection de voisins ﬁables . . . . . . . . . . . . . . . . . . . . . 51 1.4.4 Robustesse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 1.4.5 Précision des recommandations . . . . . . . . . . . . . . . . . . 53
Chapitre 2 Schéma générique, contexte applicatif et méthodologie expérimentale 55
2.1 Schéma générique de la recommandation . . . . . . . . . . . . . . . . . 55 2.2 Contexte applicatif . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 2.3 Données exploitées . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
2.3.1 Corpus d’usage . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 6

2.3.2 Corpus de notes explicites . . . . . . . . . . . . . . . . . . . . . 65 2.4 Évaluation des recommandations . . . . . . . . . . . . . . . . . . . . . 66
2.4.1 Mesures statistiques de précision . . . . . . . . . . . . . . . . . 67 2.4.2 Mesures permettant l’aide à la décision . . . . . . . . . . . . . . 68 2.4.3 Couverture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 2.4.4 Temps de calcul . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 2.5 Benchmark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71

Partie II Approche collaborative comportementale de recommandation

Chapitre 1

Vers un Filtrage Collaboratif Comportemental

75

1.1 Extraction des motifs d’usage et calcul des similarités de comportement 78 1.2 Génération des prédictions . . . . . . . . . . . . . . . . . . . . . . . . . 81 1.3 Evaluation de la qualité des prédictions . . . . . . . . . . . . . . . . . . 82
1.3.1 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 1.3.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
7

Table des matières Chapitre 2 Clustering en Filtrage Collaboratif Comportemental
2.1 Schéma du modèle BNCF-PCS . . . . . . . . . . . . . . . . . . . . . . 98 2.2 Génération des clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 2.3 Calcul des similarités de comportement et génération des prédictions . 102 2.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
2.4.1 Modèles expérimentés . . . . . . . . . . . . . . . . . . . . . . . 103 2.4.2 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 2.4.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

Partie III Approche sociale de recommandation

109

Chapitre 1 Prédiction de lien dans les réseaux comportementaux
1.1 Prédiction de lien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 1.1.1 Dans le domaine des réseaux sociaux . . . . . . . . . . . . . . . 112 1.1.2 Dans le domaine des systèmes de recommandation . . . . . . . 113
1.2 Modèle D-BNCF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 1.2.1 Modélisation du réseau comportemental . . . . . . . . . . . . . 115
8

1.2.2 Densiﬁcation du réseau comportemental . . . . . . . . . . . . . 116 1.2.3 Génération des prédictions . . . . . . . . . . . . . . . . . . . . . 122 1.3 Evaluation du modèle . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 1.3.1 Modèles expérimentés . . . . . . . . . . . . . . . . . . . . . . . 123 1.3.2 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 1.3.3 D-BNCF Combiné . . . . . . . . . . . . . . . . . . . . . . . . . 125 1.3.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126 Chapitre 2 Leaders comportementaux pour la recommandation de la nouveauté
2.1 Détection des leaders et des inﬂuenceurs . . . . . . . . . . . . . . . . . 130 2.2 Détection des leaders comportementaux . . . . . . . . . . . . . . . . . 132 2.3 Evaluation des recommandations de leaders . . . . . . . . . . . . . . . 135
2.3.1 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 2.3.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138

Conclusion et Perspectives

141

Table des ﬁgures

147

Liste des tableaux

149

Bibliographie

151

9

Table des matières 10

Introduction générale
1 Contexte
Internet est un réseau numérique mettant à la disposition des utilisateurs, notamment à travers le Web et les portails Extranet, une large variété de ressources, appelées aussi “items” qui ont la particularité d’être hétérogènes et distribués et dont le volume est sans cesse croissant. Nous entendons par item tout type de document électronique regroupant un ensemble de données informatives accessible sous un format électronique donné (e.g. format textuel ou multimédia). Selon une évaluation de l’Internet World Stats1 réalisée en 2010, il y aurait plus de 1.9 milliards d’internautes dans le monde pouvant consulter environ 109.5 millions de sites Web opérationnels et 25.21 milliards de pages2. Or, devant cette surabondance d’items, l’utilisateur devient incapable de gérer cette masse d’information et de repérer les items qui correspondent au mieux à ses attentes, que j’appellerai items pertinents.
Dans ce contexte, le recours à des outils permettant de faciliter l’accès aux items pertinents s’avère crucial. Les moteurs de recherche font partie des premiers outils qui ont été développés pour pallier ce problème d’accès aux items pertinents sur le Web. Ces moteurs ont pour rôle d’explorer et de parcourir le Web aﬁn d’indexer les items qui y sont publiés. Cette indexation consiste en l’extraction de mots-clés, considérés comme signiﬁcatifs, représentant le contenu des items. L’objectif de ces moteurs de recherche est de proposer des items correspondant aux équations de recherche formulées par les utilisateurs (sous forme de mots-clés).
La dernière décennie a été marquée par une évolution considérable des moteurs de recherche dont Google est devenu le plus populaire. Un utilisateur, qui sait a priori comment exprimer son équation de recherche, est souvent satisfait par les résultats proposés par un tel moteur de recherche. Cependant, un utilisateur précisant mal ses équations de recherche parce qu’il est peu initié à Internet ou parce qu’il a peu de connaissances sur le sujet recherché, trouvera des diﬃcultés à repérer les items qui correspondent à ses besoins. Ainsi, en choisissant un mot-clé générique tel que “réseau”, les moteurs de re-
1http ://www.internetworldstats.com 2Alessio Signorini. "Indexable Web Size". http ://www.cs.uiowa.edu/∼asignori/web-size/
11

Introduction générale
cherche proposent des milliers voire des millions de résultats se rapportant à diﬀérentes thématiques telles que “réseau informatique”, “réseau de transport”, “réseau d’entreprises” ou même “réseau de traﬁc de drogue”. De ce fait, la qualité et la pertinence des items proposés par les moteurs de recherche sont notamment conditionnées par la précision des équations de recherche des utilisateurs.
En outre, les techniques utilisées par les moteurs de recherche tel que Google, exploitent principalement le contenu des pages Web ainsi que la structure des hyperliens entre ces pages aﬁn d’évaluer la pertinence et l’importance d’un item par rapport à l’équation de recherche formulée [Brin et Page, 1998]. Peu importe qui a réalisé cette recherche, si la même requête est formulée par deux utilisateurs, les items proposés seront souvent les mêmes. Or, même si deux utilisateurs expriment la même requête, ils n’ont pas nécessairement les mêmes besoins.
Avec l’expansion du Web et le développement de nombreux outils de recherche et de diﬀusion de l’information, tel que les portails Extranet d’entreprise, l’enjeu est de considérer l’utilisateur lors du processus de recherche d’information [Tamine-Lechani et Calabretto, 2008], en vue de satisfaire ses besoins spéciﬁques et de le ﬁdéliser ainsi au service en question. Dans le cadre d’un portail Extranet, les utilisateurs étant connus au préalable et non occasionnels, il s’agit de leur facilier l’accès à des informations susceptibles de les intéresser, pouvant être cruciales et nécessaires à l’aboutissement des projets de l’entreprise et contribuant à la prise de décision.
Ces enjeux liés à la satisfaction des attentes des utilisateurs et à leur ﬁdélisation constituent les objectifs principaux de la personnalisation de l’accès à l’information. En eﬀet, la personnalisation a pour ﬁnalité de proposer des items en lien avec les goûts réels de chaque utilisateur. La personnalisation est un axe de recherche qui a suscité l’intérêt et l’engouement de nombreux chercheurs. Plusieurs approches ont été ainsi proposées, intégrant les approches basées sur le contenu [Krulwich et Burkey, 1996] [Mladenic, 1999], les techniques à base de critiques issue du domaine de raisonnement à partir des cas (“Case Based Reasoning” (CBR)) [Burke, 2000] [Aha et al., 2000], les approches basées sur la navigation sociale [Svensson et al., 2005], etc.
Les systèmes de recommandation s’inscrivent dans le cadre de la personnalisation de l’accès à l’information. Ils peuvent exploiter les approches citées ci-dessus, en vue de proposer à un utilisateur actif (i.e. un utilisateur courant), des conseils d’items qu’ils jugent pertinents par rapport à ses attentes. Ils cherchent en eﬀet à anticiper ses futurs besoins à travers la prédiction de ses appréciations concernant un ou plusieurs items qu’il n’a pas encore consultés. En d’autres termes, les systèmes de recommandation ont pour but d’assister l’activité de recherche de l’utilisateur et de l’orienter vers l’information qui lui convient. En guise d’exemple, sur un portail Extranet d’entreprise, le système de recommandation peut proposer à l’utilisateur actif un article spécialisé, une actualité ou bien un rapport technique. Sur un site d’e-commerce, le système de recommandation peut proposer à cet utilisateur un produit à acheter, un livre à lire ou un ﬁlm à regarder.
12

2. Problématique de recherche
Plusieurs techniques, issues notamment du domaine de l’apprentissage automatique et du data mining sont utilisées par les systèmes de recommandations. Le Filtrage Collaboratif (FC) [Goldberg et al., 1992] représente l’une des techniques de recommandation les plus populaires [Adomavicius et Tuzhilin, 2005]. Lorsqu’un utilisateur actif a besoin d’une recommandation, le système de FC retrouve les utilisateurs ayant des préférences et des goûts similaires à cet utilisateur (ces utilisateurs sont appelés “utilisateurs voisins”) et utilise leurs opinions pour générer une ou des recommandations susceptibles de l’intéresser.
Dans un processus de recommandation, l’identiﬁcation des appréciations des utilisateurs est souvent fondamentale, dans la mesure où elle permet de connaître l’utilisateur aﬁn de lui proposer des recommandations pertinentes. Les appréciations reﬂètent les avis positifs ou négatifs des utilisateurs vis-à-vis d’un certain nombre d’items. Leur identiﬁcation peut varier selon le type de l’approche utilisée. Par exemple dans un système de recommandation à base de critiques, elle se base sur l’implication directe de l’utilisateur pour l’expression des appréciations, appellée aussi “élicitation”. Certes, l’élicitation constitue une démarche fastidieuse pour cet utilisateur [McGinty et Smyth, 2005], puisqu’il est sollicité aﬁn d’exprimer explicitement l’intérêt qu’il porte à un certain nombre d’items. De ce fait, le recours à l’élicitation doit dépendre de l’enjeu de l’approche utilisée. En eﬀet, dans le cas où cette élicitation va à l’encontre des priorités de l’approche de recommandation, en provoquant par exemple la démotivation et l’abandon de l’utilisateur, le recours à d’autres méthodes d’identiﬁcation des appréciations s’avère indispensable. Dans cette optique, l’approche par l’analyse des usages peut se présenter comme une solution palliant ce problème. L’intérêt de cette approche est d’éviter l’élicitation en observant le comportement de l’utilisateur actif et en analysant ses actions lors de son interaction avec un système informatique tel qu’un portail Extranet. L’analyse des usages est ainsi susceptible de ressortir des indicateurs permettant de déduire les appréciations de cet utilisateur et d’identiﬁer éventuellement des communautés virtuelles.
Dans le cadre de cette thèse, nous nous intéressons à l’étude des systèmes de recommandation fondés sur le ﬁltrage collaboratif exploitant l’analyse des usages dans le contexte d’un Extranet d’entreprise. La section qui suit présente les questions de recherche que nous traitons à travers cette thèse.
2 Problématique de recherche
Comme nous l’avons indiqué précédemment, les systèmes de recommandation visent à personnaliser l’accès à l’information fournie par un système informatique. Pour atteindre cet objectif, les systèmes de recommandation peuvent notamment exploiter la technique du FC aﬁn de modéliser les utilisateurs et leur recommander des items pertinents en se
13

Introduction générale
basant sur les opinions de leurs voisins (cf. section 1). Diﬀérentes questions de recherche peuvent ressortir de cette déﬁnition :
1. En terme de modélisation des utilisateurs. Aﬁn de construire un modèle de l’utilisateur actif, le système a besoin notamment de collecter les données relatives aux appréciations de cet utilisateur. L’analyse de ces données permet ensuite de construire ce modèle utilisateur qui va être utilisé par le système pour recommander les items estimés pertinents pour cet utilisateur. De ce fait, l’exploitation des appréciations dans un tel processus de recommandation est primordiale. Or, souvent les données relatives aux appréciations ne sont pas sufﬁsamment disponibles dans le système voire pas disponibles du tout [Sarwar et al., 2000b]. Par conséquent, quand le système manque de données, la modélisation des utilisateurs devient diﬃcile et complexe. En eﬀet, dans le cadre du FC, le système serait incapable d’identiﬁer un nombre signiﬁcatif de voisins nécessaires au calcul de recommandations adaptées aux besoins de l’utilisateur actif. En outre, l’enjeu quant à l’exploitation des données d’appréciation est que, du point de vue utilisateur, les contraintes liées à leur collecte doivent être faibles. Il s’agit d’éviter l’intervention directe de l’utilisateur (l’élicitation) pour exprimer ses appréciations parce que d’une part, l’utilisateur dispose de peu de connaissances sur les items pour pouvoir les évaluer tous, et d’autre part, parce qu’il a tendance à être réticent quant à l’évaluation d’items [Burke, 2002].
2. En terme d’identiﬁcation de voisins pertinents. Les systèmes de recommandation à base de FC peuvent utiliser l’approche “kNN” (k Nearest Neighbors) [Resnick et al., 1994], qui repose sur la recherche des “plus proches voisins”, aﬁn de calculer les recommandations. L’identiﬁcation des plus proches voisins consiste à sélectionner les k voisins les plus similaires à l’utilisateur actif. Pour l’évaluation des similarités, cette approche prend en considération les appréciations relatives aux items communs à l’utilisateur actif et les autres utilisateurs. Néanmoins, un système basé sur une approche kNN peut être confronté à une situation où les utilisateurs n’ont pas d’items communs avec l’utilisateur actif (donc pas de voisins). Ainsi, faute de voisins, il sera incapable de proposer des recommandations à cet utilisateur. A cet eﬀet, l’utilisation d’autres techniques permettant de découvrir les similarités entre utilisateurs s’avère cruciale.
3. En terme de recommandation de la nouveauté. Lorsqu’un nouvel item est introduit dans le système, il ne peut pas être pris en compte dans le cadre de recommandations basées sur le FC, étant donné que les appréciations des utilisateurs vis-à-vis de cet item ne sont pas encore disponibles. Ce problème est connu sous le nom de “démarrage à froid” ou de “latence” [Schein et al., 2002]. Les systèmes de recommandation doivent ainsi faire face à ce problème dans le but de prendre en considération les nouveaux items au niveau des recommandations proposées à l’utilisateur.
14

3. Approche proposée
4. En terme de précision des recommandations [Herlocker et al., 1999]. Cette question est étroitement liée aux deux premières questions de recherche citées cidessus. En eﬀet, la précision des recommandations fournies par un système de recommandation dépend essentiellement de la disponibilité des données permettant de modéliser les utilisateurs et d’identiﬁer des voisins pertinents et ﬁables. En outre, la performance du système en terme de précision ou qualité de recommandation, émane également de la ﬁabilité de l’algorithme de modélisation utilisé. A cet eﬀet, pour atteindre une meilleure performance en terme de précision, les systèmes de recommandation ont pour enjeu de fournir à l’utilisateur actif des recommandations ﬁables correspondant à ses besoins, ce qui permettra de le ﬁdéliser le plus possible et d’améliorer l’usage du système informatique en question.
5. En terme de réduction du temps de calcul et de l’espace de recherche. La performance d’un système de recommandation est évaluée également au niveau du temps de calcul. En eﬀet, le temps de traitement requis pour le calcul des recommandations doit être réduit, notamment par la réduction de l’espace de recherche utilisé au niveau de la modélisation. Cet enjeu est lié également au passage à l’échelle, lorsque le système dispose d’un nombre considérable d’utilisateurs et d’items à traiter. D’autant plus, ce nombre évolue dynamiquement dans le temps, d’où l’intérêt de la réduction de l’espace de recherche dans le processus de recommandation.
6. En terme de robustesse. Le système de recommandation doit être robuste pour faire face aux données bruitées et garantir la ﬁabilité des recommandations.
La problématique scientiﬁque que nous traitons est liée à la modélisation des utilisateurs en se basant sur l’observation du comportement et sur l’analyse des usages dans le cadre d’un processus de recommandation exploitant le ﬁltrage collaboratif. Notre objectif est de remédier au problème de manque de données, de démarrage à froid et d’améliorer la précision des recommandations. En outre, il s’agit de garantir la robustesse du système de recommandation.
3 Approche proposée
3.1 Cadre industriel
Cette thèse s’inscrit dans le cadre du projet PERCAL réalisé en collaboration avec le Crédit Agricole S.A, en particulier avec le Pôle Innovation qui est chargé de l’étude, de l’expérimentation et de la déﬁnition des modalités de mise en œuvre des technologies au service des métiers bancaires au sein du Groupe Crédit Agricole. A partir des questions de recherche soulevées et en prenant en compte le contexte d’un
15

Introduction générale
Extranet d’entreprise, l’objectif de ce projet est de proposer de nouvelles techniques de recommandation permettant l’accès personnalisé à l’information, aﬁn d’optimiser l’usage des ressources de l’Extranet documentaire par les utilisateurs du Groupe Crédit Agricole. En eﬀet, les items et les utilisateurs de cet Extranet étant très nombreux et variés (des milliers d’utilisateurs et des dizaines de milliers d’items), l’enjeu est de pouvoir mettre en place des outils de recommandation collaboratifs, s’appuyant sur l’analyse des usages, capables de mettre à la disposition des utilisateurs des informations pertinentes adaptées à leurs besoins.
3.2 Approche
L’objectif de cette thèse est d’utiliser l’approche par analyse des usages aﬁn de construire des modèles utilisateurs à partir de l’observation de leur comportement navigationnel. En eﬀet, notre hypothèse est que l’analyse des traces d’usage, qui représentent l’ensemble des actions et des événements résultant du processus d’interaction d’un utilisateur avec le système, peut extraire un certain nombre d’indicateurs reﬂétant les appréciations de cet utilisateur. Analyser les usages va permettre ainsi de cerner le comportement de l’utilisateur, de connaître mieux ses besoins, ce qui permettra d’améliorer potentiellement les performances et la qualité des recommandations calculées par le système de recommandation. En outre, étant donné que la quantité de traces et d’observations à traiter par le système de recommandation est importante, notre objectif consiste également à proposer une approche permettant de réduire l’espace de recherche lors de l’apprentissage des modèles utilisateurs et pour la génération des recommandations. De plus, cette approche de recommandation doit permettre de faire face au problème de manque de données. A ce niveau, notre hypothèse est que les techniques issues du domaine de l’analyse des réseaux sociaux peuvent être des solutions prometteuses face à ce problème de manque de données grâce à la découverte de nouvelles relations entre utilisateurs.
3.3 Contributions
Les contributions de cette thèse comprennent :
– Un modèle de recommandation basé sur le ﬁltrage collaboratif comportemental [Esslimani et al., 2008b] [Esslimani et al., 2008a]. Ce modèle exploite les observations relatives au comportement de navigation des utilisateurs pour les modéliser et se base sur le FC pour produire des recommandations. Ce modèle vise à améliorer la qualité des prédictions et à garantir la robustesse du système de recommandation.
– Un modèle de recommandation combinant le ﬁltrage collaboratif comportemental
16

3. Approche proposée
avec une approche de clustering calculant les clusters selon les similarités de voisins entre utilisateurs [Esslimani et al., 2009a]. Ce modèle a pour objectif de réduire l’espace de recherche des voisins et d’améliorer le temps de calcul des recommandations ainsi que leur précision.
– Un modèle de recommandation exploitant les méthodes de prédiction de lien dans un réseau comportemental [Esslimani et al., 2009b] [Esslimani et al., 2009c] [Esslimani et al., 2010a]. Dans l’objectif d’améliorer l’identiﬁcation des voisins dans le cadre de ce réseau, ce modèle utilise les associations transitives et les méthodes de prédiction de lien aﬁn d’établir de nouvelles relations entre utilisateurs. Ce modèle a pour enjeu de faire face au problème de manque de données et d’améliorer la précision des recommandations.
– Un modèle de recommandation basé sur les leaders comportementaux pour la recommandation de la nouveauté [Esslimani et al., 2010c] [Esslimani et al., 2010b]. Ce modèle vise à détecter des leaders dans l’objectif de remédier au problème de démarrage à froid dans le cadre d’un réseau comportemental. Ces leaders ont la particularité d’être au “centre” de ce réseau et disposent d’une potentialité importante de prédiction des appréciations des autres utilisateurs concernant les nouveaux items introduits dans le système.
3.4 Evaluation
Pour la validation des approches proposées dans cette thèse, nous avons évalué les diﬀérents modèles au travers d’expérimentations sur un corpus d’usage réel qui contient les traces d’usage extraites de l’Extranet du Crédit Agricole. De plus, nous avons utilisé le corpus Movielens (corpus de référence dans le domaine des systèmes de recommandation) du laboratoire de recherche Grouplens3 aﬁn de confronter certains de nos résultats avec ceux de la communauté scientiﬁque. Ces approches ont été évaluées en termes de précision, de temps de calcul et de robustesse et comparées au FC standard [Herlocker et al., 1999] utilisé souvent dans les travaux de recherche comme banc d’essai (“benchmark”).
Les résultats de ces expérimentations ont été publiés dans : – des revues internationales : Journal of Digital Information Management (JDIM)
[Esslimani et al., 2008a], the Social Network Analysis and Mining Journal (SNAMJ) [Esslimani et al., 2010a] ; – des conférences internationales : WEBIST 2009 [Esslimani et al., 2009a], ASONAM 2009 [Esslimani et al., 2009b], EC-WEB 2010 [Esslimani et al., 2010c], ASONAM 2010 [Esslimani et al., 2010b] ; – un workshop international : RSPR 2008 [Esslimani et al., 2008b] ;
3http ://www.grouplens.org
17

Introduction générale
– un colloque francophone : ISKO 2009 [Esslimani et al., 2009c].
4 Structure du document
Dans ce manuscrit, nous présenterons dans la première partie le contexte général en décrivant l’origine des systèmes de recommandation ainsi que les données exploitables dans le cadre des recommandations. De plus, il sera question de décrire les principales techniques de recommandation en discutant leurs avantages et leurs inconvénients tout en soulignant les verrous scientiﬁques que nous traitons dans le cadre de cette thèse (cf. chapitre 1, partie 1). En outre, dans le chapitre suivant (cf. chapitre 2, partie 1), nous introduirons le schéma générique de la recommandation, tel que nous le percevons. Ensuite, il s’agira de décrire le contexte applicatif lié à nos travaux de recherche ainsi que la méthodologie expérimentale (corpus et mesures d’évaluation) que nous avons utilisée en vue d’évaluer la performance de nos approches.
Les parties suivantes sont consacrées à la description de nos contributions. La deuxième partie comprend la présentation de l’approche collaborative comportementale de recommandation. Ainsi, nous décrirons dans un premier temps (cf. chapitre 1, partie 2) notre modèle fondé sur le ﬁltrage collaboratif comportemental et les résultats de son évaluation. Ensuite, nous montrerons l’apport d’une approche de clustering exploitant les voisinages dans le cadre du ﬁltrage collaboratif comportemental, notamment en terme de qualité de recommandation (cf. chapitre 2, partie 2).
La troisième partie est dédiée à la description de l’approche sociale de recommandation. Il s’agit de discuter d’abord l’intérêt de faire appel aux méthodes de prédiction de lien dans le cadre d’un réseau comportemental, aﬁn de pallier le problème de manque de données. Dans la même perspective, il est question d’introduire la détection de leaders dans le cadre de ce réseau, pour la recommandation de la nouveauté. Cette partie intègre également les expérimentations qui ont été réalisées pour valider nos modèles et mettre en évidence leur performance, comparés à des modèles de l’état de l’art.
La dernière partie de la thèse comprend la conclusion et les perspectives de recherche. Cette partie résume les principales contributions de la thèse et présente quelques orientations futures de nos travaux de recherche dans le cadre des systèmes de recommandation.
————————————–
18

Première partie Contexte
19

Chapitre 1
Etat de l’art
Ce chapitre a pour objectif de faire un tour d’horizon, non exhaustif, des systèmes de recommandation liés au domaine de la recherche d’information, en évoquant leur origine et leurs applications et en décrivant les données qu’ils exploitent. De plus, il s’agit de présenter les principales techniques de recommandation en soulignant leurs apports et leurs limites et de discuter les principaux verrous scientiﬁques auxquels nous nous intéressons dans le cadre de cette thèse.
1.1 Origines et applications
Les systèmes de recommandation ont été utilisés aﬁn de faire face au problème de surcharge et de profusion d’informations disponibles notamment à travers le Web ou les e-services. Les systèmes de recommandation visent à proposer à un utilisateur actif une ou des recommandations d’items susceptibles de l’intéresser. Ces recommandations peuvent concerner un article à lire, un livre à commander, un ﬁlm à regarder, un restaurant à choisir, etc.
“Tapestry” [Goldberg et al., 1992] représente l’un des premiers systèmes de recommandation. Il a été développé en 1992 par le centre de recherche de “Xerox” aux Etats Unis. Il s’agit d’un système de recommandation intégré à une application de mail électronique, permettant de recommander des listes de diﬀusion aux utilisateurs. Tapestry est fondé sur le Filtrage Collaboratif (FC) exploitant les annotations (les tags) des utilisateurs attribués aux listes de diﬀusion. L’analyse de ces annotations par le système de FC permet de déterminer et de proposer les listes de diﬀusion qui sont pertinentes pour chaque utilisateur. Par la suite, d’autres systèmes de recommandation ont vu le jour en 1994 et en 1995, tels que le système de recommandation d’articles d’actualités et de ﬁlms développé par “GroupLens” [Resnick et al., 1994] et le système de recommandation de musique “Ringo”
21

Chapitre 1. Etat de l’art
proposé par [Shardanand et Maes, 1995]. Ces deux systèmes sont également basés sur le FC.
Quelques années plus tard, avec l’essor de l’Internet et des applications Web, il y a eu un engouement pour les systèmes de recommandation qui se sont développés dans diﬀérents domaines d’applications. Nous pouvons en citer :
– les systèmes de recommandation de ﬁlms, tels que : Movielens4 [Herlocker et al., 1999] et Eachmovie [Breese et al., 1998],
– les systèmes de recommandation de livres (Bookcrossing5 [Ziegler et al., 2005]), – les systèmes de recommandation de musique (LastFM6 [Jäschke et al., 2007]), – les systèmes de recommandation d’articles d’actualités [Billsus et al., 2002], – les systèmes de recommandation de blagues (Jester7 [Goldberg et al., 2001]), – les systèmes de recommandations introduits sur des sites e-commerce (Amazon8
[Linden et al., 2003]), – les systèmes de recommandation de restaurants [Burke, 2002], – les systèmes de recommandation intégrés aux Extranets documentaires (l’Extranet
documentaire du Crédit Agricole [Bertrand-Pierron, 2006]), – les systèmes de recommandations intégrés aux moteurs de recherche (le moteur de
recherche d’AOL9 [Pass et al., 2006]), – les systèmes de recommandations implémentés sur des sites de recrutement (Job-
Finder [Rafter et al., 2000]), – les systèmes de recommandations de citations bibliographiques [McNee et al., 2002]
[Cosley et al., 2002].
Pour tous les systèmes de recommandation développés jusqu’à nos jours, la collecte de données relatives aux utilisateurs et/ou aux items, représente une phase clé dans le processus de personnalisation. La section qui suit décrit en détails la typologie de données exploitables par les systèmes de recommandation ainsi que les enjeux liés à leur collecte.
1.2 Données
Dans le cadre des systèmes de recommandation exploitant notamment le FC, la détermination des appréciations est requise aﬁn de pouvoir modéliser l’utilisateur. Cette démarche d’identiﬁcation d’appréciations repose soit sur des approches dites “réactives” ou soit dites “proactives” [Anand et Mobasher, 2005]. Dans le cas d’une approche réactive, l’utilisateur réagit suite à la demande du système aﬁn d’exprimer ses besoins, tandis que
4http ://www.grouplens.org 5http ://www.informatik.uni-freiburg.de/∼cziegler/BX 6http ://www.lastfm.fr 7http ://eigentaste.berkeley.edu 8http ://www.amazon.com 9http ://www.gregsadetsky.com/aol-data
22

1.2. Données
dans une approche proactive, l’utilisateur est moins sollicité, c’est le système qui anticipe ses besoins.
Dans les approches réactives, la personnalisation est considérée comme un processus conversationnel fondé sur des interactions explicites avec l’utilisateur dans l’objectif d’afﬁner ses appréciations. Ce processus est réalisé via un ensemble de questions nécessitant un retour de l’utilisateur qui doit exprimer explicitement ses appréciations concernant des critères ou des items.
Les systèmes de recommandation de type réactif, utilisent pour la plupart, des techniques à base de critiques, issues du raisonnement à partir des cas [Smyth, 2007]. L’élicitation du retour de l’utilisateur y est un composant principal permettant d’adapter précisément les recommandations aux besoins exprimés par cet utilisateur. Par exemple, “Entree” [Burke, 2000] est un système de recommandation de restaurants réactif qui utilise des requêtes, à partir desquelles l’utilisateur spéciﬁe le type de cuisine, le prix, le style de restaurant, la localité, l’atmosphère, etc. L’utilisateur peut ainsi soit accepter les recommandations proposées ou bien les critiquer à travers des critères spéciﬁques (moins cher, plus calme, etc.). D’autres exemples de système à base de critique sont proposés également par [Aha et al., 2000], [Shimazu, 2001] et [McGinty et Smyth, 2005].
L’avantage des systèmes à base de critique est qu’ils sont faciles à appliquer et ne requièrent pas une connaissance approfondie du domaine de la part de l’utilisateur. Toutefois, les critiques demeurent une arme à double tranchant. En eﬀet, si elles représentent des informations explicites sur les appréciations, elles nécessitent un eﬀort et un investissement de l’utilisateur quant à l’expression de ses avis et de ses retours [McGinty et Smyth, 2005].
Les approches proactives privilégient plutôt la déduction des appréciations pour fournir des recommandations. Les systèmes de recommandation proactifs ne nécessitent pas de retour de l’utilisateur (suite aux recommandations) aﬁn d’orienter le processus de recommandation. Ces systèmes reposent sur l’observation des interactions de l’utilisateur aﬁn d’estimer ses goûts. Cette observation peut être directe ou indirecte. Quand elle est directe, elle se base sur des données exprimées explicitement par l’utilisateur en attribuant par exemple :
1. des notes aux items consultés indiquant le degré d’appréciation d’un item par cet utilisateur. Les notes sont souvent numériques et limitées par une échelle de valeurs. Une note (numérique) élevée signiﬁe que l’utilisateur accorde un grand intérêt à l’item et qu’il correspond bien à ses goûts. Cependant, une note faible signiﬁe que l’utilisateur ne s’intéresse pas à l’item. Dans d’autres cas, les notes peuvent être exprimées sous une forme binaire telle que “Aime” ou “Aime pas”. La Figure 1.1 présente un exemple tiré du site de vente en ligne “Amazon” qui oﬀre la possibilité de noter des items (par exemple le livre “Network models of the diﬀusion
23

Chapitre 1. Etat de l’art of innovation”) sur une échelle de [1 − 5]. Fig. 1.1 – Exemple de notes : Site d’Amazon

D’une manière générale, l’échelle de note doit reﬂéter les appréciations d’un utilisateur vis-à-vis d’items. Les échelles de note les plus communes sont présentées dans le tableau 1.1 [Schafer et al., 2007]. Le choix d’une échelle de note très large telle que [1 − 100] peut augmenter l’incertitude sur la valeur de note attribuée. Ainsi, il est diﬃcile de déterminer par exemple la diﬀérence entre une note de 55 et de 60 sur l’échelle [1 − 100], l’écart étant diﬃcilement interprétable par le système et la nuance diﬃcile à évaluer pour un utilisateur.

Tab. 1.1 – Les échelles de notes les plus communes

Echelle de note

Description

Unaire

“Aime” ou “Je ne sais pas”

Binaire

“Aime” ou “Aime pas”

Entier

[1 − 5], [1 − 7] ou [1 − 10]

L’utilisation des notes permet de faciliter l’apprentissage des appréciations, vu que les notes sont faciles à traiter par le système de recommandation. Néanmoins, dans

24

1.2. Données certains cas, les utilisateurs n’ayant pas les mêmes façons de noter, les notes peuvent ne pas être ﬁables. En eﬀet, certains utilisateurs attribuent des notes élevées et d’autres non. Par exemple, sur une échelle [1 − 5], une note qui vaut 3 peut être négative pour un utilisateur et plutôt neutre pour un autre. 2. des commentaires, des mots-clés ou des tags sur des items. La ﬁgure 1.2 montre un exemple d’ajout de tags sur le site de recommandation de musique “LastFM”. Ces tags sont exprimés dans un langage libre propre à chaque utilisateur, exprimant le mieux son avis. Toutefois, tout comme les systèmes à base de critiques, l’expression des appréciations via des commentaires ou tags nécessite une motivation de la part de l’utilisateur, puisqu’elle requiert un eﬀort “cognitif” plus important, par rapport à l’attribution des notes. De plus, le traitement de ces commentaires (exprimés en langage libre) par le système de recommandation demeure assez complexe. Le système doit en eﬀet procéder à une analyse du contenu et à une interprétation des commentaires aﬁn d’estimer les appréciations.
Fig. 1.2 – Exemple de tags sur le site LastFM
3. des attributs démographiques concernant l’utilisateur, tels que : l’âge, le sexe, la catégorie socio-professionnelle, le niveau d’étude, la localité géographique, le statut personnel, etc. Certes, ces attributs ne fournissent pas d’informations sur les appréciations, mais ils permettent notamment d’aﬃner le proﬁl utilisateur aﬁn d’y adapter les recommandations. Ces attributs peuvent être soit renseignés par l’utilisateur lui-même [Krulwich, 1997], ou bien extraits par exemple à partir des pages Web personnelles [Pazzani, 1999]. Par ailleurs, les proﬁls démographiques peuvent 25

Chapitre 1. Etat de l’art
être utilisés pour calculer les recommandations lorsqu’il s’agit de nouveaux utilisateurs [Vozalis et Margaritis, 2006] [Nguyen et al., 2006]. Ainsi, le système de recommandation peut considérer par exemple que les utilisateurs appartenant à des classes démographiques homogènes, ont des goûts similaires et peut exploiter ces similarités pour la génération de recommandations.
Les appréciations explicitement exprimées par l’utilisateur s’inscrivent dans le cadre d’un processus d’élicitation. Malgré son intérêt, l’élicitation présente certains risques [Rashid et al., 2008]. Elle peut être en eﬀet perçue comme un processus long et fastidieux [Burke, 2002], qui requiert un eﬀort de la part de l’utilisateur, ce qui peut engendrer un abandon du processus d’élicitation. L’enjeu quant à l’acquisition de toutes ces données explicites décrites ci-dessus, est de trouver le compromis entre collecte de données relatives aux appréciations et réduction de l’élicitation.
Quand l’observation des interactions de l’utilisateur est indirecte, elle repose sur des données ou des appréciations “implicites” déduites à partir des actions réalisées par cet utilisateur. Nous appellerons ces actions “les traces d’usage”. Ces traces peuvent inclure [Claypool et al., 2001] :
1. Des indicateurs décrivant la manipulation tels que : des “copier/coller” d’un texte à partir d’une page, la recherche d’un texte dans une page, l’ajout ou la suppression d’un item du panier ou la commande d’un item (dans le cadre des applications ecommerce), la sauvegarde ou l’impression d’une page, l’ajout d’une page aux favoris, l’envoi d’une page à un ami, etc.
2. Des indicateurs de navigation tels que : la fréquence et la durée de consultation, le nombre de clics et de survols de souris sur une page et sur des liens, le “scrolling”, etc.
3. Des indicateurs externes marquant l’intérêt. Ces indicateurs décrivent les conditions physiques et émotionnelles qui caractérisent un utilisateur lors de son interaction. Ils peuvent être mesurés par exemple par l’oculométrie10 (“eye-tracking”).
L’enjeu quant à la collecte des traces d’usage est de déﬁnir des heuristiques aﬁn de déterminer quelles actions ou quelles traces reﬂètent une appréciation positive ou bien négative. Par exemple, l’action de suppression d’un item d’un panier (sur un site d’ecommerce) peut être interprétée comme un avis négatif. De même, le critère de temps de consultation peut être aussi considéré. Or, le problème qui se pose est de déterminer s’il s’agit réellement d’une consultation de l’item. Il est possible en eﬀet que l’item soit actif pendant une certaine durée, alors que l’utilisateur ne le consulte pas réellement.
Par ailleurs, la démarche de collecte des données explicites ou implicites (les traces
10Technique de suivi et d’enregistrement du mouvement oculaire sur un site Web par exemple, pour détecter les zones du site les plus visées par l’utilisateur
26

1.3. Techniques de recommandation
d’usage) dans le cadre d’un système de recommandation doit veiller à la préservation de la vie privée et des données personnelles des utilisateurs. En outre, quel que soit le type de données collectées par le système, cette démarche doit prendre en considération la gestion de l’accroissement du volume de données dans le temps.
Dans cette section, nous avons présenté les diﬀérents types de données exploitables par les systèmes de recommandation, en discutant leurs avantages et leurs inconvénients. Nous pouvons déduire à partir de ces discussions que la mise en place d’un système de recommandation de type proactif ou réactif, exploitant des observations directes ou indirectes, requiert une réﬂexion approfondie a priori sur la collecte des données, avec ou sans la sollicitation directe de l’utilisateur.
Aprés avoir présenté la typologie des données exploitées en entrée par les systèmes de recommandation, dans la section suivante il est question de décrire les principales techniques de recommandation.
1.3 Techniques de recommandation
Il existe une large variété de techniques de recommandation. A travers les travaux de recherche, diﬀérentes tentatives de classiﬁcation des approches ou des techniques ont été réalisées. La classiﬁcation de ces approches dépend notamment du type de données exploitées et de la méthode d’apprentissage utilisée par le système de recommandation. Dans cette section, en distinguant la technique basée sur le contenu du FC basé sur la mémoire ou sur un modèle [Anand et Mobasher, 2005] [Su et Khoshgoftaar, 2009], nous présentons les principales techniques de recommandation avec leurs apports et leurs limites.
1.3.1 Technique basée sur le contenu
La technique de recommandation basée sur le contenu repose sur l’hypothèse que des items ayant des contenus similaires seront appréciés pareillement [Schafer et al., 2007]. Pour la proposition de recommandations aux utilisateurs, cette technique est fondée sur l’analyse des similarités de contenu entre les items précédemment consultés par les utilisateurs et ceux qui n’ont pas été encore consultés [Burke, 2002]. Ainsi, aﬁn de recommander par exemple des ﬁlms à un utilisateur, le système analyse les corrélations entre ces ﬁlms et les ﬁlms consultés antérieurement par cet utilisateur. Ces corrélations sont évaluées en considérant des attributs comme le titre et le genre. De ce fait, parmi ces ﬁlms, ceux qui seront recommandés à l’utilisateur, sont les plus similaires (en terme d’attribut) aux ﬁlms consultés par cet utilisateur [Adomavicius et Tuzhilin, 2005].
27

Chapitre 1. Etat de l’art
Parmi les premiers systèmes de recommandation basés sur le contenu, nous pouvons citer : NewsWeeder [Lang, 1995], Letizia [Lieberman, 1995] et InfoFinder [Krulwich et Burkey, 1996], etc. [Pazzani et Billsus, 2007] présente une synthèse de ces systèmes de recommandation en s’intéressant en particulier à la représentation du contenu et aux algorithmes utilisés pour la construction des proﬁls utilisateurs.
La technique de recommandation basée sur le contenu peut être appliquée à la recommandation de pages Web, de ﬁlms, d’articles actualités, de restaurants, etc. Si nous prenons l’exemple d’un système de recommandation d’articles scientiﬁques basé sur le contenu, lorsqu’un utilisateur a tendance à consulter souvent des articles portant sur le domaine de la génétique, le système lui proposera des recommandations liées à la génétique. En eﬀet, ces articles disposent de mots-clés communs tels que : “ADN”, “gène” ou “protéine”. Il est à signaler que ces mots-clés sont généralement soit extraits sur la base d’une indexation automatique, soit attribués manuellement. Pour ce qui est des systèmes de recommandation de ﬁlms ou de restaurants, le contenu est plutôt structuré et réprésenté par des métadonnées déﬁnies au préalable et valables pour tous les items [Pazzani et Billsus, 2007].
Dans le cadre de la technique basée sur le contenu, la mesure TF-IDF (“Term FrequencyInverse Document Frequency”) [Salton, 1989] représente la mesure la plus populaire pour l’analyse du contenu. Il s’agit d’une mesure statistique qui permet d’évaluer l’importance d’un mot dans un document ou dans un item faisant partie d’une collection ou d’un corpus [Pazzani et Billsus, 2007]. Le principe de cette mesure est que les mots-clés paraissant dans beaucoup d’items ne permettent pas de distinguer un item pertinent d’un autre qui ne l’est pas. Or, les motsclés qui sont rares et communs à quelques items déﬁnissent plus la similarité de contenu ainsi que la pertinence d’un item par rapport à un autre.
La technique basée sur le contenu a pour avantage de pouvoir générer des recommandations en dépit d’une situation de démarrage à froid. Le démarrage à froid se traduit notamment par l’introduction d’un nouvel item au système de recommandation. Lorsque ce système exploite le ﬁltrage collaboratif, il ne sera pas capable d’incorporer ce nouvel item aux recommandations, puisque les notes relatives à cet item ne sont pas encore disponibles. Ainsi, grâce à l’analyse de contenu, cet item peut être intégré aux recommandations proposées à un utilisateur actif. Néanmoins, la technique basée sur le contenu présente quelques limites, notamment :
– Le manque de diversité et la surspécialisation des recommandations. En eﬀet, les items recommandés sont toujours similaires et identiques (en terme de contenu) aux items précédemment consultés par l’utilisateur. Les autres items, ayant un contenu non similaire, ne sont jamais intégrés aux listes de recommandation, alors qu’ils pourraient intéresser l’utilisateur.
– La représentation des items est toujours limitée aux descriptions ou aux attributs
28

1.3. Techniques de recommandation
qui leur sont associés. Par conséquent, aﬁn d’avoir un ensemble suﬃsant d’attributs, il est nécessaire soit de prétraiter le contenu pour permettre une extraction automatique d’attributs, soit d’attribuer les descriptions manuellement [Shardanand et Maes, 1995]. Dans les deux cas, l’extraction d’attributs demeure une opération fastidieuse surtout lorsqu’il s’agit d’items multimédia tels que : les images, les documents audio et vidéo, etc. De ce fait, certains aspects pertinents du contenu peuvent être négligés, ce qui peut avoir un impact sur la qualité des recommandations.
Dans les sections suivantes, nous nous intéressons aux approches qui font abstraction du contenu. Ces approches, basées sur le FC, exploitent notamment les appréciations (explicites et/ou implicites) ainsi que les traces d’usage des utilisateurs dans le cadre des recommandations. Ces approches reposent en eﬀet sur l’hypothèse que les utilisateurs qui partageaient les mêmes goûts dans le passé (en attribuant des notes similaires, en achetant les mêmes articles ou en visitant les mêmes items), vont très probablement avoir les mêmes goûts dans le futur [Goldberg et al., 2001].
1.3.2 Méthodes basées sur la mémoire
L’approche basée sur la mémoire exploite les appréciations des utilisateurs sur les items (sous forme de notes par exemple), aﬁn de générer les prédictions [Sarwar et al., 2001]. Cette approche applique principalement des techniques statistiques dans le but d’identiﬁer des utilisateurs voisins ayant, sur un même ensemble d’items, des appréciations similaires à celles de l’utilisateur actif. Une fois les voisins identiﬁés, l’approche basée sur la mémoire utilise diﬀérents algorithmes aﬁn de combiner les appréciations des voisins et générer des recommandations à l’utilisateur actif [McLaughlin et Herlocker, 2004].
Dans ce contexte, la technique la plus utilisée et la plus populaire est le Filtrage Collaboratif (FC) basé sur la mémoire [Goldberg et al., 1992]. Le FC basé sur la mémoire recherche les “k plus proches voisins” (k Nearest Neighbors “kNN”) [Resnick et al., 1994], i.e. les k voisins les plus similaires à l’utilisateur actif, dans le but de générer des recommandations ﬁables. Ces voisins sont identiﬁés à partir d’une évaluation de la similarité des appréciations sur les items communs à l’utilisateur actif et les autres utilisateurs.
Dans un système de FC basé sur la mémoire, tel que décrit dans la ﬁgure 1.3, les données sont représentées sous forme d’une matrice “Utilisateur x Item” (dont un exemple est présenté dans le tableau 1.2), où les lignes représentent les utilisateurs U = {u1, ...um} et les colonnes constituent les items I = {i1, ...ij}. Les utilisateurs fournissent leurs opinions concernant les items sous forme de notes v. Pour un utilisateur actif ua (par exemple Jean) n’ayant pas exprimé son avis concernant un item ik (le ﬁlm “Les visiteurs”), le système recherche les utilisateurs voisins les plus proches notés Ua (parmi Rose, Ryan et Hélène ayant noté le ﬁlm “Les visiteurs” et qui ont déjà co-noté le ﬁlm “Pulp Fiction” avec Jean) et utilisent leurs opinions pour prédire la note manquante v(ua, ik) (v(Jean , Les visiteurs)).
29

Chapitre 1. Etat de l’art
Ainsi, nous pouvons distinguer deux phases essentielles en FC basé sur la mémoire : la phase d’identiﬁcation du voisinage et la phase de calcul des prédictions. Les sous-sections qui suivent décrivent chacune de ces deux phases.
Fig. 1.3 – Matrice “Utilisateur x Item”

Tab. 1.2 – Exemple de matrice “Utilisateur x Item”

Pulp Fiction Star Gate Les visiteurs Scream

Jean

1

5

?

3

Rose

4

2

4

?

Eric

3

?

?

5

Ryan

4

?

5

?

Hélène

2

?

4

1

Identiﬁcation du voisinage
Plusieurs mesures ont été exploitées dans le cadre du FC basé sur la mémoire dans le but d’évaluer les similarités d’appréciations entre utilisateurs et identiﬁer les utilisateurs voisins (les plus proches). Parmi ces mesures nous pouvons citer : le coeﬃcient de corrélation de Pearson [Herlocker et al., 1999], la mesure basée sur le cosinus [Sarwar et al., 2000b], la corrélation de Spearman [Resnick et al., 1994], “Mean squared diﬀerence” (qui représente une mesure de dissimilarité) [Shardanand et Maes, 1995], etc. Les mesures les plus populaires sont le coeﬃcient de corrélation de Pearson et la mesure basée sur le cosinus. Cette popularité est liée à leur contribution à la performance des systèmes de recommandation [Anand et Mobasher, 2005]. Nous décrirons ces deux mesures ci-dessous. Notons que CorrP (ua, ub) et Cos(ua, ub) désignent les similarités calculées respectivement avec le coeﬃcient de corrélation de Pearson et la mesure basée sur le cosinus, entre deux utilisateurs ua et ub. Ia et Ib représentent respectivement l’ensemble des items notés par ua et ub. v(ua) représente la moyenne de notes de ua et v(ua, i) désigne la note de ua sur l’item i. Ic désigne les items co-notés (notés en commun) entre l’utilisateur actif ua et l’utilisateur ub.
30

1.3. Techniques de recommandation

– Le coeﬃcient de corrélation de Pearson : cette mesure est présentée dans l’équation
(1.1). Lorsque CorrP (ua, ub) vaut 1, cela signiﬁe que les utilisateurs ua et ub sont fortement corrélés. Or, si CorrP (ua, ub) vaut −1, cela implique que ua et ub ont des appréciations totalement opposées. Quand cette corrélation vaut 0, aucune relation
n’existe entre les deux utilisateurs.

CorrP (ua, ub) =

i∈Ic(v(ua, i) − v(ua))(v(ub, i) − v(ub)) i∈Ic(v(ua, i) − v(ua))2 i∈Ic(v(ub, i) − v(ub))2

(1.1)

– La mesure basée sur le cosinus : cette mesure est très fréquemment utilisée dans le domaine de la recherche d’information. Dans ce contexte, elle consiste à évaluer la similarité entre deux documents représentés par des vecteurs de fréquences de mots, en calculant le cosinus de l’angle formé par ces deux vecteurs [Salton et McGill, 1983]. En FC, cette mesure peut être adaptée pour l’évaluation de la similarité entre deux utilisateurs ua et ub en calculant le cosinus de l’angle entre les vecteurs correspondant à ces deux utilisateurs sur la base de l’équation (1.2) [Breese et al., 1998], en prenant en considération les items co-notés Ic. La valeur calculée par la mesure cosinus est comprise entre 0 et 1.

Cos(ua, ub) =

i∈Ic v(ua, i) ∗ v(ub, i) i′∈Ia v(ua, i′)2 i′∈Ib v(ub, i′)2

(1.2)

L’inconvénient des deux mesures Pearson et cosinus, est que le calcul des similarités

devient non ﬁable voire impossible, lorsque le système dispose de peu d’items co-

notés entre utilisateurs. Aﬁn de pallier ce problème, certaines extensions ont été

proposées notamment par [Breese et al., 1998], telle que “La note par défaut ”

consistant à attribuer une valeur par défaut à une note manquante. Mais l’enjeu

à ce niveau est de savoir quelle valeur par défaut choisir (appréciation positive,

négative ou bien neutre) et d’évaluer son impact sur le calcul des similarités.

Par ailleurs, en vue d’améliorer la performance des systèmes de recommandation

exploitant le FC basé sur la mémoire, [Breese et al., 1998] ont proposé d’utiliser :

– “L’ampliﬁcation de cas” permettant de transformer les similarités en ampliﬁant

les valeurs proches de 1 et en pénalisant celles qui sont proches de 0, dans le

but d’attribuer un poids important aux voisins fortement similaires à l’utilisateur

actif.

– “La fréquence inverse utilisateur” inspirée de la méthode IDF (“Inverse Document

Frequency”), présentée dans la section 1.3.1. L’hypothèse est que les items appré-

ciés par un grand nombre d’utilisateurs sont moins pertinents pour le calcul des

similarités comparés à ceux qui sont appréciés par un nombre restreint d’utilisa-

teurs. Ainsi, chaque note est transformée en la multipliant par la fréquence inverse

utilisateur qui nik le nombre

de’suttéilqisuaivteaulernstaeyàanlotgnnonitké,

n étant ik.

le

nombre

total

des

utilisateurs

et

31

Chapitre 1. Etat de l’art
Calcul des prédictions
Cette deuxième phase, tout comme la première, est d’une importance cruciale dans la mesure où l’objectif de tout système de FC est le calcul des prédictions pour générer des recommandations pertinentes à un utilisateur actif. La méthode la plus utilisée pour le calcul de ces prédictions est la “somme pondérée” [Herlocker et al., 1999]. Suivant l’équation (1.3), cette méthode considère les plus proches voisins Ua (corrélés avec l’utilisateur actif) ayant déjà noté l’item ik, pour calculer la prédiction de la note de ua sur ik notée P red(ua, ik). Sim(ua, ub) désigne la valeur de similarité entre ua et un voisin ub (ub ∈ Ua) et peut être instanciée par les similarités calculées à partir du coeﬃcient de Pearson (CorrP (ua, ub)) ou bien à partir de la mesure basée sur le cosinus (Cos(ua, ub)).

P red(ua, ik) = v(ua) +

ub∈Ua Sim(ua, ub) ∗ (v(ub, ik) − v(ub)) ub∈Ua Sim(ua, ub)

(1.3)

Le choix des plus proches voisins Ua est déterminant dans la mesure où la performance du système dépend de la qualité des voisins impliqués lors de la génération des prédictions. Diﬀérentes stratégies peuvent être prises en compte pour la sélection de ces voisins :
– La détermination d’un seuil de similarité [Breese et al., 1998] [Shardanand et Maes, 1995] : il s’agit de sélectionner les plus proches voisins qui sont corrélés avec l’utilisateur actif à partir d’un seuil de similarité préétabli.
– La sélection de la taille du meilleur voisinage [Herlocker et al., 1999] : cette stratégie permet de sélectionner les voisins les plus proches (20, 50 ou 100 meilleurs voisins par exemple).
– La détermination d’un seuil pour les items co-notés [Viappiani et al., 2006] : cette stratégie consiste à ﬁltrer les plus proches voisins en fonction du nombre d’items co-notés avec l’utilisateur actif.
Au niveau des trois stratégies, les seuils choisis ne doivent pas avoir des valeurs extrêmes (ni trop élevées, ni trop faibles). En eﬀet, par exemple, si la valeur du seuil de similarité est trop faible, cela peut engendrer de mauvaises prédictions quand l’utilisateur actif est corrélé avec de nombreux utilisateurs. De la même façon, si le seuil est très élevé, cela peut aﬀecter la qualité des prédictions et la couverture (la capacité du système à générer des prédictions), quand l’utilisateur actif est faiblement corrélé avec les autres utilisateurs. En eﬀet, dans ce cas, le système ne dispose que de peu de voisins pour pouvoir générer les prédictions.
Une fois les prédictions calculées, le système de FC recommande à l’utilisateur actif les items ayant les valeurs de prédiction les plus élevées.
32

1.3. Techniques de recommandation
Par ailleurs, l’approche basée sur la mémoire peut être centrée sur l’item. Cette approche a été proposée par [Sarwar et al., 2001]. Le principe de cette approche consiste à analyser la matrice “Utilisateur x Item” pour identiﬁer des relations entre les items et utiliser ces relations aﬁn de calculer les prédictions. L’hypothèse est que l’utilisateur serait intéressé par des items, similaires aux items qu’il a appréciés auparavant (i.e. similaires en termes de notes attribuées par cet utilisateur). Pour [Sarwar et al., 2001], dans ce processus, il n’est pas nécessaire d’identiﬁer les voisinages pour les utilisateurs. Par conséquent, un tel système a tendance à calculer plus rapidement les recommandations et permettre ainsi le passage à l’échelle. Les auteurs supposent en eﬀet que le nombre d’items est généralement moins important que le nombre d’utilisateurs. Cette hypothèse peut être valable pour les applications en e-commerce, où le nombre potentiel des utilisateurs augmente régulièrement, comparé au nombre de produits proposés. Or, dans d’autres contextes, comme dans un portail Extranet (l’Extranet du Crédit Agricole par exemple), ce n’est pas vraiment le cas. En eﬀet, le nombre d’utilisateurs reste relativement stable par rapport au nombre d’items accessibles qui est de plus en plus croissant.
L’approche basée sur la mémoire a pour avantage la simplicité de l’implémentation et de l’intégration des nouvelles données dans le système. Cependant, cette approche a l’inconvénient d’être très dépendante de la quantité de notes des utilisateurs. En eﬀet, si les données s’avèrent rares, il est diﬃcile d’identiﬁer des voisins ﬁables (à partir des items co-notés) et par conséquent la performance du système décroît. De plus, dans une situation de démarrage à froid, cette approche est incapable de tenir compte des nouveaux utilisateurs et/ou items, récemment introduits au système. En eﬀet, l’approche basée sur la mémoire nécessite la disponibilité des appréciations concernant ces utilisateurs et/ou ces items pour pouvoir les intégrer parmi les recommandations. En outre, l’approche basée sur la mémoire reste limitée dans la mesure où elle ne permet pas le passage à l’échelle. En eﬀet, quand le nombre d’utilisateurs et d’items présents dans le système devient important, la génération des recommandations requiert un temps de traitement très élevé.
1.3.3 Méthodes basées sur un modèle
Les méthodes basées sur un modèle ont été intégrées aux systèmes de recommandation pour remédier aux problèmes des méthodes basées sur la mémoire, dont notamment : la non robustesse au manque de données ainsi que le non passage à l’échelle [Sarwar et al., 2000b] [Su et Khoshgoftaar, 2009]. Pour faire face à ces deux problèmes, les méthodes basées sur un modèle utilisent notamment les techniques de réduction de dimensionnalité ou le clustering dans le but d’écarter les utilisateurs ou les items non représentatifs. Ainsi l’espace de représentation utilisateur-item est plus réduit et le taux de données manquantes est moins important comparé à l’espace de représentation original. Les voisins peuvent ainsi être calculés dans cet espace réduit, ce qui permet de garantir le passage à
33

Chapitre 1. Etat de l’art
l’échelle.
Dans le cadre des méthodes basées sur un modèle, le processus de FC consiste à construire des modèles (généralement en hors ligne “oﬀ-line”) en exploitant les données collectées sur l’utilisateur et/ou sur l’item. Les modèles construits sont par la suite utilisés pour générer les prédictions qui sont proposées à l’utilisateur actif lors de son interaction avec le système. Le processus de construction du modèle est basé sur les techniques d’apprentissage automatique, telles que : le clustering, les réseaux bayésiens, les arbres de décision, etc. Ces techniques vont être explicitées dans ce qui suit.
Clustering
Un cluster est une collection d’objets qui sont similaires entre eux et dissimilaires aux objets appartenant aux autres clusters [Han et Kamber, 2001]. Dans le cadre du FC, le clustering a pour objectif de créer des clusters homogènes d’utilisateurs ou d’items. Les prédictions sont par la suite calculées en prenant en considération les opinions des utilisateurs (en FC centré sur l’utilisateur) ou les notes des items (en FC centré sur l’item) faisant partie des mêmes clusters.
Les méthodes de clustering les plus exploitées sont les méthodes de partitionnement dont k-means [MacQueen, 1967] est la plus populaire. Dans le cas d’un clustering d’utilisateurs [Kim et al., 2002], k-means consiste à créer k clusters telle que la distance entre utilisateurs intracluster est faible alors que la distance intercluster est forte. En d’autres termes, chaque cluster créé doit comprendre des utilisateurs ayant des appréciations similaires. L’algorithme (1) [Han et Kamber, 2001] présente les étapes d’un clustering k-means appliqué aux utilisateurs. Cet algorithme consiste à choisir aléatoirement des k centroïdes (des points situés au centre) à partir de l’espace de représentation (i.e. matrice “Utilisateur x Item”). Par la suite, chaque utilisateur est aﬀecté à un cluster, tel que la distance entre cet utilisateur et le centroïde du cluster est faible. Dans une étape suivante, en prenant en compte les utilisateurs qui viennent d’être aﬀectés aux clusters, la position du centroïde de chaque cluster est recalculée. Après la découverte des nouveaux centroïdes, les distances sont à nouveau réévaluées aﬁn de retrouver le cluster auquel chaque utilisateur devrait appartenir. Cette opération est itérée jusqu’à ce que les centroïdes deviennent stables et ne changent plus.
Pour illustrer ces étapes, la ﬁgure 1.4 [Han et Kamber, 2001] présente un exemple permettant la génération de trois clusters (k = 3) basée sur k-means. Au début du processus de clustering, trois utilisateurs représentant les centroïdes (représentés par le symbole “+”) sont sélectionnés arbitrairement aﬁn de construire trois clusters. Ainsi, dans la phase (a) chaque utilisateur est aﬀecté au cluster le plus proche. La phase (b) représente l’étape de recalcul des positions des centroïdes ainsi que la réaﬀectation
34

1.3. Techniques de recommandation
Algorithm 1 Algorithme de partitionnement k-means 1: Input : k : le nombre de clusters et M : matrice “Utilisateur x Item” 2: Output : k clusters
3: Choisir aléatoirement k centroïdes initiaux de clusters 4: repeat 5: Réaﬀecter chaque utilisateur au cluster auquel il est le plus similaire 6: Recalculer les distances des utilisateurs dans chaque cluster 7: Mettre à jour les centroïdes 8: until Stabilité des centroïdes
des utilisateurs aux clusters les plus proches (les diﬀérentes lignes pointillées déterminant les trois clusters, changent au fur et à mesure du recalcul des positions des centroïdes). La phase (c) représente la ﬁn du processus du clustering, les lignes pleines reﬂètent les clusters déﬁnitifs obtenus suite à la stabilité des centroïdes.
Fig. 1.4 – Clustering k-means
L’algorithme k-means a l’avantage d’être eﬃcient et son implémentation demeure facile [Su et Khoshgoftaar, 2009]. De plus, il permet le passage à l’échelle dans la mesure où il peut être appliqué à de larges corpus. Notons que la complexité de cet algorithme est O(nkt), n étant le nombre total d’utilisateurs, k le nombre de clusters et t le nombre d’itérations. Toutefois, le choix aléatoire des centroïdes au début du processus du clustering k-means ainsi que la détermination de leur nombre reste encore problématique. [Castagnos, 2008] a étudié ce problème et a proposé d’améliorer le choix des centres initiaux dans le cadre d’un clustering k-means, en garantissant la convergence de l’algorithme lorsque k = 2. Par ailleurs, la méthode k-means demeure sensible aux données aberrantes (“outliers”). Cette sensibilité découle du fait qu’un objet ou un utilisateur ayant une valeur extrêmement diﬀérente des autres (un “outlier”) peut altérer la distribution de données [Wang et Shao, 2004]. En eﬀet, lorsqu’un outlier est très loin du centroïde d’un cluster, la position du ce centroïde va être déplacée. Par conséquent, la distribution de données ne va plus être homogène.
35

Chapitre 1. Etat de l’art

“PAM” (Partitioning Around Medoïds) est un algorithme de la famille des méthodes de partitionnement. C’est une méthode de clustering de type “k-medoïde” qui a été proposée aﬁn de réduire la sensibilité aux données aberrantes et de remédier au problème de recouvrement des clusters [Han et Kamber, 2001]. Cette méthode de partitionnement a pour objectif de créer un ensemble de clusters tel que chaque cluster ait un point représentatif (un utilisateur central) appelé “médoïde”. L’algorithme (2) décrit les étapes du clustering PAM [Han et Kamber, 2001]. Au début du processus, les utilisateurs représentatifs (médoïdes) umed de chaque cluster sont choisis aléatoirement, comme dans k-means. Par la suite, aﬁn d’identiﬁer les médoïdes eﬀectifs, la méthode PAM repose sur la minimisation des dissimilarités entre chaque utilisateur up et l’utilisateur représentatif du cluster umed. L’algorithme PAM itère jusqu’à ce que que les médoïdes deviennent stables, i.e., jusqu’à ce que les umed ne changent plus. Durant cette itération, la qualité du clustering est évaluée en utilisant une fonction qui calcule le coût total S. Ce coût mesure l’erreur en cas de permutation d’un médoïde intial umed avec un autre médoïde urandom. Si S est négative, umed est remplacée eﬀectivement par urandom. Autrement, umed est considérée comme acceptable et devient stable.
Algorithm 2 Algorithme de partitionnement PAM 1: Input : k : le nombre de clusters et M : matrice “Utilisateur x Item” 2: Output : k clusters

3: Choisir aléatoirement k utilisateurs comme étant les médoïdes initiaux de clusters

4: repeat

5: Aﬀecter chaque utilisateur à un cluster tel que la dissimilarité entre cet utilisateur

et le médoïde est faible

6: Sélectionner aléatoirement un utilisateur non-représentatif (non-médoïde) urandom 7: Calculer le coût total, S, de permutation d’un utilisateur représentatif umed avec

urandom

8: if S < 0 then

9:

Remplacer umed par urandom pour former les nouveaux médoïdes

10: end if

11: until Stabilité des médoïdes

Comme nous l’avons précisé ci-dessus, l’intérêt de l’algorithme PAM comparé à kmeans, réside dans son insensibilité aux données aberrantes [Kaufman et Rousseuw, 1990] [Wang et Shao, 2004]. Cette insensibilité est dû au principe même de l’algorithme. En eﬀet, au lieu de considérer une valeur située au centre des utilisateurs comme étant le point de référence dans un cluster (comme dans k-means), PAM désigne des utilisateurs réels représentatifs des clusters (médoïdes) parmi les autres utilisateurs. Un médoïde constitue l’objet ou l’utilisateur le plus central du cluster. Ceci est assuré en permutant systématiquement un médoïde et un autre utilisateur choisi aléatoirement aﬁn de vériﬁer si la qualité du clustering décroît [Tuﬀéry, 2007]. Néanmoins, l’algorithme PAM reste inapproprié pour de larges corpus. Il requiert en eﬀet, un temps de traitement plus important que l’algorithme k-means. En eﬀet, la complexité

36

1.3. Techniques de recommandation
de cet algorithme est O(tk(n − k)2). De plus, comme k-means, la méthode PAM nécessite également de déﬁnir k qui est le nombre de clusters à générer.
Dans le cadre des systèmes de recommandation, la méthode de partitionnement kmeans a été largement appliquée aux utilisateurs et/ou aux items, en vue de réduire l’espace de recherche et le temps de calcul des recommandations, de permettre le passage à l’échelle et de pallier le manque de données [Tang et McCalla, 2003] [Xue et al., 2005] [Jiang et al., 2006]. Or, à notre connaissance, la méthode PAM a été moins utilisée par les systèmes de recommandation [Wang et al., 2008]. Par ailleurs, pour ces mêmes perspectives, d’autres algorithmes de clustering ont été intégrés aux systèmes de recommandation, notamment : ROCK [Conner et Herlocker, 1999], Gibbs Sampling [Breese et al., 1998], etc. Toutefois, l’une des limites du clustering est le risque de perte d’information cruciale lors de la création des clusters. Par exemple, suite à un clustering, deux utilisateurs proches peuvent ne pas avoir été aﬀectés au même cluster, ce qui peut se répércuter sur la performance du système de recommandations.

Modèles probabilistes

Les modèles probabilistes utilisés dans le cadre du FC visent à représenter le calcul des
prédictions sous forme de distributions de probabilité [Schafer et al., 2007]. Ces modèles
évaluent en général la probabilité qu’un utilisateur ua attribue une note v à un item ik, notée P r(v(ua, ik)) [Breese et al., 1998]. La note v est comprise entre vmin et vmax qui représentent respectivement la valeur minimale et maximale correspondant à l’échelle de
note. ix désigne un item appartenant à Iua qui constitue l’ensemble des items notés par ua.

vmax

P red(ua, ik) =

P r(v(ua, ik) = v|v(ua, ix), ix ∈ Iua) ∗ v

v=vmin

(1.4)

Les modèles probabilistes appliqués au FC intègrent notamment les réseaux bayésiens. [Breese et al., 1998] sont parmi les premiers à avoir proposé des méthodes probabilistes pour le FC basé sur les réseaux bayésiens et exploitant les arbres de décision. Le FC est ainsi perçu comme un réseau bayésien où chaque item représente un nœud. Les états de chaque nœud correspondent aux valeurs possibles de note. Ces valeurs comprennent aussi l’état “pas de note” correspondant à une note manquante. Ainsi, pour prédire ces notes manquantes, un algorithme d’apprentissage de réseaux bayésiens est appliqué. Dans les réseaux résultant de cet apprentissage, chaque item dispose d’un item parent à travers un arbre de décision qui déﬁnit les probabilités conditionnelles qu’un item soit apprécié ou pas par l’utilisateur. [Breese et al., 1998] montrent que les réseaux bayésiens exploitant les arbres de décision
37

Chapitre 1. Etat de l’art
améliorent la précision des items recommandés, comparés au FC basé sur l’approche mémoire.
La ﬁgure 1.5 présentée par [Breese et al., 1998] est un exemple d’un arbre de décision qui représente les probabilités estimées (représentées par des barres), qu’un utilisateur regarde ou pas la série “Melrose Place”, sachant que les nœuds parents sont les séries “Beverly Hills 90210” et “Friends”. Par exemple, nous pouvons observer que les utilisateurs n’ayant pas regardé “Beverly Hills 90210”, ne vont très probablement pas regarder “Melrose Place”.
Fig. 1.5 – Exemple d’arbre de décision présenté par [Breese et al.,1998]

Il existe d’autres approches probabilistes, appliquées notamment pour la réduction
de la dimensionnalité [Schafer et al., 2007]. Ainsi, une variable dite cachée P r(z|ua) est utilisée. Cette variable représente la probabilité qu’un utilisateur ua appartienne à une classe cachée z. L’équation (1.5) permet de calculer la probabilité qu’un utilisateur ua attribue une note v à un item ik.

P r(v|ua, ik) = P r(v|ik, z)P r(z|ua)
z
Ainsi, la prédiction de v est calculée sur la base de l’équation (1.6).

(1.5)

P red(v|ua, ik) = (v ∗ P r(v|z, ik)P r(z, ua))

v

z

(1.6)

Pour l’estimation des classes z, l’algorithme “Expectation-Maximization” peut être appliqué dans le cadre de l’analyse sémantique latente (“Latent Semantic Analysis”) [Hofmann, 2004]. Par ailleurs, dans le cadre des modèles probabilistes, d’autres techniques peuvent être également exploitées dans un processus de recommandation, notamment : la décomposition

38

1.3. Techniques de recommandation
en valeurs singulières (SVD “Singular Value Decomposition”) et l’analyse en composantes principales (PCA “Principal Component Analysis”) [Sarwar et al., 2000b] [Goldberg et al., 2001].
Les modèles probabilistes permettent de pallier le problème de manque de données et d’améliorer la qualité des recommandations [Breese et al., 1998]. Néanmoins, la construction des réseaux bayésiens demeure coûteuse et donc inappropriée pour un grand volume de données.
La sous-section suivante est consacrée à la présentation des techniques issues du Web Usage Mining. Ces techniques font partie des méthodes basées sur un modèle, mais au vu de leur importance vis-à-vis de nos travaux de recherche, nous avons choisi de leur consacrer une sous-section à part.
1.3.4 Techniques issues du Web Usage Mining
Le Web Usage Mining (WUM) consiste en l’analyse du comportement de l’utilisateur en se basant sur l’observation et l’analyse de ses activités de navigation et de ses échanges interactifs (ses usages) [Srivastava et al., 2000]. La ﬁnalité des techniques du WUM est de pouvoir découvrir des comportements communs d’usage entre utilisateurs aﬁn de générer des prédictions sur les futurs comportements de ces utilisateurs lors de leurs prochaines navigations.
Pour une analyse eﬃciente des usages, une collecte de traces d’usage est nécessaire. Les traces d’usage représentent une suite d’actions eﬀectuées par un utilisateur, elles sont déduites de l’ensemble des clics eﬀectués par cet utilisateur (cf. section 1.2).
Le WUM est une approche qui occupe une place de plus en plus prépondérante dans plusieurs domaines dont les applications sont relatives notamment aux portails d’information, au e-commerce/e-marketing, au e-learning et à l’IHM (Interaction Homme-Machine), etc. Sur un portail d’information, le WUM permet de prédire quel article sera lu ; sur un site de vente en ligne, il permet de savoir quel produit sera acheté ; et sur un site e-learning, le WUM permet de découvrir par exemple quelles suites d’actions mènent à la réussite ou à l’échec d’un exercice [Cheype, 2006]. De plus, le WUM peut être également utilisé pour améliorer la structure d’un site Web en mettant en évidence des liens hypertextes qui devraient relier des pages Web.
Dans l’objectif de générer des prédictions, le WUM exploite notamment les techniques d’apprentissage automatique pour la découverte des motifs d’usage [Srivastava et al., 2000]. Ces motifs permettent de prédire les futurs comportements navigationnels de ces utilisateurs en se basant sur l’analyse de leurs traces d’usage. Ainsi, contrairement aux méthodes de recommandation présentées dans les sections précédentes, les données de notes ne sont pas nécessaires dans le cadre des techniques du WUM.
39

Chapitre 1. Etat de l’art
Les sous-sections suivantes présentent quelques méthodes et algorithmes utilisés dans ce cadre.

Règles d’association
Initialement, les techniques de découverte de règles d’association ont été développées pour l’analyse des bases de données transactionnelles [Agrawal et Srikant, 1994]. Par la suite, ces techniques ont été intégrées dans d’autres domaines, notamment dans le cadre du WUM [Srivastava et al., 2000]. Au niveau d’une base de données transactionnelle, les techniques de découverte de règles d’association permettent la découverte de corrélations entre items. Ces corrélations sont identiﬁées à travers l’exploration de probabilités estimant que si un certain nombre d’items sont présents, d’autres items sont également potentiellement présents dans la même transaction [Wang et Shao, 2004].
La découverte de règles d’association dans une base de données transactionnelle repose sur deux étapes essentielles :
– La découverte d’itemsets fréquents. Un itemset désigne un ensemble d’items qui apparaissent dans une même transaction. Cette découverte est basée sur “le support” qui détermine la fréquence minimum d’apparition de ces itemsets dans la base de données.
– La découverte des règles d’association à partir des itemsets fréquents en se basant sur “la conﬁance”. La conﬁance évalue le degré d’implication d’une règle d’association. Si la conﬁance est élevée, la règle est ﬁable.
Considérons un ensemble de transactions T intégrant un ensemble d’itemsets I = {I1, I2, ...In}. Le support d’un itemset Ii ⊂ I est déﬁnie par l’équation (1.7). |T | représente le cardinal de T .

σ(Ii)

=

|t

∈

T : Ii |T |

⊆

t|

(1.7)

Une règle d’association “r” est exprimée sous la forme X ⇒ Y (σr, λr) [Agrawal et al., 1993] [Anand et Mobasher, 2005]. X et Y représentent des itemsets. σr = σ(X ∪ Y ) est le support de X ∪ Y , il représente la probabilité que X et Y se trouvent ensemble dans une transaction. λr est la conﬁance de la règle r, telle que déﬁnie par l’équation (1.8). Cette équation calcule la probabilité que Y apparaisse dans une transaction étant donné que X est déjà apparu dans cette même transaction.
40

1.3. Techniques de recommandation

λr

=

σ(X ∪ Y σ(X )

)

(1.8)

Dans le cadre du WUM, la découverte des règles d’association est d’un intérêt considérable. Par exemple, pour un Extranet d’entreprise ou un portail d’information, les règles d’association permettent d’observer que les utilisateurs consultant un item i1, consultent souvent un item i2. Cette règle aura la forme de i1 ⇒ i2.
Les règles d’association ont été largement utilisées par les systèmes de recommandation [Krulwich, 1997] [Sarwar et al., 2000a] [Fu et al., 2000] [Lin et al., 2002] [Nakagawa et Mobasher, 2003] [Wang et Shao, 2004]. Toutefois, cette technique présente quelques limites. En eﬀet, quand le système manque de données, les règles d’association et les recommandations ne peuvent pas être calculées. De plus, le processus de calcul de règles requiert un temps de calcul élevé et devient non-performant quand la taille de données est importante.

Motifs séquentiels
La recherche de motifs séquentiels, introduite par [Agrawal et Srikant, 1995], peut être considérée comme une variation des règles d’association. En eﬀet, elle repose sur le principe d’ordre des éléments ou de temporalité dans le but de découvrir des séquences fréquentes ordonnées dans le temps [Gery et Haddad, 2003]. A la diﬀérence des règles d’association, elle pose plus de contraintes. Un exemple de motif séquentiel est que les utilisateurs ont tendance à consulter dans l’ordre, sur un portail d’information, les articles : “Volcan d’Islande”, puis “Suspension des vols en Europe” et enﬁn “Prévisions météorologiques”.
A l’instar des règles d’association, la recherche de motifs séquentiels a été appliquée d’abord aux bases de données transactionnelles dans le cadre des stratégies marketing [Han et Kamber, 2001]. Ainsi, il était possible d’identiﬁer par exemple que “les clients qui ont acheté l’appareil photo numérique Samsung, vont probablement acheter plus tard une imprimante HP”. Par la suite, d’autres domaines d’applications se sont intéressés à l’étude des séquences de données, telles que :
– Le Web mining qui comprend le WUM et le “Web Structure Mining” (WSM). Dans le domaine du WSM [Srivastava et al., 2000], l’étude des séquences vise à analyser la structure de sites Web dans l’objectif d’identiﬁer les liens hypertextes et les pages Web les plus populaires (au travers des usages) et d’en faciliter l’accès. Dans le WUM, l’étude des séquences de navigation permet notamment l’aide à la navigation sur le Web [Baumgarten et al., 2000], [Mobasher et al., 2001], [Nakagawa et Mobasher, 2003], [Gery et Haddad, 2003].
41

Chapitre 1. Etat de l’art
– L’analyse des séquences biologiques (séquences ADN ou de protéines) : étude de l’alignement de séquences aﬁn de détecter d’éventuelles anomalies ou disfonctionnements génétiques [Brazma et al., 1998].
– La détection d’intrusions sur des bases de données : mise en place de systèmes de détection de transactions malveillantes grâce aux motifs séquentiels [Hu et Panda, 2004].
Etant donné un ensemble de séquences sur lesquelles les motifs séquentiels seront appris, chaque séquence “s” est représentée par une suite d’événements qui se sont produits l’un après l’autre. En considérant un support minimum, l’analyse de motifs séquentiels permet de retrouver toutes les séquences fréquentes dont la fréquence d’occurences parmi l’ensemble des séquences, est supérieur au support minimum [Agrawal et Srikant, 1995]. Lorsqu’un client réalise par exemple des achats, ces derniers constituent des événements et vont représenter une séquence pour ce client. Un client achète d’abord des items en s1, puis en s2, etc. Le nombre d’items dans une séquence représente la longueur de la séquence [Han et Kamber, 2001].
Le tableau 1.3 est un exemple d’une base de données transactionnelle triée par client et par date de transaction. Si nous considérons un support de 25%, (i3)(i9) et (i3)(i4i7) sont les séquences permettant de satisfaire le support déﬁni et représentent les motifs séquentiels. En eﬀet le motif (i3)(i9) est présent chez les deux clients Jean et Ryan et le motif (i3)(i4i7) est présent chez Rose et Ryan. Même si Rose a acheté l’item i6 en même temps que les items i4 et i7, (i4i7) représente un motif puisqu’il est une sous-séquence de (i3)(i4i7) . Il est à signaler que ces motifs sont inter-transactions, alors que les règles d’association sont intra-transactions (i.e. elles sont extraites d’une même transaction).

Tab. 1.3 – Exemple de base de données transactionnelle Client Id Date Items Id

Jean Jean Rose Rose Rose Eric Ryan Ryan Ryan Hélène

25 Mai 30 Mai 10 Mai 15 Mai 20 Mai 25 Mai 25 Mai 30 Mai 25 Juin 12 Mai

i3
i9 i1,i2
i3 i4,i6,i7 i3,i5,i7
i3 i4,i7
i9
i9

Dans le cadre du WUM, l’analyse des motifs séquentiels peut mettre en évidence des motifs séquentiels de type contigu (fermé) ou bien non contigu (ouvert) [Anand et Mobasher, 2005]. Les motifs contigus sont une forme restrictive des motifs séquentiels. En

42

1.3. Techniques de recommandation
eﬀet, la particularité des motifs contigus est que les items contenus dans le motif séquentiel doivent être adjacents suivant l’ordre de la séquence. Par exemple un motif séquentiel contigu i4i5i6 est satisfait par la séquence {i4, i5, i6} et non pas par {i4, i5, i8, i6} qui représente plutôt un motif séquentiel ouvert, étant donné que i8 apparaît entre i5 et i6.
L’utilisation des motifs séquentiels pour la recommandation de pages Web est d’un grand intérêt. Cependant, cette technique s’avère limitée lorsqu’il est question de traiter un grand volume de traces d’usage et de générer des motifs en temps réel.
Par ailleurs, il existe d’autres techniques permettant la découverte des motifs séquentiels, telle que :
– La technique LCS (Longuest Common Subsequences) : C’est une technique issue de la programmation dynamique. Elle permet d’extraire un cas particulier de motifs séquentiels. En eﬀet, cette technique vise à identiﬁer la plus longue sous-séquence commune à deux séquences données. Dans le cadre des systèmes de recommandation, [Jalali et al., 2008] ont proposé une architecture de classiﬁcation des motifs séquentiels, en se basant sur la découverte de LCS. Ces motifs permettent de prédire les futures activités de navigation des utilisateurs. Dans [Banerjee et Ghosh, 2001], un algorithme basé sur la technique LCS est utilisé pour le clustering d’utilisateurs en exploitant les traces d’usage. Cette approche de clustering prend en compte les similarités entre les chemins de navigation, basées sur les LCS, ainsi que la durée de consultation des items contenus dans ces LCS.
– Les modèles de Markov : cette approche vise à mettre en évidence des liens séquentiels entre les items consultés durant les activités de navigation des utilisateurs. En estimant les probabilités conditionnelles de transition entre items, les dépendances séquentielles de comportement de navigation sont modélisées sur la base des modèles de Markov [Eirinaki et al., 2005]. Plusieurs travaux de recherche ont intégré les modèles de Markov dans le processus de recommandation notamment : [Zimdars et al., 2001], [Shani et al., 2005], [Liu et al., 2007], [Bonnin et al., 2009] et [Verma et al., 2009].
Diﬀérents algorithmes ont été proposés pour la recherche de motifs séquentiels depuis leur émergence en 1994, notamment : GSP [Srikant et Agrawal, 1996], FreeSpan [Han et al., 2000], SPADE [Zaki, 2001], SPAM [Ayres et al., 2002], etc. Tous ces algorithmes ont été intégrés dans diverses applications. Dans le domaine du WUM, de nombreux travaux de recherche ont eu un engouement pour les motifs séquentiels, notamment : [Baumgarten et al., 2000], [Gaul et Schmidt-Thieme, 2001], [Mobasher et al., 2001], [Nakagawa et Mobasher, 2003], [Gery et Haddad, 2003].
Les techniques issues du WUM présentées ci-dessus, ont pour avantage d’analyser les usages et de prédire les futurs comportements navigationnels des utilisateurs sans l’utilisation des notes (requises notamment dans l’approche basée sur la mémoire). Or, comme pour les autres approches présentées précédemment, les algorithmes d’extraction
43

Chapitre 1. Etat de l’art
de motifs séquentiels ou de règles d’association traitent les données sans prendre en compte leur évolution dynamique dans le temps. Le passage à l’échelle, l’optimisation du temps de calcul et la génération de motifs en temps réel demeurent encore des enjeux de taille. De plus, dans le cadre de ces techniques, seul le critère de consultation d’items est considéré (pour la recommandation de pages Web par exemple). En eﬀet, deux utilisateurs ayant visité les mêmes items, auront les mêmes recommandations, alors qu’ils peuvent avoir des goûts diﬀérents.
1.3.5 Techniques hybrides
Les diﬀérentes techniques exploitées par les systèmes de recommandation ont chacune leurs apports mais aussi leurs limites. Le tableau 1.4 présente une synthèse comparant les avantages et les inconvénients des techniques de recommandation qui ont été présentées dans cet état de l’art. Nous pouvons observer à partir de ce tableau que le FC basé sur un modèle peut être performant, cependant cette performance reste un compromis entre amélioration de la qualité des recommandations et construction coûteuse de modèles. Quant au FC basé sur la mémoire, bien qu’il soit ﬁable et simple à implémenter, il demeure peu performant surtout lorsque le système manque de données, telles que les notes. La technique basée sur le contenu permet de remédier à ce problème de manque de données. Toutefois, les recommandations qu’elle génère sont très spécialisées et manquent de diversité (i.e. les items recommandés à un même utilisateur ont un contenu similaire). Ainsi, le choix d’une technique de recommandation reste un compromis entre performance, facilité d’implémentation et complexité.
De ce fait, aﬁn de combler les faiblesses d’une technique par une autre, plusieurs travaux de recherche ont proposé de combiner ou d’hybrider des techniques de recommandation qui sont potentiellement complémentaires.
Le système de recommandation hybride le plus courant consiste à combiner les techniques basées sur le contenu avec le FC basé sur la mémoire [Balabanović et Shoham, 1997], [Pazzani, 1999], [Claypool et al., 1999], [Schein et al., 2002]. Il existe diﬀérentes possibilités de combinaison, [Adomavicius et Tuzhilin, 2005] les ont classiﬁé en quatre catégories :
– Implémenter séparément le FC basé sur la mémoire et les méthodes basées sur le contenu et combiner les prédictions par la suite en se basant sur une combinaison linéaire des notes prédites.
– Incorporer certaines caractéristiques issues du contenu dans le cadre du FC basé sur la mémoire. De ce fait, au lieu de calculer les similarités sur la base des items co-notés comme en FC, les similarités entre utilisateurs sont évaluées en se basant sur la corrélation du contenu des items consultés [Balabanović et Shoham, 1997].
44

1.3. Techniques de recommandation

Catégorie
Technique basée sur le contenu

Tab. 1.4 – Synthèse comparative des techniques de recommandation

Exemples d’algo- Avantages

Inconvénients

rithmes utilisés

– Analyse de similarité de contenu (TF/IDF)
– Clustering – Arbres de décision

– Amélioration de la qualité des recommandations
– Réduction du problème de manque de données

– Manque de diversité des recommandations
– Nécessité d’indexation de contenus (extraction d’attributs représentatifs)
– Problème d’indexation de documents multimédia

FC basé sur la mémoire

– FC exploitant l’approche kNN (basée sur l’utilisateur ou sur l’item)
– Utilisation des mesures Pearson ou cosinus

– Implémentation simple – Intégration facile de
nouvelles données – Précision des recom-
mandations

– Dépendance aux données de notes
– Détérioration de la qualité de recommandations à cause du manque de données
– Problème de passage à l’échelle

FC basé sur un modèle

– Clustering – Approches probabi-
listes (réseaux bayésiens) – Méthodes de réduction de dimensionnalité (SVD, PCA) – WUM (règles d’association, motifs séquentiels, modèles de Markov)

– Amélioration de la qualité des recommandations
– Réduction du problème de manque de données
– Prédiction des futurs comportements de navigation

– Construction coûteuse de modèles
– Risque de perte d’information pertinente dû à la réduction de dimensionnalité
– Problème de calcul des règles ou de motifs quand le système manque de données
– Pas de considération du proﬁl utilisateur (pour les modèles du WUM)

45

Chapitre 1. Etat de l’art
Cette stratégie de combinaison permet de pallier certains problèmes de manque de données, dûs par exemple à un faible nombre d’items co-notés entre utilisateurs.
– Incorporer certaines caractéristiques issues du FC basé sur la mémoire dans le cadre d’une approche basée sur le contenu. Il s’agit de créer par exemple une vue collaborative des proﬁls utilisateurs qui sont représentés par des vecteurs de termes extraits du contenu des items [Soboroﬀ et Nicholas, 1999].
– Construire un modèle général uniﬁant les caractéristiques issues à la fois du contenu ainsi que du FC basé sur la mémoire. [Popescul et al., 2001] proposent en eﬀet une méthode probabiliste aﬁn d’uniﬁer ces caractéristiques en se basant sur l’analyse sémantique latente.
[Burke, 2002] analyse également les diﬀérentes stratégies de combinaison de techniques de recommandation d’une manière générale. Il présente ainsi diﬀérentes méthodes d’hybridation, dont notamment :
– La méthode pondérée : les notes calculées par les diﬀérentes techniques de recommandation sont combinées et pondérés aﬁn de générer une seule recommandation. L’intérêt de cette méthode est que la combinaison est simple à réaliser et permet d’ajuster l’hybridation en fonction des performances.
– La méthode “switching” : le système change à chaque fois de technique de recommandation selon les performances atteintes dans le but de ne conserver que les meilleures prédictions. Proposé par [Billsus et al., 2000], le système “DailyLearner” utilise cette méthode dans le cadre d’une hybridation entre contenu et FC basé sur la mémoire. Ce système applique d’abord la méthode basée sur le contenu. Lorsque cette dernière génère des recommandations de faible qualité, le système fait appel à la technique du FC. La méthode “switching” introduit une complexité supplémentaire au processus de recommandation. En eﬀet, le critère permettant le choix d’une technique doit être déterminé, ce qui requiert un autre niveau de paramètrage sur le système.
– La méthode mixte : les recommandations issues de diﬀérentes techniques sont toutes présentées simultanément aux utilisateurs. Le problème qui peut ressortir quant à l’utilisation de cette méthode est la diﬃculté de calculer les scores pour ordonner une liste de recommandation, lorsque toutes les techniques recommandent les mêmes items mais avec des notes diﬀérentes.
Les diﬀérents travaux qui s’intéressent à l’hybridation de techniques de recommandation ont démontré empiriquement que cette hybridation permet d’améliorer la précision des recommandations comparée par exemple au FC basé sur la mémoire ou à la technique basée sur le contenu [Balabanović et Shoham, 1997] [Pazzani, 1999] [Melville et al., 2002]. Les systèmes hybrides permettent en outre de remédier à certains problèmes tels que le manque de données.
46

1.4. Verrous scientiﬁques
Toutefois, l’hybridation rajoute encore plus de complexité au processus de recommandation [Su et Khoshgoftaar, 2009]. En eﬀet, elle requiert diﬀérentes sources de données et met en application plusieurs techniques à la fois. Elle nécessite ainsi des paramétrages supplémentaires liés à la combinaison de diﬀérentes méthodes. Par conséquent, les calculs requis pour cette hybridation deviennent coûteux.
Après avoir présenté les principales techniques utilisées par les systèmes de recommandation, dans la section suivante il est question de discuter les verrous scientiﬁques auxquels nous nous intéressons dans cette thèse.
1.4 Verrous scientiﬁques
Malgré le succès des systèmes de recommandation, certains points demeurent encore problématiques, notamment : le manque de données, le démarrage à froid, la sélection de voisins ﬁables, la robustesse et la précision des recommandations. Cette section vise à expliciter ces points problématiques en soulignant les propositions qui ont été eﬀectuées dans les travaux de recherche avec leurs avantages et leurs inconvénients.
1.4.1 Manque de données
Dans le cadre d’une approche de recommandation fondée sur le FC (basé sur la mémoire), l’identiﬁcation des appréciations des utilisateurs est l’un des piliers de base du processus de recommandation. Elle permet en eﬀet de modéliser les utilisateurs dans le but de prédire les futurs goûts d’un utilisateur actif en se basant sur les appréciations connues d’un groupe d’utilisateurs.
Ces appréciations sont soit renseignées explicitement par les utilisateurs eux-mêmes ou bien induites par le système sur la base de l’analyse des interactions de ces utilisateurs avec le système. Or, dans les deux cas, souvent les données relatives aux appréciations des utilisateurs manquent et s’avèrent insuﬃsantes pour le bon fonctionnement du système de recommandation [Sarwar et al., 2000b]. En eﬀet, la quantité de données ou de notes disponible demeure toujours insuﬃsante pour pouvoir prédire correctement les notes manquantes. Par conséquent, en raison de ce manque de données, la modélisation des utilisateurs devient complexe. Les modèles utilisateurs deviennent ainsi peu ﬁables, parce qu’ils ont été construits en se basant sur un volume limité de données. En outre, dans le cadre du FC basé sur la mémoire, quand la matrice “Utilisateur x Item” est très creuse11, le système est incapable d’identiﬁer un nombre signiﬁcatif de voisins en
11Par exemple, sur la base de Movielens, environ 94% de la matrice de notes est vide
47

Chapitre 1. Etat de l’art
s’appuyant sur les items co-notés, ce qui se répércute sur la qualité des recommandations proposées à l’utilisateur actif et sur la performance de la totalité du système.
Pour les approches de recommandation basées sur le WUM, elles ont l’avantage de ne pas requérir de notes puisqu’elles exploitent les données d’usage. Toutefois, ces approches font face également au problème de manque de données. En eﬀet, une masse importante de données (traces d’usage) est nécessaire aﬁn de pouvoir découvrir des motifs ﬁables et prédire eﬃcacement les futurs comportements de navigation.
Plusieurs travaux de recherche ont étudié le problème de manque de données dans le cadre du FC, en examinant l’intérêt d’exploiter certaines techniques telles que les méthodes basées sur le contenu et les méthodes basées sur un modèle (le clustering, SVD, etc.) aﬁn de remédier à ce problème.
Comme nous l’avions décrit précédemment (cf. sections 1.3.1 et 1.3.5), devant l’indisponibilité des données de notes, le contenu peut être exploité en vue d’évaluer les similarités entre items et eﬀectuer les recommandations. Dans ce contexte, la technique basée sur le contenu peut être hybridée avec le FC basé sur la mémoire [Balabanović et Shoham, 1997] [Pazzani, 1999] [Melville et al., 2002] et/ou avec une technique basée sur un modèle telle que naive Bayes [Xiaoyuan et al., 2007].
Dans le cadre des méthodes basées sur un modèle et pour remédier au manque de données, le clustering (cf. section 1.3.3) a été largement utilisé. Parmi ces travaux, le clustering a été appliqué soit aux utilisateurs ou bien aux items ou bien aux deux, aﬁn de générer des clusters d’utilisateurs ou d’items similaires dans le but de prédire les notes manquantes. Diﬀérents algorithmes de clustering ont été utilisés dans cette optique, notamment : k-means [Ungar et Foster, 1998] [Xue et al., 2005], Gibbs Sampling [Breese et al., 1998], ROCK [Conner et Herlocker, 1999], etc.
En outre, les techniques de réduction de dimensionnalité ont été intégrées également au processus de FC pour faire face au problème de manque de données [Sarwar et al., 2000b] [Zhang et al., 2005] [Gong et al., 2009]. La réduction de dimensionnalité vise à représenter les données dans un espace ayant une dimension plus réduite que celle du départ. SVD constitue une technique de réduction de dimensionnalité, qui consiste en la factorisation d’une matrice “Utilisateur x Item” [Sarwar et al., 2000b] [Goldberg et al., 2001] [Zhang et al., 2005] [Gong et al., 2009]. Outre son apport face au manque de données, l’utilisation de la technique SVD par les sysèmes de recommandation permet d’une part de produire une représentation de plus faible dimension de l’espace original “Utilisateur x Item” et de calculer les similarités utilisateurutilisateur au niveau de cet espace réduit. D’autre part, elle met en évidence les relations latentes entre utilisateurs et items permettant le calcul des notes manquantes [Sarwar et al., 2000b]. Toutefois, la complexité de SVD en temps et en mémoire est très importante, ce qui rend l’apprentissage coûteux et inapproprié pour de grandes matrices.
48

1.4. Verrous scientiﬁques
Les techniques citées ci-dessus parviennent à traiter le problème de manque de données, toutefois elles présentent quelques limites. La technique basée sur le contenu permet de calculer les recommandations concernant des items peu notés dans le système. Cependant, cette technique engendre un manque de diversité du contenu des recommandations. En ce qui concerne les techniques de clustering et de SVD, elles permettent notamment de condenser l’espace de représentation de données en supprimant les utilisateurs ou les items non représentatifs. Cependant, le risque lié à cette suppression est la perte d’information potentielle (concernant par exemple des voisins ﬁables), susceptible d’entraîner une dégradation de la performance du système de recommandation.
1.4.2 Démarrage à froid
Le problème de démarrage à froid se traduit par la diﬃculté de générer des recommandations concernant de nouveaux items ou de nouveaux utilisateurs qui viennent d’être introduits au système de recommandation. Déﬁni comme le problème de “systemic bootstrapping” par [Rashid et al., 2008], le démarrage à froid peut concerner tous les types données (concernant les utilisateurs et les items). Ce problème se produit lorsqu’il s’agit par exemple d’un nouveau service créé et pour lequel aucune donnée n’est encore disponible [Schein et al., 2002]. Ainsi, le nouveau système de recommandation en question ne peut recommander aucun item, à aucun utilisateur.
Nouveaux utilisateurs
Proposer des recommandations à un nouvel utilisateur, récemment introduit au système, constitue un enjeu pour les systèmes de recommandations. Dans le cadre du FC, tant que le système n’a aucune connaissance sur les appréciations de ce nouvel utilisateur, sa modélisation reste complexe et le système de recommandation ne sera pas capable de lui proposer des recommandations personnalisées. Dans ce contexte, l’élicitation (à travers la sollicitation de notes explicites, de critiques ou d’informations démographiques) peut se présenter comme une solution. Or, cette sollicitation directe peut entraîner l’abandon de l’utilisateur tel que décrit dans la section 1.2. Un autre moyen d’aborder le problème de nouveauté de l’utilisateur, est de lui proposer des recommandations arbitraires dès sa première utilisation du système. Cependant, cette stratégie risque d’occasionner une insatisfaction chez l’utilisateur, au vu de la faible qualité des recommandations. [Rashid et al., 2008] présentent d’autres stratégies pour faire face au problème de nouveauté de l’utilisateur. Ces stratégies exploitent la popularité des items et l’entropie consistant à évaluer la dispersion des avis des utilisateurs sur un item. Par ailleurs, les proﬁls démographiques des utilisateurs (cf. section 1.2) représentent aussi un moyen de remédier au manque de données. En eﬀet, l’information démographique peut être exploitée en vue de construire les modèles utilisateurs. Ainsi, deux utilisateurs appartenant au même segment démographique, sont considérés comme similaires [Pazzani,
49

Chapitre 1. Etat de l’art
1999] [Vozalis et Margaritis, 2006]. En s’appuyant sur le principe du FC, ces similarités permettent d’identiﬁer les voisins dont les appréciations sont considérées pour le calcul des recommandations. Or, même si des utilisateurs appartiennent à un même segment démographique, ils ne partagent pas nécessairement les mêmes goûts.
Nouveaux items
Recommander de nouveaux items constitue également un enjeu de taille pour les systèmes de recommandation. Ce problème est connu sous le nom de “latence”. En eﬀet, quand un nouvel item est intégré au système, les préférences des utilisateurs par rapport à cet item ne sont pas encore disponibles. Par conséquent, le nouvel item ne sera pas impliqué dans le cadre des recommandations. Le problème de latence a, en particulier, plus d’un impact sur les systèmes qui incorporent de nouveaux items régulièrement, comme les systèmes recommandant les articles d’actualité [Sollenborn et Funk, 2002] [Burke, 2002].
Pour pallier ce problème de latence, une stratégie consiste à sélectionner aléatoirement les nouveaux items et à proposer à l’utilisateur actif d’y attribuer des appréciations. Cependant, tel que discuté précédemment, cette stratégie pourrait occasionner une lassitude chez l’utilisateur qui risque d’abandonner le système. Une solution alternative consiste à exploiter la technique basée sur le contenu [Lang, 1995] [Krulwich et Burkey, 1996] [Billsus et Pazzani, 2000]. Cette technique est utilisée tant que les notes sur un item ne sont pas suﬃsamment disponibles. Quand un nouvel item est introduit, la technique basée sur le contenu évalue la similarité de son contenu avec les items disponibles aﬁn de l’impliquer au processus de recommandation. Néanmoins, l’utilisation de la technique basée sur le contenu engendre un manque de diversité des recommandations, ce qui entrave la performance du système de recommandation (cf. section 1.3.1). Une nouvelle technique de ﬁltrage (basée sur le contenu) exploitant les ontologies, a été suggérée également comme une solution au problème de latence. Cette technique a été notamment utilisée par le système Entree (qui recommande des restaurants) [Burke, 2002] et le système Quickstep-Foxtrot (qui recommande des papiers scientiﬁques) [Middleton et al., 2004]. Les méthodes d’apprentissage utilisent les ontologies mises en place dans le cadre de ces systèmes, aﬁn de classiﬁer et de catégoriser les items et générer les modèles utilisateurs. Or, la limite de cette technique est la nécessité de la construction préalable d’une ontologie relative au domaine de connaissance.
Les travaux de recherche présentés dans cette section ont proposé diﬀérentes approches dans le but de faire face au problème de démarrage à froid pour de nouveaux utilisateurs ou de nouveaux items. Ces approches exploitent par exemple l’élicitation, le FC exploitant l’information démographique, la technique basée sur le contenu ou sur les ontologies. Malgré leurs intérêts, ces approches présentent quelques limites liées notamment au manque de diversité des recommandations ou à la détérioration de la qualité des recommandations (en raison de l’utilisation de l’information démographique par exemple).
50

1.4.3 Sélection de voisins ﬁables

1.4. Verrous scientiﬁques

Dans le cadre du processus de FC basé sur la mémoire (centré sur l’utilisateur), l’approche kNN permet de retrouver les k voisins les plus proches d’un utilisateur actif dans le but d’utiliser leurs avis pour générer des recommandations pertinentes à cet utilisateur actif. Ces k plus proches voisins sont considérés comme étant les voisins les plus informatifs. Ils ont en eﬀet des appréciations similaires vis-à-vis de l’utilisateur actif, au vu de leurs opinions concernant des items notés ou consultés en commun antérieurement.
L’identiﬁcation de ces voisins dans une approche kNN peut notamment reposer sur des stratégies telles que la détermination d’un seuil de similarité ou la détermination d’un seuil d’items co-notés (cf. section 1.3.2). Or, la détermination de ce type de seuil reste problématique. En eﬀet, avec l’intégration de nouveaux utilisateurs et d’items, pour être plus ﬁable, le système de recommandation réinitialise le calcul des voisinages. Par conséquent, l’ensemble des k voisins les plus proches varie et son choix n’est jamais déﬁnitif. De ce fait, ces seuils doivent être adaptés au fur et à mesure de la réinitialisation du système, tout en évitant de ﬁxer des valeurs extrêmes pour que le pouvoir prédictif du système ne soit pas faible et pour que le bruit ne soit pas engendré à cause de voisins peu pertinents.
La limite d’une telle approche est qu’elle demeure dépendante des items notés en commun aﬁn d’évaluer le degré de similarité entre utilisateurs et de déterminer les plus proches voisins. En l’absence de ces items co-notés, aucune modélisation d’utilisateurs n’est possible et aucun voisinage ﬁable ne peut être sélectionné. Dans cette optique, d’autres méthodes permettant d’identiﬁer des similarités entre utilisateurs ont été proposées. Il s’agit d’exploiter par exemple les associations transitives aﬁn d’établir des liens entre utilisateurs ou entre utilisateurs et items. [Papagelis et al., 2005] et [Golbeck, 2009] exploitent le principe d’inférence aﬁn d’explorer les associations entre utilisateurs dans l’objectif d’identiﬁer des voisins potentiellement ﬁables, susceptibles d’améliorer la qualité des recommandations. Néanmoins, considérant que les systèmes de recommandation sont dynamiques et que la phase de calcul du voisinage requiert un temps de calcul important, l’application de ce type d’association devrait se baser sur des stratégies permettant de limiter par exemple le nombre d’utilisateurs concernés, aﬁn de permettre le passage à l’échelle.
Par ailleurs, la notion de conﬁance a également été étudiée comme un moyen de détermination de voisins ﬁables dans le cadre des systèmes de recommandation. [Massa et Bhattacharjee, 2004] [O’Donovan et Smyth, 2005] [Papagelis et al., 2005] [Golbeck, 2009] proposent en eﬀet de considérer la conﬁance en prenant notamment en compte la capacité antécédente d’un voisin à fournir ou à contribuer à des recommandations pertinentes. Par exemple, en utilisant des mesures de conﬁance, le système proposé par [O’Donovan et Smyth, 2005] peut spéciﬁer à un utilisateur actif ua que “le système vous recommande la voiture Toyota Verso, cette recommandation vous a été générée par les utilisateurs uc, ud et ue, ces utilisateurs ont déjà recommandé la Toyota Verso n fois dans le passé, et ces recommandations ont été ﬁables r fois”.
51

Chapitre 1. Etat de l’art
Toutefois, une telle démarche de recommandation va à l’encontre du respect de la vie privée. En eﬀet, pour appuyer la notion de conﬁance, ce système de recommandation se permet d’annoncer quel utilisateur a recommandé tel ou tel item et combien de fois son avis a été utilisé dans le passé dans le cadre des recommandations. De plus, les systèmes de recommandation basés sur la conﬁance requièrent un retour d’expérience des utilisateurs vis-à-vis des items recommandés. En eﬀet, les utilisateurs doivent exprimer directement leurs retours suite à la réception des recommandations et ce en évaluant chacun des items recommandés. Ce processus s’inscrit dans l’élicitation et pourrait provoquer un agacement chez l’utilisateur (cf. section 1.2). Autrement, des heuristiques pour évaluer l’intérêt vis-à-vis d’une recommandation, devraient être déﬁnies (par exemple la durée de consultation, la lecture d’une vidéo, la commande d’un produit, etc.).
La sélection des plus proches voisins est primordiale dans la mesure où la qualité des prédictions peut être inﬂuencée par la ﬁabilité des voisins. L’exploitation de l’approche kNN ou du principe de conﬁance permettent de sélectionner des voisins pertinents, mais requièrent respectivement la disponibilité des items co-notés ou le retour de l’utilisateur. L’utilisation des inférences pour identiﬁer des voisins potentiellement ﬁables est une solution prometteuse, mais reste peu appropriée pour un grand volume de données.
1.4.4 Robustesse
La robustesse constitue un challenge pour toutes les applications en ligne. Devant la diﬃculté d’évaluer la conﬁance des utilisateurs utilisant les systèmes de recommandation, ces derniers demeurent vulnérables aux manipulations et aux données bruitées. En eﬀet, il n’y pas de garantie que les données intégrées aux systèmes de recommandation reﬂètent les réelles appréciations des utilisateurs. [O’Mahony et al., 2006] distinguent deux catégories de données bruitées :
– Le bruit naturel : ce bruit relève du fait que l’expression des appréciations est souvent perçue par les utilisateurs comme un processus fastidieux, ce qui peut inﬂuencer la qualité des opinions attribuées par ces utilisateurs.
– Le bruit malicieux : ce bruit provient de l’insertion d’information biaisée de la part de certains utilisateurs malveillants. Une de leurs motivations par exemple est de promouvoir leur produit ou leur article en forçant le système de recommandation à générer des notes élevées pour ceux-ci et à en faire un “push”, au détriment d’autres items (concurrents) présents dans le système. De plus, le bruit malicieux peut aussi bien consister à endommager la totalité du système.
[Lam et Riedl, 2004] évaluent l’impact des attaques et des données bruitées sur l’eﬃcacité du système. Cette évaluation est eﬀectuée en termes de vulnérabilité d’algorithmes
52

1.4. Verrous scientiﬁques
utilisés et de capacité prédictive du système de recommandation. En outre, [Lam et Riedl, 2004] proposent des mesures de détection d’attaques et étudient les propriétés des items attaqués. Pour remédier au problème des données bruitées et garantir la stabilité du système, [O’Mahony et al., 2006] déﬁnissent des méthodes permettant de détecter le bruit en exploitant une théorie de détection du signal et montrent la ﬁabilité de ces méthodes pour la garantie de la robustesse du système contre diﬀérentes stratégies d’attaques. [Mehta et al., 2007] étudient l’intérêt de certaines méthodes statistiques, telles que les techniques de factorisation de matrice, pour la stabilité du système de recommandation, malgré la présence de bruit. Par ailleurs, [O’Donovan et Smyth, 2005] montrent l’importance des modèles de conﬁance pour améliorer la robustesse des systèmes de recommandation. L’utilisation des modèles de conﬁance ont ainsi un double avantage. Ils contribuent d’une part à la sélection de voisins ﬁables, ils permettent d’autre part de garantir la stabilité des systèmes de recommandation.
1.4.5 Précision des recommandations
L’évaluation des systèmes de recommandation constitue une étape clé dans un processus de recommandation dans la mesure où elle reﬂète la performance de l’intégralité du système. Pour tout système de recommandation, prédire eﬃcacement les futures appréciations contribue à la satisfaction des besoins des utilisateurs et à leur ﬁdélisation.
L’évaluation des systèmes de recommandation peut prendre en compte diﬀérents critères, à savoir : la précision, la couverture, la satisfaction de l’utilisateur, la robustesse, le temps de calcul, la nouveauté et la diversité des recommandations, etc. [Anand et Mobasher, 2005]. La plupart des travaux de recherche portant sur les systèmes de recommandation, évaluent la performance de leurs algorithmes en s’appuyant notamment sur le critère de précision des prédictions. La précision permet en eﬀet d’évaluer la capacité du système à recommander des items que l’utilisateur apprécie réellement. A travers les algorithmes proposés par les travaux cités dans ce chapitre, l’amélioration de la précision était souvent un enjeu majeur. La performance de ces algorithmes était mesurée en eﬀet selon le degré de précision des recommandations comparée à des techniques de recommandation standards.
Il est à signaler que la qualité et la précision des recommandations est étroitement liée à la disponibilité des données sur les appréciations. En eﬀet, quand ces données sont rares, le système ne peut générer des prédictions précises. En outre, cette qualité de recommandation dépend également de la ﬁabilité de l’algorithme utilisé pour l’apprentissage des modèles utilisateurs.
Les mesures utilisées pour évaluer la précision des systèmes de recommandation vont
53

Chapitre 1. Etat de l’art être détaillées dans le chapitre suivant.
Conclusion Dans ce chapitre, nous avons décrit la typologie des données susceptibles d’être exploitées dans le cadre des systèmes de recommandation. De plus, nous avons présenté un état de l’art relatif aux principales techniques de recommandation, à savoir : la technique basée sur le contenu, le FC basé sur la mémoire ou sur un modèle, les techniques du WUM ainsi que les techniques hybrides. A travers les travaux de recherche cités notamment dans ce chapitre, il s’avère que chaque technique a des apports mais également des limites. Le choix d’une technique ou d’une autre est liée à la problématique traitée, au contexte applicatif ainsi qu’à la disponibilité des données à l’entrée du système. Après avoir présenté les principales questions de recherche auxquelles nous nous intéressons, nous allons décrire dans le chapitre suivant l’approche générique que nous proposons, notre contexte applicatif ainsi que la méthodologie expérimentale utilisée en vue d’évaluer la ﬁabilité des modèles de recommandation proposés à travers cette thèse.
54

Chapitre 2
Schéma générique, contexte applicatif et méthodologie expérimentale
2.1 Schéma générique de la recommandation
Rappelons que notre travail de recherche consiste à proposer de nouvelles approches de recommandation s’inscrivant dans le cadre d’un processus de personnalisation sur le Web. L’objectif de ces approches est d’améliorer l’accès des utilisateurs aux items au niveau des systèmes de recherche d’information, tels que les portails et les Extranets documentaires d’entreprise.
La ﬁgure 2.1 décrit le schéma générique de la recommandation auquel nous nous intéressons dans le cadre de cette thèse. A partir de l’analyse des interactions entre les utilisateurs et les items, l’objectif de ce schéma consiste à construire des modèles ou des proﬁls utilisateurs. Ces interactions peuvent être extraites de l’ensemble des actions eﬀectuées sur un item par un utilisateur donné, telles que :
– une consultation d’item, – une évaluation d’item au travers de l’attribution de note ou d’appréciation, – une action relative à la navigation à travers des items (cf. section 1.2, chapitre 1,
partie 1).
La construction des modèles utilisateurs repose notamment sur l’analyse des actions de cet utilisateur quant aux items consultés auparavant, aﬁn de générer les prédictions des futures opinions de cet utilisateur concernant des items qu’il n’a pas encore consultés. Il s’agit de connaître les besoins de l’utilisateur en exploitant ses actions antérieures dans le but de prédire ses futurs appréciations.
55

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
Fig. 2.1 – Schéma générique de la recommandation
Une fois les prédictions générées, une liste d’items jugés pertinents, triée généralement par ordre d’importance (i.e. un classement d’items selon un ordre de pertinence estimé par le système), est proposée automatiquement à l’utilisateur qui choisit d’accepter ou non de consulter les items recommandés. Ainsi, l’enjeu de ce schéma de recommandation est d’anticiper les besoins et de garantir la ﬁdélisation des utilisateurs à ces systèmes grâce à la satisfaction de leurs attentes.
Dans les sections qui suivent, nous présenterons d’une part le contexte d’application liée à nos travaux de recherche. D’autre part, la méthodologie d’évaluation sera décrite en présentant à la fois les corpus de données exploités, les métriques d’évaluation utilisées pour l’évaluation des approches de recommandation que nous avons proposées ainsi que le modèle de recommandation de l’état de l’art qui nous a servi comme banc d’essai (“benchmark”).
2.2 Contexte applicatif
Cette thèse s’inscrit dans le cadre du projet PERCAL entre le Crédit Agricole S.A, en particulier avec le Pôle Innovation et l’équipe de recherche KIWI12 du LORIA. Le Crédit Agricole représente un des leaders de la banque de proximité en France qui compte plus que 7000 agences dans son réseau (regroupées en 39 caisses régionales) et plus de 20 millions de clients en intégrant Le Crédit Lyonnais (LCL) et ses ﬁliales internationales. A l’origine, le Crédit Agricole proposait des services ﬁnanciers dans le domaine de l’agriculture, ces services se sont étendus par la suite à divers acteurs économiques incluant les particuliers, les professionnels et les entreprises.
12http ://kiwi.loria.fr
56

2.2. Contexte applicatif
Le Crédit Agricole S.A constitue l’organe central du Groupe Crédit Agricole. Il est chargé notamment d’assurer le développement et la coordination des stratégies métiers en proposant les produits et les services à commercialiser et en fédérant les moyens et les compétences incluant notamment le développement d’une plate-forme informatique commune. De plus, le Crédit Agricole S.A. a un rôle de gouvernance sur les technologies et l’innovation.
Le Pôle Innovation relève de la Direction IIG (Informatique Industrielle du Groupe) du Crédit Agricole S.A. Ce Pôle est chargé de l’étude, de l’expérimentation et de la déﬁnition des modalités de mise en œuvre des technologies au sein du Groupe Crédit Agricole. Ses missions consistent à :
– assurer la veille technologique en évaluant de nouveaux produits et en proposant des solutions techniques concernant les projets du Groupe Crédit Agricole,
– assister la mise en place de nouvelles technologies, – assurer le respect des standards et des normes concernant les nouvelles technologies
introduites au Groupe Crédit Agricole.
Le projet PERCAL s’inscrit dans les perspectives du Pôle Innovation du Crédit Agricole S.A. L’objectif de ce projet consiste en eﬀet, à proposer de nouvelles techniques de recommandation permettant de personnaliser l’accès à l’information, en prenant en compte le contexte d’un portail Extranet d’entreprise.
Ce portail, dont l’extrait est présenté dans la ﬁgure 2.2, met notamment à la disposition des utilisateurs du Groupe Crédit Agricole des informations en matière de veille technologique (nouveaux produits, nouvelles normes, nouvelles solutions technologiques, etc.) [Bertrand-Pierron, 2006]. En outre, il oriente ces utilisateurs vers les diﬀérents sites du Groupe. Ce portail est potentiellement accessible par ces trois catégories d’utilisateurs :
– 1100 utilisateurs qui s’authentiﬁent actuellement sur le portail, – 6000 à 10000 informaticiens du Groupe Crédit Agricole pouvant accéder également
au portail, – jusqu’à 150000 utilisateurs (représentant l’ensemble des employés du Groupe Crédit
Agricole) pouvant consulter le portail.
Le portail Extranet est géré par l’outil “JCMS”13 dont l’architecture fonctionnelle et technique sont présentées respectivement dans les ﬁgures 2.3 et 2.4. Basé sur Java et XML, cet outil intégre des fonctions de gestion de contenu, de gestion documentaire et de workﬂow, de gestion d’espaces collaboratifs et de réseau social. Suivant les rôles attribués aux utilisateurs, JCMS permet :
– la création, l’édition et la suppression de contenus,
13http ://www.jalios.com
57

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
Fig. 2.2 – Extrait du portail Extranet du Crédit Agricole (S.A)
– la gestion de versions de documents, – l’indexation de contenus, – la gestion des rôles, des droits d’accès et des circuits de validation, – la gestion de la présentation graphique, – la navigation et la recherche, – le développement d’échanges et de conversations à travers des outils de réseaux
sociaux. Les items accessibles sur le portail Extranet du Crédit Agricole sont très variés, ils peuvent inclure : des articles d’actualité, des rapports techniques, des FAQ, des sondages, des blogs, des livres, etc. Leur nombre est en constante croissance. De ce fait, à partir des questions de recherche soulevées (cf. section 1.4 du chapitre précédent) et en prenant en compte ce portail Extranet, l’objectif de notre travail de recherche est de proposer de nouvelles approches de recommandation permettant d’optimiser l’usage des ressources de l’Extranet par les utilisateurs du Groupe Crédit Agricole. En eﬀet, l’enjeu est de pouvoir mettre en place des outils de personnalisation et de recommandation collaboratifs, s’appuyant sur les usages, capables de mettre à la disposition des utilisateurs des informations pertinentes adaptées à leurs proﬁls. Dans le but de valider les approches de recommandation proposées à travers cette thèse, nous avons exploité des corpus de données d’usage réel et de notes explicites. Ces corpus vont être décrits dans la section suivante. 58

2.3. Données exploitées Fig. 2.3 – Architecture fonctionnelle de JCMS
Fig. 2.4 – Architecture technique de JCMS
2.3 Données exploitées
2.3.1 Corpus d’usage
Les traces d’usage permettent de décrire l’ensemble des activités de navigation eﬀectuées par un utilisateur sur un site Web donné. Le WCA14 avait publié un projet portant sur les déﬁnitions des termes relatifs aux informations contenues dans les traces d’usage. Ils concernent notamment les notions d’utili-
14World Wide Web Comittee web usage characterization Activity : http ://www.w3.org/wca
59

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale

Tab. 2.1 – Principaux types de traces d’usage

Action

Description

Commander

Acheter un item

Evaluer

Noter un item

Utilisation répétée Consulter un item d’une manière répétitive

Enregistrer/Imprimer

Enregistrer ou imprimer un item

Supprimer

Supprimer un item

Référer

Faire référence à un item

Marquer

Ajouter aux favoris

Examiner/lire

Consulter la totalité de l’item

Considérer (Temps)

Consulter le résumé

Rechercher

Rechercher un item

sateur, de page (item), de clickstream et de session. Un utilisateur est déﬁni comme étant un individu accédant à un ﬁchier à partir d’un ou de plusieurs serveurs Web à travers son navigateur. Une page est représentée par tout ﬁchier contribuant à l’aﬃchage d’une vue sur le navigateur en un seul moment. Cette page comprend des “frames”, des graphiques, des scripts, etc. Un “clickstream” est un ensemble de séries séquentielles de requêtes de pages. Une session utilisateur est représentée par les clickstreams eﬀectués sur des pages durant une session, i.e. le moment où l’utilisateur a commencé la visite des pages Web et le moment où il a quitté le site Web en question.
Par ailleurs, [Nichols, 1997] a présenté un classement des traces d’usage dont les principaux types sont décrits dans le tableau 2.1. Ces traces concernent en particulier les sites d’e-commerce. Nous soulignons à ce niveau l’importance d’utiliser des actions telles que la commande ou la note d’un item aﬁn d’estimer l’intérêt porté sur cet item.
D’une manière générale, à partir de la navigation, chaque activité ou demande d’afﬁchage de page Web ou d’item de la part d’un utilisateur, génère une requête (http). Les informations relatives aux requêtes sont stockées automatiquement dans le ﬁchier log du serveur Web. Ce ﬁchier log constitue ainsi une importante source d’information dans la mesure où il permet de représenter le comportement navigationnel de l’utilisateur et d’inférer ses appréciations d’une manière “implicite” (contrairement à la façon explicite où l’utilisateur intervient directement pour fournir des informations sur ses appréciations vis-à-vis d’items).
Les ﬁchiers logs peuvent être stockés sous diﬀérents formats tels que “Common Log Format (CLF)” ou “Extended CLF (ECLF)”15. Le format le plus courant est le CLF [Srivastava et al., 2000]. Selon ce format, six informations sont stockées, à savoir :
– le nom ou l’adresse IP de la machine, – le nom et le login HTTP de l’utilisateur,
15http ://www.w3.org/TR/WD-logﬁle.html
60

2.3. Données exploitées
– la date de la requête (date, heure, écart GMT), – la méthode utilisée dans la requête (GET, POST, etc.) et le nom ou l’identiﬁant de
la ressource Web demandée, – le statut de la requête, – la taille du ﬁchier envoyé.
Le format ECLF représente une version plus complète du CLF. Il contient en plus le nom et la version du navigateur Web, le système d’exploitation et l’adresse de la page où se positionnait l’utilisateur au moment de l’envoi de la requête.
Le nom ou l’identiﬁant unique de l’utilisateur n’est pas souvent une information disponible à partir d’un ﬁchier log, surtout lorsqu’il concerne un site Web accessible aux utilisateurs sans authentiﬁcation. En eﬀet, les protocoles de communication ne peuvent pas identiﬁer un ordinateur via l’adresse IP. En outre, les serveurs proxy peuvent regrouper plusieurs utilisateurs ou ordinateurs sous la même adresse IP. De plus, souvent ces adresses IP sont dynamiques et sont régulièrement renouvellées.
Aﬁn de remédier à ce problème d’identiﬁcation de l’utilisateur, les “cookies” peuvent être utilisés. Néanmoins, le recours aux cookies demeure problématique16 dans la mesure où il pourrait être à l’encontre du respect de la vie privée et des données personnelles [Cooley et al., 1999]. En outre, les cookies ne sont pas ﬁables vu que plusieurs utilisateurs peuvent utiliser un même ordinateur. Il devient ainsi complexe d’identiﬁer un utilisateur unique.
En ce qui concerne notre contexte applicatif lié au portail Extranet du Crédit Agricole, le problème d’identiﬁcation de l’utilisateur à travers les ﬁchiers logs, n’est pas soulevé. En eﬀet, les utilisateurs ne peuvent accéder à ce portail Extranet sans être authentiﬁé (section 2.2). Ces logs sont stockées sous forme de ﬁchiers XML tel que présenté dans la ﬁgure 2.5. Ces ﬁchiers sont générés à partir de “log4j” qui est une API de journalisation très populaire dans le monde Java.
Les principales balises contenues dans ces ﬁchiers log sous format XML sont décrites dans le tableau 2.2. De ce fait, nous pouvons extraire à partir de ces ﬁchiers des informations concernant notamment : l’utilisateur (balise “mid”), l’item (balise “id”) et la session (balise “sessionId”).
Estimation des notes
Comme nous l’avions indiqué précédemment, nous avons choisi d’exploiter l’approche par analyse des usages dans le cadre de nos modèles de recommandation. Les modèles
16la CNIL(http ://www.cnil.fr) met en particulier en garde contre l’utilisation des cookies, pour le proﬁlage systématique des utilisateurs, à leur insu
61

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale Fig. 2.5 – Extrait du ﬁchier log en format XML

Tab. 2.2 – Description des principales balises du ﬁchier log du Crédit Agricole

Balise

Description

ip

L’IP de l’utilisateur

port

Le port de l’utilisateur

startDate / endDate Le temps de début et de ﬁn de consultation de l’item

method

GET ou POST du protocole HTTP

referer

L’URL source du clic

mid

Identiﬁant de l’utilisateur authentiﬁé sur JCMS

id

Identiﬁant de l’item

type

Type de l’item consulté (Faq, News, Brèves...)

pub

Identiﬁant de la publication parente

name

Nom de la page

sessionId

Identiﬁant de la session

port

Numéro du port

locale

La langue utilisée

userAgent

Le navigateur de l’utilisateur

proposés à travers cette thèse, dont la description sera détaillée dans la deuxième et la troisième partie de ce manuscrit, sont collaboratifs, centrés sur l’utilisateur et s’inscrivent dans le cadre des approches proactives de recommandation (c.f. section 1.2). Dans la phase de prédiction, nous avons exploité la fonction de prédiction du FC basé sur la mémoire, aﬁn de générer des valeurs numériques de prédiction, en se basant sur les notes “implicites” des voisins identiﬁés a priori. Le choix de calculer ces valeurs relève notamment du besoin de comparer la performance de nos approches au FC basé sur la mémoire, utilisé largement par la communauté scientiﬁque. De ce fait, pour calculer ces notes implicites, nous avons exploité les traces d’usage.
L’intérêt d’utiliser les traces d’usage pour estimer les appréciations ou les notes implicites a été déjà examiné dans quelques travaux de recherche. [Chan, 1999] exploite en eﬀet les traces d’usage aﬁn d’estimer l’intérêt que porte un utilisateur sur un item ou une page Web donnée. Chan a proposé à cet eﬀet la formule (2.1) “Page Interest Estimator” pour estimer une appréciation en prenant en compte les
62

2.3. Données exploitées
indicateurs suivants :
– la fréquence ou le nombre de visites d’une page Web (Frq(Page)), – l’ajout aux favoris d’une page Web (IsBookmark(Page)), – la durée de consultation d’une page Web (Dur(Page)), – la récence de visite d’une page Web (Rec(Page)), – les liens visités sur une page Web (LinkPerc(Page)).

Interest(P age) =

(2.1)

F rq(P age) ∗ (1 + IsBookmark(P age) + Dur(P age) + Rec(P age) + LinkP erc(P age)

Dans le cadre de notre travail de recherche, nous nous sommes inspirés de l’étude de [Chan, 1999] pour estimer les appréciations à partir des traces contenues dans les ﬁchiers logs du Crédit Agricole, concernant les items accessibles sur le portail Extranet. Il est à signaler qu’au départ, nous avions opté pour les indicateurs soulignés par [Chan, 1999] tels que : l’ajout aux favoris d’un item, la fréquence de consultation d’un item et la durée de consultation d’un item. Nous avions choisi en outre d’exploiter d’autres indicateurs tels que : l’envoi d’un item à un ami et l’impression d’un item. Toutefois, les informations se rapportant à certains indicateurs (comme l’ajout aux favoris, l’envoi ou l’impression d’un item) ne pouvaient pas être disponibles vu que les utilisateurs n’exploitent pas ces fonctionnalités au niveau du portail Extranet. De ce fait, nous avons retenu les indicateurs de fréquence de visite et de durée de visite d’un item. Notons que nous n’avons pas pris en compte le critère de récence parce que nous considérons que le fait de consulter un item plus récemment qu’un autre peut être lié notamment à la date de première publication de cet item. En eﬀet, comme la récence de visite d’un item (selon [Chan, 1999]) est évaluée notamment en fonction de la date actuelle, les items visités dont la publication est récente auront un plus grand poids au détriment des items publiés et visités précédemment. Or, ces derniers peuvent être plus pertinents pour l’utilisateur.
Le corpus de données que nous avons exploité et qui inclut ces ﬁchiers logs, comprend 748 utilisateurs et 3856 items. Ces données ont été collectées durant les années 2007 et 2008. Depuis l’année 2008, le corpus a augmenté en incluant de nouvelles données (ﬁchiers logs de navigation), mais pour des raisons de stabilisation d’échantillon, nous avons gardé le corpus initial. Comme dans un processus de WUM, la première étape consiste à prétraiter les traces d’usage [Cooley et al., 1999] [Han et Kamber, 2001] et à parser les ﬁchiers logs en XML, aﬁn d’eﬀectuer un “nettoyage” de données (en supprimant les entrées dans les logs qui ne sont pas nécessaires à l’analyse d’usage) et de repérer :
– l’identiﬁant de l’utilisateur,
63

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
– l’identiﬁant de l’item visité, – l’identiﬁant de la session, – le temps de début et de ﬁn de session, – le temps de visite d’un item.
Dans une deuxième étape, pour l’estimation des notes implicites, nous avons pris en compte les indicateurs précisés ci-dessus. La fréquence correspond au nombre de fois où l’utilisateur a consulté un item. Elle est calculée sur la base de l’équation (2.2). En considérant un utilisateur actif ua, la fréquence de visite d’un item ik est le ratio entre le nombre de visites de ik (N(ua,ik)) et le nombre moyen de visites de tous les items I (N(ua,I)).

F requency(ua,ik)

=

N(ua ,ik ) N(ua ,I )

(2.2)

En ce qui concerne la durée, elle est calculée comme le ratio entre la durée totale de visite de ik (Drt(ua,ik)) et la durée totale de visites de tous les items I (Drt(ua,I)), selon l’équation (2.3). La durée de visite d’un item a été calculée à partir des informations fournies par les balises “startDate” et “endDate” contenues dans les ﬁchiers logs. La durée maximale de visite d’un item a été ﬁxée par un “timeout” aﬁn d’éviter une situation où l’utilisateur ne consulte pas réellement l’item même s’il a envoyé une requête pour l’aﬃchage de cet item.

Duration(ua,ik)

=

D r t(ua ,ik ) Drt(ua,I)

(2.3)

Une fois les fréquences et les durées calculées pour chaque item, nous avons utilisé

l’équation (2.4) proposée par [Castagnos, 2008] aﬁn de pouvoir calculer et normaliser les

notes selon l’échelle choisie [1 − 5]. Il s’agit de l’échelle de note la plus utilisée par les

systèmes de recommandation exploitant les notes numériques.

Dans sur ik

l’équation (2.4) fT . vmin et vmax sont

rraensspf(eucat,iikv)edméesnigtnleeslanofotensctmioinnimdeumtraentsfmoramxiamtiuomn

de la note de ua correspondant à

l’échelle de note, i.e. 1 et 5. p(c) représente le poids attribué au critère (fréquence et durée

dans notre cas), c(ua, ik) est la valeur du critère et cmax représente la valeur maximum du critère.

fT ransf(ua,ik) = vmin + (

c

p(c) ∗ c(ua, c p(c)

ik)

∗

vmax − vmin ) cmax

(2.4)

Après la normalisation des valeurs, une matrice de notes “implicites” est générée, telles que les lignes représentent les utilisateurs et les colonnes représentent les items. Les notes

64

2.3. Données exploitées
implicites obtenues suite à l’application de cette normalisation ont été validées parce qu’elles correspondent à l’échelle de notes retenue [1 − 5] et leur répartition sur cette échelle reﬂète les diﬀérents degrés d’appréciation des utilisateurs concernant les items.
Pour les besoins d’évaluation, le corpus de données exploitant cette matrice a été réparti en deux corpus : un corpus d’apprentissage et un corpus de test qui comprennent respectivement 80% et 20% de données. Cette répartition a été eﬀectuée en prenant en considération l’ordre des sessions dans les ﬁchiers logs (i.e. pour un utilisateur donné, ses premières sessions font partie du corpus d’apprentissage alors que les sessions les plus récentes se retrouvent dans le corpus test).
Pour le corpus d’apprentissage, la matrice de note utilisée a un niveau de notes manquantes (“sparsity”) de 96%. Il est calculé comme étant le rapport entre le nombre d’entrées vides et le nombre total des entrées dans la matrice (taille de la matrice) (cf. équation 2.5).

N iveauSparsity = N ombreEntreesV ides T ailleM atrice

(2.5)

2.3.2 Corpus de notes explicites

Dans le but d’évaluer la qualité des recommandations produites par nos approches, nous avons eu recours également au corpus de données de notes explicites “Movielens” proposé par le laboratoire de recherche Grouplens17.
Le corpus utilisé comprend 100.000 notes attribuées par 943 utilisateurs sur 1682 ﬁlms. Les valeurs de notes sont des entiers qui correspondent à l’échelle [1 − 5]. Dans ce corpus, chaque utilisateur a au moins noté 20 items. 80% de ce corpus constitue les données d’apprentissage et 20% représente les données de test. Chaque ligne du corpus représente une note d’un utilisateur sur un ﬁlm en indiquant le timestamp de cette action. Le tableau 2.3 présente des exemples de lignes de notes provenant du corpus Movielens. Dans ces lignes les informations sont présentées sous la forme suivante : utilisateur id | item id | note | timestamp.

Tab. 2.3 – Exemple de notes du corpus Movielens

Identiﬁant de l’utilisateur Identiﬁant de l’item Note attribuée

196

242

3

184

302

4

22

177

1

Timestamp 881250949 891717742 878887116

17http ://www.grouplens.org

65

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
Le niveau de manque de données (“sparsity”) correspondant à la matrice de notes Movielens est équivalent à environ 94%.
L’utilité du corpus Movielens reste indéniable. En eﬀet, il intègre d’une part des données de notes explicites réelles des utilisateurs, attribués à travers la plate-forme de recommandation Movielens18 (permettant de générer des recommandations personnalisées de ﬁlms). D’autre part, il est largement exploité par la communauté scientiﬁque, d’où l’intérêt de son utilisation pour expérimenter et valider les approches de recommandation proposées en les comparant aux travaux de recherche existants. Toutefois, l’inconvénient de l’utilisation de ce corpus est qu’il ne représente pas réellement un corpus de traces d’usage. En eﬀet, les consultations d’items contenues dans ce corpus ne constituent pas de réelles séquences de navigation des utilisateurs. Il s’agit d’une suite d’items notés successivemennt par les utilisateurs sur la plate-forme Movielens.
2.4 Évaluation des recommandations
Aﬁn d’évaluer la performance des systèmes de recommandation et de valider les approches de recommandation que nous proposons par rapport à des approches de l’état de l’art, diﬀérentes métriques d’évaluation sont utilisées dans la cadre des expérimentations. Le choix de telle ou telle métrique dépend notamment de la problématique de départ, des objectifs escomptés et de la nature de l’expérimentation à mener. [Paris et al., 2009] proposent une méthode d’évaluation qui prend en considération les différents acteurs dans le cadre d’une activité de recherche d’information dont notamment l’utilisateur, le système de recherche d’information et le fournisseur du contenu informationnel. Dans le contexte des systèmes de recommandation, [Herlocker et al., 2004] ont étudié les diﬀérentes stratégies d’évaluation du point de vue utilisateur, prédictions, types de corpus utilisés, etc. D’une manière générale, les diﬀérentes métriques d’évaluation évaluent la précision, la couverture, la satisfaction de l’utilisateur, la robustesse et le passage à l’échelle.
Le critère le plus évalué dans le cadre des systèmes de recommandation est la précision. La précision mesure la performance du système de recommandation en évaluant la qualité des prédictions comparées aux appréciations réelles. Les mesures de précision peuvent être soit statistiques, soit des mesures permettant l’aide à la décision.
18http ://www.movielens.org
66

2.4. Évaluation des recommandations
2.4.1 Mesures statistiques de précision

MAE
Les mesures statistiques de précision consistent à évaluer la diﬀérence existant entre les notes prédites et les notes réellement attribuées par les utilisateurs. La mesure de précision la plus populaire pour l’évaluation des systèmes de recommandation est la MAE (Mean Absolute Error). Selon l’équation (2.6), la MAE calcule, pour chaque paire <noteprédiction>, la moyenne d’erreur absolue entre les notes prédites P red(ua, i) et les notes réelles des utilisateurs v(ua, i). n représente le nombre d’items prédits présents dans le corpus test. Plus la valeur de MAE est faible, plus les prédictions sont précises et le système de recommandation est performant.

M AE =

n i=1

|v(ua,

i)

−

P

red(ua,

i)|

n

(2.6)

La MAE a été fréquemment utilisée pour l’évaluation des systèmes de recommandation et du FC [Shardanand et Maes, 1995] [Herlocker et al., 1999]. L’avantage de la MAE est qu’elle est simple à utiliser, facile à interpréter et qu’elle est largement utilisée par la communauté scientiﬁque, ce qui permet de positionner les approches de recommandation proposées par rapport aux travaux de recherche existants. Néanmoins, pour l’évaluation de systèmes de recommandation proposant des listes ordonnées de recommandation (listes TopN), la mesure MAE peut ne pas être appropriée [McLaughlin et Herlocker, 2004].
Il existe d’autres mesures statistiques de précision évaluant les prédictions numériques, notamment : “Root Mean Squared Error”, “Mean Squared Error” qui attribuent un poids plus important aux prédictions dont l’erreur est élevée, par rapport aux prédictions précises (i.e. ces deux mesures pénalisent plus que la MAE les sytèmes de recommandation générant des prédictions dont le taux de précision est faible).

HMAE
Les systèmes de recommandations ont pour objectif de calculer les prédictions des notes manquantes concernant le maximum de paires <utilisateur-item>. Une fois ces prédictions calculées, les items ne sont pas tous recommandés par la suite aux utilisateurs. En eﬀet, seuls les items ayant les valeurs de prédiction les plus élevées sont proposées. Dans ce cas, l’erreur concernant les items ayant de faibles valeurs de prédiction n’est pas utile quant à l’évaluation de la performance des systèmes de recommandation, tandis que l’erreur relative aux items ayant des notes prédites élevées est d’une grande importance
67

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
en terme d’évaluation. La HMAE permet en eﬀet d’évaluer les “faux positifs” qui représentent les items jugés pertinents par le système, alors qu’ils ne le sont pas réellement (en comparaison avec le corpus test par exemple). Avec la détection des faux positifs, le système ne risque pas d’être pénalisé suite à une recommandation d’item non pertinent susceptible d’engendrer une insatisfaction chez l’utilisateur.
Aﬁn d’évaluer la capacité d’un système de recommandation à proposer des items pertinents aux utilisateurs actifs, la HMAE (High MAE) [Baltrunas et Ricci, 2007] peut être utilisée. Selon l’équation (2.7), la HMAE est similaire à la MAE, mais elle a la particularité de considérer uniquement les prédictions élevées. Dans le cadre de nos expérimentations, nous avons pris en compte les notes P red′(ua, i) ∈ [4 − 5] comme étant les notes élevées. m représente ici le nombre d’items prédits avec des valeurs élevées. Plus la valeur de HMAE est faible, plus le système de recommandation est performant.

HM AE =

m i=1

|v(ua,

i)

−

P

red′(ua

,

i)|

m

(2.7)

La HMAE n’exploite pas les items ayant des valeurs de prédictions faibles, mais qui ont des valeurs réelles élevées dans le corpus test. Son avantage est sa capacité à évaluer la précision des recommandations, jugées pertinentes, qui sont eﬀectivement suggérées aux utilisateurs.

2.4.2 Mesures permettant l’aide à la décision
Les mesures permettant l’aide à la décision consistent à évaluer jusqu’à quel point le système de recommandation peut recommander des items potentiellement pertinents pour l’utilisateur [Adomavicius et Tuzhilin, 2005] (les items susceptibles d’être très appréciés). En d’autres termes, ces mesures évaluent la pertinence des recommandations en calculant, dans une liste de recommandation, la proportion d’items qui sont eﬀectivement utiles et pertinents pour l’utilisateur actif.
Pour les besoins d’évaluation en terme d’aide à la décision, les appréciations ou les notes des utilisateurs doivent être transformées dans le cadre d’une échelle binaire (“Aime” ou “Aime pas”) aﬁn de distinguer les items pertinents de ceux qui ne le sont pas, pour un utilisateur donné. Ainsi, dans le cadre de nos expérimentations, un item est considéré comme pertinent lorsqu’il dispose des valeurs les plus élevées, c’est-à-dire des valeurs entre 4 et 5 sur l’échelle choisie [1 − 5]. Nous considérons que les notes de 1 à 3 correspondent à des items non pertinents pour l’utilisateur.
Les mesures permettant l’aide à la décision sont principalement issues du domaine de
68

2.4. Évaluation des recommandations
la recherche d’information. Elles incluent notamment : la précision, le rappel et la mesure F1 [Herlocker et al., 2004].

Précision
La précision évalue si un item sélectionné par un utilisateur est réellement perçu comme étant pertinent par ce même utilisateur [Anand et Mobasher, 2005]. Un item sélectionné représente un item qui est proposé par le système de recommandation à l’utilisateur actif et qui est contenu en même temps dans le corpus test. Le tableau 2.4 [Herlocker et al., 2004] présente les catégories d’items répartis selon l’intersection entre les listes de recommandation et les appréciations réelles des utilisateurs. A partir de ce tableau, la précision est calculée sur la base de l’équation (2.8) comme étant le rapport entre le nombre d’items pertinents sélectionnés Nps et le nombre d’items sélectionnés par un utilisateur actif Ns.

P = Nps Ns

(2.8)

La précision générale du système de recommandation correspond ainsi à la moyenne des précisions calculées pour chaque utilisateur actif. Plus cette précision est élevée, plus le système de recommandation est performant.

Tab. 2.4 – Catégories d’items basées sur l’intersection entre listes de recommandation et préférences réelles
Sélectionné (s) Non Sélectionné (ns) Total

Pertinent (p) Non Pertinent (np)
Total

Nps Nnps Ns

Npns Nnpns Nns

Np Nnp N

Rappel
Le rappel mesure la probabilité qu’un item pertinent soit sélectionné par l’utilisateur actif. Il est calculé sur la base de l’équation (2.9) comme étant le ratio entre le nombre d’items pertinents sélectionnés par l’utilisateur “Nps” et le nombre total d’items pertinents disponibles “Np” [Herlocker et al., 2004].

R = Nps Np

(2.9) 69

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale
Comme pour la précision, le rappel relatif à la totalité du système est évalué comme étant la moyenne des rappels calculés individuellement.
Il existe une mesure combinant la précision et le rappel [Sarwar et al., 2000a]. Il s’agit de la mesure “F1”. Elle représente la moyenne harmonique entre la précision et le rappel, suivant l’équation (2.10). La valeur de F1 varie de 0 à 1. Lorsque les scores de précision et de rappel sont équivalents, la qualité des recommandations est considérée comme parfaite.

F1

=

2P R P +R

(2.10)

2.4.3 Couverture
La couverture mesure la capacité du système à fournir des recommandations. En FC basé sur la mémoire, la couverture peut être évaluée par rapport à la capacité du système de recommandation à générer des prédictions pour toutes les notes manquantes au niveau de la matrice de notes “Utilisateur x Item”. Elle peut être également évaluée en prenant en considération uniquement les prédictions contenues dans le corpus test19. En eﬀet, dans certains cas, le système de recommandation exploitant le FC, peut être incapable de calculer les recommandations. Cette incapacité peut notamment être engendrée par le manque de données. En eﬀet, faute de notes provenant des voisins, le système aura des diﬃcultés à calculer certaines prédictions.
Ainsi, un système de recommandation ne peut être performant que lorsqu’il est susceptible de calculer un nombre suﬃsant de prédictions concernant un maximum d’utilisateurs. Autrement dit, le système doit pouvoir répondre aux attentes des diﬀérents utilisateurs actifs présents dans le système.

2.4.4 Temps de calcul
La performance d’un système de recommandation peut être également évaluée en terme de temps de calcul. Il s’agit d’un temps de calcul réel qui permet d’évaluer le temps requis pour l’exécution des algorithmes et l’obtention des résultats escomptés. Il va de soi que la mesure du temps de calcul est dépendante des spéciﬁcations matérielles de la machine utilisée pour l’exécution de ces calculs, ainsi que des programmes et applications lancés simultanément sur cette machine au moment des calculs. En ce qui concerne nos expérimentations, elles ont été réalisées sur un PC DELL avec Windows Server 2003, ayant 2 Go de RAM et un processeur de 3,4 GHz (Pentium IV).
19L’intérêt de cette évaluation découle du fait que la qualité des recommandations est mesurée également sur le corpus test
70

2.5 Benchmark

2.5. Benchmark

La validation des approches et des algorithmes de recommandation proposés dans le cadre de cette thèse repose sur l’évaluation de la performance de ces approches comparée à des modèles de l’état de l’art. Nous avons ainsi choisi de comparer nos approches au principal modèle de l’état de l’art qui est le FC que nous allons appeler dans la suite de cette thèse “Filtrage Collaboratif Standard” (FCS) (cf. section 1.3.2). Le FCS est une méthode de recommandation basée sur la mémoire, exploitant les données de notes aﬁn de prédire les futures appréciations des utilisateurs. Pour identiﬁer les plus proches voisins, le FCS utilise le “coeﬃcient de corrélation de Pearson” aﬁn d’évaluer les similarités entre utilisateurs. Les voisins identiﬁés sont par la suite impliqués au calcul des prédictions en se basant sur la “somme pondérée”.
Il est à signaler qu’au moment de la prédiction, les mêmes paramètres ont été appliqués à la fois à nos approches et au FCS aﬁn de permettre leur comparaison. Ces paramètres concernent le seuil de similarité et le nombre d’items co-notés entre un utilisateur actif et ses voisins, permettant le choix des voisins les plus proches.
Dans ce chapitre, nous avons présenté le schéma générique de la recommandation, tel que nous le percevons. Nous avons également décrit le contexte applicatif ainsi que la méthodologie expérimentale incluant les corpus et les métriques d’évaluation utilisés pour évaluer la performance des modèles que nous avons proposés. La partie suivante est consacrée à la présentation de l’approche collaborative comportementale de recommandation, qui représente l’une des contributions majeures de cette thèse.

71

Chapitre 2. Schéma générique, contexte applicatif et méthodologie expérimentale 72

Deuxième partie Approche collaborative comportementale de recommandation
73

Chapitre 1
Vers un Filtrage Collaboratif Comportemental
Parmi les verrous qui entravent la performance des systèmes de recommandation, nous pouvons citer : le manque de données (de notes explicites) ainsi que la précision des recommandations (cf. section 1.4, chapitre 1, partie 1). Dans la perspective de lever ce verrou et d’améliorer la performance des systèmes de recommandation, nous avons proposé un nouveau modèle de recommandation qui repose sur un ﬁltrage collaboratif comportemental centré sur l’utilisateur. Ce modèle est appellé “Behavioral Network Collaborative Filtering (BNCF)” [Esslimani et al., 2008b] [Esslimani et al., 2008a]. Selon la classiﬁcation des approches de recommandation de [Anand et Mobasher, 2005], ce modèle s’inscrit dans le cadre des approches proactives de recommandation qui privilégient la déduction des appréciations. Ainsi, contrairement aux approches réactives, le retour de l’utilisateur et le recours à l’élicitation n’est pas nécessaire. Ce modèle consiste à observer le comportement navigationnel de l’utilisateur et à analyser ses traces d’usage dans le but de modéliser cet utilisateur. La construction d’un modèle utilisateur dans le cadre du BNCF repose sur l’analyse du comportement aﬁn de prédire les goûts de l’utilisateur et d’estimer l’intérêt qu’il porte à chaque item.
Le concept de comportement englobe généralement diﬀérents aspects se rapportant à l’agissement et aux réactions d’un utilisateur dans une situation donnée. Ce comportement peut être notamment représenté par les mouvements, les actions ou les expressions verbales de cet utilisateur. Dans le contexte des systèmes d’information sur le Web (portail d’entreprise par exemple), nous entendons par comportement, l’ensemble des actions liées à la navigation de l’utilisateur à travers un site Web. Ces actions peuvent être observées à partir de (cf. section 1.2 du chapitre 1, partie 1) :
– une consultation de page Web ou d’item, – une manipulation d’item : des actions de copier/coller, d’enregistrement ou d’im-
75

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
pression, d’ajout aux favoris, d’envoi par mail, etc. – indicateurs externes comme l’oculométrie (“eye-tracking”), – indicateurs de navigation : fréquence et durée de visite d’item.
Dans le cadre du BNCF, nous considérons comme traces d’usage, les actions de consultation d’un item (en phase d’apprentissage) ainsi que les indicateurs de navigation (en phase de prédiction). Nous supposons en eﬀet que l’analyse de ces traces est susceptible de mettre en évidence des similarités de comportement navigationnel entre utilisateurs. Le BNCF est ainsi capable d’exploiter ces similarités en vue de recommander des items à un utilisateur actif, adaptés à ses besoins.
Le modèle BNCF est inspiré à la fois des approches prédictives issues du WUM (Web Usage Mining), ainsi que des approches de recommandation basées sur la mémoire tel que le Filtrage Collaboratif Standard (FCS) [Goldberg et al., 1992]. L’objectif du BNCF est de tirer proﬁt des avantages des deux approches du WUM et du FCS, tout en remédiant aux limites qu’elles présentent. En eﬀet, les modèles basés sur le WUM [Anand et Mobasher, 2005] exploitent les traces d’usage dans le but d’eﬀectuer les prédictions, grâce notamment à la découverte des motifs d’usage. Or, ces modèles requièrent une masse importante de données ou de traces aﬁn de pouvoir extraire des motifs pertinents et de générer des prédictions ﬁables. En outre, l’utilisateur n’est pas considéré pendant le processus de prédiction. Par exemple, nous supposons qu’un modèle (standard) de WUM extrait le motif fréquent noté i8i5i2 , signiﬁant que parmi toutes les traces d’usage analysées, la consultation de l’item i2 est fréquemment produite après la séquence {i8, i5} (i.e. la consultation de i8 puis de i5). Peu importe l’utilisateur qui aura réalisé la séquence {i8, i5} pendant une session de navigation sur un site Web, l’item i2 sera recommandé.
Quant au FCS, malgré son succès, certaines questions de recherche restent soulevées, dont notamment le manque de données explicites (les notes des utilisateurs). Par conséquent, un système de recommandation exploitant exclusivement ces données, peut être incapable de générer des prédictions adéquates s’il ne retrouve pas suﬃsamment de notes disponibles dans le système permettant l’identiﬁcation des voisins. A cet eﬀet, l’exploitation du comportement dans un processus de recommandation permet d’éviter le problème de rareté des données de notes explicites. En eﬀet, dans le cas d’une navigation sur le Web, la quantité de traces est potentiellement supérieure à la quantité de notes explicites pouvant être disponible. En outre, l’exploitation du comportement permet de réduire le processus d’élicitation. En eﬀet, la sollicitation directe de l’utilisateur n’est pas requise. A partir du comportement de navigation, le système est capable d’évaluer les appréciations potentielles des utilisateurs vis-à-vis d’items et même de mesurer les similarités entre utilisateurs, tel que nous le proposons ici.
La ﬁgure 1.1 décrit les diﬀérentes phases du processus de recommandation correspondant au BNCF et au FCS. Le BNCF comprend deux phases majeures : une phase
76

Fig. 1.1 – FC comportemental “BNCF”
d’apprentissage des modèles utilisateurs (PHASE I) inspirée du WUM et une phase de génération des prédictions (PHASE II) inspirée du FCS. Dans la phase d’apprentissage, à partir des traces d’usage (les consultations d’items), le BNCF identiﬁe les séquences de navigation des utilisateurs. Ces séquences sont par la suite analysées aﬁn d’extraire les motifs d’usage. Ces motifs sont exploités en vue d’évaluer les similarités de comportement et de générer une matrice de similarité “Utilisateur x
77

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
Utilisateur”. Ainsi, la particularité du modèle BNCF réside dans l’exploitation des motifs dans le but d’évaluer les similarités entre utilisateurs et non pas pour prédire directement comme dans le WUM. La deuxième phase (PHASE II) représente la phase de prédiction. Elle vise à identiﬁer les plus proches voisins à partir de la matrice de similarité générée et utilise leurs appréciations extraites de la matrice de notes “Utilisateur x Item” (notes estimées à partir des traces d’usage) aﬁn de calculer les prédictions pour chaque utilisateur actif. Le modèle FCS inclut également deux phases. La première phase (PHASE I) permet de calculer les similarités de note entre utilisateurs en exploitant la matrice de note “Utilisateur x Item”. Dans la deuxième phase du FCS (PHASE II), il s’agit d’exploiter ces similarités aﬁn de calculer les prédictions en utilisant les appréciations des voisins. Le dernier volet de la ﬁgure 1.1 correspond à l’hybridation des prédictions générées par le BNCF et le FCS. Cette hybridation consiste à étudier l’impact de chaque modèle sur la performance du système de recommandation et à évaluer leur éventuelle complémentarité.
Ces phases vont être décrites en détails dans ce qui suit.
1.1 Extraction des motifs d’usage et calcul des similarités de comportement
La première phase du BNCF consiste en l’extraction des motifs d’usage qui vont être exploités aﬁn de calculer les similarités de comportement navigationnel entre les paires d’utilisateurs. Dans le cadre du BNCF, nous supposons que plus la longueur d’un motif commun à deux utilisateurs est élevée, plus ils ont un comportement similaire. Nous entendons ici par motif, une séquence fréquente, contenant une suite ordonnée d’items et qui est commune à deux utilisateurs (cf. section 1.3.4, chapitre 1, partie 1).
L’algorithme 3 présente le processus d’extraction de la longueur maximale de motifs communs. Ainsi, pour toute paire d’utilisateurs ua,ub , cet algorithme exploite en entrée les séquences de navigation contenues dans leurs sessions, notées respectivement Sua et Sub, dans l’objectif d’extraire leurs motifs communs (βi) et de calculer les longueurs correspondant à ces motifs L(βi). Chaque longueur correspond au nombre d’items contenus dans un motif commun. L’algorithme permet de calculer les longueurs de motifs pour chaque paire d’utilisateurs ua,ub et d’en déduire la longueur maximale des motifs Lmax (Lmax(ua, ub) = M ax(L(βi))) communs à ua et ub.
A la diﬀérence des motifs utilisés dans le domaine du WUM, dans notre modèle nous ne spéciﬁons pas de support minimum déterminant un seuil pour la sélection des motifs (par exemple 20%, 30% ou 50%). En eﬀet, l’extraction de motifs dans le cadre du BNCF est eﬀectuée par paire d’utilisateurs, ce qui implique que le support correspondant est in-
78

1.1. Extraction des motifs d’usage et calcul des similarités de comportement

tuitivement égal à 100%, i.e. le motif doit être nécessairement présent parmi les séquences des deux utilisateurs à la fois pour qu’il soit extrait.
Algorithm 3 Extraction de la longueur maximale de motifs 1: Input : Items ordonnés par sessions pour les utilisateurs ua et ub 2: Output : Longueur maximale de motifs communs 3: Sua = { S1−ua , S2−ua , ...Sj−ua }, Sub = { S1−ub , S2−ub , ...Sκ−ub } 4: β et γ sont deux séquences telles que : β ⊂ Sµ−ua et γ ⊂ Sν−ub, µ ∈ [1, ..., j] et ν ∈ [1, ..., κ], β = { i1, i2, ...in }, γ = { i′1, i′2, ...i′n } 5: L(β) = |β|

6: for each <ua,ub> (ua = ub) do

7: for each session de Sua do

8:

for each session de Sub do

9:

if ∃ entiers ent1<ent2<ent3...<entn Tel que i1 = i′1, i2 = i′2,....in = i′n

then

10:

return L(βi)

11:

end if

12:

end for

13: end for

14: return M ax(L(βi))

15: end for

Aﬁn d’évaluer les similarités entre utilisateurs, nous avons proposé la nouvelle équation (1.1), permettant de calculer la similarité de navigation ou de comportement entre deux utilisateurs donnés. Cette équation prend en considération les critères suivants :

– les motifs communs entre ces deux utilisateurs, – la longueur maximale de leurs motifs communs, – les tailles maximales de leurs sessions.

SimN av(ua, ub)

=

Lmax(ua, ub) min(SessM ax(ua), SessM ax(ub))

(1.1)

L’equation (1.1) calcule la similarité SimN av(ua, ub) entre les utilisateurs ua et ub comme étant le ratio entre la longueur maximale de leurs motifs communs Lmax(ua, ub) et le minimum des tailles maximales des sessions de ua et ub notées respectivement SessM ax(ua) et SessM ax(ub). Notons que la valeur de SimN av(ua, ub) est normalisée entre 0 et 1. Ainsi, plus la taille de Lmax est proche des tailles de sessions des deux utilisateurs, plus SimN av(ua, ub) tend vers 1 signiﬁant que ua et ub ont des comportements très similaires.
Il est à signaler que dans le but d’améliorer le traitement requis pour l’extraction des
motifs d’usage et pour l’évaluation des similarités, nous avons évidemment réduit les
paires concernées par le calcul des similarités, en considérant les relations symétriques

79

Chapitre 1. Vers un Filtrage Collaboratif Comportemental

Tab. 1.1 – Séquences d’items de u1 et u2

Utilisateur u1

Utilisateur u2

Sessions de u1 Items Sessions de u2 Items

S1−u1

i1 i5 i14 i9

S1−u2

i12 i1 i5 i8

S2−u1

i2 i10

S2−u2

i20 i25 i15

S3−u1

i8 i20 i13

S3−u2

i7 i18 i2 i19

(SimN av(ua, ub) = SimN av(ub, ua)). Au niveau de l’équation (1.1), nous avons utilisé le minimum des tailles maximales de session dans le dénominateur aﬁn d’éviter de pénaliser un nouvel utilisateur qui a réalisé peu de sessions de faible taille et tout utilisateur qui dispose de sessions courtes. En effet, si nous considérons le maximum ou la moyenne des sessions au dénominateur au lieu du minimum, un utilisateur ayant réalisé uniquement des sessions courtes (en consultant par exemple un ou deux items par session) sera toujours faiblement similaire aux autres utilisateurs disposant de sessions de taille importante. Cette nouvelle équation met ainsi l’accent sur l’apport des motifs d’usage pour évaluer les similarités de comportement navigationnel entre utilisateurs.
Aﬁn d’illustrer ce processus, nous proposons l’exemple du tableau 1.1 qui présente les séquences d’items consultés par les utilisateurs u1 et u2 par session. En utilisant ces sessions, nous retrouvons que u1 et u2 ont les motifs communs suivants :
– motifs de longueur 1 (L = 1) : i1 i5 i8 i20 i2 (les items i14, i9, i10, i13 étant consultés uniquement par u1 et non pas par u2. De même, les items i7, i18, i19, i25, i15, i12 sont consultés uniquement par u2),
– motifs de longueur 2 (L = 2) : i1i5 , – motifs de longueur 3 (L = 3) : ∅.
Ainsi, pour u1 et u2, la longueur maximale Lmax(u1, u2) de leurs motifs communs est 2 correspondant au motif i1i5 et le min(SessM ax(u1), SessM ax(u2)) vaut 4. Alors, la similarité entre u1 et u2 est équivalente à 0.5.
En outre, en guise d’exemple de calcul des similarités par le modèle BNCF comparé au FCS entre deux utilisateurs u3 et u4 (notées respectivement SimN av(u3, u4) et SimN ote(u3, u4)), nous considérons le tableau 1.2 représentant les items consultés ou notés par ces deux utilisateurs. Notons que, pour des raisons de simplicité, ce tableau présente uniquement une session par utilisateur. Nous pouvons remarquer que u3 et u4 ont noté en commun les items i3 et i5 (Ic = {i3, i5}), qui représentent en même temps leur motif commun le plus long ( i3i5 ). Ainsi, la longueur maximale correspondante est 2 (Lmax(u3, u4) = 2). Les tailles maximales des sessions de u3 et u4 (S1−u3 et S1−u4) sont équivalentes respectivement à 5 et 6. Nous retiendrons 5 comme étant le minimum des tailles maximales de leurs sessions. Alors, nous pouvons calculer les similarités ainsi :
80

1.2. Génération des prédictions

Tab. 1.2 – Items consultés par les utilisateurs u3 et u4

Utilisateurs Session

Items

Notes Moyenne de note

u3

S1−u3

i1 i3 i5 i10 i13

14425

3

u4

S1−u4 i3 i5 i18 i16 i30 i2 4 4 2 2 1 5

3

–

SimN av(u3, u4)

=

2 5

= 0.4

–

SimN ote(u3, u4) =

P
i∈Ic

(v(u3

,i)−v(u3

))(v(u4,i)−v(u4

))

q

P
i∈Ic

(v(u3

,i)−v(u3

))2

P
i∈Ic

(v(u4,i)−v(u4

))2

= √ (4−3)(4−3)+(4−3)(4−3)

=1

((4−3)2+(4−3)2)((4−3)2+(4−3)2)

L’écart entre SimN av(u3, u4) et SimN ote(u3, u4) est dû d’une part à la diﬀérence de données utilisées séparément par le BNCF et le FCS, d’autre part, à la technique
permettant l’évaluation des similarités entre utilisateurs. A partir de cet exemple, nous
constatons que u3 et u4 sont considérablement similaires en terme de notes. Or, en terme de comportement navigationnel, ces utilisateurs ne sont pas très similaires.

Cette phase (PHASE I) du BNCF, décrite dans cette section, permet de générer une matrice de similarité de comportement “Utilisateur x Utilisateur”. Les voisins peuvent ainsi être identiﬁés et intégrés, dans une étape suivante, au calcul des prédictions.

1.2 Génération des prédictions

Une fois les similarités calculées entre utilisateurs, la deuxième phase (PHASE II) du BNCF exploite la matrice de similarité générée aﬁn d’identiﬁer les voisins. Les appréciations de ces voisins (récupérées à partir de la matrice de notes) sont par la suite considérées lors du calcul des prédictions. Ces prédictions sont générées sur la base de la somme pondérée (cf. section 1.3.2, chapitre 1, partie 1), présentée dans l’équation (1.2). Cette équation est en eﬀet la plus utilisée par les systèmes de recommandation exploitant notamment le FCS. SimN av(ua, ub) représente la valeur de similarité comportementale. Seuls les voisins qui sont corrélés avec l’utilisateur actif ua (notés Ua) et ayant déjà noté l’item ik sont considérés lors du calcul des prédictions.

P red(ua, ik) = v(ua) +

ub∈Ua SimN av(ua, ub) ∗ (v(ub, ik) − v(ub)) ub∈Ua SimN av(ua, ub)

(1.2)

Dans le but d’évaluer la performance de notre nouveau modèle BNCF comparé au FCS, d’étudier leur éventuelle complémentarité et d’examiner la capacité du BNCF à

81

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
améliorer la précision des recommandations, nous avons également choisi de combiner les prédictions provenant de chacun de ces deux modèles (BNCF et FCS) dans le cadre d’un système de recommandation hybride. Comme nous l’avons décrit dans l’état de l’art, les systèmes de recommandation hybrides combinent deux ou plusieurs techniques aﬁn de combler les faiblesses d’une technique par une autre. Le dernier volet de la ﬁgure 1.1 représente l’étape d’hybridation des prédictions. Ces prédictions sont combinées sur la base de l’équation (1.3) selon une méthode pondérée d’hybridation [Burke, 2002]. P redComb(ua, ik) représente la prédiction combinée à partir des prédictions du BNCF et du FCS notées respectivement P redBN CF (ua, ik) et P redF CS(ua, ik), pour un utilisateur actif ua concernant un item ik. α ∈ [0 − 1] désigne le paramètre de combinaison linéaire des prédictions. Il représente le poids de chaque modèle.
P redComb(ua, ik) = α ∗ P redBN CF (ua, ik) + (1 − α) ∗ P redF CS(ua, ik) (1.3)
Il est à rappeler que pour le calcul des P redF CS(ua, ik), la similarité de note entre utilisateurs est utilisée. Cette similarité est calculée avec le coeﬃcient de Pearson. De ce fait, la principale divergence entre les modèles BNCF et FCS réside dans la phase d’apprentissage permettant le calcul des similarités.
1.3 Evaluation de la qualité des prédictions
En vue d’évaluer la qualité des prédictions générées par le BNCF et le FCS, nous avons utilisé le corpus Movielens ainsi que le corpus du Crédit Agricole décrits dans la section 2.3.2 du chapitre précédent.
Le corpus Movielens comprend 100.000 notes explicites attribués par 943 utilisateurs sur 1682 items (ﬁlms). Ce corpus ne contient pas de données réelles d’usage et la notion de session n’est pas vraiment explicite. Il s’agit d’une suite d’items, qui ont été notés par les utilisateurs du système Movielens, selon des dates données (“timestamp”). A cet eﬀet, pour l’adapter à nos besoins, nous avons considéré qu’une session correspond, dans ce corpus, à une valeur spéciﬁque de timestamp. Or, la limite de la considération de ces timestamp est que les sessions correspondantes sont parfois très courtes. Il est à signaler que pour obtenir des motifs ﬁables et reﬂétant mieux la similarité du comportement entre utilisateurs dans le cadre du BNCF, nous n’avons pas considéré les sessions de taille 1 (i.e. des sessions où l’utilisateur a noté un seul item). Concernant l’ordre séquentiel des items, nous avons considéré l’ordre des items tels qu’ils ﬁgurent dans le ﬁchier qui comprend le corpus d’apprentissage.
82

1.3. Evaluation de la qualité des prédictions
Le corpus du Crédit Agricole constitue un corpus d’usage réel incluant les ﬁchiers logs qui correspondent aux activités de navigation de 748 utilisateurs pouvant consulter plus de 3000 items sur le portail Extranet. Nous avons extrait principalement les informations se rapportant aux identiﬁants d’utilisateurs (il s’agit d’identiﬁants anonymes), les séquences d’items consultés, les identiﬁants de sessions et le temps de début et de ﬁn de session (cf. section 2.3.1, chapitre 2, partie 1).
Pour évaluer la précision des prédictions générées (PHASE II), nous avons utilisé les métriques d’évaluation MAE et HMAE (cf. section 2.4 du chapitre précédent). En outre, l’objectif de cette expérimentation consiste à évaluer également la robustesse et la stabilité de notre système de recommandation en présence de notes non valides. Ainsi, dans l’expérimentation, nous avons modiﬁé les entrées en inversant en particulier les notes ayant les valeurs de 4 et 5 dans le corpus test. Le but est d’analyser la stabilité du BNCF et du FCS en calculant la HMAE sur ce nouveau corpus. Il s’agit en eﬀet d’évaluer jusqu’à quel point le système de recommandation peut être stable au niveau des prédictions générées et en particulier pour celles qui sont équivalentes à 4 et 5, correspondant aux items qui seront recommandés à l’utilisateur actif.
1.3.1 Résultats
Dans l’objectif d’analyser la performance de notre modèle, nous avons d’abord comparé la précision des prédictions générées par le système de recommandation en considérant que α vaut soit 0 ou bien 1. Il s’agit d’une évaluation séparée de chacun des modèles BNCF et FCS, au niveau de la qualité des prédictions en termes de MAE, de HMAE et de robustesse.
Pour la sélection des plus proches voisins au niveau des deux modèles étudiés, sur les deux corpus expérimentés, nous avons appliqué les stratégies suivantes (cf. section 1.3.2 du chapitre 1, partie 1) :
– Un seuil de similarité minimum entre un utilisateur actif et les voisins, noté θ.
– La déﬁnition d’un nombre minimum d’items co-notés (pour le FCS) ou co-visités (pour le BNCF) entre un utilisateur actif et ses voisins. Pour toutes les expérimentations, nous avons testé d’abord diﬀérentes valeurs du nombre d’items co-notés/covisités. Nous avons déduit que 20 permet de réaliser les meilleurs résultats de MAE (stratégie conﬁrmée en eﬀet par [Viappiani et al., 2006]). De ce fait, nous avons retenu ce nombre en tant que paramètre de sélection des plus proches voisins.
Ainsi, tous les utilisateurs ayant co-noté ou co-visité un minimum de 20 items avec l’utilisateur actif et ayant une similarité supérieure à θ avec cet utilisateur, sont considérés
83

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
comme les plus proches voisins de cet utilisateur actif.
La ﬁgure 1.2 présente les pourcentages de voisins répartis selon les intervalles de similarités calculés sur le corpus Movielens, par les modèles BNCF et FCS. Les pourcentages présentés dans la ﬁgure 1.2 ont été calculés par rapport au nombre total de voisins obtenu après l’application des deux stratégies présentées ci-dessus. En observant cette distribution, nous remarquons que la plus grande proportion de voisins calculés par le BNCF sur ce corpus (environ 90% du nombre total de voisins) ont des similarités entre 0.2 et 0.4. Pour le FCS, la répartition de ces voisins est relativement similaire à celle du BNCF, la plupart des voisins (environ 84% du nombre total des plus proches voisins identiﬁés par le FCS) ont des similarités entre 0 et 0.4. Notons que lorsque la similarité surpasse le seuil de 0.4 et tend vers 1, le nombre de voisins devient très faible voire nul au niveau des deux modèles.
Fig. 1.2 – Distribution des pourcentages des plus proches voisins identiﬁés sur le corpus Movielens par le BNCF et le FCS
La ﬁgure 1.3 présente la distribution de voisins calculés avec les modèles BNCF et FCS sur le corpus du Crédit Agricole. Au niveau de la distribution des valeurs de similarités dans la ﬁgure 1.3, nous remarquons que, comparé au FCS, le BNCF a en moyenne des valeurs de similarité plus faibles. De plus, il a également un écart type plus petit. En eﬀet, dans le cas du FCS, il est plus facile d’obtenir de grandes valeurs de similarités si les deux utilisateurs ont des notes similaires sur 20 items co-notés. Or, dans le cas du BNCF une grande valeur de similarité suppose que les motifs communs à deux utilisateurs ont une longueur proche du minimum des tailles maximales des sessions réalisées par ces deux utilisateurs (cf. équation (1.1)). Notons que sur le corpus Movielens (cf. ﬁgure 1.2), les voisins identiﬁés par le FCS ont des valeurs de similarité plus faibles que sur le corpus du Crédit Agricole. Il semblerait en eﬀet que sur Movielens, très peu de voisins ont des notes similaires sur 20 items co-notés avec les autres utilisateurs.
84

1.3. Evaluation de la qualité des prédictions
Fig. 1.3 – Distribution des pourcentages des plus proches voisins identiﬁés sur le corpus Crédit Agricole par le BNCF et le FCS
En prenant en considération ces distributions, nous avons fait le choix d’évaluer les modèles BNCF et FCS sur les corpus Movielens et Crédit Agricole selon diﬀérents seuils θ variant de 0 à 0.4. En eﬀet, quand θ dépasse la valeur de 0.4, le système ne peut pas retrouver suﬃsamment de voisins pour le BNCF et le FCS sur le corpus Movielens (cf. ﬁgure 1.2). De même, dans la ﬁgure 1.3, si nous ﬁxons le seuil θ à une valeur supérieure à 0.4 sur le corpus du Crédit Agricole, le système va négliger une grande proportion de voisins pour le BNCF, ce qui risque de dégrader la précision des prédictions et le pouvoir prédictif du BNCF. Sur le même corpus, le FCS parvient à avoir des voisins au delà du seuil 0.4. Cependant, nous avons constaté que plus ce seuil augmente plus la couverture est faible. Ainsi, les seuils ont été choisis (de 0 à 0.4) dans le but d’évaluer la performance des modèles BNCF et FCS sur un nombre signiﬁcatif de prédictions.
Résultats du BNCF et du FCS (sans hybridation)
MAE Nous avons utilisé la MAE aﬁn d’évaluer l’écart entre les prédictions et les notes réelles (contenues dans le corpus test). Le tableau 1.3 présente les résultats de la MAE concernant les prédictions calculées séparément par le BNCF et le FCS sur le corpus Movielens, selon la valeur du paramètre θ qui a été appliqué pour le choix des plus proches voisins. Nous observons d’abord que les deux modèles BNCF et FCS évoluent pareillement au fur et à mesure que la valeur du seuil θ augmente. En outre, à partir des résultats du tableau 1.3, si nous considérons les résultats en MAE lorsque le seuil θ est ﬁxé à 0.1, nous constatons que le BNCF génère des prédictions moins précises d’environ 2%, comparé aux
85

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
prédictions du FCS.
Notons que lorsque α = 1 (en cas du BNCF) et θ = 0, nous obtenons la même MAE comparé à θ = 0.1, parce que nous disposons pratiquement des mêmes plus proches voisins à la base. En eﬀet, très peu de voisins ont des valeurs de similarités inférieures à 0.1 pour le BNCF (cf. ﬁgure 1.2). Concernant le FCS, approximativement une même précision est atteinte lorsque les valeurs du seuil θ sont situés entre 0 et 0.3. Dans ce cas, ce n’est pas nécessairement dû aux mêmes voisins qui sont impliqués. En eﬀet, si le seuil θ augmente pour le FCS, un nombre non négligeable de voisins n’est pas pris en compte, lors du calcul des prédictions. Ainsi, le résultat similaire en MAE pour le FCS peut être expliqué par le fait que le poids associé à ces voisins n’a pas eu beaucoup d’impact sur les prédictions.

Tab. 1.3 – MAE selon la valeur du paramètre θ : corpus Movielens

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.757

0.741

0.1

0.757

0.740

0.2

0.760

0.740

0.3

0.776

0.744

0.4

0.802

0.763

Le tableau 1.4 présente les résultats de précision en MAE selon la valeur du seuil θ pour les modèles BNCF et FCS, en utilisant le corpus du Crédit Agricole. Nous remarquons que la meilleure précision en MAE, pour les modèles BNCF et FCS, est atteinte lorsque le seuil θ est ﬁxé à 0.2. Notons que le FCS parvient à générer des prédictions plus précises d’environ 3% comparées aux prédictions calculées par le BNCF, en considérant ce même seuil. De plus, comme pour le corpus Movielens, lorsque les seuils 0 et 0.1 sont utilisés par le BNCF et par le FCS, le résultat de la MAE reste similaire puisque les voisins impliqués au calcul des prédictions sont approximativement les mêmes. En eﬀet, peu de voisins ont des similarités inférieures à 0.1 sur ce corpus (cf. ﬁgure 1.3). Lorsque le seuil est équivalent à 0.4, la précision en MAE a tendance à se dégrader respectivement pour les modèles FCS et BNCF. Il est à signaler que pour le modèle FCS, suivant la distribution des voisins présentée dans la ﬁgure 1.3, certains voisins peuvent disposer de similarités au delà du seuil 0.4. Nous avons ainsi évalué la performance du FCS en prenant en compte d’autres seuils allant jusqu’à 0.9. Il s’est avéré que la précision en MAE s’est dégradée et la couverture tend à être très faible (perte d’environ 80% de la capacité prédictive du système). En outre, à cause de cette grande baisse de couverture, les résultats deviennent diﬃcilement interprétables et peuvent ne pas être signiﬁcatifs puisque peu de prédictions sont considérées lors de l’évaluation de la performance du FCS.
Si nous considérons les résultats en MAE obtenus sur les deux corpus, nous constatons que les résultats restent homogènes, notamment au niveau de la performance du
86

1.3. Evaluation de la qualité des prédictions

Tab. 1.4 – MAE selon la valeur du paramètre θ : corpus Crédit Agricole

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.799

0.772

0.1

0.799

0.772

0.2

0.789

0.763

0.3

0.790

0.774

0.4

0.847

0.779

FCS. Toutefois, l’utilisation du BNCF demeure avantageuse puisqu’il ne nécessite pas les données de notes en phase d’apprentissage, comme en FCS, aﬁn d’évaluer les similarités entre utilisateurs. D’après les résultats, il semble en eﬀet que les motifs d’usage exploités par le BNCF représentent des indicateurs aussi informatifs que les notes explicites et permettent d’éviter des cas où ces notes ne peuvent pas être ﬁables. Il s’agit notamment des cas où les utilisateurs peuvent ne pas avoir la même façon de noter les items (i.e. même s’il s’agit d’une même appréciation positive, certains utilisateurs attribuent des notes élevés et d’autres non (cf. section 1.2, chapitre 1, partie 1)).
HMAE
L’utilisation de la HMAE permet d’évaluer la performance du système de recommandation concernant la génération de prédictions ayant des valeurs élevées. Ces prédictions représentent en eﬀet les items qui sont réellement recommandés à l’utilisateur actif. Le tableau 1.5 compare les résultats du BNCF et du FCS en terme de HMAE, sur le corpus Movielens. Les résultats montrent que le BNCF atteint sa meilleure performance lorsque θ est équivalent à 0.2. Ainsi, les meilleurs voisins pour le BNCF sont choisis à partir de ce seuil et ont une capacité à prédire correctement les items pour les utilisateurs actifs. Or, lorsque le seuil θ est ﬁxé à 0.3 ou 0.4, le nombre de voisins impliqués est réduit (cf. ﬁgure 1.2). Il s’avère ainsi que la réduction des voisins engendre une déterioration de la précision en HMAE, pour le BNCF et le FCS. Notons que, comme pour la MAE, avec l’utilisation des seuils 0 et 0.1 pour le BNCF, nous obtenons les mêmes résultats en HMAE en raison de l’implication des mêmes voisins pour calculer les prédictions. En outre, lorsque θ est ﬁxé à 0, le FCS s’avère plus performant que le BNCF. Ce résultat induit que la stratégie d’augmentation du seuil θ pour la sélection de voisins pertinents, n’est pas appropriée dans le cadre du FCS.

Tab. 1.5 – HMAE selon la valeur du paramètre θ : corpus Movielens

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.443

0.416

0.1

0.443

0.444

0.2

0.436

0.461

0.3

0.500

0.512

0.4

0.626

0.555

87

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
Le tableau 1.6 présente les résultats en HMAE, selon diﬀérentes valeurs du seuil θ, obtenus sur le corpus du Crédit Agricole. Nous observons d’abord que, contrairement au corpus Movielens, le BNCF contribue à une meilleure performance en terme de HMAE, comparée à celle du FCS, quel que soit la valeur du seuil θ. Cette performance du BNCF est liée notamment à l’utilisation du corpus d’usage réel du Crédit Agricole permettant d’extraire des motifs ﬁables et d’identiﬁer eﬃcacement les voisins. De plus, nous constatons que la précision du FCS est plus inﬂuencée par l’augmentation de θ, dans la mesure où la HMAE correspondant au FCS se détériore plus qu’en BNCF, au fur et à mesure que θ augmente. Notons que les voisins ayant des valeurs de similarité entre 0 et 0.3 prédisent de la même façon les items pour le modèle BNCF, puisqu’une même HMAE est atteinte. Comme pour l’évaluation en MAE, nous avons testé la performance du modèle FCS en HMAE au delà du seuil 0.4 considérant la distribution des voisins présentée dans la ﬁgure 1.3. Nous avons constaté que la HMAE se dégrade au fur et à mesure que le seuil augmente jusqu’à 0.9. Rappelons que l’application de cette stratégie de sélection de voisins se répercute également sur la couverture. En eﬀet, sur le corpus Crédit Agricole, le système de recommandation fondé sur le FCS génère peu de prédictions lorsque θ est supérieur à 0.4. De ce fait, nous avons choisi d’eﬀectuer l’évaluation en robustesse présentée dans la section suivante, en considérant le seuil θ entre 0 et 0.4.

Tab. 1.6 – HMAE selon la valeur du paramètre θ : corpus Crédit Agricole

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.501

0.545

0.1

0.501

0.545

0.2

0.501

0.541

0.3

0.502

0.571

0.4

0.528

0.588

Robustesse
Dans l’objectif d’évaluer la robustesse du système de recommandation, nous avons examiné la performance des modèles BNCF et FCS en terme de HMAE en utilisant le nouveau corpus de test, contenant les entrées erronées. Notons que nous avons maintenu les mêmes stratégies pour la sélection des plus proches voisins pour le BNCF et le FCS. Les tableaux 1.7 et 1.8 présentent les résultats en HMAE selon diﬀérentes valeurs du seuil θ, en utilisant respectivement le corpus Movielens et le corpus du Crédit Agricole.
Les résultats du tableau 1.7 montrent que le BNCF est relativement robuste malgré la présence de données erronées dans le corpus. Comparé aux résultats du tableau 1.5, nous constatons que le BNCF garde la même évolution. En outre, le BNCF s’avère plus stable que le FCS, si nous comparons en particulier les résultats en cas de θ = 0 dans les deux tableaux 1.5 et 1.7. En eﬀet, la HMAE relative au BNCF augmente d’environ 18%, le FCS reste moins robuste vu que la HMAE correspondante augmente d’environ 24%.
88

1.3. Evaluation de la qualité des prédictions

Tab. 1.7 – Robustesse évaluée en HMAE selon la valeur du paramètre θ : corpus Movielens

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.542

0.546

0.1

0.542

0.547

0.2

0.544

0.551

0.3

0.542

0.554

0.4

0.536

0.559

Tab. 1.8 – Robustesse évaluée en HMAE selon la valeur du paramètre θ : corpus Crédit

Agricole

Seuil θ FC Comportemental (BNCF) α = 1 FC Standard (FCS) α = 0

0

0.498

0.454

0.1

0.498

0.454

0.2

0.498

0.458

0.3

0.499

0.428

0.4

0.471

0.411

A partir du tableau 1.8, contrairement au corpus Movielens, nous constatons que, comparé au BNCF (lorsque le seuil θ est ﬁxé à 0.4) et comparé aux résultats en HMAE du tableau 1.6, le FCS contribue à une meilleure robustesse du système de recommandation. En outre, nous observons que l’augmentation du seuil de similarité n’a pas beaucoup d’eﬀet sur la robustesse et la stabilité du BNCF. En eﬀet, des valeurs similaires de HMAE ont été atteintes, en particulier lorsque θ est ﬁxé entre 0 et 0.3.
Sur le corpus Movielens, le BNCF est moins sensible aux données bruitées, ce qui garantit la ﬁabilité et la qualité des prédictions et la non vulnérabilité du système de recommandation. Sur le corpus du Crédit Agricole, malgré la meilleure performance du FCS, la robustesse du BNCF reste généralement assez stable.
Nous pouvons déduire de cette expérimentation que la robustesse demeure inﬂuencée par la nature du corpus.

Résultats d’hybridation du BNCF et du FCS
Dans cette section, nous nous intéressons à l’évaluation de la performance du système de recommandation hybride combinant les prédictions du BNCF et du FCS. Cette évaluation a été eﬀectuée en termes de MAE et de HMAE en utilisant les corpus de Movielens et du Crédit Agricole. Nous avons utilisé diﬀérents poids représentés par le paramètre α. Nous avons également pris en compte les stratégies utilisées dans les tests précédents pour la sélection des plus proches voisins, en ﬁxant le nombre minimum des items co-notés ou co-visités à 20 et le
89

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
seuil θ à 0.2 en considérant les résultats atteints avec ce seuil (cf. tableaux 1.3, 1.4, 1.5 et 1.6).
La ﬁgure 1.4 présente les résultats de cette expérimentation en termes de MAE et de HMAE sur le corpus Movielens. Nous observons d’une part que la combinaison pondérée des prédictions contribue d’une manière générale à une légère amélioration de la performance en terme de MAE. En eﬀet, comparée aux résultats du tableau 1.3 (où 0.74 était le meilleur taux de MAE atteint), en cas d’hybridation le meilleur résultat de MAE est d’environ 0.73. De plus, si nous comparons les résultats en MAE et en HMAE dans la ﬁgure 1.4, nous pouvons observer que la MAE atteint de meilleurs scores de précision lorsque le FCS est plus impliqué dans le calcul de la prédiction ﬁnale (par exemple lorsque α = 0.1). Or, nous obtenons généralement la meilleure précision en HMAE, lorsque le BNCF a la pondération la plus importante (par exemple lorsque α = 0.9). A cet eﬀet, le BNCF reste plus adéquat pour la proposition de recommandations potentiellement pertinentes à un utilisateur actif.
Fig. 1.4 – Résultats en MAE et en HMAE sur le corpus Movielens
La ﬁgure 1.5 présente les résultats d’hybridation du BNCF et du FCS en termes de MAE et de HMAE sur le corpus du Crédit Agricole. Nous remarquons que l’évolution des résultats pour le corpus du Crédit Agricole est à peu près similaire à l’évolution des résultats en cas d’utilisation du corpus Movielens en particulier pour la MAE (cf. ﬁgure 1.4). En eﬀet, lorsque le FCS a le poids le plus important (i.e. α tend vers 0), les prédictions calculées par le système de recommandation hybride sont plus précises en terme de MAE. Or, la meilleure HMAE est atteinte lorsque le BNCF a le poids le plus important (i.e. α tend vers 1) dans le calcul de la prédiction ﬁnale. Ainsi, comme pour Movielens, l’importante implication du BNCF au niveau des prédictions combinées, permet de générer des recommandations appropriées aux utilisateurs actifs.
90

1.3. Evaluation de la qualité des prédictions Fig. 1.5 – Résultats en MAE et en HMAE sur le corpus Crédit Agricole

En outre, nous avons réalisé un autre test aﬁn d’évaluer la stabilité du système de recommandation hybride sur les corpus du Crédit Agricole et de Movielens, en considérant le corpus de test contenant les données erronées lors de l’évaluation. Considérant les résultats d’hybridation du BNCF et du FCS, présentés dans les ﬁgures ci-dessus, nous avons sélectionné en particulier les prédictions combinées lorsque la valeur d’α est ﬁxée à 0.9 suivant l’équation (1.3) (lorsque α = 0 et α = 1). Il s’agit en eﬀet du meilleur résultat obtenu en terme de HMAE, sur les deux corpus, concernant le système de recommandation hybride (0.401 pour Movielens et 0.505 pour le Crédit Agricole).
Le tableau 1.9 présente les résultats d’évaluation de la robustesse du système hybride, en cas d’utilisation des deux corpus. Le résultat de la HMAE a atteint une précision de 0.494 pour le Crédit Agricole et 0.548 pour Movielens. Comparé aux résultats des tableaux 1.7 et 1.8, en particulier lorsque θ vaut 0.2, nous constatons que la robustesse demeure approximativement stable au niveau des deux corpus. Ce résultat conﬁrme ainsi que les données erronées n’ont pas d’eﬀet sur la robustesse du système de recommandation hybride, en particulier pour le BNCF qui dispose d’un poids important dans cette expérimentation.

Tab. 1.9 – Robustesse des prédictions combinées : corpus Crédit Agricole et Movielens

Crédit Agricole Movielens

Robustesse (HMAE)

0.494

0.548

91

Chapitre 1. Vers un Filtrage Collaboratif Comportemental
1.3.2 Discussion
Le modèle BNCF a été proposé aﬁn de modéliser les utilisateurs sur la base de l’analyse du comportement navigationnel. Ainsi, des utilisateurs ayant en commun des motifs d’usage, sont considérés comme similaires et partagent potentiellement les mêmes appréciations. L’exploitation des motifs d’usage dans le cadre du BNCF, permet de faire face au problème de rareté de données de notes explicites et de réduire l’élicitation. En eﬀet, le BNCF ne requiert pas de données de notes dans la phase d’apprentissage tel qu’en FCS. De plus, le BNCF prend en considération les traces d’usage, non pas pour prédire directement comme dans le WUM, mais pour évaluer les similarités entre utilisateurs.
Les diﬀérentes expérimentations présentées dans ce chapitre, avaient pour objectif d’évaluer l’impact du BNCF (comparé au FCS) sur la performance du système de recommandation en termes de MAE, de HMAE et de robustesse, en utilisant deux corpus diﬀérents (corpus du Crédit Agricole et de Movielens).
Si nous comparons les résultats obtenus sur les deux corpus, nous constatons que les résultats restent globalement homogènes, en particulier en termes de MAE, de robustesse et de l’hybridation des prédictions.
Au niveau du corpus du Crédit Agricole, le BNCF contribue à une meilleure précision en HMAE, en considérant l’évaluation du BNCF séparé (cf. tableau 1.6) et de l’hybridation des prédictions avec une pondération importante pour le BNCF (cf. ﬁgure 1.5). Quant au FCS, en utilisant le même corpus, ses meilleures performances ont été obtenues en termes de MAE (cf. tableau 1.4) et de robustesse (cf. tableau 1.8).
Lorsque les modèles sont expérimentés sur le corpus Movielens, le FCS parvient à générer des prédictions précises en termes de MAE et de HMAE. Or, en exploitant ce corpus, le BNCF s’avère plus robuste et moins vulnérable face aux données bruitées, en considérant l’évolution de la HMAE correspondant au BNCF et au FCS présentée dans les tableaux 1.5 et 1.7.
Il s’avère ainsi que le BNCF demeure globalement plus performant en cas d’hybridation des prédictions (avec une importante pondération pour le BNCF) pour les deux corpus et en terme de HMAE en cas d’utilisation du corpus d’usage. En eﬀet, ce corpus d’usage permet au BNCF d’identiﬁer des motifs ﬁables permettant de retrouver des voisins pertinents contribuant à une meilleure précision en HMAE. La robustesse et la stabilité du système de recommandation exploitant le BNCF ou le FCS, est très inﬂuencée par la nature du corpus utilisé.
Nous pouvons déduire des résultats de ces expérimentations que les traces d’usage sont une source d’information ﬁable permettant au système de recommandation de modéliser eﬃcacement les utilisateurs et de générer des prédictions potentiellement pertinentes.
92

1.3. Evaluation de la qualité des prédictions
Ainsi, il serait judicieux dans les prochaines expérimentations d’évaluer la performance des modèles exploitant les motifs d’usage, sur le corpus du Crédit Agricole puisqu’il intègre des traces d’usage réelles, contrairement à Movielens. En outre, à partir des résultats présentés dans ce chapitre, le BNCF s’avère plus approprié pour la recommandation d’items dans le cas de la navigation sur le Web en s’appuyant sur l’analyse de données implicites (des usages) telle que les données d’usage de l’Extranet du Crédit Agricole. Or, pour la recommandation d’items sur des applications de type e-commerce, le modèle FCS peut être performant à condition que les données de notes explicites soient suﬃsamment disponibles dans le système.
Au niveau de l’hybridation des prédictions présentée dans ce chapitre, au delà de son apport pour l’évaluation de l’impact des deux modèles sur la performance du système de recommandation, l’intérêt de cette hybridation serait l’amélioration du pouvoir prédictif du système de recommandation. En eﬀet, le BNCF et le FCS peuvent génèrer des recommandations pour diﬀérentes paires < utilisateur, item >, puisqu’ils utilisent au moment de la prédiction des voisinages différents. Il s’agit de voisinages calculés soit à partir des similarités de motifs d’usage ou bien à partir des similarités de notes. Bien que cette hybridation requiert des calculs plus importants et des paramètrages supplémentaires, elle a l’avantage de produire potentiellement des recommandations, en cas d’incapacité de l’un des deux modèles BNCF ou FCS à les génèrer. Dans le but d’améliorer cette phase d’hybridation, une stratégie consisterait par exemple à automatiser le processus de combinaison des prédictions en fonction des données disponibles et du contexte d’utilisation du système de recommandation.
Il est à signaler qu’en collaboration avec la société Sailendra S.A.S20, le modèle BNCF a été intégré au niveau de la plate forme CASA du Crédit Agricole contenant les outils applicatifs du portail Extranet du Groupe. Les ﬁgures 1.6 et 1.7 représentent des aperçus des recommandations sur ce portail. La ﬁgure 1.6 est un aperçu du menu de personnalisation des recommandations proposé aux utilisateurs du portail Extranet. Les utilisateurs peuvent notamment paramétrer le nombre de recommandations à aﬃcher. La ﬁgure 1.7 est un aperçu de la liste (TopN) de recommandations proposée à un utilisateur, triée par ordre de pertinence (ordre estimé par le système). Notons que l’utilisateur a la possibilité d’exprimer son avis concernant les recommandations proposées par le système. Le BNCF est actuellement testé au niveau du site Extranet du service de veille stratégique avant d’être déployé au niveau de tout le portail. Ainsi, après cette phase de déploiement, il serait pertinent d’avoir les retours des utilisateurs du Crédit Agricole suite aux recommandations proposées par notre système de recommandation. En eﬀet, ces retours vont nous permettre d’évaluer directement la qualité des recommandations ainsi que le degré de satisfaction des utilisateurs.
20http ://www.sailendra.fr/
93

Chapitre 1. Vers un Filtrage Collaboratif Comportemental Fig. 1.6 – Aperçu du menu de personnalisation des recommandations par les utilisateurs du portail Extranet du Crédit Agricole
Par ailleurs, au delà du contexte applicatif, en vue de réduire l’espace de recherche des voisins, il serait judicieux d’étudier l’intérêt des méthodes de clustering, notamment pour la limitation du nombre de paires d’utilisateurs impliquées lors du calcul des similarités. Dans le chapitre suivant, il est question en eﬀet d’examiner l’apport du clustering dans le cadre du BNCF. Ce chapitre est dédié à la description de cette contribution.
94

1.3. Evaluation de la qualité des prédictions Fig. 1.7 – Aperçu des recommandations générées par le BNCF au niveau du portail Extranet du Crédit Agricole
95

Chapitre 1. Vers un Filtrage Collaboratif Comportemental 96

Chapitre 2
Clustering en Filtrage Collaboratif Comportemental
Les expérimentations du chapitre précédent pour l’évaluation du modèle BNCF nous mènent à aborder les enjeux suivants : l’amélioration de la précision des recommandations et la réduction de l’espace de recherche pour l’identiﬁcation de voisins dans un but de passage à l’échelle. C’est dans cette optique que nous avons proposé une nouvelle approche de recommandation nommée “BNCF-PAM Clustering on Similarities“ (BNCF-PCS) [Esslimani et al., 2009a]. Pour atteindre les objectifs cités ci-dessus, cette nouvelle approche exploite notamment un clustering d’utilisateurs.
Le clustering est une technique permettant de grouper des objets en clusters, tel que les objets appartenant au même cluster sont similaires. Dans le contexte des systèmes de recommandation, le clustering peut être appliqué aux utilisateurs ou bien aux items [Ungar et Foster, 1998]. L’avantage d’utiliser le clustering dans un processus de recommandation est de permettre à la fois de réduire l’espace de recherche pour l’identiﬁcation des voisins et de pallier les problèmes de manque de données et de passage à l’échelle [Sarwar et al., 2002], [Tang et McCalla, 2003], [Xue et al., 2005], [Jiang et al., 2006].
Les méthodes de clustering les plus exploitées par les systèmes de recommandation sont les méthodes de partitionnement dont k-means [MacQueen, 1967] est la plus populaire. Cette méthode a l’avantage d’être eﬃciente et permet le passage à l’échelle. Toutefois, la méthode k-means demeure peu robuste. Ce manque de robustesse est dû à sa sensibilité aux données aberrantes (“outliers”) [Wang et Shao, 2004] (cf. section 1.3.3, chapitre 1, partie 1). De ce fait, nous avons choisi d’exploiter la méthode de clustering PAM (Partitioning Around Medoid) qui est une méthode de type “k-medoïde” [Han et Kamber, 2001]. Habituellement, le clustering peut être exploité dans le cadre du Filtrage Collaboratif Standard
97

