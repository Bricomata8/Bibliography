Institute of Technology Blanchardstown Ireland
Masters of Science
Traﬃc Prediction and Analysis using a Big Data and Visualisation Approach

Author: Declan McHugh

Supervisor: Laura Keyes

A thesis submitted in partial fulﬁlment of the requirements for the degree of Masters of Science in the ﬁeld of Computer Science
Business Intelligence and Data Mining
September 2014

Declaration of Authorship
I, Declan McHugh, declare that this thesis titled, ’Traﬃc Prediction and Analysis using a Big Data and Visualisation Approach’ and the work presented in it are my own. I conﬁrm that:
This work was done wholly or mainly while in candidature for a research degree at this University. Where any part of this thesis has previously been submitted for a degree or any other qualiﬁcation at this University or any other institution, this has been clearly stated. Where I have consulted the published work of others, this is always clearly attributed. Where I have quoted from the work of others, the source is always given. With the exception of such quotations, this thesis is entirely my own work. I have acknowledged all main sources of help. Where the thesis is based on work done by myself jointly with others, I have made clear exactly what was done by others and what I have contributed myself.
Signed:
Date:
i

“Thanks to my solid academic training, today I can apply my knowledge of Data Science in both the Academic and Industry ﬁelds”
Declan McHugh

Abstract
This thesis is an approach of using big data, visualisation and data mining techniques to predict and analyse traﬃc. The objective is to understand traﬃc patterns in Dublin City. The data was captured from open data sources, Dublinked, Wunderground and Twitter. With the aid of Python’s Sklearn Kit, Google Maps and MongoDB a scalable solution was implemented to identify the roads that are impacted by adverse weather conditions, amoung other causes for poor traﬃc conditions and which regression models best predict areas of the city. Seasonality and trends found that traﬃc pattern on weekends diﬀer from business days. Peak time also diﬀer spatially. Peak times for traﬃc is not the same time and can vary from the expected time 8-9am to late evening 8-9pm for inbound traﬃc. The ARIMA model was heavily used as a forecasting model. Using Ordinary least squares regression a clear pattern was shown to that lagging the day by 3, and using a lagged week 1 would be best suited for a regression model. The importance of using all spatial neighbours for the prediction model was insigniﬁcant and the highest correlated neighbour was used measured by Principle Component Analysis. Weather conditions also cause diverse traﬃc patterns. With high temperature it was found the travel increases around national parks and city centre. This indicates people are likely to leave the home to socialise, go for walks or shopping. Wet conditions the impact is more evenly spread. Traﬃc tweets with geographical position stored was unsuccessful for determining the location of a traﬃc incident or the cause. This was due to users do not immediately tweet updates at the time of the occurring event. The end result was an high performance web application that produces a analytical dashboard providing traﬃc prediction and analysis using historical traﬃc and social media data.

Acknowledgements
Thanks to Laura Keyes for the guidance in writing this paper, Geraldine Grey for putting together a well structured course and Marcus Hoﬀemann for the experience in the ﬁeld of Data Mining.
iv

Contents

Declaration of Authorship

i

Acknowledgements

iv

Contents

v

List of Figures

viii

List of Tables

x

Abbreviations

xi

1 Introduction

1

1.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2 Project Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.3 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.4 Methodology Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.5 Big Data Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.6 Application Tooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.7 Structure of this thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

2 Literature Review

5

2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2.2 At The Beginning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2.3 Forecasting Time Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

2.4 Eﬀects of Weather on Traﬃc . . . . . . . . . . . . . . . . . . . . . . . . . 8

2.5 Spatial Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.6 Social Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.7 Big Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

2.7.1 Map Reduce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

2.7.2 Analytical dashboards . . . . . . . . . . . . . . . . . . . . . . . . . 15

2.7.3 NoSQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.8 Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

v

Contents

vi

3 Data Understanding

19

3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.2 Traﬃc Data Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.2.1 Traﬃc Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

3.2.2 Junction Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

3.2.3 Routes Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

3.3 Weather Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

3.4 Twitter Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

3.4.1 Twitter User Timeline Traﬃc Data . . . . . . . . . . . . . . . . . . 26

3.4.2 Twitter Streaming Data . . . . . . . . . . . . . . . . . . . . . . . . 27

3.4.3 Twitter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

4 Data Collection and Exploration

30

4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

4.2 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

4.2.1 Traﬃc Data Extraction . . . . . . . . . . . . . . . . . . . . . . . . 31

4.2.2 Traﬃc Web Scraping . . . . . . . . . . . . . . . . . . . . . . . . . . 31

4.2.3 Traﬃc Indexing and Map Reduce . . . . . . . . . . . . . . . . . . . 32

4.2.4 Weather Data Extraction . . . . . . . . . . . . . . . . . . . . . . . 34

4.2.5 Twitter API Data Extraction . . . . . . . . . . . . . . . . . . . . . 36

4.2.5.1 Geographical Referenced Tweets . . . . . . . . . . . . . . 36

4.2.5.2 User Timeline Tweets . . . . . . . . . . . . . . . . . . . . 37

4.2.5.3 Tweet Map Reduce . . . . . . . . . . . . . . . . . . . . . 37

4.2.6 Collection Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

4.3 Data Exploration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

4.3.1 Exploring Traﬃc . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

4.3.1.1 Travel Time Data Sets . . . . . . . . . . . . . . . . . . . 41

4.3.1.2 Standard Deviation of Travel Time . . . . . . . . . . . . 42

4.3.1.3 Seasonality of Travel Time . . . . . . . . . . . . . . . . . 46

4.3.1.4 Exploring Traﬃc Result . . . . . . . . . . . . . . . . . . . 48

4.3.2 Exploring Weather . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.3.2.1 Weather Data Set . . . . . . . . . . . . . . . . . . . . . . 48

4.3.2.2 Daily Aggregation Precipitation . . . . . . . . . . . . . . 51

4.3.2.3 Hourly Aggregation Precipitation . . . . . . . . . . . . . 52

4.3.2.4 Daily Aggregation Temperature . . . . . . . . . . . . . . 52

4.3.2.5 Weather Exploration Result . . . . . . . . . . . . . . . . 54

4.3.3 Exploring Twitter . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

4.3.3.1 User Timeline Tweets . . . . . . . . . . . . . . . . . . . . 54

The tokenizer parameters . . . . . . . . . . . . . . . . . . . 55

The word cloud . . . . . . . . . . . . . . . . . . . . . . . . . 55

Traﬃc . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

Location . . . . . . . . . . . . . . . . . . . . . . . . . . 56

Punctuated Twitter Words . . . . . . . . . . . . . . . . 56

4.3.3.2 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . 57

4.3.3.3 Geographical Referenced Tweets . . . . . . . . . . . . . . 57

4.3.3.4 Twitter Conclusion . . . . . . . . . . . . . . . . . . . . . 60

Contents

vii

5 Model Selection

61

5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

5.1.1 Standard Travel Time (STT) Model Selection . . . . . . . . . . . . 61

5.1.1.1 Standard Travel Time (STT) Conclusion . . . . . . . . . 65

5.1.2 Weather Model Selection . . . . . . . . . . . . . . . . . . . . . . . 65

5.1.3 Weather Model Selection Conclusion . . . . . . . . . . . . . . . . . 69

5.1.4 Spatial Model Selection . . . . . . . . . . . . . . . . . . . . . . . . 70

5.1.4.1 Spatial Model Selection Conclusion . . . . . . . . . . . . 72

5.1.5 Prediction Model Fitting . . . . . . . . . . . . . . . . . . . . . . . 73

5.1.5.1 Predictive Datasets . . . . . . . . . . . . . . . . . . . . . 73

5.1.5.2 Prediction Algorithms . . . . . . . . . . . . . . . . . . . . 73

5.1.5.3 Evaluating estimator performance . . . . . . . . . . . . . 74

5.1.5.4 Prediction Results . . . . . . . . . . . . . . . . . . . . . . 74

5.2 Twitter Traﬃc Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . 77

5.2.1 Twitter Conclusion and Analysis . . . . . . . . . . . . . . . . . . . 78

6 Results and Conclusions

79

6.1 Big Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

6.2 Visualisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

6.3 Traﬃc Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

6.3.1 Seasonality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

6.3.2 Weather . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

6.3.3 Prediction Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

6.3.4 Analytics Dashboard . . . . . . . . . . . . . . . . . . . . . . . . . . 82

6.4 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

A Appendix Traﬃc Web Crawl

86

B Appendix Transform Traﬃc Data

89

C Appendix Available Weather Stations

94

D Appendix Sample Tweet

95

E Appendix Sample Predictive Model Dataset

97

F Appendix Prediction Algorithm Results

101

List of Figures
1.1 MongoDB internal divide and conquer approach . . . . . . . . . . . . . . 3
2.1 Comparison of predicted travel ﬂow with diﬀerent models . . . . . . . . . 7 2.2 Part of speech sentence pattern . . . . . . . . . . . . . . . . . . . . . . . . 11 2.3 Traﬃc word cloud, event features . . . . . . . . . . . . . . . . . . . . . . . 11 2.4 Wedding word cloud, event features . . . . . . . . . . . . . . . . . . . . . 12 2.5 Proposed architecture for Big Data solution [1] . . . . . . . . . . . . . . . 14 2.6 Map and Reduce [1] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.7 Collision Prediction [1] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.8 Big data Color Visualisation . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.9 Big data Spatial Visualisation . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.10 Sci-Py Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
3.1 DubLinked Google Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3.2 Open Data Weather Stations Dublin . . . . . . . . . . . . . . . . . . . . . 23 3.3 Wunderground Day View . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.4 Wunderground Day View . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.5 AA Roadwatch Tweets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.6 Monitering of Twitter Stream . . . . . . . . . . . . . . . . . . . . . . . . . 27
4.1 Traﬃc Extraction Process . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 4.2 Traﬃc Observation Archive . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.3 High Level Observation collection . . . . . . . . . . . . . . . . . . . . . . . 33 4.4 Weather collection Document . . . . . . . . . . . . . . . . . . . . . . . . . 35 4.5 Twitter API ﬁlter by location . . . . . . . . . . . . . . . . . . . . . . . . . 37 4.6 Observation location with 26834 observations . . . . . . . . . . . . . . . . 40 4.7 Data Sets from 23/07/2012 to 19/04/2014 23:50 . . . . . . . . . . . . . . 41 4.8 Daily Mean of 40/1/1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 4.9 Inbound and Outbound Traﬃc Observations . . . . . . . . . . . . . . . . . 43 4.10 Inbound and Outbound, Low - Medium - High . . . . . . . . . . . . . . . 45 4.11 Peak Hours Inbound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 4.12 Weather Histograms, Lucan, Co. Dublin . . . . . . . . . . . . . . . . . . . 49 4.13 Weather Histograms for Blackrock, Dublin 8 . . . . . . . . . . . . . . . . . 49 4.14 Weather Histograms for Artane, Dublin 5 . . . . . . . . . . . . . . . . . . 50 4.15 Weather Stations Rain Daily Mean . . . . . . . . . . . . . . . . . . . . . . 51 4.16 Weather Stations Rain Hourly January 24th-29th . . . . . . . . . . . . . . 52 4.17 Weather Stations Temperature Daily Mean . . . . . . . . . . . . . . . . . 53 4.18 Weather Stations Temperature Daily Correlation . . . . . . . . . . . . . . 53
viii

List of Figures

ix

4.19 AA Road Watch Cloud . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.20 Geographical Referenced Tweets 2014/04/18 9:00pm . . . . . . . . . . . . 58 4.21 Junction Wexford St and Kevin St . . . . . . . . . . . . . . . . . . . . . . 59 4.22 Tweet From Location 2014/04/25 18:00-18:59pm . . . . . . . . . . . . . . 60
5.1 Correlation coeﬃcients Matrix Colour Coded . . . . . . . . . . . . . . . . 62 5.2 Auto Correlation of most volatile time 30/7/1 [’8:00’, ’8:59’] . . . . . . . . 63 5.3 Auto Correlation of most volatile time 13/2/1 [’8:00’, ’8:59’] . . . . . . . . 63 5.4 Auto Correlation of most volatile time 17/6/1 [’8:00’, ’8:59’] . . . . . . . . 64 5.5 Correlation of Rain Map Direction Inbound Peak Times . . . . . . . . . . 66 5.6 Correlation of Rain Map Direction Outbound Peak Times . . . . . . . . . 67 5.7 Correlation of Temperature Map Direction Inbound Peak Times . . . . . 68 5.8 Correlation of Temperature Map Direction Outbound Peak Times . . . . 69 5.9 Vertex neighbouring with no ﬁlter . . . . . . . . . . . . . . . . . . . . . . 70 5.10 Sample vertex neighbouring with matrix . . . . . . . . . . . . . . . . . . . 71 5.11 Sample spatial correlation result . . . . . . . . . . . . . . . . . . . . . . . 72 5.12 Linear Regression Fit intercept and Normalise 14/3/2 . . . . . . . . . . . 75 5.13 Support Vector Machine Regression 30/20/1 . . . . . . . . . . . . . . . . . 75 5.14 Bayesian Ridge Regression 31/5/2 . . . . . . . . . . . . . . . . . . . . . . 76 5.15 Online Passive Aggressor Regression 18/6/1 . . . . . . . . . . . . . . . . . 76 5.16 Oﬀ-peak and Inbound Algorithm Map . . . . . . . . . . . . . . . . . . . . 77
6.1 Dashboard Analysis for 21/04/2014 8pm to 9pm . . . . . . . . . . . . . . 81

List of Tables
1.1 Main Python Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.1 Performance comparison of diﬀerent predictor . . . . . . . . . . . . . . . . 7 2.2 Summary of ARIMA variations [2] . . . . . . . . . . . . . . . . . . . . . . 8 2.3 Comparison of performance using RMSE of ARIMA, SARIMA, and ARIMA-
GARCH with historical values (HV) on Downtown Street (DS), State Highway (SH), Interstate Highway (IH) [2] . . . . . . . . . . . . . . . . . . 8 2.4 Comparison of wet and dry conditions on traﬃc ﬂow . . . . . . . . . . . . 9 2.5 Part of Speech Names . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
3.1 Observation Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.2 Junction Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.3 Route Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.4 Weather Stations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.5 Weather URL Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.1 Weather Collection Attributes . . . . . . . . . . . . . . . . . . . . . . . . . 35 4.2 Weather Collection Attributes . . . . . . . . . . . . . . . . . . . . . . . . . 36 4.3 Samples Distribution of Travel Time Values in Seconds . . . . . . . . . . . 40 4.4 Sample Weekday Inbound Peak hours . . . . . . . . . . . . . . . . . . . . 46 4.5 Peak Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 4.6 Weather Stations Correlation Linear Regression on HourlyPrecipMM in
Jan 24th - 29th . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 4.7 Weather Stations Correlation Linear Regression on TemperatureC . . . . 54 4.8 Tf-idf Tokenizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
5.1 Correlation coeﬃcients Matrix Colour Coded Summary . . . . . . . . . . 61 5.2 Correlation coeﬃcients Rain and Temperature Peak Times . . . . . . . . 69 5.3 Description sample spatial correlation result ﬁgure . . . . . . . . . . . . . 71 5.4 Overview of Spatial Correlation Results . . . . . . . . . . . . . . . . . . . 72 5.5 Description sample spatial correlation result ﬁgure . . . . . . . . . . . . . 73 5.6 Estimation algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5.7 Real-time Tweets Classiﬁed as Traﬃc . . . . . . . . . . . . . . . . . . . . 78
6.1 Volumes of Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
F.2 Peak Algorithm Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
x

Abbreviations

STT Standard Travel Time

OL Observed Location

P

Parameters ID

MSE Mean Error

R2 R2 (coeﬃcient of determination) regression score function

EVS Explained Varience Score

MAE Mean Absolute Error

Q

Quantile 80

xi

For my wife for being patient with me during my studies
xii

Chapter 1
Introduction
1.1 Overview
The aim of this thesis is to analyse traﬃc patterns for an urban city, Dublin and to provide a visual dashboard for analysing traﬃc for a Smarter City. The initial data sets used vary from remote sensed data and social media information from open-data sources. One of the challenges this paper achieve is the Big Data four V’s (volume, velocity, variety and veracity), see section 1.5. Smart Cities is an initiative that has been adopted in many European cities. Smart Cities goal is an enabler for better planning, social and infrastructure management. Examples of cities using this includes Dublin, Lyon, Amsterdam and Barcelona. Many European cities including Dublin have an active open data programme. Although there ongoing issues around privacy laws there are still many open data portals available online to the general public. The Dublin City Council make over 250 data sets available [3]. Wireless sensor networks is a technology which has played a massive role enabling a Smarter City. Dublin along with many other cities is using this technology to gather data related to traﬃc. The objective is to have a complete infrastructure that enable the monitoring of traﬃc behaviours so decisions on city development can be made in a smarter way. Variables such as weather conditions and seasonality may be able to improve decision on road network design.
1

Chapter 1. Indroduction

2

1.2 Project Objectives

Objectives of this work are:

• To obtain and store historical traﬃc, related weather data to build and generate a generic prediction model.
• To obtain and store twitter data and design an approach to provide further analysis for traﬃc related events.
• To create a analytics dashboard demonstrates traﬃc patterns from data mining techniques, prediction models and twitter analysis.

1.3 Research Question
Can open data and social media be used to predict and analyse traﬃc as part of a smarter city?

1.4 Methodology Outline
Research was conducted to identify traditional methods of traﬃc prediction and analysis in the area forecasting and spatial data mining. This was used to identify problems that researchers had developing analyses. Further research was to form concept how to approach an analysis of traditional traﬃc prediction method with historical data and social media. Data Mining CRISP DM methodology was used throughout the project. CRISP DM is an industry standard for data mining. This methodology played a key role appropriate techniques and tools.

1.5 Big Data Background
Throughout the thesis techniques where employed in all phases of development to handle the four V’s of Big Data: volume, velocity, variety and veracity.
• Volume of traﬃc data is a challenge that is overcome using MapReduce. By grouping related data together that allowed the database system perform searching eﬃciently through another mechanism called Indexing.

Chapter 1. Indroduction

3

• Velocity of twitter data for this system was read in at real-time. Again MapReduce and Indexing was used to process and store the data.
• Variety of the data sources traﬃc, weather and twitter contain data types such as timestamps, geo-spatial, strings and integers. The database system called MongoDB was used and catered for these needs.
• Veracity in this case is the storing the data in preparation for analysis.

The technique for overcoming in big data systems divide and conquer [4]. MongoDB is a NoSQL the considers the challenges of the four V’s[5] and allows users implement a design in such a way that data can be stored and retrieved eﬃciently. NoSQL is lightweight Big Data database. When implementing a solution the database design creating indexes is crucial. These indexes allow for the system to divide a collection into segments. In the background the database the collections are being chunked and an index table is then generated for mapping data and its location on the ﬁle system. For instance in ﬁgure 1.1, a user collection on the ﬁle system is chunked based on the index criteria score. This leads to fast retrieval of the collection as the database knows to only search chunked ﬁles containing relevant data.

Figure 1.1: MongoDB internal divide and conquer approach [5]
For time-series collection of data, such as this paper provides, the data is indexed based on the timestamp and or spatial location.
1.6 Application Tooling
In this work there are a number of aspects that needed to be considered. There a lot of data preprocessing, natural language processing, mathematical algorithms, twitter integration, spatial data mining, visualization, web application, storage of structured and unstructured data. Python provides many of the tools necessary for data and scientiﬁc processing 1.1.

Chapter 1. Indroduction

4

Table 1.1: Main Python Modules

Package SciPy NumPy Django TwitterAPI PyMongo

Description Scientiﬁc Algorithms and Methods Number Manipulation Web Application Twitter Integration MongoDB NoSQL Integration

1.7 Structure of this thesis

The aim of this work, as described within this chapter, is to explore the open data from Dublinked, Wunderground and Twitter using big data and data mining techniques which include methods such as visualisation. Chapter 2 explains the diﬀerent components for traﬃc prediction, big data and smart city. Chapter 3 gives in greater detail the information the open data sources make available. Chapter 4 is the collection and exploration the data while integrating the divide and conquer approach. Chapter 5 contain the development of the generic traﬃc prediction model and an approach for text classiﬁcation analysis of twitter. Chapter 6 outlines the results and conclusions of the investigation as well analytics dashboard outcome.

Chapter 2
Literature Review
Much research around traﬃc patterns in road networks in a city limited to small number of roads and/or limited size if time series [some reference]. In this paper there is an objective if recognising how the many diﬀerent algorithms perform. Dublin City oﬀers a an opportunity to avail of showing the contrasting roads.
2.1 Introduction
This section starts with a detailed review of traﬃc prediction and analyses. The focus of the review is to identify diﬀerent methods and techniques researchers have applied in algorithms, analysis with social media and big data. The following will contain the aspects of the reading that are deemed most relevant to the paper.
2.2 At The Beginning
Remote sensory system is the most common method for monitoring traﬃc. The resulting data is in the form of traﬃc volumes rather than speed or travel time. Travel time is estimation is down to its most common method Kalman Filtering. Kalman ﬁltering, one of the most advanced methods in modern control theory. This method was initially proposed in 1960 by Kalman R.E. Stephanedes (1983) compares two very well established methods for predicting traﬃc ﬂow and volume taken from the Kalman Filter theory and the other is UTCS-2 (Urban traﬃc control system) [6]. The paper explains the mathematical applications mostly deployed today in calculating speed and travel time in Urban Traﬃc Control. An evolution of techniques are provided to give the reader some background on prediction methods then follows that with a detailed analyses of
5

Chapter 2. Literature Review

6

UTCS-2 using average prediction error and average error. As result many wireless sensor networks that are installed in cities are measure volume. Algorithms based on Kalman Theory for state space control measures volume to calculate travel time. These calculations a not 100% accurate but is a very common technique which it algorithms has been modiﬁed and improved over a long period of time and has been accepted as the best way of measuring travel time. The reason for measure volume and not travel time is to account for traﬃc signals and vehicles not completing routes.

2.3 Forecasting Time Series
Autoregressive Integrated Moving Average (ARIMA) is the most common approaches taken for forecasting travel time. In 1983 [2] outlines the variations of the ARIMA that can be seen in 2.2 .
Research into traﬃc prediction is a common use case around a time series problem. Autoregressive Integrated Moving Average (ARIMA) and Neural Networks are algorithms the appear to perform best in this area. For example in 2008, Dehuai Zeng et el explores the variations of the linear model ARIMA and non-linear Neural Network [7] and in 2010 claims support vector regression model (SVR) has been widely used to solve non-linear time series problems [8].
The models are modiﬁed to cater for the randomness of the so called unknown factors that eﬀect traﬃc. This is also known as ARIMA-GARCH. GARCH is algorithms and models that account for the errors. Some of the random factors have been investigated such as weather and road incidents [9–11].
The core of most traﬃc prediction analysis is with time-series data model built from historical data as discussed in by Stephanedes (1983) [12].
A study in 2008 Dehuai Zeng et el compares the artiﬁcial neural network, ARIMA, and a hybrid model ANN-ARIMA, see ﬁgure 2.1 and table 2.1.
Dehuai Zeng et el parametrises ANN with the ARMA model (BPNN) and the hybrid model is an extension of BPNN by using its predictions of error terms for the ARIMA model [7].

Chapter 2. Literature Review

7

Figure 2.1: Comparison of predicted travel ﬂow with diﬀerent models

Table 2.1: Performance comparison of diﬀerent predictor

Predictor ARIMA BPNN Hybrid

rmerr% 0.92 0.89 0.58

marerr% 4.26 3.94 2.34

rmsrerr% 12.44 11.64 5.68

As technology has improved, roads networks have got better and car safety has improved. The number of road incidents decreased and historical data can be accessed easier making predictability of traﬃc delay more accessible to research [2]. With this the ARIMA models have evolved. V. Gavirangaswamy et el takes ARIMA and variations of the model.

Chapter 2. Literature Review

8

Table 2.2: Summary of ARIMA variations [2]

SARIMA FARIMA MARIMA/ARIMAX k-factor GARIMA
Switching ARIMA

Seasonal ARIMA Fractional ARIMA Multivariate ARIMA Gegenbauer Polynomials ARIMA
Diﬀerent ARIMA models are ﬁtted

Good for data with

short range recurring

pattern

Considers recurring

pattern over long

ranges

Includes other time se-

ries as dependent vari-

able

Accounts for both the

short-range and lon-

grange dependencies

considering diﬀerent K

data frequencies

Apply

diﬀerent

ARIMA for diﬀer-

ent characteristic

The historical data from Metro Detroit was aggregated hourly from the years 2009 to 2011. Initial time series chart showed the presence of seasonal data which was ideal for SARIMA. The scoring mechanism used was root mean squared error (RMSE). Using SARIMA the performance of the test improved by 5 % over ARIMA. ARIMA-GARCH model’s predicted result is improved by 40% 2.3. The application of this model can be used both for short time traﬃc prediction and oﬄine. The generation of the model is computationally expensive. The use of some modern big data techniques and technologies would be of great beneﬁt to such implementation [4].

Table 2.3: Comparison of performance using RMSE of ARIMA, SARIMA, and ARIMA-GARCH with historical values (HV) on Downtown Street (DS), State Highway
(SH), Interstate Highway (IH) [2]

HV DS SH IH

DS SH IH

DS SH IH

300 367.29 375.55 143.68 346.52 346.67 140.91 212.82 251.86 89.57

500 374.42 340.71 133.92 361.1 316.53 126.52 214.09 207.26 86.08

800 339.82 355.63 142.42 346.53 347.3 142.33 214.56 207.3 88.33

2.4 Eﬀects of Weather on Traﬃc
In an eﬀort to improve traﬃc prediction accuracy, much research has been done to add variables to historical traﬃc data such a weather conditions. There is little doubt that weather conditions are correlated in some manner to traﬃc times and volume. According to Stephen Dunne and Bidisha Ghosh in 2013 ”Rainfall inﬂuences traﬃc conditions and, in turn, traﬃc volume in urban arterials”. Therefore when possible the data model

Chapter 2. Literature Review

9

should include weather variables when building a prediction algorithm for traﬃc conditions. Stephen Dunne and Bidisha Ghosh show that using stationary version of Discrete Wavelet Transform (DWT) called SWT for a forecasting model can show correlation between the traﬃc volume and weather conditions outperforming Artiﬁcial Neural Network for the same tests. The studies build a traﬃc volume data built on Kalman Filtering. A structure of SWT is used to create a weather neurowavelet traﬃc forecasting system. The neurowavelet (SWT) prediction algorithm is proposed for forecast hourly traﬃc ﬂow while also accounting for rainfalls levels. The study uses the wavelet form where other research uses variations of moving average. Ideally comparisons between moving average of the rather other wavelet forms would be more ideal. The study shows that rainfall has an impact on traﬃc ﬂow and that an algorithm as results in ﬁgure below display [11].

Table 2.4: Comparison of wet and dry conditions on traﬃc ﬂow

TCS 106 SWT-ACNN Model

Overall MAPE Dry Period Wet Period

9.0936

10.6463

4.4362

TCS 106 Standard-ANN Model

Overall MAPE Dry Period Wet Period

14.1061

16.5664

6.7254

TCS 125 SWT-ACNN Model

Overall MAPE Dry Period Wet Period

8.0082

9.9116

2.2979

TCS 125 Standard-ANN Model

Overall MAPE Dry Period Wet Period

13.3406

15.9555

5.4958

The result do not take into account the seasonality or trends of the traﬃc data. Traﬃc volumes diﬀer on days of the week and times of the day. Keay and Simmonds investigated the inﬂuence of weather variables with road volume in 2004 [9]. The authors make a big eﬀort in comparing trend and seasonality data in analysing results of basic regressions models. They split day-time and night-time data in understanding traﬃc volume and compare it to daily data. They also compares a multitude trend separation i.e. separate each day Monday-Friday and Saturday/Sunday and include school and public holidays etc. They found that Rainfall plays the big inﬂuence in traﬃc volume. High rainfall and colder weather decreases traﬃc at night-time and cooler months but highlight day-time volume stays the same with weather conditions. It is suggested the reason for this is that people need to travel to work and schools where optional activities decrease with harsher weather conditions. The study shows that there is a correlation between cool and wet weather and traﬃc volume. Traﬃc volume decreases in cool wet conditions. On week days the reduction in traﬃc volume is minimal at 1% compared to the 17% reduction on Sundays, showing that the necessity for people to get to work or similar

Chapter 2. Literature Review

10

activities is great. The analyses was all done using stepwise standard linear regression against season, weekly trend traﬃc volume data and weather variables [9].

2.5 Spatial Techniques
In a study Zhang (2012) uses a method of traﬃc clustering to group road points that are spatially and time related. This is a way of reducing the amount of computation of necessary. Neural Network was the proposed prediction mechanism. They mention future investigation is needed for improvements in accuracy but the main focus of the exercise was to provide the clustering approach. They propose their own online traﬃc clustering algorithm by clustering combination road point of similar dynamics. This is certainly a good consideration for a option avoid high computation cost in a bid data solution. The clustering algorithm is compared against Bayesian Neural Networks [13].
Road in networks are correlated both spatially and temporally. Roads volumes inﬂuence the travel times of its neighbours. Upstream bare an obvious signiﬁcance and distant roads are insigniﬁcant. A number of models have been tested to improve the predictive value of traﬃc volume. In many cases traditional forecasting models have been used including Holt Winters and Multivariate Structural Time Series. In 2012 Yousef-Awwad Daraghmi et el compared Na¨ıve Bayes Regression against the forecasting models. The proposed method used a series of lags tested over a number of diﬀerent time’s intervals using stepwise forward elimination in adding the number of variables to be included into the model until the diﬀerences irrelevant [14].

2.6 Social Media
Endarnoto et al wrote a paper on “Traﬃc Condition Information Extraction & Visualization from Social Media Twitter for Android Mobile Application” (2011). The research devised a model using text data mining techniques to extract traﬃc events in Jakarta. The experiments used tweets from a “TMC Polda Metro Jaya”, the Twitter of National Traﬃc Management Center of Indonesia. Twitter account which suggested that the data extract conformed to a semi-structured text. In this case Part of Speech tagging played a pivotal role in the results. The main cause of disruption of result was due to the prediction of location is a ‘From’ location or a ‘To’ location. The experiment did however use a simple model that could be used for not just traﬃc event where it extract date/time, location to/from and condition. The source of tweet data is reliant on the quality of information from the user. In this case it is the national body the reports on

Chapter 2. Literature Review

11

metropolitan information. This is realistic situation for most known cities and in turn makes the study relevant in many cases. The study used the sequential order of the part of speech names, see ﬁgure 2.2, based on the POS dictionary in table 2.5.

Figure 2.2: Part of speech sentence pattern

Table 2.5: Part of Speech Names

POS 1 2 3 4 5 6 7 8

POS AJ AT AV CJ N NP P V

Name Adjective Adjective Adverb Conjunction Noun Noun Preposition Verb

Example Ramai (crowded), Macet (jammed) Time 06:50 Sangat (highly) Dan (and), Lalu (then) Lalin (traﬃc), Arus (stream) Place Pondok Indah, Bintaro Di (at), Ke (to), Dari (from) Merayap (crawling), Terjadi (happening)

The main obstacle in this research is that tweets that do not conform to these rules which they call, Out of Rules and Out of Vocabulary and it is handled by using a POS “indicator”. The results of the simpliﬁed rules in ﬁgure 1 are at best 70% from the tested run in the experiment. [15]
Alternatively to Sri Krisna Endarnoto et al approach, Bei Pan et el look into using TFIDF approach to against classiﬁed traﬃc related tweets. The tweets themselves are not necessarily traﬃc related but also of social events that may have an impact on traﬃc. In the study one such event determined was a wedding event exhibition.

Figure 2.3: Traﬃc word cloud, event features

Chapter 2. Literature Review

12

Figure 2.4: Wedding word cloud, event features
The research also builds a corpus based on a predeﬁned source the Beijing Transportation Bureau to extract features relevant to traﬃc. The research provides limited details on how tweets on the event in 2.3 were extract or if any document tokenizing implementation where used. The tweets were retrieved from an area where traﬃc anomalies reported by local authorities but no traﬃc incidents had occurred. [10]
2.7 Big Data
Big Data is data that is so large and complex where it becomes problematic. The problems largely focus on the four V’s of Big Data [16].
• Volume Back in the year 2000 a PC might have had 10 gigabytes of storage. Social Media sites such as Twitter and Facebook consumes 500 terabytes a day.
• Velocity This mostly relates to the capturing of real-time data at high speed. In particular Twitter is a good example of real-time data monitoring. As well as consuming realtimes messages from users, they are exposing APIs that allow the public leverage on this data. Internally Twitter is consuming an quickly process as much or even more than 500 terrabytes of data.
• Variety Big Data needs to be able handle a variety of data type such as spatial attributes, graphic, audio and video, and unstructured text. Traditional RDBMS were designed to handle smaller volumes of structured data.
• Veracity Is a more recent adage of the V’s. Is the term for using the data analysis for decision making, problem solving and knowledge outcomes. With this ensuring data quality.

Chapter 2. Literature Review

13

Traditional database systems are designed to operate on a single machine. This provides a limitation to the scalability of the solution as capacity is ﬁnite. The use of application and development practices have become agile, as production have evolved onto the cloud for multi-tenet user base the database needs to grow horizontally the more users there are using the system. Big Data databases, such as MongoDB, solve these problems and provide companies with the means to create tremendous business value [5].

2.7.1 Map Reduce
Map Reduce is a technique that plays a massive role in the volume and velocity of big data. Map Reduce is elastic scalable, promotes eﬃciency and high availability [17, 18].
In some of the works mentioned in this paper it has a common problem with detailing with large volumes data from traﬃc observations and twitter data [2, 7, 10]. In recent year the term Big Data has come into fruition. Vinay Gavirangaswamy et el [2] mentions with regards the tests took around 220 computational hours to run these experiments on a machine with 8 gigabytes of RAM. Big Data is data that is so large and complex where it becomes problematic. Brito et al proposed an approach called StreamMapReduce a task that is considered a Big Data problem. The characteristics of Big Data are mainly Volume, Variety, Velocity and Veracity[19, 20]. The research claims that its mechanism can allow a hundred fold improvement in response time and a ten-fold per node throughput increase in comparison to Hadoop. The concept behind the approach acts as an improvement on Event Stream Process and MapReduce by ﬁltering out data that is not relevant or considered duplicates. Mostly the improvements in performance are down to aggregation of data which inevitably lose some data or mapping documents that contain the same class data. The study does highlight that MapReduce and/or Event Stream Processing does not answer all Big Data problems and StreamMapReduce is a solution to some use cases [21]. However in 2013, Duckwon Chung et el apply big data technology Hadoop and HBase to analyse real-time traﬃc collisions from a number of diﬀerent sources, traﬃc information, social sites, mobile phone GPS signals. One terrabyte of data was extracted from these sources over a ten year period. The solution involves multiple data nodes for consume the observation data distributed by a master data node , see ﬁgure 2.5. The master node decides which of the nodes to send the observation based on an index. In this case location called detectors was the deemed the mostly ﬁtting index. The nodes then map and reduce the date which is a way of aggregating the data for further analyses. Once the aggregation is processed algorithm can be generated, see ﬁgures 2.6 2.7 [1]

Chapter 2. Literature Review

14

Figure 2.5: Proposed architecture for Big Data solution [1] Figure 2.6: Map and Reduce [1]

Chapter 2. Literature Review

15

Figure 2.7: Collision Prediction [1]
It is generally understood that analysing streaming Twitter streams is the volume of data consumed by an application. With a large Twitter data set McCreadie et al experiments with a divide and conquer technique to eﬃciently scale big data streams at estimated thousands of tweets per second [4]. McCreadie seem certain that MapReduce and traditional DBMS are not well suited for real-time Twitter streaming processing, especially DBMS where it uses a ‘store-then-process’ method for dealing with data. The experiment uses a platform called Storm, which is now part of the Hadoop stack to handle real-time streams of data. It works but releasing short batches of streaming data to diﬀerent nodes. Within its Event Detection Topology it uses algorithm for clustering data that are similar using a Distributed Lexical Key Partitioning (DLKP) to cluster data documents in groups. DLKP is term for Storm to implement a Local Cosine Distance calculation. The paper gives a good approach for handling unstructured twitter data with unknown key attributes. [4]
2.7.2 Analytical dashboards
With Big Data is not all about writing and reading data. It is necessary to provide analytical views of data. It is diﬃcult for users to read volumes of data. Analytic dashboard is technique for display analytical information. In 2013 Kristopher Reese et al explain the importance of using visual dashboards for analysing large amounts of data [22]. Examples are provided to show how best use colours and spatial information, see ﬁgures 2.8 and 2.9

Chapter 2. Literature Review

16

Figure 2.8: Big data Color Visualisation [22]

Figure 2.9: Big data Spatial Visualisation [22]

Chapter 2. Literature Review

17

2.7.3 NoSQL

The trend to use NoSQL databases in place of relational databases have increased in certain use cases. Often requirements of data model can change frequently. In 2013, Lu´ıs A. Basti˜ao Silva et al explain that document-based databases do not have the limitation of RDBMS databases [23]. The demonstrate that Lucene, MongoDB and CoucheDB have high performance levels.

2.8 Algorithms
Linear and non-linear algorithms have been used for forecasting time series. Dr. Vincent Granville in 2014 describes linear regression algorithms and is summerized in list 2.8 [24].
• Linear regression Is the oldest regression model. Sensitive to over-ﬁtting and outliers.
• Logistic (Poisson or Cox) regression Often used in clinical trials, scoring and fraud detection and is considered.
• Ridge regression Regression with constraints on the coeﬃcients. Not as sensitive to over-ﬁtting as the Linear regression model.
• Lasso regression Same as Ridge except it automatically uses variable reduction.
• Logic regression Sets all the variables to binary. Can be more robust than logistic regression. Often used in fraud detection.
• Bayesian regression Assumes prior knowledge of the coeﬃcients. Flexible compared to linear regression and the error must contain a normal distribution.
• Logistic regression Compares the relationship between a dependent variable and one or more independent variables. Is analogous to linear regression.
Other Non-linear algorithms as mentioned in section 2.3 can be used in regression models as Support Vector Regression as long as the kernal is set to RBF by Monte Carlo approximation of its Fourier transform while Stochastic Gradient Descent (SGD) can be

Chapter 2. Literature Review

18

used as an Artiﬁcial Neural Net when using back-propagation. As Neural Net is know to perform slowly SGD performs well for large scale learning [25, 26].
The Python Sci-Py kit provide algorithm for regression, classiﬁcation, clustering and dimension reduction, see ﬁgure 2.10.

Figure 2.10: Sci-Py Algorithms [26]
Some of the linear algorithms mentioned perform well with handling of noise with many parameters available to manipulate the coeﬃcients through techniques as normalisation and setting boundaries to the independent variable known as upper and lower bound limits 2.8.
2.9 Conclusion
State space control is the underlying method for measuring traﬃc volume and speed. Kalman Theory is the most prominently in modern day algorithms and is widely used in traﬃc monitoring systems. These methods do not guarantee absolute accuracy but is the most widely used method in traﬃc estimation systems. Based on the data generated from the monitoring systems forecasting methods are implemented to form traﬃc prediction. Many of the model used for prediction are ARIMA and GARCH. GARCH is used to manage noise in the traﬃc data sets. For the purpose of the exercise algorithms from Python SciPy will be compare. Python SciPy has a wide variety of Linear models, some that handle noise in diﬀerent ways and only limited options Non Linear algorithm. Perceptron will be used for Artiﬁcial Neural Net and Support Vector Regression (SVR).

Chapter 3
Data Understanding
3.1 Introduction
This section describes the information made available from the open data sources Dublinked, Wunderground and Twitter prior to data collection. The objective of chapter is to provide a background on the information available.
3.2 Traﬃc Data Sets
TRIPS data is comprised of three datasets which is made available through an open data website DubLinked [3]. Journey times are provided some of the main routes across Dublin City. Each route consists of a number of links, each link is a pair of geo-referenced traﬃc control sites. DubLinked distribute maps that can be imported into Open Street Map and Google Maps known as shapeﬁles and KML ﬁles, see ﬁgure 3.2. With this the locations of the traﬃc control sites marked by yellow pins in in google maps along designated routes. The purpose of the traﬃc control sites is to monitor traﬃc volume using sensors.
19

Chapter 3. Data Understanding

20

Figure 3.1: DubLinked Google Map
3.2.1 Traﬃc Data
Historical traﬃc data is stored via the DubLinked TRIPS Archive Directory [3]. The archive is a HTTP directory-list of binary zip ﬁles. Each binary zip ﬁle contains one day of historical observation data in a CSV format 3.2.1. The ﬁle name is marked with the date in the format day-YYMMDD.csv.bz2
1 Timestamp , Route , Link , D i r e c t i o n , STT, AccSTT , TCS1 , TCS2 −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
3 20131213−1339, 4 , 3 , 2 , 18 , 168 ,125 ,470 20131213−1339, 4 , 4 , 1 , 35 , 204 ,125 ,667
5 20131213−1339, 4 , 4 , 2 , 43 , 211 ,667 ,125 20131213−1339, 4 , 5 , 1 , 22 , 226 ,667 ,422
7 20131213−1339, 4 , 5 , 2 , 19 , 230 ,422 ,667 20131213−1339, 4 , 6 , 1 , 49 , 275 ,422 ,151
9 20131213−1339, 4 , 6 , 2 , 37 , 267 ,151 ,422
Listing 3.1: File day-20131213.csv.bz2$day-20131213.csv line 501052-501059

Chapter 3. Data Understanding

21

Table 3.1: Observation Attributes

Attribute Timestamp Route Link Direction

Description Date time of observation YYYYMMDD-HHmm Road with 1 or more observed links Segment of road between 2 control sites Direction of ﬂow of traﬃc

3.2.2 Junction Data

DubLinked provide junction data which relate to the Traﬃc Control Sites. Each observation recorded hold identiﬁers about the two traﬃc control sites called TCS1 and TCS2 as seen in listing 3.2.1. The details are provided in three formats, CSV, KML, and Shape ﬁle the example privided in junctions.csv 3.2.2. Between the traﬃc control sites TCS1 and TCS2 is the value of travel time is estimated and in further references in the research will be know as Observed Location (OL).

Table 3.2: Junction Attributes

Attribute SiteID X Y Location

Description Relates to the identiﬁer TCS1 and TCS2 Longitude [Irish Grid (IG; EPSG:29902) Coordinate Value] Latitude [Irish Grid (IG; EPSG:29902) Coordinate Value] Name of Road

1 SiteID , X, Y, Location −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
3 1 2 5 , 3 1 2 6 6 6 , 2 3 6 2 9 0 , NAVAN RD NEPHIN RD 1 2 6 , 3 1 5 1 2 8 , 2 3 3 6 4 0 , BULL ALLEY ST NICHOLAS STREET BRIDE ROAD
5 1 2 7 , 3 1 4 8 4 2 , 2 3 5 8 7 2 , NORTH CIRCULAR ROAD CABRA ROAD 1 2 8 , 3 1 5 9 4 2 , 2 3 5 7 4 3 , NORTH CIRCULAR ROAD BELVEDERE ROAD
7 1 2 9 , 3 1 6 2 3 9 , 2 3 5 6 4 7 , NORTH CIRCULAR ROAD FITZGIBBON ST 1 3 0 , 3 1 3 3 7 8 , 2 3 4 8 8 7 , NCR INFIRMARY RD
9 1 3 1 , 3 1 3 1 1 2 , 2 3 9 1 0 0 , NORTH RD MELLOWES RD 1 3 2 , 3 1 7 2 8 1 , 2 3 5 9 7 1 , NORTH STRAND RD EAST WALL RD
Listing 3.2: Example data junctions.csv
3.2.3 Routes Data
DubLinked provide route data which relate to a section of road made up of a number of links. A link is the length of road between to Traﬃc Control Sites (TCS1 and TCS1)

Chapter 3. Data Understanding

22

and mentioned above. Each observation recorded hold identiﬁers route and link, see 3.2.1. The details are provided in three formats, CSV, KML, and Shapeﬁle with the routes.csv listed in 3.2.3

Attribute Route Link Direction TCS1 TCS1 WKT

Description Stretch of road being monitored Segment of the Route Direction of traﬃc along link Control point for traﬃc entering link Control point for traﬃc exiting link Irish Grid Coordinates

Table 3.3: Route Attributes

Route , Link , D i r e c t i o n , TCS1 , TCS2 ,WKT 2 1 , 1 , 1 , 6 0 0 6 , 2 0 3 1 ,LINESTRING( 3 2 1 9 0 9 228333 comma 321106 2 2 8 8 6 3 )
1 , 1 , 2 , 2 0 3 1 , 6 0 0 6 ,LINESTRING( 3 2 1 1 0 6 228863 comma 321909 2 2 8 3 3 3 ) 4 1 , 2 , 1 , 2 0 3 1 , 6 0 0 3 ,LINESTRING( 3 2 1 1 0 6 228863 comma 320545 2 2 9 2 7 2 )
1 , 2 , 2 , 6 0 0 3 , 2 0 3 1 ,LINESTRING( 3 2 0 5 4 5 229272 comma 321106 2 2 8 8 6 3 ) 6 1 , 3 , 1 , 6 0 0 3 , 6 0 0 8 ,LINESTRING( 3 2 0 5 4 5 229272 comma 320380 2 2 7 1 0 0 )
1 , 3 , 2 , 6 0 0 8 , 6 0 0 3 ,LINESTRING( 3 2 0 3 8 0 227100 comma 320545 2 2 9 2 7 2 ) 8 1 , 4 , 1 , 6 0 0 8 , 1 1 2 5 ,LINESTRING( 3 2 0 3 8 0 227100 comma 319684 2 2 9 2 0 3 )
1 , 4 , 2 , 1 1 2 5 , 6 0 0 8 ,LINESTRING( 3 1 9 6 8 4 229203 comma 320380 2 2 7 1 0 0 )

Listing 3.3: Example data routes.csv

3.3 Weather Data
Much research has shown the impact weather conditions has had on traﬃc[9]. This section will cover the weather data extraction process. The weather data itself is taken from an open source website Weather Underground [27]. Wunderground is a provider of weather station data. The weather stations are owned by the general public. It this paper three stations are select as a source of weather data, see appendix C for a list of stations. Weather conditions move and change over time. Wet weather conditions can be speciﬁc to a small area at one time and not guaranteed the greater Dublin area with experience wet condition all at once. For example rain takes time to travel. This means that rain eﬀects traﬃc at diﬀerent times and locations. The weather station are located in the North, West and South Dublin 3.3.

Chapter 3. Data Understanding

23

Id ICODUBLI2 ILEINSTE8 IDUBLINC2

Location Lucan, Co Dublin West Blackrock, Dublin 8, South Artane, Dublin 5, North

Table 3.4: Weather Stations

Figure 3.2: Open Data Weather Stations Dublin

Chapter 3. Data Understanding

24

The number icons in ﬁgure 3.3 are weather stations available on the Wunderground website provide access to historical weather of each day and location separately via the web [27]. Highlighted in orange are the weather station capture for the purpose of the paper.
http://www.wunderground.com/personal-weather-station/dashboard?ID=IDUBLINF2# history/data/s20140423/e20140423/mtoday

Figure 3.3: Wunderground Day View

Chapter 3. Data Understanding

25

The complete data set can be accessed in CSV format using the parameters described in table 3.5 with the URL below for any particular day. The URL has the identiﬁer ICODUBLI2 which is related to Fairview. By passing the parameters day=21, month=05 and year=2014 means the data returned is for 21st May 2014 in Fairview.

http://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID=ICODUBLI2&day= 21&year=2014&month=05&format=1

Parameter ID day year month

Description Identiﬁer for weather station Day of month Year Month

Table 3.5: Weather URL Parameters

Wunderground also provide its own forecast information for the area. This is potential useful for building the non lagged weather data with the predictive model, ﬁgure 3.4.

Figure 3.4: Wunderground Forecast View http://www.wunderground.com/weather-forecast/IE/Dublin.htm

Chapter 3. Data Understanding

26

3.4 Twitter Data

Twitter provides an API for searching historical data based on diﬀerent types of ﬁlters on attribute and/or search streaming tweets. Using the technique of capturing data from a provider of traﬃc related tweets to classify live streaming tweets. Known providers of traﬃc data such as AA Roadwatch 3.5 are a public server to provide traﬃc information updates.

3.4.1 Twitter User Timeline Traﬃc Data
The tweets from AA Road Watch and Live Drive providers do not carry any geographical information other the text data. Where the live stream carry the geographical information i.e. co-ordinates. But the text data may not provide the location. The object here is to relate traﬃc related tweets to the geographical position within the tweet. The diﬀerence between the two sources is that the tweets from Live Drive are re-tweets from the general public and the tweets from AA Road Watch are tweets delivered as a National Service. Although the AA Road Watch and Live Drive tweets are Traﬃc related it does not guarantee that all tweet contain traﬃc information 4.

Figure 3.5: AA Roadwatch Tweets

Chapter 3. Data Understanding

27

3.4.2 Twitter Streaming Data

The Twitter Streaming API provides a service for capturing data live Tweets in realtime. The Twitter API has geographical parameters the allows for targeting speciﬁc areas around the world. In this research Dublin will be targeted, see ﬁgure 3.6. The sample of a tweet from the twitter real-time service contain user, geographic and the text, see listing 3.4.2.

Figure 3.6: Monitering of Twitter Stream

1{

” id ” : ”456013499119190016” ,

3

”user contributors enabled” : ”False” ,

” u s e r n o t i f i c a t i o n s ” : ”None” ,

5

” user default profile ” : ”False” ,

” timestamp ” : ISODate ( ”2014−04−15T11 : 1 7 : 5 3 . 0 0 0 Z” ) ,

7

”item id” : ”456013499119190016” ,

”user default profile image” : ”False” ,

9

”geo” : ”{ ’ type ’ : ’ Point ’ , ’ coordinates ’ : [52.9731794 , −6.0478466]}” ,

” date ” : ”2014−04−15 1 1 : 1 7 : 5 3 ” ,

11

” user statuses count ” : ”30038” ,

”retweeted” : ”False” ,

13

” u s e r p r o f i l e b a c k g r o u n d i m a g e u r l h t t p s ” : ” h t t p s : / / abs . twimg . com/

images/themes/theme10/bg . g i f ” ,

” place id ” : ”577c65949ddabbc9” ,

15

” u s e r u r l ” : ”None” ,

” u s e r f o l l o w r e q u e s t s e n t ” : ”None” ,

17

” u s e r p r o f i l e s i d e b a r f i l l c o l o r ” : ”F6FFD1” ,

”user is translation enabled” : ”False” ,

19

” u s e r p r o f i l e b a c k g r o u n d i m a g e u r l ” : ” http : / / abs . twimg . com/ images /

themes/theme10/bg . g i f ” ,

” user listed count ” : ”15” ,

21

” user id ” : ”398974774” ,

Chapter 3. Data Understanding

28

” u s e r p r o f i l e b a c k g r o u n d c o l o r ” : ” 382D8A” ,

23

” u s e r p r o f i l e i m a g e u r l h t t p s ” : ” h t t p s : / / pbs . twimg . com/ p r o f i l e i m a g e s

/3623831526/ fe8cefe137693b064bba63cad65403cc normal . jpeg” ,

” coordinates ” : ”{ ’ type ’ : ’ Point ’ , ’ coordinates ’ : [ −6.0478466 ,

52.9731794]}” ,

25

” user id str ” : ”398974774” ,

” u s e r p r o f i l e b a c k g r o u n d t i l e ” : ”True” ,

27

”user name” : ” Alistair ” ,

” user is translator ” : ”False” ,

29

” user verified ” : ”False” ,

” place full name ” : ”Wicklow” ,

31

” u s e r l o c a t i o n ” : ”Wicklow , Ireland ” ,

” u s e r c r e a t e d a t ” : ”Wed Oct 26 2 0 : 2 1 : 4 6 +0000 2011 ” ,

33

” user geo enabled ” : ”True” ,

” s o u r c e ” : ”<a h r e f =\” h t t p : / / t w i t t e r . com/ download / a n d r o i d \ ” r e l =\”

n o f o l l o w \ ”>T w i t t e r f o r Android </a>” ,

35

”place contained within” : ” [] ” ,

” place attributes ” : ”{}” ,

37

”user time zone” : ”Dublin” ,

” user friends count ” : ”1663” ,

39

”place place type” : ”city” ,

” u s e r p r o f i l e l i n k c o l o r ” : ”FF0000” ,

41

” user profile sidebar border color ” : ”000000” ,

”place name” : ”Wicklow” ,

43

” u s e r p r o f i l e b a n n e r u r l ” : ” h t t p s : / / pbs . twimg . com/ p r o f i l e b a n n e r s

/398974774/1397201272” ,

” user favourites count ” : ”11458” ,

45

”user screen name” : ”Al toMyFriends” ,

” user utc offset ” : ”3600” ,

47

” user profile text color ” : ”333333” ,

” t e x t ” : ” @ v i t a m i n s l u d g e You p r o b a b l y t e a c h C h i n e s e s t u d e n t s , s o you

would have some i n s i g h t s . @guardian @whithernow” ,

49

”user protected” : ”False” ,

” user lang ” : ”en” ,

51

” place country code ” : ”IE” ,

” user followers count ” : ”843” ,

53

” user profile use background image ” : ”True” ,

”user description” : ”Irish .

Friendly .

Apathetic activist .

In a time of universal deceit telling the truth is a revolutionary act

. − George Orwell” ,

55

” u s e r p r o f i l e i m a g e u r l ” : ” http : / / pbs . twimg . com/ p r o f i l e i m a g e s

/3623831526/ fe8cefe137693b064bba63cad65403cc normal . jpeg” ,

” u s e r f o l l o w i n g ” : ”None” ,

57

”place country” : ”Ireland” ,

” p l a c e u r l ” : ” h t t p s : / / a p i . t w i t t e r . com / 1 . 1 / geo / i d /577 c65949ddabbc9 . j s o n

”,

Chapter 3. Data Understanding

29

59

”place bounding box” : ”{ ’ type ’ : ’ Polygon ’ , ’ coordinates ’ :

[[[ −6.791799 , 52.682057] , [ −6.791799 , 53.2338548] , [ −5.9988317 ,

53.2338548] , [ −5.9988317 , 52.682057]]]} ”

}

Listing 3.4: Example data routes.csv

3.4.3 Twitter Summary
The objective of using the two sources for tweets is that the user speciﬁc tweets can be used to extract features that are related to the subject matter of traﬃc tweets and use a similarity measure with associated rule learning to match traﬃc related tweets from the real-time data which contains the geographic location which is not part of the user-timeline data.

Chapter 4
Data Collection and Exploration
4.1 Introduction
In this section it is explained how big data techniques are used to store the data in an unstructured database called MongoDB. There is an emphases on divide and conquer. This database along Python Pandas module is used to provide faster searching queries of large document store with indexing. Using Pythons Pandas is a time series module for manipulating time series data. Pandas is has feature that aggregate and manipulate time series data for the purpose of Map Reduce which is used to move the reduced collection of data back into the NoSQL database. In the following sections the Traﬃc and Weather is merged for a data model that can be used for regression models. Twitter data is reduce to contain only the attribute important for traﬃc analysis.
4.2 Data Collection
The data for this research consists of three fundamental areas traﬃc, weather and twitter data. All the data can be obtained through web and open data on-line sources. In the following sections the paper will discuss the techniques used to collect and store all the data for the three areas. The techniques include web scraping, data manipulation, data quality, database storage and performance.
30

Chapter 4. Data Collection and Exploration

31

Figure 4.1: Extraction process of traﬃc observations
4.2.1 Traﬃc Data Extraction
The data store of traﬃc observations is known as TRIPS is maintained in an DubLinked Archive [3]. For each day of data the a Comma Separated Value (CSV) ﬁle is generated and placed into an BZIP2 Compressed ﬁle that can be access via an individual links [3]. The data needs validate prior to storage. A concern for the storage is the volume of data. A Big Data approach is necessary for making the data accessible and for fast queries to retrieve the data for analysis.
4.2.2 Traﬃc Web Scraping
Web scraping is a term used for extracting data from the web. DubLinked contains a list of the most currently available BZIP2 Compressed ﬁles, see ﬁgure 4.2 [3]. Using Python, a list of archive ﬁles are read and ﬁles are downloaded and stored into a temporary archives directory 4.2.2.

Chapter 4. Data Collection and Exploration

32

Figure 4.2: Traﬃc observation archive

# check i f f i l e already e x i s t s on disk

2

i f os . path . i s f i l e ( outputFile ) i s not True :

print (”Skipping ” + archiveFile )

4

print (”Downloading ” , archiveFile )

http pool = urllib3 . connection from url ( archiveFile )

6

r c s v = h t t p p o o l . u r l o p e n ( ’GET ’ , a r c h i v e F i l e )

# save data to disk

8

output = open ( o u t p u t F i l e , ’wb ’ )

10

output . write ( rcsv . data )

output . close ()

12

14

i f os . path . i s f i l e ( ” extracted /” + filename + ” . csv ” ) i s not True :

zfobj = bz2 . BZ2File ( outputFile , ’ rb ’ )

Listing 4.1: Download Archive File

4.2.3 Traﬃc Indexing and Map Reduce
Once the raw data has been store locally the data needs to be store in the database so it can be read eﬃciently. In a traditional solution the data set of observations are inserted as is in a structure database table with deﬁned columns. In listing 4.2.3 is an example of CSV records. Each archive ﬁle contains observations which amount above 3.3mb in ﬁle size and have between 900,000 and 1,000,000 records. RDBMS can limit database or table size and or even record count size.

Chapter 4. Data Collection and Exploration

33

The approach in consider the divide and conquer technique to organise the observations for fast retrieval. Each document in a mongoDB collection groups the observations based on its time-stamp attributes day and hour as well as the spatial location/direction, see ﬁgure 4.3.

Figure 4.3: High Level Observation collection indexed

Chapter 4. Data Collection and Exploration

34

20140125−0232, 5 , 5 , 2 , 2 20140125−0232, 5 , 6 , 1 ,
20140125−0232, 5 , 6 , 2 , 4 20140125−0232, 6 , 1 , 1 ,
20140125−0232, 6 , 1 , 2 , 6 20140125−0232, 6 , 2 , 1 ,

22 , 186 ,459 ,458 87 , 277 ,459 ,405 86 , 272 ,405 ,459 24 , 24 ,405 ,150 30 , 30 ,150 ,405 22 , 46 ,150 ,148

Listing 4.2: File day-20140125.csv.bz2$day-20140125.csv

1{
3 5 7 9 11 13 15 17
19 }

” id ” : ”17/5/2/20140202/17” , ”hour” : ”17” , ” link ” : ”5” , ”day” : ”20140202” , ” direction ” : ”2” , ”item” : [
{ ” date ” : ISODate ( ”2014−02−02T17 : 0 0 : 0 0 . 0 0 0 Z” ) , ” stt ” : 30
}, {
” date ” : ISODate ( ”2014−02−02T17 : 0 1 : 0 0 . 0 0 0 Z” ) , ” stt ” : 30 }, ..... ], ” route ” : ”17”

Listing 4.3: MongoDB observation collection Reduced

As a result the data is transformed using Map Reduce from the CSV 4.2.3 to the NoSQL JSON format 4.2.3. The attributes in listing 4.2.3 ” id”, ”hour”, ”link”, ”day”, ”direction”, ”route” are all there to facilitate queries to the databases and are also indexes in the collection. The ”items” is the attribute that contain all observations for the time and spatial location.

4.2.4 Weather Data Extraction
The weather data does not impose the same level of volume as traﬃc or twitter data. This task therefore does not impose the level of performance issues that a larger dataset can produce. In section 3.3 it is discussed where the data is available. Also it is available in CSV format. The CSV of historical weather data for each day is accessible. Each weather collection item contains all the recorded observation for that day and location.

Chapter 4. Data Collection and Exploration

35

The collection index is set to the day and location value, see ﬁgure 4.4. The ”items” is the attribute that contain all weather observations for the time and spatial location.

Figure 4.4: Weather Collection Document

Table 4.1: Weather Collection Attributes

Attribute id month year location date item

Description Index generated from date and location Month of weather observations in item set Month of weather observations in item set Id of the weather station location Date of weather observations in item set item set containing weather observation

Chapter 4. Data Collection and Exploration

36

Table 4.2: Weather Collection Attributes

Attribute Humidity WindDirection WindSpeedGustKMH HourlyPrecipMM Conditions WindDirectionDegrees Clouds WindSpeedKMH dailyrainMM PressurehPa Time TemperatureC DateUTC¡br¿ DewpointC SoftwareType

Description Humidity Wind Direction Wind Speed Gust KMH Hourly Precip MM Conditions Wind Direction Degrees Clouds WindSpeed KMH Daily rain MM PressurehPa Time TemperatureC Date UTC Dew point C Software Type

4.2.5 Twitter API Data Extraction

As mentioned in Chapter 3 Twitter provides a number of methods for collecting tweets. For the purpose of this study tweets are collected based on streaming tweets which can be ﬁltered by geographical location and speciﬁc users. The purpose of collecting the user speciﬁc tweets is to act as training data. The trained algorithm is to be applied to the streamed data to capture Real-Time traﬃc related tweets. Each tweet within the Twitter is capture in real-time through Python with the module Twitter API http service, see ﬁgure ??. User timeline searched tweet does not contain the geographical location of a tweet where the streaming tweets can be ﬁltered based on the tweet attribute. Unlike the traﬃc observation section 4.2.1 the tweets already come in the JSON format ready MongoDB. Once the data read from the TwitterAPI then it can be stored into the database. An exercise is still necessary to reduce the number of attributes. This exercise is to improve the performance for running queries faster.

4.2.5.1 Geographical Referenced Tweets
Capturing Twitter data is an example of a Big Data problem. Each tweet can have up to 60 attributes of information. In this paper the geographical area being capture is Dublin with the co-ordinates of ’-7,51,-5,54’, see ﬁgure 4.5.

Chapter 4. Data Collection and Exploration

37

Figure 4.5: Twitter API ﬁlter by location
4.2.5.2 User Timeline Tweets
Tweets from #AARoadWatch timeline contain tweets on the domain of Traﬃc. There is no spatial information on these tweet other that what is in the text itself. The tweets from the time line are used to generate features that can be used in a classiﬁcation of real-time tweets.
4.2.5.3 Tweet Map Reduce
A single tweet contains a lot of data attributes. This research is not performing analysis on the tweet user or the relationship between user and the text. The objective is to do text analyses for user timeline for traﬃc features for extraction of traﬃc tweets from Twitter Streaming API as gathered in appendix D . Listing 4.2.5.3 is a small view of some of the attribute that make a tweet. Using Map Reduce the tweet is reduced to 4.2.5.3. In the same way of observations tweets are aggregated with into a collection item based on the date and hour YYYYMMDD/HH, see listing 4.2.5.3. The example 4.2.5.3 reﬂect the only tweet within the mapped reduced into a one collection item. Most

Chapter 4. Data Collection and Exploration

38

collection will range from 1,000 - 2,000 tweets into a single collection item or tweets for that hour.

1{

” id ” : ObjectId (”534 bfab9c009e418f4c742a1”) ,

3

” u s e r p r o f i l e s i d e b a r f i l l c o l o r ” : ”EFEFEF” ,

” u s e r c r e a t e d a t ” : ”Sun Apr 04 2 3 : 5 8 : 5 5 +0000 2010 ” ,

5

...

” text ” : ”@FunStarsGoLive @haven @DonifordOwners Hahahahahaha ! ! ! ! Didn ’

t even know #Stanboardman d i d a #WorldCupSong ! You p r o p e r made me

chuckle !” ,

7

” p l a c e p l a c e t y p e ” : ”admin” ,

...

9

” coordinates ” : ”{ ’ type ’ : ’ Point ’ , ’ coordinates ’ : [ −3.36751463 ,

50.61453593]}” ,

” u s e r d e s c r i p t i o n ” : ”London born Luton r a i s e d Devon based comedian

coming to a town near you ! ” ,

11

....

” user lang ” : ”en” ,

13

” user followers count ” : ”1594” ,

”user default profile image” : ”False”

15 }

Listing 4.4: Twitter Tweet

1{

” id ” : ”2014/04/18/09” ,

3

” items id ” : ”2014/04/18/09” ,

”item” : [

5

{

”hour” : ”09” ,

7

”parent id” : ”2014/04/18/09” ,

”item id” : ”457081081184157696” ,

9

” coordinates ” : ”{ ’ type ’ : ’ Point ’ , ’ coordinates ’ : [ −6.25743524 ,

53.36674358]}” ,

” date ” : ”2014−04−18 0 9 : 5 9 : 5 9 ” ,

11

” text ” : ”@neilmbriscoe thankfully I have a green floor which

i s now an e x c e p t i o n a l l y w e l l n o u r i s h e d g r e e n f l o o r #w i l l i e v e r l e a r n ” ,

”place place type” : ”city” ,

13

” timestamp ” : ISODate ( ”2014−04−18T09 : 5 9 : 5 9 . 0 0 0 Z” ) ,

”geo” : ”{ ’ type ’ : ’ Point ’ , ’ coordinates ’ : [53.36674358 ,

−6.25743524]}”

15

},

....

17

]

}

Listing 4.5: Twitter Tweet Attribute Map

Chapter 4. Data Collection and Exploration

39

4.2.6 Collection Result

As a result of the collection exercise all records of observations attained and accessible with no data loss. Each traﬃc related observation can be re-generated back to its full form. The same applies to Twitter tweets. Tweets have been reduced into another collection removing unnecessary attributes for fast analytic queries. Each record can be mapped back to its original form. This may be useful if further investigation is required for a twitter user.

4.3 Data Exploration
The data exploration section will provide a detailed description of the data collected in the section 4.2 along with visualisations. Using visualisation through Google Maps and Python is used to identify quality issues that is not feasible ﬁlters through a manual process or using standard tools. The objective of this section is to generate a generic data model that regression algorithms could be applied to each of the observed locations (OL). The main purpose of using a generic model is that testing a best ﬁt model all the OLs is not a practical. By analysing features through principle component analysis, histograms and correlation matrices allows for a better general understanding of the data and create a data model that each individual dataset can using.

4.3.1 Exploring Traﬃc
In this section the traﬃc observation is discussed in details exploring diﬀerent distribution of values, aggregation of the data, varied seasonality of data and meta data mostly using visualisation.
A complexity of analysing the observations in a big data is the volume of information. Some of the detail is easier to comprehend using visualisation with detailed maps. Listing 4.3.1 details a total of 47 routes across the urban road network. A route can have up to 25 observed links going in 2 directions.

2 count min
4 max

direction 698 1 2

links 698 1 25

routes 698 1 47

Listing 4.6: Junction Meta Data

Chapter 4. Data Collection and Exploration

40

Table 4.3 is showing distribution of values from 23/07/2012 to 19/04/2014 23:50. The table provides the number of observation sample used count, standard deviation std, minimum and maximum value, and the quantile distribution. Quantile distribution at .50 (%50) is the average value and .80 (%80) is the average of the top %20 percent of values. 128 of the 698 observed locations have a count of 26834. The observed locations considered invalid for the analysis. The volume of data missing is too large to perform any imputation of missing values. Some of the observed location with count values of 26834 have been found to be duplicate locations of other location with a more complete observation count. As a result the number of complete observation data sets are 578. In ﬁgure 4.6 shows a view of travel time observations for location 10/8/2.

Table 4.3: Samples Distribution of Travel Time Values in Seconds

id 1/1/1 1/1/2 1/10/1 1/10/2 1/11/1 1/11/2 1/12/1 1/12/2 1/13/1 1/13/2 1/14/1

count std min max .20 .40 .60 .80

91584 62 117 1045 118 127 133 159

91584 8 59 411 60 61 62 63

91584 51 7 773 7 7 7 99

91584 29 7 482 15 19 29 53

91584 22 18 242 18 18 18 27

91584 24 18 242 18 18 18 31

91584 11 9 130 10 10 11 16

91584 17 9 103 9 9 18 33

91584 17 5 263 12 23 35 39

91584 17 5 263 5 5 5 29

26834 2 5

86 10 11 11 11

10/8/2

Figure 4.6: Location has 26834 observations

Chapter 4. Data Collection and Exploration

41

4.3.1.1 Travel Time Data Sets

Figure 4.7 shows that the full data sets have gaps in the data. The gaps are consistent across all links. The pattern in the data are still in tact. The tests on the data set are reduced to the date within the purple rectangle in the ﬁgure 4.7.
Data Set [40/1/1 14/4/1 9/10/1] from 23/07/2012 to 19/04/2014 23:50

Figure 4.7: Data Sets from 23/07/2012 to 19/04/2014 23:50
The date range from September/October in 2012, May/July in 2013, Jan/May 2014. Due to this some seasonality test such as monthly, weekly is not possible. Figure 4.8 represent a daily mean data set values for the observed location 40/1/1.

Chapter 4. Data Collection and Exploration

42

Figure 4.8: Daily Mean of 40/1/1
4.3.1.2 Standard Deviation of Travel Time
This is true for observed locations that are on the same links. In table 4.3 a sample of meta data shows the complexity ﬁltering useful information. Using visualisation the information spatial elements of the data helps identify similarities between observed locations. Figure 4.9 demonstrates the standard deviation of travel times in Dublin from 23/07/2012 to 19/04/2014 23:50. Standard deviation can be considered a way of measuring the volatility [28]. A range of colour from Red to Green to Blue reﬂects the standard deviation from Low to Medium to High. Junctions 30/7/1, 13/2/1, 17/6/1 are examples of these categories with values of 9, 102, 146 respectively. Base on the same standard deviation scale in outbound direction 2 of 0 to 204 junctions 30/4/2, 10/7/2, 16/2/2 are examples of these categories with values of 13, 102, 192.

Chapter 4. Data Collection and Exploration

43

Inbound - Direction 1

Outbound - Direction 2

Figure 4.9: Inbound and Outbound Traﬃc Observations

Chapter 4. Data Collection and Exploration

44

Most standard deviations (STD) are in the low to medium value ranges. The volatility of observed junctions does not change much between inbound direction 1 traﬃc and outbound direction 2 traﬃc. Outbound at Aungier Street 16/2/2 demonstrates that it clearly the most volatile. This means that the route link is the most unpredictable observed location in Dublin City. Dublin city centre Inbound shows a more medium to high STD opposed to outbound demonstrate low STD, see ﬁgures 4.10

Chapter 4. Data Collection and Exploration

45

Inbound - Direction 1

Outbound - Direction 2

Figure 4.10: Inbound and Outbound, Low - Medium - High

Chapter 4. Data Collection and Exploration

46

4.3.1.3 Seasonality of Travel Time

Seasonality are commonly observed in quarterly and monthly time series, with multiple overlying seasonality occurring in weekly, daily and hourly data [29].

Fluctuations over segmented periods of time are commonly observed in research in order to relate patterns in data to time [29]. Often these periods are in the form for yearly, seasonally (Summer/Winter/Spring/Autumn), monthly, weekly, daily, and hourly. Stephen Dunne and Bidisha Ghosh [11] and Sri Krisna Endarnoto et al [15] have both researched the seasonality diﬀerences of peak time traﬃc and also the diﬀerences in week-day and week-end traﬃc. Sri Krisna Endarnoto et al assumed a peak time of 9am. In this section this assumption is explored.

The method of understanding peak times comes from using quantile percentage. Quantile 0.80 is used as a measure to identify high value points in the data. Quantile is similar to the mean value. The mean is equal to quantile of point 0.50. In ﬁgure 4.10 the x-axis provides the quantile distribution. The axis at point 7 is quantile 0.80. To calculate the peak hours of a road section the hour that return the highest quantile at 0.80 is used. As a result the data shows that not all roads. In table 4.4 shows that it is incorrect to assume the inbound traﬃc peak times are from early morning between 7am and 10am. The result shows the 14/4/1 road is busy between the 14th hour and the 16th, ie 2pm to 6pm. Both Road 14/4/1 and 40/1/1 are both a similar distance from the city centre but have diﬀerent peak hours, see 4.5. In general during peak times appear to be outside working hours before 10am and after 4pm. On weekends peak hours are highest around 12am and before midnight. Outbound in much of the peaks times is in the late evening after 5pm working hours. It could be considered unusual that peak hours are between 9pm and 11pm. This could be down to many late evening events that people drive too or grocery shopping.

Table 4.4: Sample Weekday Inbound Peak hours

id 14/4/1 1/7/1 17/6/1 40/1/1 9/10/1 6/6/1 43/2/1

hour (value) from highest 15 (170.57) 14 (168.93) 16 (168.0) 21 (126.4) 20 (126.4) 19 (126.4) 17 (401.0) 9 (401.0) 16 (401.0) 8 (186.16) 7 (173.08) 9 (161.62) 8 (65.73) 23 (56.0) 22 (56.0) 8 (71.0) 7 (70.81) 9 (70.99) 9 (61.2) 8 (57.78) 7 (56.19)

Chapter 4. Data Collection and Exploration

47

Table 4.5: Peak Times

Sample Weekend Inbound Peak hours id 14/1/1 1/7/1 17/6/1 40/1/1 9/10/1 6/6/1 43/2/1 Sample Weekday Outbound Peak hours id 14/4/2 1/7/2 17/6/2 40/1/2 9/10/2 6/6/2 43/3/2 Sample Weekend Outbound Peak hours id 14/4/2 1/7/2 17/6/2 40/1/2 9/10/2 6/6/2 43/2/2

hour (value) from highest 12 (139.0) 13 (139.0) 14 (138.07) 20 (126.4) 19 (126.4) 18 (126.4) 13 (401.0) 14 (401.0) 15 (401.0) 13 (149.8) 12 (148.5) 14 (147.78) 23 (56.0) 22 (56.0) 21 (56.0) 9 (63.4) 10 (62.63) 11 (57.0) 23 (47.0) 22 (47.0) 21 (47.0)
hour (value) from highest 17 (239.77) 15 (236.66) 16 (232.6) 23 (62.0) 22 (62.0) 21 (62.0) 23 (73.0) 22 (73.0) 21 (73.0) 17 (362.7) 16 (345.62) 18 (337.0) 23 (57.0) 22 (57.0) 21 (57.0) 23 (7.0) 22 (7.0) 21 (7.0) 17 (30.86) 18 (29.28) 8 (28.74)
hour (value) from highest 14 (232.43) 15 (226.5) 13 (226.47) 23 (62.0) 22 (62.0) 21 (62.0) 23 (73.0) 22 (73.0) 21 (73.0) 14 (309.3) 13 (301.68) 15 (298.49) 23 (57.0) 22 (57.0) 21 (57.0) 23 (7.0) 22 (7.0) 21 (7.0) 18 (53.6) 17 (52.1) 14 (52.09)

Figure 4.11: Peak Hours Inbound

Chapter 4. Data Collection and Exploration

48

4.3.1.4 Exploring Traﬃc Result

Much of the remote sensor data available is corrupt and conﬁgured incorrectly leading duplication of roads and large numbers of observations missing. Patterns in the data are still available as seen in 4.8. Some roads have little change in its traﬃc travel times. Other roads show large deviations in times and identifying volatility on roads was simpliﬁed using Google Maps. Seasonality was identiﬁed by separating weekday and weekend data. By listing the peak times it is proven that in table 4.5 that each observed location has diﬀerent characteristics. In section 5 Model Selection will identify some of the characteristics that inﬂuence an observed location.

4.3.2 Exploring Weather
For this research three diﬀerent weather stations has been chosen to build a model for traﬃc analyses. Each station is records data at random interval mostly between 5 and 10 minutes. There is no guarantee on the time of the weather observation is recorded. The three data sets are comprised of up to 100,000 observations. For exploration the data sets are compared to each other with diﬀerent forms of aggregation. Initially some detail of the full data sets are provided. Other data sets will use aggregated seasonal data sets such as daily, hour and diﬀerent time ranges. At this point we know from other research that weather does eﬀect road conditions [11]. As this study is exploring the dynamics of roads over a large geographical location. It is required to know that not all roads are under the same whether condition at one time or even receive the same level of condition.
The weather variables associated with rainfall and temperature are discussed in greater details in terms of seasonality and reasons behind dimension reduction.

4.3.2.1 Weather Data Set
In listing 4.3.2.1 the description of the data shows more often the conditions dry and the normal temperature ranges from 7 to 15 averaging 11 for a normal giving day. The maximum hourly rainfall is at 2539.7mm. This is either an outlier or a sign of poor data quality.
The correlation between HourlyPercipMM and DailyPercipMM is very high. One of these attributes is a candidate for attribute reduction. DailyPercipMM is derived from an accumulation HourlyPercipMM.

Chapter 4. Data Collection and Exploration

49

Figure 4.12: Weather Histograms, Lucan, Co. Dublin

Figure 4.13: Weather Histograms for Blackrock, Dublin 8

Chapter 4. Data Collection and Exploration

50

Figure 4.14: Weather Histograms for Artane, Dublin 5

2 count mean
4 std min
6 25% 50%
8 75% max
10
12 c o u n t mean
14 s t d min
16 25% 50%
18 75% max

HourlyPrecipMM 98 ,666.00 0.21 16.34 0.00 0.00 0.00 0.00 2 ,539.70

Humidity 98 ,666.00
85.41 14.10 19.00 77.00 90.00 98.00 99.00

TemperatureC \ 98 ,666.00 11.34 5.52 −3.30 7.20 11.00 15.00 34.50

WindSpeedGustKMH 98 ,666.00 14.63 13.41 0.00 0.00 13.40 23.30 177.00

dailyrainMM 98 ,666.00 3.61 34.75 0.00 0.00 0.00 0.50 2 ,539.70

Listing 4.7: Weather Data Set for ICODUBLI2, Lucan

1
HourlyPrecipMM 3 Humidity
TemperatureC 5 WindSpeedGustKMH
dailyrainMM

HourlyPrecipMM 266.87 0.29 0.35 −1.18 266.74

Humidity \ 0.29
198.91 −38.60 −32.36 −24.19

Chapter 4. Data Collection and Exploration

51

7
9 HourlyPrecipMM Humidity
11 TemperatureC WindSpeedGustKMH
13 dailyrainMM

TemperatureC 0.35
−38.60 30.49 13.57 0.41

WindSpeedGustKMH \ −1.18
−32.36 13.57
179.90 −16.85

15
HourlyPrecipMM 17 Humidity
TemperatureC 19 WindSpeedGustKMH
dailyrainMM

dailyrainMM 266.74 −24.19 0.41 −16.85
1 ,207.90

Listing 4.8: Weather Correlation Matrix for ICODUBLI2, Lucan

4.3.2.2 Daily Aggregation Precipitation
In ﬁgure 4.15, using the daily mean of rain it clearly demonstrates that the levels of rain vary according to geographic location. This show a signiﬁcant diﬀerence between weather conditions with each weather station.

Figure 4.15: Weather Stations Rain Daily Mean

Chapter 4. Data Collection and Exploration

52

4.3.2.3 Hourly Aggregation Precipitation

By focusing in on a smaller sample time frame it is evident that the rainfall closing aligned. Still the graph proves the data has some level of correlation but does not align exactly 4.6. In ﬁgure 4.16 on the 27th of January it even demonstrates that has rained in North Dublin (ICODUBLI2 ) but yet the rain did not follow into West or South Dublin.

Figure 4.16: Weather Stations Rain Hourly Mean January 24th-29th

ICODUBLI2 IDUBLINC2 ILEINSTE8

ICODUBLI2 1.000000 0.435804 0.754284

IDUBLINC2 0.435804 1.000000 0.587087

ILEINSTE8 0.754284 0.587087 1.000000

Table 4.6: Weather Stations Correlation Linear Regression on HourlyPrecipMM in Jan 24th - 29th

4.3.2.4 Daily Aggregation Temperature
In ﬁgure 4.18, using the daily mean of temp it clearly demonstrates that the levels of rain vary according to geographic location. Unlike the precipitation the temperature shows an element of seasonality as discussed by [11]. In IDUBLINC2, Artane Dublin 5 there is erroneous values. In July 2013 values diﬀerentiate by nearly 400 degrees Celsius. In table 4.7 the correlation is higher than the precipitation.

Chapter 4. Data Collection and Exploration

53

Figure 4.17: Weather Stations Temperature Daily Mean

Figure 4.18: Weather Stations Temperature Daily Correlation

Chapter 4. Data Collection and Exploration

54

ICODUBLI2 IDUBLINC2 ILEINSTE8

ICODUBLI2 1.000000 0.672347 0.774402

IDUBLINC2 0.672347 1.000000 0.502557

ILEINSTE8 0.774402 0.502557 1.000000

Table 4.7: Weather Stations Correlation Linear Regression on TemperatureC

4.3.2.5 Weather Exploration Result

As a result of the weather exploration if the graphs show that there a clear indication the reasoning behind using diﬀerent weather stations is positive. The weather stations demonstrate diﬀerent patterns in the data. Therefore it is reasonable to believe that the eﬀects on a weather station is spatially related to a road. It has been proven by Kevin Keay and Ian Simmonds in 2004 [11] the there is a relationship between weather condition and traﬃc patterns. Using correlation techniques the dimension of data can be reduced. Precipitation variable HourlyPrecipMM is the best measure for determining wet and dry conditions and TemperatureC is the best variable for cool and hot conditions. It is not necessary to have dailyrainMM and Himidity to ﬁt any model.

4.3.3 Exploring Twitter
There are two twitter data sets, user timeline data set which will be used to aid the extract the classiﬁcation of traﬃc related tweets from real-time tweets. The objective of this is to classify tweets with traﬃc features from AA Road Watch tweets.
Using the AA Road Watch data set the tweets are analysed and split into word tokens. The token analyser will ﬁlter words out that provide better results. These options are explored in the model selection 5. The tokens are used as features for scoring geographically referenced tweets as traﬃc related.
The process of correlating the traﬃc tweets to traﬃc observations is a visual mechanism. The tweet data set available does not span across the same time frame as the traﬃc observations. The geographically referenced tweets data ranges from 2014/04/15 to 2014/04/26. The AA Road Watch user timeline data set is a sample taken from 2013/12/15 to 2014/04/26.

4.3.3.1 User Timeline Tweets
The AA Road produce tweets that are communicated to the public as a service to the state with information contain traﬃc news. The AA Road Watch corpus contains 5267 tweets. Using tokeniser parameters 4.3.3.1 a TF-IDF vector 4.3.3.1 represents the sample

Chapter 4. Data Collection and Exploration

55

features in traﬃc related tweets. The result accumulates 4866 total features. Using 4.19 the features are visualised. This method reveals immediate inﬂuential key features and provides an overview of the vocabulary used to provide traﬃc information.

2 TfidfVectorizer (

analyzer=’ word ’ ,

4

t o k e n p a t t e r n=r ’ [ a−z ] { 4 , } ’ ,

u s e i d f=True ,

6

strip accents=’ unicode ’ ,

s u b l i n e a r t f=False )

Listing 4.9: Python Word Tokenizer

The tokenizer parameters allows for each tweet to be broken into token features. Not all parameter are utilized in the exploration stage. Further investigation into NGrams and Frequency Ranges are considered in the Chapter Model Selection 5.

Parameter analyzer
token pattern
strip accents

Options ’word’, ’char’, ’char wb’
r’[a-z]4,’ only contains letters a-z length 4 ’ascii’, ’unicode’, None

Description types of tokens, words or characters Regular expression denoting what constitutes a ”token” Remove accents during the preprocessing step. ’ascii’ is a fast method that only works on characters that have an direct ASCII mapping. ’unicode’ is a slightly slower method that works on any characters. None (default) does nothing.

Table 4.8: Tf-idf Tokenizer

The word cloud 4.19 provides an insight into the traﬃc vocabulary. The TFIDF scores the features in the corpus and the word cloud displays the most prominent features. The features can be categorised into three fundamental areas. Word associated with Traﬃc, Location and Punctuated Twitter Words.
Traﬃc features words from the word cloud are traﬃc, debris, volume, broken, overturned. The Traﬃc feature in the thesis will be used to score or categorise the geographically referenced tweets.

Chapter 4. Data Collection and Exploration

56

Location features are not an indicator of a tweets being traﬃc related but do indicate the location of where a traﬃc information is referring too, i.e. waterford, monastervin, bray, knock.

Punctuated Twitter Words are features associated with HashTag, Users and URLs, i.e. #AARW, Peterbowles and http://t.co/YEsG6RDQW3. The vectorisor mechanism transforms the URL from http://t.co/YEsG6RDQW3 to YEsG6RDQW3.

Figure 4.19: AA Road Watch Cloud

2 affect

0.259152401722

cleared

0.42853734037

4 closures

0.42853734037

collision

0.42853734037

6 limerick

0.140959969996

monastervin

0.245823461838

8 msfrugalone

0.21506648088

newtownmountkennedy 0.289172991764

Chapter 4. Data Collection and Exploration

57

10 northbound ofzigkql
12 outbound overturned
14 quay quays
16 qvbpcgxuj removed
18 r e p o r t southbound
20 t a r a there
22 t h i s traffic
24 volume

0.312560130227 0.26570466618 0.232460185377
0.312560130227 0.312560130227
0.152360240527 0.312560130227 0.312560130227 0.4472135955
0.4472135955 0.301011047979
0.301011047979 0.404731899373
0.344059090764 0.404731899373

Listing 4.10: Word TF-IDF Vector Sample

4.3.3.2 Conclusion
As a result the word cloud makes it easier to understand the data compared to the word vector listing 4.3.3.1. In chapter 5 the scoring mechanism will compare the geographical referenced tweets using the diﬀerent categories of features such as traﬃc, location and punctuated twitter words. Some tweets updates do not contain traﬃc information. Often updates contain only thank you messages such as ” @HamillsRecovery Thanks for that” and ” @Clareokeeﬀe19 Thanks for the heads up Clare. http://t.co/qvBPcggRh8”. The data set contains 5270 tweets. The TF-IDF Vectorizer is not eﬀected by such tweets.
4.3.3.3 Geographical Referenced Tweets
The purpose of this section is to explore geographically referenced tweets. Using Google Maps the number of tweets is visualised, see 4.20. The ﬁgure represents all tweets for the date and hour of 2014/04/18 9:00pm. Google Maps provide a clustering mechanism the groups the spatially related tweets together.

Chapter 4. Data Collection and Exploration

58

Figure 4.20: Geographical Referenced Tweets on 2014/04/18 9:00pm
Without the traﬃc scoring mechanism in place is no apparent relationship between the tweets from potentially high volume traﬃc in ??. The Hat icons represent universities in Dublin, Trinity College in the city centre, Dublin City University in the north of Dublin and University College Dublin in south of Dublin. The high volume yellow clusters correlate with the universities of Dublin, one yellow cluster in Dublin Airport and one on the Malahide Road. In chapter 5 the relationship between extremely busy junctions along with traﬃc tweets will be analysed.
In ﬁgure 4.21 junction 16/2/1 of Wexford St and Kevin St shows that this particular junction is a volatile junction as discussed in section 4.3.1. The peak time for junction 16/2/1 during week days is the hours of 18:00 and 17:00. Using the method of extracting peak times in section 4.3.1 and searching tweets that contain any of the words from the word cloud 4.19 traﬃc, debris, volume, broken, overturned proves that traﬃc tweets exist within the data set within the maximum distance of 1km from the junction.

Chapter 4. Data Collection and Exploration

59

Figure 4.21: Junction Wexford St and Kevin St
Based on the tweets containing traﬃc, debris, volume, broken, overturned the listings show mixed results matching traﬃc related tweets using those terms. Debris and overturned contain no results, traﬃc contained 4 results which are related to traﬃc and volume, broken both returned results not related to traﬃc.
1 It took almost 20 minutes to get from Parnell to t r i n i t y the t r a f f i c i s ridiculous today wtf
Today I may c r y a s a commuter #p r o t e s t #s i t t i n g o n a b u s f o r o v e r a h r #t r a f f i c # Dublin
3 Last 67 and the bus d r i v e r wouldnt open the door ten yards from the stop f o r someone who ’ d m i s s e d i t . We were s t u c k i n t r a f f i c . Awful s t u f f .
Jesus . Junkie bleeding from his face and playing Frogger with Capel St and Quays t r a f f i c then lunging and grabbing at t o u r i s t s . Shocking .
Listing 4.11: Tweets with ’traﬃc’ 2014/04/25 18:00-18:59pm
1 Someone i s p l a y i n g r o c k / heavy metal on max volume . Guess I ’ l l have t o w a i t a l i l b i t l o n g e r then b e f o r e I can study #s o r r y i m n o t s o r r y
Listing 4.12: Tweets with ’volume’ 2014/04/25 18:00-18:59pm
1 @towerdublin p l s t e l l us what l i m i t i s on #u n b r o k e n u n t i e d ? @ d e l o r e n t o s f a n s wanna h e l p each o t h e r out . Wanna t e l l p p l i f we can ’ t buy \&g t ; 1
Listing 4.13: Tweets with ’broken’ 2014/04/25 18:00-18:59pm

Chapter 4. Data Collection and Exploration

60

4.3.3.4 Twitter Conclusion

As a result the geographical referenced tweets contain traﬃc related tweets. The most words with that scored highest in the TF-IDF result does not ensure to produce tweets closer related to traﬃc using the mechanism of a single word search. Further investigation on this is in the Model Section chapter 5. The result of the traﬃc word search resulted in traﬃc tweets. In both cases locations mentioned in the tweets can reﬂect the location of where the tweet was broadcast 4.22.

Figure 4.22: Tweet From Location 2014/04/25 18:00-18:59pm

Chapter 5
Model Selection

5.1 Introduction
In this chapter, we will present data models for prediction based on features travel time observations, spatial neighbours and weather data. The features used are determined by analysing and reducing the necessary ARIMA attributes for building a generic model that will ﬁt all observed locations OLs. To create a generic model features a selected by analysing the correlation using data mining techniques and visualisation.

5.1.1 Standard Travel Time (STT) Model Selection

In this section the focus is mainly on prediction of peak times during weekdays. Three types of traﬃc volatility identiﬁed in the data exploration section analysing distribution of observation values categorised as Low to Medium to High 4.3.1.2. These junctions cover the categories Low to Medium to High. the daily seasonality for observations on peak times during business days Monday to Friday 4.3.1.3. Other seasonality and trends are ignored with the volume of quality data being limited 4.6. Therefore there is no attempt to ﬁnd trends for monthly or quarterly means.

Table 5.1: Correlation coeﬃcients Matrix Colour Coded Summary

>= 0.5 >0 and <0.5 <0

Lag -1 50% 49% 0.2%

Lag -2 39% 59% 1.0%

Lag -3 34% 63% 1.5%

Lag -4 29% 68% 2.0%

Lag -5 30% 69% 1.0%

61

Chapter 5. Chapter Model Selection

62

Figure 5.1: Correlation coeﬃcients Matrix Colour Coded

Figure 5.1 represents the mean peak time daily mean correlation of observed locations. The ﬁrst row is of junction 1/13/2 daily mean for the peak hour 10pm. The columns are the correlation of the daily lag i.e, Lag 1 is equal to -1 day, Lag 2 is -2 days and so on. The colour range demonstrates the correlation to the Standard Travel Time (STT) from positive value 1 correlation is closer Green to negative value -1 correlation Red and similarly yellow is closer to 0 is little or no correlation.

The algorithm for the correlation is based on the relationship between the correlation coeﬃcient matrix, ‘P‘, and the covariance matrix, ‘C‘, is

Pij =

Cij Cii ∗ Cjj

The results show there mostly a correlation with the Lag of -1 and gradual deterioration the more distant the lag becomes. In some cases there is a slight increase in correlation Lag -4 which is a week in business days terms. The ﬁgures [5.2,5.3,5.4] also clarify the daily and weekly correlation. These correlograms represent High, Medium and Low volatility.

Chapter 5. Chapter Model Selection

63

Ordinary Least Squares No. Observations Intercept Adj. R-squared Prob (F-statistic) Lag 1,2,3,4,5,6 Cond. No.

180 40.9404 0.347 2.70 0.39, 0.16, 0.01, 0.18, 0.04, -0.07 2.75

Figure 5.2: Auto Correlation of most volatile time 30/7/1 [’8:00’, ’8:59’]

Ordinary Least Squares No. Observations Intercept Adj. R-squared Prob (F-statistic) Lag 1,2,3,4,5,6 Cond. No.

180 40.9404 0.347 2.70 0.39, 0.16, 0.01, 0.18, 0.04, -0.07 2.75

Figure 5.3: Auto Correlation of most volatile time 13/2/1 [’8:00’, ’8:59’]

Chapter 5. Chapter Model Selection

64

Ordinary Least Squares No. Observations Intercept Adj. R-squared Prob (F-statistic) Lag 1,2,3,4,5,6 Cond. No.

180 40.9404 0.347 2.70 0.39, 0.16, 0.01, 0.18, 0.04, -0.07 2.75

Figure 5.4: Auto Correlation of most volatile time 17/6/1 [’8:00’, ’8:59’]

Chapter 5. Chapter Model Selection

65

5.1.1.1 Standard Travel Time (STT) Conclusion

As a result data models for each observed location above 0.5 exists for 50% and is positive for another 49% for lagged -1 day. This percentage slowly decreases further down the historical path with a slight increase in lag -5 which represent lag -1 week. Therefore it may be beneﬁcial to maintain the lag -1 week in the data model. With the correlogram in Figure 5.2 demonstrates a clear correlation between lag week -1. Figures [5.3 , 5.4] do not contain such correlation. In the section 5.1.5 a comparison of exponential moving average and historical lagged data is evaluated.

5.1.2 Weather Model Selection
In this section the STT correlation with the weather conditions of rain (dailyrainMM) and temperature (TemperatureC). The exploration section has identiﬁed these attributes 4.3.2.1 as the variables suitable for weather prediction. The same correlation metric is used for weather that was used in the STT modelling section 5.1.1 which is the correlation coeﬃcient matrix and the covariance matrix. The ﬁgure [5.55.6] are visualisations using Google Maps of the correlation of rainfall and ﬁgures [5.55.6] are visualisations of the correlation of temperature. The visualisations circles on the map provides the strength of the correlation by the size of the circle and the colour representing the weather station it has the strongest correlation too. The circles are overlaying its related observed location. Negative correlation is apparent in the map when the circle has an opacity of 0.5 making it half transparent. The range values for correlation is between -1 and 1. On the maps the circle represent the station with the correlation value furthest from 0 whether it is negative or positive. The yellow circles provide the scale and transparency as an example of the value representation.
For example, if green Blackrock is value -0.3 and the red Artane value is 2.9, then the map will display the value -0.3 represented by the green BlackRock.

Chapter 5. Chapter Model Selection

66

Figure 5.5: Correlation of Rain Map Direction Inbound Peak Times
In ﬁgure 5.5 the strongest rain correlation for peak times inbound is dominated by the weather station IDUBLINC2 in Artane Dublin 5. The correlation is also mostly positive. The circle A at location 4/1/1 and B at location 30/2/1 are highly aﬀected by rain. The dailyRainMM correlation for 4/1/1 is 0.36 and the correlation for 30/2/1 is 0.34. Many of the other correlations are less signiﬁcant and contradictory to adjacent locations where the correlation is positive. This is demonstrated by area at C where the correlations are also in green for weather station ILEINSTE8, Blackrock Dublin 4, see table 5.1.2. Both streches of road along the coastline see little or no correlations.
Location Correlation 27/2/1 -0.22 28/8/1 0.19

Chapter 5. Chapter Model Selection

67

Figure 5.6: Correlation of Rain Map Direction Outbound Peak Times
In ﬁgure 5.6 the strongest rain correlation for peak times outbound is spread between the weather station IDUBLINC2 in Artane Dublin 5 and ILEINSTE8, Blackrock Dublin 4. Weather ICODUBLI2 in Lucan is not the main inﬂuence at any point. The peak outbound results are not as strong as the impact as the peak inbound. The most likely reason for this is that the weather has a stronger impact in the morning times. Peak times during the business days Monday - Friday are mostly at the hours 8am and 9am with some exceptions see table 4.4 compared to outbound peak times which is mostly after 2pm, see table 2.4.

Chapter 5. Chapter Model Selection

68

Figure 5.7: Correlation of Temperature Map Direction Inbound Peak Times
In ﬁgure 5.7 the strongest Temperature correlation for peak times inbound is spread between the weather station IDUBLINC2 in Artane Dublin 5 and ILEINSTE8, Blackrock Dublin 4. Weather ICODUBLI2 in Lucan is not the main inﬂuence at any point. When the temperature is high and is warm the map appears to have a positive correlation in the national parks Phoenix Park and St. Annes labeled A, C in the ﬁgure. The city centre has a largely positive inﬂuence. The indicates that when the temperature is warm the traﬃc volume increase to both the nation parks and the city centre. The suburban areas on the other hand traﬃc increases when the weather is cold as marked on the map at D, E, F. This indicates people are more likely to use their cars as transport in cold weather.

Chapter 5. Chapter Model Selection

69

Figure 5.8: Correlation of Temperature Map Direction Outbound Peak Times

In ﬁgure 5.8 the Peak Outbound correlation map is similar to the Peak Inbound correlation map.

Table 5.2: Correlation coeﬃcients Rain and Temperature Peak Times

Range >= 1 & >= 0.66 >= 0.33 & <= 0.66 >= 0.0 & <= 0.33 <= 0.0 & >= -0.33 <= -0.33 & >= -0.66 >= -1 & <= -0.66

Lucan Rain Temp 0% 0% 5% 0% 71% 63% 28% 31% 0% 1% 0% 0%

Blackrock Rain Temp 0% 0% 7% 2% 40% 58% 60% 31% 3% 0% 0% 0%

Artane Rain Temp 0% 0% 8% 8% 65% 59% 34% 31% 2% 8% 0% 0%

5.1.3 Weather Model Selection Conclusion
In table 5.2 the correlation of weather variables to the observed location are on the low range between -0.33 to 0.33. This indicates that not much impact on weather to the locations. Any location lower than -0.33 or above 0.33 implies the further investigation on the quality of the road or design of the road network may need further investigation.

Chapter 5. Chapter Model Selection

70

The beneﬁt of having Artane and Blackrock weather variables has signiﬁcant importance to predicting STT and will used as features in the prediction model.

5.1.4 Spatial Model Selection

In spatial model selection the focus is determining the best predictive features for the

standard travel time (STT). The number of attributes vary between diﬀerent locations.

The number of neighbours using the vertex method may can range from 1 to 39, ex-

cluding itself. Vertex is the point of where two lines meet 5.9. The ﬁgure shows 9/10/1

Inbound neighbours as white arrows and Outbound arrows in bright blue. The spatial

modelling compares the features using both Inbound and Outbound together and then

comparing Inbound locations with Inbound neighbours or Outbound with Outbound

neighbours and the highest correlated neighbour. Using all neighbours as features for

the predictive model is considered non feasible in this paper due to the complexity of

diﬀerences in locations with the number of neighbours. The sample subset matrix in

ﬁgure 5.10 illustrates this complexity. For the scoring of spatial models correlation based

on the relationship between the correlation coeﬃcient matrix, ‘P‘, and the covariance

matrix, ‘C‘ [26], is:

Pij =

Cij Cii ∗ Cjj

This correlation score is the primary scoring factor for each location. Each data will

only contain peak times of each location during business days Monday to Friday.

Figure 5.9: Vertex neighbouring with no ﬁlter

Chapter 5. Chapter Model Selection

71

Figure 5.10: Sample vertex neighbouring with matrix

Any location neighbours will contain one or more neighbouring locations. The STT for each neighbour converted to a single feature using the mean of each set of neighbours. As described in section 5.1.1 historical data available is only available after 1 day. The correlation measure will be compared to a minimum of one day lagged. The section also has proven that lag one day is highest scoring correlation. with this the spatial correlation be measured against the same historical distance measure. In the ﬁgure 5.11 the sample of the results is described in table 5.3.

Table 5.3: Description sample spatial correlation result ﬁgure

Label itself-1 inout-1 samedir-1 oppdir-1 max-1

Description The location with lagged STT of one day Inbound & Outbound neighbours with lagged STT of one day Directionally similar neighbours with lagged STT of one day Directionally opposite neighbours with lagged STT of one day Highest correlated neighbour lagged STT of one day value

Evaluating the sample correlation result in ﬁgure 5.11 each location varies in the strength of the correlation from the STT. inout-1, oppdir-1 and samedir-1 show little variance in values. These variables also show minor diﬀerences to the STT lagged -1.
Max-1 highlifhted in blue 5.11 variable is the most likely to pose the signiﬁcant diﬀerence. Column 13/5/1 at max-1 the value is -0.16 while 15/12/1 at max-1 the value is 0.98.

Chapter 5. Chapter Model Selection

72

Figure 5.11: Sample spatial correlation result

Table 5.4: Overview of Spatial Correlation Results

>= 0.5 & <= 1 >= 0.0 & <= 0.5 >= 0.0 & <= 0.5

itself-1 33.96% 62.30% 3.21%

inout-1 31.55% 65.24% 3.21%

max-1 33.96% 53.48% 12.30%

oppdir-1 33.96% 62.83% 3.21%

samedir-1 35.03% 59.89% 4.81%

5.1.4.1 Spatial Model Selection Conclusion
The table 5.4 is the overview of the correlation result scores. It demonstrates the each data model works with similar eﬀect as a potential variable to best predict STT. The correlations above 0.5 are above 30%. The beneﬁt of having each variable as a feature in a prediction has been proven that it may have little signiﬁcant diﬀerence with compared to the SST lagged -1. The one exception to this is the variable max-1. In the prediction model section 5.1.5 the max-1 (strongest correlation neighbour) will be used as a feature. The inout-1, oppdir-1, samedir-1 not be tested as features.

Chapter 5. Chapter Model Selection

73

5.1.5 Prediction Model Fitting

In this section the prediction algorithms are applied to the dataset comprised of the features discussed in the Standard Travel Time Selection 5.1.1, Weather Model Selection 5.1.2, Spatial Model Selection 5.1.4. The objective of this section is the generate the best ﬁt model for estimating next day STT. In this a description of the datasets are provided,
To estimate the best ﬁt model a scoring mechanism is needed to build a comparison of algorithms for each observed location.

5.1.5.1 Predictive Datasets

Spatial data and Weather data variables account for some of the noise associated with the STT value. The lagged values provide a measure forecasting. Each 563 observed locations is a unique dataset comprised of the same features described in 5.5. A sample dataset is in Appendix E.

Table 5.5: Description sample spatial correlation result ﬁgure

Feature STT S MAX W DLR W DLT W ILR W ILT STT1 STT2 STT3 STT5

Description The predictive label lagged STT -1 day Highest Correlated neighbour Artane Rainfall in Millimetres Artane Temperature in Celcius Blackrock Rainfall in Millimetres Blackrock Temperature in Celcius lagged STT -1 day lagged STT -2 day lagged STT -3 day lagged STT -5 day or -1 week

To avoid over ﬁtting cross validation is used split the dataset into training and testing datasets. The test size set to 30% of the full datasets resulting into a 93 to 40 split. The dataset contain 138 samples. The missing 5 samples are due to the removal of missing values from the moving average mechanism.

5.1.5.2 Prediction Algorithms
The algorithms chosen are to handle the noise that is not accounted for in the current features in the datasets. The STT prediction values are can be highly volatile (see section 4.3.1.3) and weather and spatial features can account for some of the noise, see table

Chapter 5. Chapter Model Selection

74

5.6. The algortihm are part of the Sklearn toolkit within Python. Linear regression is one of oldest algorithm. Both Bayesian Ridge and Online Passive Aggressive Regressor are modern linear algorithm that account for noise by setting bounds on the residuals. While Support Vector Regression is a popular non-linear algorithm.

Table 5.6: Estimation algorithms

Algorithm LinearRegression LinearRegression BayesianRidge Online Passive Aggressive Regressor Support Vector Regression

Parameters Fit Intercept , Normalise Coeﬃents Default Default Default kernel rbf

5.1.5.3 Evaluating estimator performance
To avoid over ﬁtting cross validation is used to split the data sets in training and testing data set. The samples are split to the ratio 7:3. Due to the limited size of the dataset some over ﬁt still occurs.
The python Sklearn scipy kit provides approaches to evaluate the quality of estimation algorithm for Regression models [26].
Regression models scoring mechanisms known as Mean Absolute Error (MAE), Mean Squared Error (MSE), Regression Coeﬃcient score (R2), Explained Variance Score (EVS) are all available scoring mechanisms in Sklearn.
MAE is used for scoring the best prediction algorithm. MAE score measure is best when closer to 0. EVS best score is 1 and worst is 0 and provide a easier mechanism for comparison to other OL scores.
5.1.5.4 Prediction Results
As result it was achievable to build a generic model that would match a good level of accuracy for each observed location OL. Appendix F provides detailed results while the result are plotted in ﬁgures 5.12 5.14 5.13 5.15 give a overview of the accuracy.
• Linear regression Ordinary Least Square Linear Regression scores the best prediction algorithm in the majority of cases. This is due to the standard distribution (STD) of the values having a value of less than 1. STD of value less than 1 occurs on 39 of the 563

Chapter 5. Chapter Model Selection

75

predictors. For the other Linear Regression algorithms the perform best when the parameters are set to ﬁt intercept is true and normalize is true.
Figure 5.12: Linear Regression Fit intercept and Normalise 14/3/2

• Support Vector Regression (SVR) can be used when the kernal is linear. This algorithm also performs well. SVR is a type of Support Vector Machine algorithm that can be ﬁt for linear models.
Figure 5.13: Support Vector Machine Regression 30/20/1

Chapter 5. Chapter Model Selection

76

• Bayesian Ridge Regression Bayesian Ridge assumes gaussian process and is similar to ARD Regression without the normalisation of parameters [26].
Figure 5.14: Bayesian Ridge Regression 31/5/2

• Online Passive Aggressor Regression A variation of the SGD Regressor the Online Passive-Aggressive [26, 30].
Figure 5.15: Online Passive Aggressor Regression 18/6/1

Chapter 5. Chapter Model Selection

77

As a result the ﬁgure 5.16 the spatial distribution of algorithms in Dublin at oﬀ-peak time with inbound direction. This highlights the high use of the linear model of Bayesian Ridge.

Figure 5.16: Oﬀ-peak and Inbound Algorithm Map

5.2 Twitter Traﬃc Modelling

The objective of this section is to analyse the approach of using the traﬃc domain tweets to extract tweets from real-time data that is related to the traﬃc domain.

• Passive Aggressive Classiﬁer

Tokeniser

1 TfidfVectorizer (

a n a l y z e r= ’ word ’ , t o k e n p a t t e r n=r ’ [ a−z ] { 3 , } ’ ,

3

u s e i d f=True , s t r i p a c c e n t s= ’ u n i c o d e ’ ,

s u b l i n e a r t f=True , max df =0.95 , m i n d f =0.05 ,

5

stop words= ’ e n g l i s h ’ )

Result

1 \lablel{algorithm tweetresult}

precision

recall

f1−score support samples

Chapter 5. Chapter Model Selection

78

3

Traffic

1.00

0.31

0.48

5000

5

Non−T r a f f i c 0 . 5 9

1.00

0.74

5000

7

avg / total 0.80

0.66

0.61

10000

Passive Aggressive Classiﬁer is an example of one of the algorithms used to classify the real-time traﬃc tweets. Using TﬁdfVectorizer in Python tweets are tokenised to ﬁt the predictive model for the classiﬁer. The result contain the result of using samples taken from the traﬃc domain and real-time data. As expected tweets from the traﬃc domain is 100%. For a successful result for extracting traﬃc tweets from real-time data must not be 100%. Table 5.7 show the result of real-time tweets classiﬁed as traﬃc related.

Table 5.7: Real-time Tweets Classiﬁed as Traﬃc

Accuracy True Positive
False Positive

Text No better way to start your day with a car crash, and then forgetting about the banana in my pocket going through security... We’re gonna crash vine if we keep doing this

False Positive Lyndsay Lohan looks like a car crash.... She is wrote oﬀ #ChattyMan

True Positive I bloody hate waiting #delays http://t.co/Yh55PrfQK3 True Positive There’s after been a crash outside my estate, 3 ﬁre trucks and 3
ambulances

5.2.1 Twitter Conclusion and Analysis
Not enough variations of tokenising, feature selection and algorithm have been tested. Part of Speech would be useful to identify celebrities or place name that may improve the elimination of the false positives. As a proof of concept the classiﬁcation approach worked as designed. The real-time traﬃc tweet could be used to provide further analysis on traﬃc delays. Results section 6.2 provides more details such implementation.

Chapter 6
Results and Conclusions

6.1 Big Data

As a result of using NoSQL to overcome the challenges of the four V’s the approach stored volumes of data that on a single machine RDMS system would of been problematic 6.1.

Table 6.1: Volumes of Data

Data Source Traﬃc Observations Real-time Tweets User Tweets Weather Records

Items 501,402,840 3,048,310 5,267 229,311

No. of Documents 8,356,714 116 5,267 2,103

Throughout the sections of data collection, exploration and modelling techniques of divide and conquer allowing for the data to be aggregated to the point 563 prediction models were created for peak and oﬀ-peak times, see chapters 4 and 5. The work was done on a single machine but the database system and the indexing mechanism provide scalability that allow adding more machines to that database for velocity and volume storage.

6.2 Visualisation
Google Maps, JQuery and Pythons web framework Django was heavily utilised to create an application that was not only for exploration spatial data but analysing the patterns of traﬃc such as volatility, analyse past events and predict traﬃc. The resulting application provides functionality for visual analysis on, volatility of roads, the eﬀect of weather on

79

Chapter 5. Results and Conclusions

80

locations with respect to travel times and performing analysis on locations for a speciﬁc time, see ﬁgure 6.1.

Chapter 5. Results and Conclusions

81

Figure 6.1: Dashboard Analysis for 21/04/2014 8pm to 9pm

Chapter 5. Results and Conclusions

82

6.3 Traﬃc Analysis

6.3.1 Seasonality
Measuring all aspects of seasonality came as a challenge due to the lack of quality data. This is a common problem when dealing with open data. Annual, quarterly and monthly trend analysis could not be performed. The work concentrated mostly on weekly and daily trends. The diﬀerence in peak traﬃc times of weekend and weekday was clear. Week-end peak times usually centred on mid-day and week-day peak time was in the morning or evening time from 2pm on.

6.3.2 Weather
Trends in the traﬃc patterns based on weather were identiﬁed. It was demonstrated that high temperature people were more likely to travel into the city centre and public parks as travel times would spike when this happened. The impact with rainfall was with an increase in travel time near small villages at Castleknock, Raheny, Drumcondra among others. This could indicate the village cannot handle the increase in traﬃc ﬂow while people are more likely to drive than walk in the rain to their shopping. This may indicate that people will travel short distances to a local village when it is raining but when it is dry and warm people may travel to do there shopping in the city centre.

6.3.3 Prediction Model
The ﬁnal prediction model became a hybrid of SARIMA and Multivariate ARIMA. It may be considered the linear outperformed the non-linear algorithms for prediction accuracy. It also needs to be considered that the data model designed was a generic model that would ﬁt all observed locations. One of the limitations was the an artiﬁcial neural network could not be implemented as part of Python SciPy Toolkit. Therefore only one non-linear model was compared to four linear algorithms. Due to the number of overall samples tested there may be a case that over-ﬁtting aﬀected some results. Some algorithms beneﬁted due to the lack of volatility in the standard deviation.

6.3.4 Analytics Dashboard
In ﬁgure 6.1 the dashboard contains a some false positives for the time 21/04/2014 8pm to 9pm. The approach of obtaining tweets from a speciﬁc domain to classify real-time data feasible. It this classifying tweets using more intelligent classiﬁcation

Bibliography

83

models is needed. In ﬁgure 6.1 it is reasonable to see why ”Lyndey Lohan looks like a car crash.. she is wrote oﬀ #ChattyMan” is classiﬁed as a traﬃc related tweet. At the same time ”We hope our new display doesn’t cause too many delays in Donnybrook .... http://t.co/sDKrey1pJf”.

6.4 Future Work
For future due to the data quality the number of samples was limited. Seasonality comparisons were not tested to account for school holidays over the summer or winter breaks. In the visualisation of prediction results the observed locations did not apply any sort of key performance indicator (KPI). The current state applies higher or lower than predicted by colouring the prediction red or green. A method for using a colour range to allow the reader understand the scale the prediction deviates from the actual result. More evaluation on the algorithms, tokenising mechanisms and scoring of the Twitter traﬃc classiﬁcation is necessary to improve the quality of the result. Text mining techniques such as Stop Word removal and Part-of-Speech would likely help to improve the classiﬁcation.

Bibliography
[1] Duckwon Chung et el. Road traﬃc big data collision analysis processing framework. IEEE, 2013.
[2] Vinay Gavirangaswamy et el. Assessment of arima-based prediction techniques for road-traﬃc volume. 2013.
[3] DubLinked. Trips data, 2012-2014. URL http://www.dublinked.ie/datastore/ datasets/dataset-215.php.
[4] McCreadie et al. Scalable distributed event detection for twitter. IEEE, 2013. [5] MongoDB. Big data explained @ONLINE, 2014. URL http://www.mongodb.com/
big-data-explained. [6] Kalman R. E. A new approach to linear ﬁltering and prediction problems. IEEE,
1960. [7] Dehuai Zeng et el. Short term traﬃc ﬂow prediction using hybrid arima and ann
models. 2008. [8] Wei-Chiang Hong et al. Seasonal adjustment in a svr with chaotic simulated an-
nealing algorithm traﬃc ﬂow forecasting model. 2010. [9] Kevin Keay and Ian Simmonds. The association of rainfall and other weather
variables with road traﬃc volume in melbourne australia. 2004. [10] Bei Pan et el. Crowd sensing of traﬃc anomalies based on human mobility and
social media. IEEE, 2013. [11] Stephen Dunne and Bidisha Ghosh. Weather adaptive traﬃc prediction using neu-
rowavelet models. 2013. [12] Yorgos J. Stephanedes. Dynamic prediction of traﬃc volume through kalman ﬁl-
tering theory rescue. 1983. [13] Bowu Zhang et al. Traﬃc clustering and online traﬃc prediction in vehicle networks.
A Social Inﬂuence Perspective, 2012. 84

Bibliography

85

[14] Yousef-Awwad Daraghmi et el. Space-time multivariate negative binomial regression for urban short-term traﬃc volume prediction. IEEE, 2012.
[15] Sri Krisna Endarnoto et al. Traﬃc condition information extraction & visualization from social media twitter for android mobile application. IEEE, 2011.
[16] Amit Sheth. Transforming big data into smart data: Deriving value via harnessing volume, variety, and velocity using semantic techniques and technologies. 2014.
[17] Shweta Pandey and Dr.Vrinda Tokekar. Prominence of mapreduce in big data processing. 2014.
[18] Howard Gobioﬀ Sanjay Ghemawat and Shun-Tak Leung. The google ﬁle system, October, 2003.
[19] Duckwon Chung et el. United nations global pulse, 2012, big data for development: Challenges & opportunities. May 2012.
[20] Executive Oﬃce of the President. Oﬃce of science and technology policy. IEEE, 2012.
[21] Brito et al. Scalable and low-latency data processing with streammapreduce. IEEE, 2011.
[22] Pricilla Hancock Kristopher Reese, Russell Bessette. Knowyourcolors: Visual dashboards for blood metrics and healthcare analytics. IEEE, 2013.
[23] Carlos Costa Lu´ıs Bastiao Silva Louis Beroud and Jos´e Luis Oliveira. Medical imaging archiving: a comparison between several nosql solutions. 2013.
[24] Dr. Vincent Granville. Developing analytic talent: Becoming a data scientist. Wiley; 1st edition, 2014.
[25] Gong Jun et al. Forecasting urban traﬃc ﬂow by svr. 2013.
[26] Machine Learning in Python Scikit-learn. Scikit-learn developers, 2010 - 2014. URL http://scikit-learn.org/.
[27] Wunderground. Wunderground, 2012 - 2014. URL http://www.wunderground. com.
[28] Daniel J Tulloch. A garch analysis of the determinants of increased volatility of returns in the european energy utilities sector since liberalisation. IEEE, 2012.
[29] Rohit Dhawan Sven F. Crone. Forecasting seasonal time series with neural networks: A sensitivity analysis of architecture parameters. IEEE, 2007.
[30] et al Koby Crammer. Online passive-aggressive algorithms. 2006.

Appendix A
Appendix Traﬃc Web Crawl

1 import bz2 import os
3
import attrdict 5 import urllib3
from datetime import datetime 7 from bs4 import BeautifulSoup

9 # check for extraction directories existence

i f not os . path . i s d i r ( ’ downloaded ’ ) :

11

os . makedirs ( ’ downloaded ’ )

13 i f not o s . path . i s d i r ( ’ e x t r a c t e d ’ ) : os . makedirs ( ’ extracted ’ )

15

def persistTrafficData (a) :

17

#i f os . path . i s f i l e (” extracted /” + a) :

filename = a

19

date = filename [4:12]

21

argv = attrdict . AttrDict ()

argv . filename = a

23

argv . date = date

#d e l GisConvert

25

#i f ”201310” in a :

import smartcity . module . TransformTrafficData as tranformData

27

import s m a r t c i t y . module . WeatherCrawlExtract as wc

29

d a t e = d a t e t i m e . s t r p t i m e ( date , ”%Y%m%d” )

w = wc . crawlWeatherForDate ( date )

31

g = tranformData . processfile ( argv )

86

Appendix Traﬃc Web Crawl

87

33

del g

del w

35

del argv

37 h t t p = u r l l i b 3 . PoolManager ( ) a r c h i v e D i r e c t o r y = ” h t t p : / /www. d u b l i n k e d . i e / d a t a s t o r e / l o c a l /DCC/ t r i p s / archive /”
39 h t t p p o o l = u r l l i b 3 . c o n n e c t i o n f r o m u r l ( a r c h i v e D i r e c t o r y ) stream = h t t p p o o l . u r l o p e n ( ’GET ’ , a r c h i v e D i r e c t o r y )
41 t e x t = stream . data

43

# r e t r i e v e l i s t o f URLs from t h e w e b s e r v e r s

45 soup = B e a u t i f u l S o u p ( t e x t )

r e s = soup . f i n d a l l ( ’ a ’ , h r e f=True )

47 l i n k s = [ ]

for n in res :

49

if ”.” in n[ ’ href ’ ]:

l i n k s . append (n [ ’ href ’ ] )

51
# only parse urls 53 f o r f i l e n a m e i n l i n k s :
if ’ . ’ in filename :

55

# download the f i l e

57

archiveFile = archiveDirectory + filename

outputFile = ”downloaded/” + filename

59

p r i n t ( ” S t a r t ” , d a t e t i m e . now ( ) )

# check i f f i l e already e x i s t s on disk

61

i f os . path . i s f i l e ( outputFile ) i s not True :

print (”Skipping ” + archiveFile )

63

print (”Downloading ” , archiveFile )

http pool = urllib3 . connection from url ( archiveFile )

65

r c s v = h t t p p o o l . u r l o p e n ( ’GET ’ , a r c h i v e F i l e )

# save data to disk

67

output = open ( o u t p u t F i l e , ’wb ’ )

69

output . write ( rcsv . data )

output . close ()

71

73

i f os . path . i s f i l e ( ” extracted /” + filename + ” . csv ” ) i s not True :

zfobj = bz2 . BZ2File ( outputFile , ’ rb ’ )

75

try :

#s a v e e x t r a c t e d f i l e

77

f = open ( ” e x t r a c t e d / ” + f i l e n a m e + ” . c s v ” , ’wb ’ )

f . write ( zfobj . read () )

79

f . close ()

