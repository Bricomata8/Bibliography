Online Packet Scheduling with Hard Deadlines in Wired Networks

Zhoujia Mao, C. Emre Koksal, Ness B. Shroff E-mail: maoz@ece.osu.edu, koksal@ece.osu.edu, shroff@ece.osu.edu

Abstract—The problem of online job or packet scheduling with hard deadlines has been studied extensively in the single hop setting, whereas it is notoriously difﬁcult in the multihop setting. This difﬁculty stems from the fact that packet scheduling decisions at each hop inﬂuences and are inﬂuenced by decisions on other hops and only a few provably efﬁcient online scheduling algorithms exist in the multihop setting. We consider a general multihop wired network topology in which packets with various deadlines and weights arrive at and are destined to different nodes through given routes. We study the problem of joint admission control and packet scheduling in order to maximize the cumulative weights of the packets that reach their destinations within their deadlines. We ﬁrst focus on uplink transmissions in the tree topology and show that the well known earliest deadline ﬁrst algorithm achieves the same performance as the optimal off-line algorithm for any feasible arrival pattern. We then address the general topology with multiple source-destination pairs, develop a simple online algorithm and show that it is O(PM log PM )competitive where PM is the maximum route length among all packets. Our algorithm only requires information along the route of each packet and our result is valid for general arrival samples. Via numerical results, we show that our algorithm achieves performance that is comparable to the non-causal optimal offline algorithm. To the best of our knowledge, this is the ﬁrst algorithm with a provable (based on a sample-path construction) competitive ratio, subject to hard deadline constraints for general network topologies.
I. INTRODUCTION
We consider a wired network in which nodes receive packets with various (hard) deadlines, enqueued at the intermediate nodes through multiple hops along given routes to given destinations. We assume a time slotted system in which each packet has an identical (unit) length and each link in the network can serve an integer number of packets at a given time slot. Each packet has a certain weight and a deadline and we address the problem of scheduler design in order to maximize the total weight over the packets that are successfully transferred to their destinations within their deadlines. We ﬁrst focus on the tree topology and show that the Earliest Deadline First (EDF) algorithm achieves the same performance as the optimal off-line algorithm for any feasible or under-loaded (i.e., there exists an off-line algorithm under which all jobs can be served before their deadlines) network arrival pattern. Next, we study the general topology with multiple source-destination pairs. We develop a low-complexity on-line joint admission control and packet scheduling scheme and evaluate its competitive ratio1
1The competitive ratio of an on-line algorithm is the minimum ratio of the revenue of the on-line algorithm to the revenue of the optimal off-line algorithm, where the minimization is over all possible arrival patterns.

with respect to the cumulative weight achieved by the optimal

off-line algorithm. Our scheme only requires information of the

packet queues along the route of each packet. To the best of our

knowledge, this is the ﬁrst scheme with a provable (based on a

sample-path construction) competitive ratio in general network

topologies.

The on-line job scheduling problem with hard deadlines is

gaining increasing importance with the emergence of cloud

computing, large data centers, and grid communications. In

such applications, a large amount of time-sensitive information

needs to be carried among servers and users over a mainly-

wired infrastructure. Meeting the deadline requirements of these

jobs with an efﬁcient use of resources requires a careful design

of schedulers that decide on how and when data should be

transferred over the network. Due to the large volume of data,

the complexity of schedulers should be kept low to reduce

the amount of energy consumed by these data centers. To that

end, our objective is to develop a low-complexity and provably

efﬁcient scheduler and an associated admission controller for

deadline-constrained data.

On-line job scheduling has been a widely-studied problem.

Since the seminal work in [1], various versions of the problem

for single hop systems have been considered. It has been shown

that EDF has the same performance as the optimal off-line

algorithm [1, 2] for the scenario in which the system is under-

loaded. When considering over-loaded arrivals (i.e., the case

when even the best off-line policy drops some jobs), there

is the additional question of whether the controller needs to

decide to accept or reject a job upon arrival, i.e., admission

control. With the constraint that the admission controller and

the scheduler do not have to decide on a job’s admission into

the system and the period that it is scheduled upon arrival, it

is

shown

in

[3]

that

1 4

is

the

best

competitive

ratio

among

all

on-line algorithms and an online algorithm is provided [4] to

achieve this ratio. With this constraint the problem is addressed

in [5, 6]. In addition to immediate decisions, the model studied

in [7] imposes a penalty on the unﬁnished workload, and the

autho√rs propose an on-line algorithm with competitive ratio 3 − 2 2 and show that this ratio is the best achievable ratio for

all on-line algorithms. Within the single hop setting, similar

problems of job scheduling have been studied in [8–12] for

the scenario with parallel processors, where the controller

needs to decide which machine to process each job as well

as scheduling and admission control. An on-line algorithm

requiring immediate decision upon job arrival is proposed in [9]

with

an

asymptotic

competitive

ratio

e−1 e

.

It

is

later

shown

2

in [10] that this ratio is the maximum achievable ratio for

any on-line algorithm. In [11, 12] a penalty-based model is

introduced for unﬁnished workload and competitive ratios were

derived for various algorithms.

All of the works mentioned above require continuous pro-

cessing of jobs, i.e., each job can be processed, paused, and

restarted at any point in time preemptively. In [13], a slotted

single queue system is considered in which all jobs have

unit length and uniform weights, and it is shown that EDF

has the same performance as the optimal off-line algorithm.

In [14, 15], the same discrete model is considered with jobs

having heterogenous weights an√d it is shown that the achievable

competitive ratio is within [0.5,

5−1 2

].

Furthermore,

it

is

shown

that the lower bound 0.5 is achieved by the largest weight ﬁrst

policy and a lex-optimal scheduling policy is provided.

There have also been a few works that have investigated

the problem of scheduling jobs with deadlines in the multihop

setting. In [16], it has been shown that a modiﬁed version of

EDF achieves the same performance as the optimal off-line

algorithm for any arrival sample path under a wired uplink tree

with uniform link capacities and packet weights. In the ﬁrst part

of our paper, we consider under-loaded arrivals but allow links

to have heterogenous link capacities and show that EDF has the

same performance as that of the optimal off-line algorithm. Our

approach to the problem with the general multihop topology is

motivated by competitive routing in virtual circuit network [17].

In the competitive routing model, link bandwidth is the resource

to be allocated. By viewing the time slots as resources, the

packet scheduling problem can be transferred to a similar

resource allocation problem. However, the model of packet

scheduling with deadlines is different from that of routing

in virtual circuit networks. In virtual circuit networks, the

constraint is the link bandwidth. In contrast, here, the packet

scheduling problem is constrained by the deadlines. It cannot be

mapped to a bandwidth constraint problem by simply viewing

time slots as resources since each packet and its scheduling

decision have an impact on the potential time resources of

other packets. However, as we show in the paper, the idea

used in competitive routing can still be applied with clever

modiﬁcations to develop a competitive ratio based framework

for packet scheduling with deadlines.

Other studies that focus on wireless resource allocation

with hard deadlines include [18–25]. In all of these studies

except [25], either the notions of deadlines are more restricted

or the ﬂows are single hop. In [25], a utility maximization

framework is developed under a general multihop wireless

network with an arbitrary deadline model for arrivals, but

the scheduler in their proposed algorithm needs to enumerate

over all possible schedules that satisfy the interference and

deadline constraints, which is extremely complex. Furthermore,

the authors in [25] are only interested in the feasible (under-

loaded) arrival regions.

To summarize our main contributions in this paper:

• We show that EDF has the same performance of the optimal off-line algorithm under a wired uplink tree with

heterogenous link capacities for any under-loaded arrivals. • We develop a competitive ratio based admission control
and packet scheduling framework that has low complexity and is O(PM log PM )-competitive2 where PM is the maximum route length among all packets, under general wired network topologies and arrival samples. To the best of our knowledge, this is the ﬁrst work on packet scheduling problems with hard deadlines in a general network setting under a sample path argument. This framework also has a nice structure to be extended to wireless networks.

II. PROBLEM STATEMENT

We study the packet scheduling problem with hard deadlines in wired networks. We assume a time slotted system. The arrival sample path consists of K packets where each packet i ∈ {1, 2, . . . , K} (the packet set is indexed in the order of arrival times of the packets) is associated with a triplet (ai, di, ρi). Here, ai and di are the arrival time and the deadline, respectively, both of which are given in slot indices. We allow each packet i to have a weight ρi, which is an arbitrary real number that represents the importance of the packet. We assume inﬁnite packet buffers at all nodes. If packet i is still at a nondestination node by the end of slot di, then it expires and is deleted from the network. Note that, when all packets have ﬁnite deadlines, the packet queues in the network will always remain bounded. We assume that each packet has an identical (unit) length and each link in the network can serve an integer number (possibly different for different links) of packets at a given time slot. Let us deﬁne the indicator function for any policy p, to identify whether a packet reaches its destination within its deadline as:

1pi =

1 0

if i reaches its destination before the end of di otherwise

(1)

and the weighted revenue gained by the successfully received packets as:

Rp =

ρi1pi .

(2)

i∈{1,2,...,K }

Our objective is to solve maxp Rp.

III. OPTIMAL PACKET SCHEDULING IN UPLINK TREE
NETWORKS WITH UNDER-LOADED ARRIVALS
In this section, we consider a wired uplink tree network as shown in Fig. 1. Each packet i arrives at an arbitrary non-root node in slot ai and is destined to the root through multiple hops within its deadline di. We assume uniform weight here for all packets, then our objective reduces to maximizing the throughput, i.e., maxp Rp ≡ maxp i∈{1,2,...,K} 1pi .
Deﬁnition 1: The slack time of packet i in time slot t ∈ [ai, di] is deﬁned as di − t − hi(t) + 1, where hi(t) is the

2O(x)-competitive means the competitive ratio goes to 0 at least as fast as x → ∞.

3

1jp= 1

root

j

1

2

3

m

packet k

n

ak ,dk

Fig. 1. An Uplink Wired Tree

number of hops from the node at which packet i resides in time slot t to the destination of i.
Deﬁnition 2: Policy p is called a work-conserving packet scheduling policy if it keeps each link fully utilized in each time slot, as long as the queue feeding the link contains sufﬁciently many unexpired packets.
Lemma 1: For any non-work-conserving policy, there exists a work conserving policy that achieves an identical or higher throughput under any given arrival pattern.
The intuition behind Lemma 1 is fairly clear, since non-workconserving policies waste resources unnecessarily under all arrival patterns. The detailed proof can be found in [26]. From Lemma 1, we only need to focus on work conserving packet scheduling policies to solve the problem, i.e., maxp Rp ≡ maxp∈C Rp, where C is the set of work conserving packet scheduling policies.
Deﬁnition 3: A work conserving earliest deadline ﬁrst (WCEDF) policy is one in which each node transmits the largest possible set of packets that the link capacity allows with the earliest deadlines among all the packets in its packet queue.
Theorem 1: [16] For an uplink wired tree with identical link capacity, given any arrival sample path (either under-loaded or over-loaded), the WC-EDF policy that only serves packets with non-negative slack times in each slot achieves the same performance as the optimal off-line algorithm in maximizing the throughput.
This theorem, proven in [16], is for an uplink wired tree with identical link rates. Generalization to the case in our scenario, i.e., links may have different rates (as long as they are integer number of packets/time slot) is not straightforward and not provided in [16]. In the following theorem, we extend the result for under-loaded trafﬁc.
Theorem 2: For an uplink wired tree with possibly different link capacities that are integer number of packets per time slot, for all under-loaded arrivals, the WC-EDF policy ensures that all packets reach their destinations before their deadlines.
The detailed proof of Theorem 2 can be found in Appendix A. Note that the proof of Theorem 2 is completely different from that of Theorem 1.
Theorem 2 shows that under WC-EDF, all packets in any under-loaded arrival sample reach their destinations before their deadlines and hence generates the same throughput as the optimal off-line algorithm. Theorem 2 can then be used

to test whether an arrival sample is feasible. Note that, both Theorem 1 and Theorem 2 are not generalizable to a general network topology. Indeed, it can be shown that even for simple topologies, such as the followings, there exists no on-line algorithm that has the same performance as the optimal offline algorithm by constructing appropriate arrival patterns.
• Down-link wired tree even with homogeneous link capacity and under-loaded arrivals
• Line network with multiple ﬂow destinations even with under-loaded arrivals
• Uplink wired tree with heterogeneous link capacities and overloaded arrivals
The details of all three of these examples can be found in [26]. For brevity, here, we focus only on the line network with multiple destinations, and show that no online algorithm can have the same performance as the optimal off-line algorithm even for under-loaded arrivals, by constructing sample arrivals (that the online algorithms can not support) via an adversary.
Example 1: Consider a line network 3 → 1 → 2 and suppose that the link capacity of each link is 1. Initially at node 3, there are two packets k1 and k2 with deadline dk1 = 2, dk2 = 4 whose destinations are node 1 and 2, respectively. Suppose that node 3 transmits k1 to node 1 in time slot 1, and that there is no arrival by the end of slot 1, then node 3 transmits k2 to node 1 in slot 2. Let an adversary inject a packet k3 with deadline dk3 = 3 whose destination is node 2, at node 1 by the end of slot 2, then node 1 transmits k3 to node 2 in slot 3. Further let the adversary inject a packet k4 with deadline dk4 = 4 whose destination is node 2, at node 1 by the end of slot 3, then by the end of slot 4, either k2 or k4 expires. However, this arrival sample is feasible since the off-line algorithm transmits k2 in slot 1 and all four packets are able to reach their destinations within their deadlines. Similarly if node 3 transmits k2 to node 1 in time slot 1, then let the adversary inject a packet k3 with deadline dk3 = 2 (whose destination is node 1), at node 3 by the end of slot 1, then by the end of slot 2, either k1 or k3 expires. However, this arrival sample is also feasible since the off-line algorithm transmits k1 in slot 1 and all three packets are able to reach their destinations before their deadlines. This means under this scenario, no matter what online decision node 3 makes in slot 1, the adversary can always chooses future arrivals so that the online decision is worse than the optimal offline algorithm even though the whole arrival sample is underloaded.
One of the main conclusion one can draw from this section is that, other than some particular settings, there exists no on-line algorithm that achieves the same performance as an optimal offline algorithm. This motivates our study for developing on-line algorithms that have a provable (non-zero) competitive ratio, relative to the optimal off-line algorithm for the general network topology and arrival patterns.
IV. COMPETITIVE PACKET SCHEDULING FOR GENERAL TOPOLOGIES AND ARRIVAL PATTERNS
In this section, we consider a general network topology represented by a directed graph as shown in Fig. 2. We assume

4

that each packet i is routed through a given path3 Pi from its source node to its destination, where Pi denotes the set of links through which the packet is routed in order. For any link l ∈ Pi, let hl(i) denote the hop index of link l in the route of packet i. We assume in this section that each link transmits at most one packet in each slot4 for ease of notation. We allow packets to have different weights ρi, i = 1, 2, . . . , K, and our objective function is as stated in Equation (2).

packet i

ai ,di , ρi ,Pi

src 1

dest 2

dest 1 src 2

Fig. 2. General Network Topology with Multiple Source-Destination Pairs

Upon arrival of each packet, the controller of its source node
decides whether to accept or reject this packet. If there are multiple packets arriving at the network in the same time slot,
we assume the controllers of different packets make decisions at
different instances (in the same time slot) in the same order as the packet index. If packet i is accepted, then each link l ∈ Pi needs to reserve a time slot so that packet i will be transmitted through link l in this reserved slot. The reserved time slot is not changed in the subsequent time slots. Let ti(l) denote the index of this reserved time slot in which packet i is transmitted through link l ∈ Pi if i is accepted. Deﬁne for any i, j, l the following indicator

1  Il(i, j) = 0

packets i, j are accepted; l ∈ Pi, l ∈ Pj; tj(l) ∈ [ai + (hl(i) − 1)si, ai + hl(i)si − 1] otherwise
(3)

where

si =

di − ai + 1 |Pi|

(4)

is the average slack time per hop for packet i with |Pi| as the number of total hops on its route. Note that di − ai + 1 is the maximum allowable end to end delay for packet i in the network. If we divide this delay evenly on each hop, then si is the maximum allowable delay on each hop and [ai + (hl(i) − 1)si, ai + hl(i)si − 1] is the set of time slots that i can use to be transmitted through link l. From another perspective, a time slot can be viewed as a resource and [ai + (hl(i) − 1)si, ai + hl(i)si − 1] is then the set of available resources for packet i and si is the total amount of resources at each link on the route of i. When both i and j are accepted and link l is in the route of both i and j, if the reserved transmission slot of j takes one

3Our framework can be easily generalized when the route of each packet is not predetermined, but for ease of notation, we only present our idea for ﬁxed routing.
4Our results can be generalized when link rates are distinct, as long as they are integer number of packets per time slot.

resource in i’s resource set at link l, then the indicator Il(i, j) becomes 1. This means packet j consumes one unit of resource of packet i at link l. Furthermore, we deﬁne the cost of packet j taking a resource of i at link l as

cl(i, j) = si(µλl(i,j) − 1),

(5)

where µ is a control parameter (we will discuss how to choose the value of µ later when we analyze the performance of our algorithm proposed later in this section) and

λl(i,

j)

=

m<j

Il(i, m) si

(6)

is the fraction of i’s resources5 that have already been taken before arrival of packet j at link l. By letting λl(i, 1) = 0 for all i, l, we have the following recursive relationship:

λl(i,

j

+

1)

=

λl(i,

j)

+

Il(i, si

j),

(7)

i.e., λl(i, j) and thus cl(i, j) is increasing in j for any given i and l.

Before describing our algorithm, we further need to deﬁne for i = j that

1     I˜l(i, j) = 







 

0

the intersection of the intervals aj + hl(j) − 1, dj − |Pj | + hl(j) and ai + (hl(i) − 1)si, ai + hl(i)si − 1 are nonempty; l ∈ Pi, l ∈ Pj; i is accepted otherwise
(8)

and

I˜l(j, j) = 1, ∀j, l ∈ Pj .

(9)

Note that ai + hl(i) − 1, di − |Pi| + hl(i) is the region of time slots that packet i can possibly stay at link l for it to reach the
destination before its deadline under any algorithm. Deﬁne

Si = di − ai − |Pi| + 2

(10)

to be the maximum possible delay of packet i at each link

l ∈ Pi and it is easy to see that si ≤ Si for all i. Variable I˜l(i, j) indicates whether packet j may take a resource of packet i under any possible scenario. Note that tl(j) ∈ [aj + hl(j) − 1, dj − |Pj| + hl(j) for all l ∈ Pj for any scheduler, since allocating any time slot out of this interval to transmit j over

l ∈ Pj will lead to the expiration of j. Hence, one can see that Il(i, j) ≤ I˜l(i, j) for all i, j, l from Eqs. (3), (8), and (9).

Our admission control and packet scheduling algorithm is

described in Algorithm 1. Note that from Equation (8), we

have

l

i≤j

I˜l

(i,j) si

cl

(i,

j

)

=

l∈Pj

i≤j

I˜l

(i,j) si

cl

(i,

j

),

i.e.,

the calculation only needs information on the route6 of packet j.

5If link capacity is integer C > 1, then Csi is the total amount of resources per link on route and deﬁnitions of cl(i, j) and λl(i, j) need to be modiﬁed accordingly.
6If the route of each packet is not predetermined and there exist multiple possible routes whose total cost is less than the packet weight, then choose the
route with the smallest cost to route the accepted packet.

5

Algorithm 1 Admission Control and Packet Scheduling

Upon arrival of packet j:

1) If 2) If

l l

i≤j i≤j

I˜l (i,j )

I˜l

si (i,j

)

si

cl(i, cl(i,

j) j)

> ≤

ρj , ρj ,

then then

reject j accept

; j

and

let

tl(j)

be the empty time slot with the largest index in [aj + (hl(j) −

1)sj, aj + hl(j)sj − 1]. Put packet j into tl(j), ∀l ∈ Pj ;

3) Any accepted packet j is transmitted through link l ∈ Pj at

time slot tl(j).

For each l ∈ Pj, the calculation of the term

i≤j

I˜l

(i,j) si

cl

(i,

j

)

only requires the information of packets that may route through

link l. It is also easy to see that the calculation of the cost term

does not require future information for times after the arrival

of each packet j, i.e., Algorithm 1 is on-line. Furthermore,

λl(i, j +1), i ≤ j is calculated from λl(i, j) using Equation (7) when packet j is processed by Algorithm 1, and Equation (6)

is only used to calculate λl(j, j) upon j’s arrival.

The basic intuition behind our algorithm is simple: We

ﬁrst allocate the end-to-end delay of each packet evenly over

the links along its path. The algorithm then schedules the

transmission for an accepted packet in a slot within its allocated

time region at each link. Consequently, the end-to-end deadline

constraint is met. With this approach, the natural questions are:

(1) When a packet j is accepted, is there always an empty (non-

reserved) slot in [aj + (hl(j) − 1)sj, aj + hl(j)sj − 1], ∀l ∈ Pj so that we can reserve a slot tl(j) for j at link l? (2) What

is the performance of Algorithm 1 compared to the optimal

off-line algorithm? We answer these questions in the following

theorem. Note that we measure the performance in terms of the

competitive ratio: if r is the competitive ratio achieved by our algorithm, then R ≥ rR∗, where R is the weighted revenue of successful reception achieved by Algorithm 1 and R∗ is

the weighted revenue of successful reception achieved by the

optimal off-line algorithm.

Theorem

3:

If

the

arrival

sample

satisﬁes

PM

<

2sm −1

( ) , 2sM

ρM ρm

where PM = maxi |Pi| is the maximum route length,

sm = mini si is the minimum average slack time, sM =

maxi si is the maximum average slack time, ρm = mini ρi

is the minimum weight and ρM = maxi ρi is the maxi-

mum weight among all packets, then every packet accepted

by Algorithm 1 reaches its destination before its dead-

line. Furthermore, Algorithm 1 achieves competitive ratio

r

2

2

SM sm

+1

1

+

sM

ρM ρm

−1
log(µ) + 1 with SM =

maxi Si as the maximum possible delay per hop among all

packets.

Hence, our algorithm is O(PM log PM )-competitive, where

PM is the maximum route length. The assumption PM <

2sm −1

( ) 2sM

ρM ρm

maximum

in Theorem route length

3 imposes an upper bound on the PM for the validity of the provided

competitive ratio. Roughly, PM must be upper bounded by an

exponential function of the minimum average slack time sm.

In Section V, we can see from the numerical examples that our

algorithm achieves a high performance relative to the optimal

off-line algorithm, even when this condition is not satisﬁed.

To prove this theorem, we ﬁrst make the following trans-

formation.

µ so that

i.e.,

µ−1 2PM

With condition log(µ) ≤ sm

PM and

< µ

>2s2Ms2m(ρρ−ρρM mM m1s)M,

we PM

can choose + 1 ≥ 1,

>

ρM ρm

sM

≥

sM . Then, we make the following

transformation. First, we choose a factor, F ∈

, 2PM sM µ−1

ρm

ρM

,

and normalize the weight ρi for all i with factor F and use

F ρi, instead of ρi for all i in the problem (the objective is

still equivalent to the original one). With this change, we have

log(µ) ≤ sm ≤ sM

≤

ρm 2PM

≤

ρM 2PM

<

µ−1 2PM

,

i.e.,

Il(i, j) ≤ 1 ≤

sm log(µ)

≤

si log(µ)

,

∀i, j;

(11)

2|Pj|sM ≤ 2PM sM ≤ ρm ≤ ρj, ∀j;

(12)

ρj ≤ ρM < µ − 1, ∀j.

(13)

We need the following lemmas to prove Theorem 3:

Lemma 2: If j is accepted by Algorithm 1, then there exists

at least one time slot in the interval [aj + (hl(j) − 1)sj, aj + hl(j)sj −1] that has not been reserved by other accepted packets for each l ∈ Pj.
Lemma 3: Let Q denote the set of packets that are rejected

by Algorithm 1 but successfully received by the optimal off-

line algorithm, then

j∈Q ρj ≤

2

SM sm

+1

l i cl(i, K),

where K is the last packet of the arrival sample.

Lemma 4: Let A denote the set of packets that

are accepted by Algorithm 1, then l i cl(i, K) ≤

2

1

+

sM

ρM ρm

log(µ)

j∈A ρj .

Proofs of Lemmas 2, 3 and 4 can be found in Appendix B, C

and D, respectively.

Proof of Theorem 3: From Lemma 2, we see that for every

accepted packet j, there exists an unreserved time slot tl(j) in the interval [aj +(hl(j)−1)sj, ai+hl(j)sj −1] for transmission at any l ∈ Pj. By the way of allocating the total slack time on each hop, it is apparent that j can reach its destination before

deadline dj if it is transmitted through l in slot tl(j) for all l ∈ Pj.

Lemma 2 completes the proof of the ﬁrst part of the theorem.

The remaining part is proved in two steps: First we upper bound

the weighted revenue of packets that are rejected by our on-line

algorithm but have successful receptions by the optimal off-line

algorithm as in Lemma 3. We then lower bound the weighted

revenue of packets that are accepted by our on-line algorithm

as in Lemma 4. Combining the Lemmas 2, 3 and 4, we have

R∗ ≤ ρj + ρj

j∈Q

j∈A

≤

2

SM sm

+1

l

≤2

2

SM sm

+1

=2

2

SM sm

+1

cl(i, K) + ρj

i

j∈A

1

+

sM

ρM ρm

log(µ) + 1

ρj

j∈A

1

+

sM

ρM ρm

log(µ) + 1

R

=

R r

.

6

Note that sm ≥ 1 for a slotted system. From Eqs. (4)

and (10), we have Si ≤ (si + 1)|Pi| − |Pi| + 1 ≤ si|Pi| + 1

and By

then SM letting µ

≤ =

sM PM + 1.

2

ρM ρm

sM

PM

Recall that + 1 + ǫ,

µ>2 where

ρM ρm

sM PM

+

1.

ǫ > 0 can be

arbitrarily small, we have r ≥ 2 2(sM PM + 1) + 1 1 +

−1

ρM ρm

sM

log

2

ρM ρm

sM

PM

+

1

+

ǫ

+1

. Hence, our algorithm

is O(PM log PM )-competitive.

Our competitive ratio based framework of packet schedul-

ing with deadlines is motivated by the competitive routing

model [17]. However, there are signiﬁcant differences between

the two models: 1) The amount of link bandwidth is ﬁxed

and known at the beginning in the routing model, but the time

slot resources are related to the accepted packets and are then

related to the algorithm itself; 2) An earlier packet may use the

resource of a later packet, which brings difﬁculties to making

online decisions; 3) There are multiple ways of allocating the

total end-to-end delay dj − aj + 1 of each packet j on each hop, which brings more complexities.

In Algorithm 1, we allocate the total end-to-end delay of

each packet evenly on each hop, i.e., every accepted packet j

reserves slot tl(j) in [aj +(hl(j)−1)sj, aj +hl(j)sj −1] at link l ∈ Pj. We brieﬂy explain the reason for evenly allocating the total end-to-end delay on each hop as follows: Suppose we use

a general way of allocating the total end-to-end delay of packet

j. Let sl,j denote the slack time allocated to link l ∈ Pj, then

we always have l∈Pj sl,j = dj − aj + 1. Note that the maximum allowable delay on each hop Sj remains unchanged and

SM = maxj Sj. However, the maximum and minimum per hop

slack time are changed to sM = maxj maxl∈Pj sl,j ≥ maxj sj

and sm = minj minl∈Pj sl,j ≤ minj sj since minl∈Pj sl,j ≤

sj

=

⌊

dj

−aj +1 |Pj |

⌋

≤

maxl∈Pj sl,j .

This

means

allocating

the

total

slack

time

evenly

will

lead

to

smallest

sM

and

SM sm

,

i.e.,

largest r (better lower bound) as stated in Theorem 3 among

all methods of allocating the slack time.

Note that r characterizes the worst-case performance ratio

between our online algorithm and the optimal off-line algo-

rithm. When the route length PM , the average slack times sM

and the maximum allowable per hop delay to the smallest

average slack time ratio

SM sm

are larger, an accepted packet

has more freedom to reserve a transmission slot and is more

likely to deviate from the off-line algorithm while the online

algorithm has no information of future arrivals to help make

the decisions. Similarly, if the ratio of weights

ρM ρm

is large,

then the difference of the contribution of each packet becomes

large and the online decision becomes more difﬁcult. Therefore,

when these parameters increase, r decreases and the worst-case

performance of the online algorithm tends to become worse.

From the discussion in Section III, in a general wired topology,

there is usually no online algorithms with competitive ratio 1.

It is then interesting to ask: What is the largest achievable value

for r? Is O(PM log PM )-competitive already the best an online algorithm can do under a general wired network topology?

In the literature of competitive analysis [3, 17], the upper

bound of competitive ratio is usually derived by a converse

via an adversary argument. We leave these questions to our future work. Although the theoretical worst-case ratio can be small, in Section V, we see from the numerical examples that by appropriately choosing the control parameter log(µ) and normalizing the weights ρi, i = 1, 2, . . . , K, our algorithm achieves good performance compared to the optimal off-line algorithm in practice.

V. NUMERICAL EXAMPLES

We ﬁrst consider an uplink wired tree shown in Fig. 3 (a)

with homogeneous link rates. There are 10000 packets with

homogeneous weights and the inter-arrival times of packets are

chosen

to

be

0

w.p.

1 2

and

1

time

slot

w.p.

1 2

.

We

generate

the initial slack time (the difference between the deadline

and the arrival time, increased by 1) uniformly at random

between 24 and 30. The source node of each packet is chosen

uniformly at random over all non-root nodes. It is easy to

see that the maximum route length PM = 3 for all packets in this network. Thus, the maximum average slack time is

sM = 30 and the minimum average slack time is sm = 8,

i.e.,

PM

=

3

<

2sm −1

2sM

ρM ρm

=

255 60

.

As

given

in

the

proof

of

Theorem 3, we choose the control parameter log(µ) = 7.5 so

that log

2

ρM ρm

sM PM

+

1

= 7.4 < log(µ) ≤ sm = 8. From

Fig. 4 (a), we can see that by increasing the normalization

factor of the packets’ weight, the performance of our online

algorithm increases and achieves more than 90% of the optimal

off-line algorithm (the optimal value is obtained using the

algorithm in Theorem 1). When the normalized weight is large

enough, almost all packets are admitted and this result shows

that admission control is only necessary in the proof of worst-

case lower bound and our algorithm can still be efﬁcient without

the admission control component in practice.

Similarly, for another choice of slack times, generated

uniformly at random between 0 and 5, when the condition

P < 2sm −1

M

2sM

ρM ρm

is violated, our online algorithm still achieves

about 80% of the optimal algorithm.

1

3

1

1

2

3

4

5

5

4

7

2 5

4

2

10 8

6

6

12

3

6

7

8

11

9

7

(a)

(b)

Fig. 3. Example topologies: (a) An Uplink Wired Tree, and (b) A General Wired Mutlihop Network with Multiple Source-Destination Flows

We then consider a general topology as shown in Fig. 3

(b). There are 10000 packets and the inter-arrival times of

packets

are

chosen

to

be

0

w.p.

1 2

and

1

time

slot

w.p.

1 2

.

The

packets weights are generated uniformly at random between 1

and

100

with

ρM ρm

= 100.

The

given

route

Pi

of

each

packet

i

is randomly generated with 1 ≤ |Pi| ≤ 3 in the setup stage. We

7

ﬁrst generate the initial slack time uniformly at random between

45

and

50

so

that

the

condition

PM

=3

<

2sm −1

2sM

ρM ρm

=

215 −1 10000

is satisﬁed. Note that the theoretical region of the control

parameter µ

is

log

2

ρM ρm

sM

PM

+

1

= 11.55 < log(µ) ≤

sm = 15 in this example. With normalized packets weights

(normalization factor is 300), we simulate the generated revenue

as a function of log(µ). We see from Fig. 4 (b) that our

online algorithm achieves a revenue close to the upper bound

of the optimal off-line algorithm (we compare our scheme with

the revenue upper bound, i.e., the total normalized revenue,

rather than the actual revenue of the off-line algorithm due to

the extremely high complexity of the calculation of the off-

line algorithm). Note that log(µ) is in the denominator of the

competitive ratio by Theorem 3, so this result is consistent with

the theorem.

Similarly, for another choice of slack times, generated

uniformly at random between 0 and 5, when the condition

P < 2sm −1

M

2sM

ρM ρm

is violated, our online algorithm still achieves

more than 80% of the upper bound with appropriately chosen

log(µ).

From examples (a) and (b), we can see that the assumption

PM

<

2sm −1

2sM

ρM ρm

, the theoretical region of µ, the weight

normalization factor and the admission control component are

only needed to prove the worst-case bound. In practice while

the theoretical constraints are relaxed, the control parameters

can be appropriately tuned for different scenarios so that our

algorithm has efﬁcient performance.

Finally, we consider a line network 1 → 2 → 3 → 4 with

four nodes and 3 links (identical link rates of 1 packet/time

slot). The arrival sample is periodic with 6 slots as a period. In

slot 1, packet k1 arrives at node 1 with destination 4, deadline 6 and weight 100, and k2 arrives at node 1 with destination 2, deadline 1 and weight 90. In slot 2, k3 arrives at node 1 with destination 2, deadline 2 and weight 1. In slot 3, k4 arrives at node 1 with destination 2, deadline 3 and weight 1, k5 arrives at node 2 with destination 4, deadline 5 and weight 200, and k6
arrives at node 2 with destination 4, deadline 4 and weight 1.

In slot 4, k7 arrives at node 1 with destination 2, deadline 4 and weight 1, and k8 arrives at node 2 with destination 4, deadline

5 and weight 50. This arrival pattern repeats every 6 slots, until

a total of 10000 packets arrive. We use the normalization factor

F = 12 for the packets weights in the algorithm. It is easy to

calculate 200 + 50

the +1

o+pt1im) ∗al1w2 e=igh6t.e6d×re1v0e6n.uWe e10c08o0m0 p∗ar(e10o0ur+o9n0lin+e

algorithm with two well known algorithms EDF and LWF. In

EDF, each link transmits the packet with the earliest deadline

among the packets with nonnegative slack time every time slot.

In LWF, each link transmits the packet with the largest weight

among the packets with nonnegative slack time every time slot.

Note

that

the

condition

PM

<

2sm −1

2sM

ρM ρm

is already violated

for this arrival sample. By choosing log(µ) = 10, we have

that the total revenue of successful reception for our online algorithm is 5.9 × 106, for EDF is 5.3 × 106 and for LWF is 4.4 × 106. This means our algorithm outperforms EDF and

Total Successful Reception Total Revenue of Successful Reception

LWF, and achieves about 90% of the off-line performance. This example also shows that our provably efﬁcient online algorithm is more robust than EDF and LWF for a general network and arrival sample.

10000 8000 6000 4000 2000 0 0

Optimal Offline Optimal Offline (Violate Assumption) Online Online (Violate Assumption)

2

4

6

8

10

log(Normalization Factor of Weights)

(a)

1.6 x 108

1.5

1.4

1.3

1.2

1.1

1

0.9

0.8

0

10

Upper Bound of Optimal Offline Online Online (Violate Assumption)

20

30

40

50

60

log(µ)

(b)

Fig. 4. (a) Performance of Online Algorithm with Different Normalized Packets Weights, and (b) Performance of Online Algorithm with Different log(µ)

VI. CONCLUSION
In this paper, we studied the packet scheduling problem with hard deadline constraints in wired networks. We ﬁrst show that WC-EDF has the same performance as the optimal off-line algorithm in maximizing the throughput given any feasible arrival sample path for the uplink tree topology. We then proposed an on-line joint admission control and packet scheduling algorithm that requires only information on the route of each packet in the calculation and has provable competitive ratio to the optimal off-line algorithm in maximizing the weighted revenue. Furthermore, we show through numerical examples that our algorithm usually performs much better than the theoretical worst-case lower bound. As future directions, we will investigate whether the competitive ratio of our online algorithm is the highest achievable among all on-line algorithms for the general network topology. Furthermore, we are extending the competitive admission and packet scheduling framework to a wireless network setting, in which we need to take into account the scheduling constraints as well.
REFERENCES
[1] C. L. Liu and J. W. Layland, “Scheduling Algorithms For Multiprogramming In a Hard-Real-Time Environment,” Journal of ACM, vol. 20, pp. 46–61, 1973.
[2] M. Dertouzos, “Control Robotics: The Procedural Control of Physical Processes,” in IFIP Congress, 1974, pp. 807–813.
[3] S. Baruah, G. Koren, D. Mao, B. Mishra, A. Raghunathan, L. Rosier, D. Shasha, and F. Wang, “On The Competitiveness of On-Line RealTime Task Scheduling,” Real-Time Systems, vol. 4, pp. 125–144, 1992.
[4] G. Koren and D. Shasha, “Dover: An Optimal On-Line Scheduling Algorithm for Overloaded Uniprocessor Real-Time Systems,” SIAM Journal of Computing, vol. 24, pp. 318–339, 1995.
[5] A. Bar-Noy, J. A. Garay, and A. Herzberg, “Sharing Video on Demand,” Discrete Applied Mathematics, vol. 129, no. 1, pp. 3–30, 2003.
[6] M. Goldwasser and B. Kerbikov, “Admission Control with Immediate Notiﬁcation,” Journal of Scheduling, pp. 269–285, 2003.
[7] S. Chen, L. Tong, and T. He, “Optimal Deadline Scheduling with Commitment,” 49th Allerton Conference on Communication, Control and Computing, September 2011.
[8] J. Ding and G. Zhang, “Online Scheduling with Hard Deadlines on Parallel Machines,” in 2nd AAIM, 2006, pp. 32–42.

8

[9] J. Ding, T. Ebenlendr, J. Sgall, and G. Zhang, “Online Scheduling of Equal-Length Jobs on Parallel Machines,” in 15th ESA, 2007, pp. 427– 438.
[10] T. Ebenlendr and J. Sgall, “A Lower Bound for Scheduling of Unit Jobs with Immediate Decision on Parallel Machines,” in 6th WAOA, 2008, pp. 43–52.
[11] N. Thibault and C. Laforest, “Online Time Constrained Scheduling with Penalties,” in 23rd IEEE Int. Symposium on Parallel and Distributed Processing, 2009.
[12] S. P. Y. Fung, “Online Preemptive Scheduling with Immediate Decision or Notiﬁcation and Penalties,” in the 16th Annual International Conference on Computing and Combinatorics, ser. COCOON10, 2010, pp. 389–398.
[13] T. Ling and N. B. Shroff, “Scheduling Real-Time Trafﬁc in ATM Networks,” in Proc. of IEEE INFOCOM, March 1996, pp. 198–205.
[14] B. Hajek, “On the Competitiveness of On-Line Scheduling of UnitLength Packets with Hard Deadlines in Slotted Time,” in Conference on Information Sciences and Systems, Johns Hopkins University, March 21-23 2001, pp. 434–439.
[15] B. Hajek and P. Seri, “Lex-Optimal Online Multiclass Scheduling with Hard Deadlines,” Mathematics of Operations Research, vol. 30, no. 3, pp. 562–596, August 2005.
[16] P. P. Bhattacharya, L. Tassiulas, and A. Ephremides, “Optimal Scheduling with Deadline Constraints in Tree Networks,” IEEE/ACM Transactions on Automatic Control, vol. 42, no. 12, pp. 1703–1705, December 1997.
[17] B. Awerbuch, Y. Azar, and S. Plotkin, “Throughput Competitive Online Routing,” in Proc. of the 34th Annual Symposium on Foundations of Computer Science, November 1993, pp. 32–40.
[18] S. Hariharan and N. B. Shroff, “Maximizing Aggregated Information in Sensor Networks Under Deadline Constraints,” IEEE/ACM Transactions on Automatic Control, vol. 56, no. 10, pp. 2369–2380, 2011.
[19] S. S. Panwar, D. Towsley, and J. K. Wolf, “Optimal Scheduling Policies for a Class of Queues with Customer Deadlines to the Beginning of Service,” Journal of ACM, vol. 35, no. 4, pp. 832–844, 1988.
[20] S. Shakkottai and R. Srikant, “Scheduling Real-Time Trafﬁc with Deadlines Over a Wireless Channel,” Wireless Networks, vol. 8, no. 1, pp. 13–26, January 2002.
[21] A. Dua and N. Bambos, “Downlink Wireless Packet Scheduling with Deadlines,” IEEE Transactions on Mobile Computing, vol. 6, no. 12, pp. 1410–1425, December 2007.
[22] I. H. Hou and P. R. Kumar, “Scheduling Heterogeneous Real-Time Trafﬁc over Fading Wireless Channels,” in Proc. of IEEE INFOCOM, San Diego, CA, March 2010.
[23] V. Raghunathan, V. Borkar, M. Cao, and P. R. Kumar, “Index Policies for Real-Time Multicast Scheduling for Wireless Broadcast Systems,” Proc. of IEEE INFOCOM, pp. 1570–1578, April 2008.
[24] Q. Liu, X. Wang, and G. B. Giannakis, “A Cross-Layer Scheduling Algorithm with QoS Support in Wireless Networks,” IEEE/ACM Transactions on Vehicle Technology, vol. 55, no. 3, pp. 839–847, May 2006.
[25] J. J. Jaramillo and R. Srikant, “Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks with Elastic and Inelastic Trafﬁc,” IEEE/ACM Transactions on Networking, 2011.
[26] Z. Mao, C. E. Koksal, and N. B. Shroff, “Online packet scheduling with hard deadlines in wired networks,” Tech. Rep., 2012. [Online]. Available: http://www.ece.osu.edu/˜maoz/Infocom2013.pdf
APPENDIX A
PROOF OF THEOREM 2
We provide an outline of the proof here. For a more detailed
version, we refer the readers to [26]. Let policy p∗ be a work conserving optimal off-line policy.
Suppose T0 is the ﬁrst time slot in which policy p∗ differs from WC-EDF p. Then, all the nodes in the network have the same set of packets in all slots before slot T0. We show that WC-EDF p is optimal for any under-loaded arrival sample by induction. Choose T − 1 > T0 and let the following holds as hypothesis ∀t ∈ (T0, T − 1]: 1) There is no packet expiring under p at the end of slot t; 2) The total number of packets at any node n under policy p∗ and p are the same at the end of slot t. Any packet k at any

node n under policy p can be paired with a packet k∗ at the same node n under policy p∗ at the end slot t;
3) For any packet pair (k0∗, k0) at any node n at the end of slot t, there is a sequence of packet pairs (k0∗, k0), . . . , (ki∗, ki) at node n and its descendent nodes so that dk1∗ ≤ dk0 , . . . , dki∗ ≤ dki−1 , dk0∗ ≤ dki if i ≥ 1 and dk0∗ ≤ dk0 if i = 0.

It is easy to show that the base case holds (details in [26])

and we need to show that hypothesis 1)-3) hold for T . At

the beginning of slot T , all nodes have the same amount of packets under p∗ and p by the hypothesis. We use the

following rule to pair the transmitted and remaining packets:
If (k∗, k) forms a packet pair at the beginning of slot T , and k∗, k are transmitted by node n in slot T under policy p∗ and p, respectively, then (k∗, k) still forms a packet pair after transmission. If (k∗, k) forms a packet pair at the beginning of slot T , k∗ is transmitted by node n in slot T under p∗ but k

is not transmitted by p, since the total number of transmitted

packets are the same for both policies, there must exist another packet pair (q∗, q) at node n so that q is transmitted by node n in slot T under p but q∗ is not transmitted p∗, then (k∗, q) is a transmitted packet pair by node n in slot T and (q∗, k)

is a remaining packet pair after transmission. New arrivals

form common packet pairs. Consider an arbitrary node n

and suppose the capacity of the link between node n and its

parent node is 1 without loss of generality. If the link capacity
is c, then repeat the same arguments c times. Let k∗ and q denote the transmitted packets by node n under policy p∗ and p, respectively. Without loss of generality, we assume (k∗, k) and (q∗, q) form different packet pairs at the beginning of

slot T , i.e., the end of slot T − 1. Consider any packet pair
(k0∗, k0) (assume this packet pair is at an arbitrary node m) in the network and by hypothesis 3) for slot T − 1, (k0∗, k0) has a sequence of packet pairs (k0∗, k0), . . . , (ki∗, ki) at node m and its descendent nodes at the beginning of slot T so that

dk1∗ ≤ dk0 , . . . , dki∗ ≤ dki−1 , dk0∗ ≤ dki if i ≥ 1 and dk0∗ ≤ dk0 if i = 0. We have the following cases: I) The sequence (k0∗, k0), . . . , (ki∗, ki) does not contain the packet pairs (k∗, k) and (q∗, q), then the reforming of (k∗, k) and (q∗, q) and the transmission of (k∗, q) do not inﬂuent the packet pair (k0∗, k0); II) The sequence (k0∗, k0), . . . , (ki∗, ki) contains the packet pair (k∗, k) but does not contain (q∗, q). This means node n

is node m or a descendent node of node m. By hypothesis

3) for packet pair (q∗, q) in slot T − 1, there is a sequence

(q∗, q), . . . , (qj∗, qj) at node n and its descendent nodes

so that dq1∗ ≤ dq, . . . , dqj∗ loss of generality, let

≤ dqj−1 , dq∗ ≤ dqj . Without (k0∗, k0), . . . , (k∗, k), . . . , (ki∗, ki)

denote the sequence of (k0∗, k0) that contains (k∗, k), then

(k0∗, k0), . . . , (k∗, q), (q1∗, q1), . . . , (qj∗, qj), (q∗, k), . . . , (ki∗, ki)

is a sequence of packet pairs at node m and its descendent

nodes so that dk1∗ ≤ dk0 , . . . , dq1∗ ≤ dq, . . . , dq∗ ≤ dqj , . . . , dki∗ ≤ dki−1 , dk0∗ ≤ dki . If node n is a descendent node of node m, then after the transmission of packet pair
(k∗, q), hypothesis 3) holds for (k0∗, k0). If node n is node m, then packets k0 and q are both at node n at the beginning

9

of slot T , and dq and (k0∗, k0), (q1∗,

≤ q1),

dk0∗ ...

,

by (qj∗

EDF. Then, , qj), (q∗, k),

dq1∗ ...,

≤ (ki∗

,

dq ki

)

≤ dk0∗ is a

sequence of packet pairs at node n and its descendent nodes

that satisﬁes hypothesis 3) after transmission of (k∗, q).

Similarly, if the sequence (k0∗, k0), . . . , (ki∗, ki) contains the packet pair (q∗, q) but does not contain (k∗, k), hypothesis 3)

also holds for (k0∗, k0) at the end of slot T ; III) The sequence (k0∗, k0), . . . , (ki∗, ki) contains the packet pairs (k∗, k) and (q∗, q). Similar to case II) (details are

in [26]).

Therefore, by repeating the above argument for all transmit-

ted packet pairs, hypothesis 3) holds for all packet pairs at the

end of slot T . Suppose a packet k at any node n is expiring

under policy p at the end of slot T , then there is another packet
k∗ with dk∗ ≤ dk and k∗ is at node n or its descendent node by hypothesis 3), i.e., k∗ is also expiring which contradicting the
optimality of policy p∗. Therefore, there is no packet expiring

under p at the end of slot T , i.e., hypothesis 1) holds. Note that

the total number of transmitted packets and received packets are

the same under both policies in the wired uplink tree network

and no packets expire under both policies, then the total number

of packets at any node under both policies are the same at the

end of slot T , i.e., hypothesis 2) holds.

APPENDIX B PROOF OF LEMMA 2

Suppose j is the ﬁrst packet that is accepted by Algorithm 1

but there exists l ∈ Pj so that all time slots in the interval

[aj + (hl(j) − 1)sj, aj + hl(j)sj − 1] are occupied by other

accepted packets when j is accepted. From Eqs. (3) and (6), we

have

λl(j, j)

=

1

and

cl (j,j ) sj

=

µλl(j,j)

−1

≥

µ − 1.

Note

that

I˜l(j, j) = 1 by Equation (9), combined with Equation (13),

we then have

l′

i′ ≤j

I˜l′

(i′ si′

,j)

cl′

(i′

,

j

)

≥

I˜l

(j,j) sj

cl

(j,

j

)

=

cl (j,j ) sj

≥

µ−1

>

ρj ,

i.e.,

j

is

rejected

by

Algorithm

1

which

is a contradiction.

APPENDIX C PROOF OF LEMMA 3

For any j ∈ Q, from Algorithm 1 and the fact that cl(i, j) is increasing in j, given any i and l, i.e., cl(i, j) ≤ cl(i, k), ∀l, i if j ≤ k, we have

ρj <

l

i≤j

I˜l(i, si

j)

cl(i,

j

)

≤

l

≤
l

i

I˜l(i, si

j)

cl(i,

K

).

i

I˜l

(i, si

j

)

cl

(i,

j

)

Consider any packet i and any link l ∈ Pi, if i is rejected

by Algorithm 1, then I˜l(i, j) = 0, ∀j = i and I˜l(i, i) = 1, we

then have

j∈Q

I˜l (i,j ) si

≤

1 si

;

otherwise,

we

have

I˜(i, j)

=

1

only for j with ai + (hl(i) − 1)si ≤ dj − |Pj | + hl(j) and

aj + hl(j) − 1 ≤ ai + hl(i)si − 1. Let t∗l (j) be the time slot

in which packet j is transmitted through link l ∈ Pj under

the optimal off-line algorithm. Note that t∗l (j) ∈ [aj + hl(j) −

1, dj −|Pj|+hl(j)] since this interval is the maximum allowable

transmission interval for the successful reception of j under all

algorithms. Furthermore, if t∗l (j) < ai+(hl(i)−1)si−Sj +1 or

t∗l (j) > ai+hl(i)si−1+Sj−1, then it means dj −|Pj|+hl(j) ≤

t∗l (j 1>

)+Sj −1 < ai+(hl(i)−1)si ai + hl(i)si − 1, i.e., I˜(i, j)

or =

aj 0.

+hl(j)−1 Therefore,

≥ t∗l (j)−Sj+ we must have

t∗l (j) I˜(i, j all j

∈ [ai + (hl(i) − 1)si

) = 1, then

I˜l j∈Q

∈ Q and combining

− Sj
(i,j) si
with

+ 1, ai + ≤ 2Sj +si
si
the fact

hl(i)si −2 . By I˜l(i, j)

− 1 + Sj − 1] if summing over = 0, ∀l ∈/ Pi,

we have

ρj <

j∈Q

l

i

cl(i,

K)

j∈Q

I˜l(i, si

j)

≤

2

SM sm

+1

l

cl(i, K),
i

where SM = maxi Si is the maximum link delay among all packet and sm = mini si is the minimum average slack time among all packets.

APPENDIX D PROOF OF LEMMA 4

Note that for any l, i and j ∈ A, we have

cl(i, j + 1) − cl(i, j) =siµλl(i,j)

µ Il (i,j) si

−1

=si µλl (i,j )

2 − 1 log(µ)

Il

(i,j) si

≤µλl(i,j)Il(i, j) log(µ)

=

cl(i, si

j)

+

1

Il(i, j) log(µ),

(14)

where the inequality is from Equation (11) and the fact 2x−1 ≤

x, x ∈ [0, 1]. The last equality is from Equation (5).

Recall that Il(i, j) ≤ I˜l(i, j), ∀i, j, l by Equation (3) and

Equation (8); cl(i, j) ≤ cl(i, i), ∀i > j by Equation (5),

Equation (7) and Equation (3); and

l

i≤j

I˜l

(i,j si

)

cl

(i,

j

)

≤

ρj, ∀j ∈ A from Algorithm 1. From Equation (3), we

have i Il(i, j) = i∈A Il(i, j), ∀j ∈ A. From Lemma 2, tl(i) ∈ [ai + (hl(i) − 1)si, ai + hl(i)si − 1] for any i ∈ A.

Note that in order to have Il(i, j) = 1, we must have

ai + (hl(i) − 1)si ≤ tl(j) ≤ ai + hl(i)si − 1. For any i ∈ A,

if tl(i) < tl(j) − si + 1 or tl(i) > tl(j) + si − 1, then it means

ai + hl(i)si − 1 ≤ tl(i) + si − 1 < tl(j) or ai + (hl(i) − 1)si ≥

tl(i) − si + 1 > tl(j), i.e., Il(i, j) = 0. Therefore, if Il(i, j) =

1, ∀i ∈ A, then tl(i) ∈ [tl(j) − si + 1, tl(j) + si − 1], i.e.,

l
using

i Il(i, j) = l Equation (12),

i∈A
and

Il(i, j) ≤ 2|Pj|si ≤ 2|Pj|sM ≤ ρj

i∈A

ρi ρj

Il(i, j)

≤

2

ρM ρm

sM .

For

any

l, i and j ∈ A, by summing over l and i of Equation (14), we

have

l

i

cl(i, j + 1)− cl(i, j)

≤2

1

+

sM

ρM ρm

log(µ)ρj

(detailed steps can be found in [26]). Combined with cl(i, j +

1) − cl(i, j) = 0, ∀j ∈/ A, we have

cl(i, K) =

cl(i, j + 1) − cl(i, j)

li

l i j∈A

≤2

1

+

sM

ρM ρm

log(µ) ρj.
j∈A

