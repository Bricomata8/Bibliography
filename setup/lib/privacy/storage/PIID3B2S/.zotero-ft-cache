Security and privacy in online social networks
Leucio Antonio Cutillo
To cite this version:
Leucio Antonio Cutillo. Security and privacy in online social networks. Other [cs.OH]. T√©l√©com ParisTech, 2012. English. <NNT : 2012ENST0020>. <pastel-00932360>

HAL Id: pastel-00932360 https://pastel.archives-ouvertes.fr/pastel-00932360
Submitted on 16 Jan 2014

HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers.

L‚Äôarchive ouverte pluridisciplinaire HAL, est destin√©e au d√©p√¥t et √† la diffusion de documents scientifiques de niveau recherche, publi√©s ou non, √©manant des √©tablissements d‚Äôenseignement et de recherche fran√ßais ou √©trangers, des laboratoires publics ou priv√©s.

2012-ENST-020

EDITE - ED 130
Doctorat ParisTech
TH√àSE
pour obtenir le grade de docteur d√©livr√© par
TELECOM ParisTech
Sp√©cialit√© ¬´ Informatique et R√©seaux ¬ª
pr√©sent√©e et soutenue publiquement par
Leucio Antonio CUTILLO
le 5 Avril 2012
Protection des Donn√©es Priv√©es dans les R√©seaux Sociaux

Directeur de th√®se : Professeur Refik MOLVA

Jury M. Claude CASTELLUCCIA, Directeur de Recherche, INRIA, Saint Ismier M. Jon CROWCROFT, Professeur, University of Cambridge, Cambridge M. Antonio LIOY, Professeur, Politecnico di Torino, Torino M. David HALES, Docteur, The Open University, Milton Keynes
TELECOM ParisTech √©cole de l‚ÄôInstitut T√©l√©com - membre de ParisTech

Rapporteur Rapporteur Examinateur Examinateur

3
Uno solo √® il mio desiderio, quello di vedervi felici nel tempo e nell'eternit√†. sac. Giovanni Bosco

4

Abstract
Social network applications allow people to establish links and exchange information based on various interests such as professional activities, hobbies, et similia. Several commercial social networking platforms that came to light recently suddenly became extremely popular at the international arena. Apart from obvious advantages in terms of fast community building, rapid exchange of information at the professional and private level, social network platforms raise several issues concerning the privacy and security of their users. The goal of this thesis is to identify privacy and security problems raised by the social networks and to come up with the design of radically new architectures for the social network platform. As current social network platforms are based on centralized architectures that inherently threat user privacy due to potential monitoring and interception of private user information, the goal is to design social network platforms based on a distributed architecture in order to assure user privacy. New mechanisms are investigated in order to solve some classical security and trust management problems akin to distributed systems by taking advantage of the information stored in the social network platforms. Such problems range from trust establishment in self-organizing systems to key management without infrastructure to cooperation enforcement in peer-to-peer systems.
This thesis suggests a new approach to tackle these security and privacy problems with a special emphasis on the privacy of users with respect to the application provider in addition to defense against intruders or malicious users. In order to ensure users' privacy in the face of potential privacy violations by the provider, the suggested approach adopts a decentralized architecture relying on cooperation among a number of independent parties that are also the users of the online social network application. The second strong point of the suggested approach is to capitalize on the trust relationships that are part of social networks in real life in order to cope with the problem of building trusted and privacy-preserving mechanisms as part of the online application. The combination of these design principles is Safebook,
i

ii

Abstract

a decentralized and privacy-preserving online social network application. Based on the two design principles, decentralization and exploiting real-life trust, various mechanisms for privacy and security are integrated into Safebook in order to provide data storage and data management functions that preserve users'privacy, data integrity, and availability.
Apart from the design of Safebook, a signicant part of the thesis is devoted to its analysis and evaluation using various methods such as experimenting with real social network platforms.
Finally, this thesis presents an implementation of Safebook that is written in python and can be executed on multiple operating systems such as Windows, Linux and MacOs. The Safebook implementation is a multithread event-driven application composed by dierent managers in charge of building and keeping the social network and P2P overlays, performing cryptography operations and providing the main social network facilities such as friendship lookup, wall posting and picture sharing through a user interface implemented under the form of a webpage.

Acknowledgments
This dissertation is the result of three years and a half of research supported by ideas, experiments, prototypes a lot of students, colleagues and friends contributed to.
My intellectual debt to prof. Rek Molva, prof. Thorsten Strufe, Dr. Melek Onen and Dr. Matteo dell'Amico is enormous. With their patient help, I've started taking my rst steps into the amazing world of research.
Many thanks to prof. Pietro Michiardi, Dr. Oliver Blass, Carmelo Velardo, Alessandro Duminuco, Marco Paleari, Antonio Barbuzzi, Giuseppe Reina and Mario Pastorelli for their strong inuence on my thinking during lots of problem identication and solving steps.
A special acknowledgement goes to seventeen among the best students I have ever met: Dennis Roch, Yao Liu, Jens Trinh, Etienne Peron, Jean Baptiste Barrau, Luca Boasso, Paolo Viotti, Mustafa Zengin, Marco Garieri, Wenting Li, Girolamo Piccinni, Andrea Milazzo, Esko Mattila, Waqas Liaqat Ali, Rajat Rajendra Hubli, Yu Liu, and Yuling Shi. Their help in translating the theory of this work to the practice of a real software prototype was crucial.
Finally, my last and biggest acknowledgment goes to my father Angelo and my girlfriend Veronica, they always supported me in every dicult moment. This thesis is dedicated to them.
iii

iv

Acknowledgments

Contents

Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xix Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxii

1 Introduction

1

1.1 Research objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.2 Main contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.3 Thesis organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

I Security and Privacy Issues in OSN

9

2 Online Social Networks

11

2.1 Social Network Providers and Their Customers . . . . . . . . . . . . . . . . . 13

2.2 Functional Overview of Online Social Networks . . . . . . . . . . . . . . . . . 14

2.2.1 Networking functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

2.2.2 Data functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

2.2.3 Access control functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 16

2.3 Data contained in Online Social Networks . . . . . . . . . . . . . . . . . . . . 17

2.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

v

vi

Contents

3 Main threats in OSN

23

3.1 Security and privacy objectives . . . . . . . . . . . . . . . . . . . . . . . . . . 24

3.1.1 Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

3.1.2 Integrity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

3.1.3 Availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

3.2 Attack Spectrum and Countermeasures . . . . . . . . . . . . . . . . . . . . . . 28

3.3 The Big Brother problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

3.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

4 Decentralized OSN

43

4.1 Client-Server based Decentralized OSNs . . . . . . . . . . . . . . . . . . . . . 44

4.2 P2P-based Decentralized OSNs . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.3 Main Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

II A privacy preserving distributed OSN leveraging real life trust 51

5 Safebook

53

5.1 Rationale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

5.1.1 Design principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

5.1.2 Idea of the solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

5.2 Main components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

5.2.1 Matryoshka . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

5.2.2 Peer-to-peer substrate . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

5.2.3 Trusted Identication Service . . . . . . . . . . . . . . . . . . . . . . . 62

5.3 Functionalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64

5.3.1 Data Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64

5.3.2 Key Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

5.3.3 Communication Management . . . . . . . . . . . . . . . . . . . . . . . 66

5.4 Core protocols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

5.4.1 Prole Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

5.4.2 Social Network Service setup and maintenance . . . . . . . . . . . . . 70

5.4.3 Social Network Communication and Relationship management . . . . 74

Contents

vii

5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

6 Performance of the Approach

79

6.1 Mirror reachability - building one chain . . . . . . . . . . . . . . . . . . . . . 80

6.2 Data availability - Matryoshka feasibility . . . . . . . . . . . . . . . . . . . . . 81

6.3 Data storage and availability . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

6.3.1 Maximum fragment size evaluation . . . . . . . . . . . . . . . . . . . . 86

6.3.2 Retrieved data evaluation . . . . . . . . . . . . . . . . . . . . . . . . . 87

6.3.3 Prole size evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

6.3.4 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

6.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89

7 Impact of social graphs on performance and privacy

93

7.1 Privacy from the graph theory perspective . . . . . . . . . . . . . . . . . . . . 93

7.1.1 Node degree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94

7.1.2 Clustering Coecient . . . . . . . . . . . . . . . . . . . . . . . . . . . 95

7.1.3 Mixing time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97

7.1.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98

7.2 Impact of social graphs on Safebook . . . . . . . . . . . . . . . . . . . . . . . 99

7.2.1 Impact on privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

7.2.2 Impact on performance . . . . . . . . . . . . . . . . . . . . . . . . . . 100

7.2.3 Performance and privacy trade-o . . . . . . . . . . . . . . . . . . . . 101

7.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

8 Implementation

105

8.1 Overall Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

8.2 Account creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109

8.3 User interface and OSN facilities . . . . . . . . . . . . . . . . . . . . . . . . . 110

8.4 S2S: the P2P overlay of Safebook . . . . . . . . . . . . . . . . . . . . . . . . . 114

8.5 Additional challanges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

8.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

9 Conclusion and future work

119

9.1 Directions for future research . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

viii

Contents

Appendices

125

A R√©sum√© √©tendu

127

A.1 Objectifs de recherche . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

A.2 Contributions principales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

B Further Matryoshka security features

147

B.1 Matryoshka Verication Protocol . . . . . . . . . . . . . . . . . . . . . . . . . 148

B.2 Specic vulnerabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

B.2.1 Denial of Service and Trac Analysis . . . . . . . . . . . . . . . . . . 149

C Privacy Preserving Picture Sharing in Distributed OSNs

153

C.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154

C.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156

C.2.1 Usage control for picture sharing in online social networks . . . . . . . 156

C.2.2 Decentralized online social networks . . . . . . . . . . . . . . . . . . . 156

C.3 The proposed usage control mechanism . . . . . . . . . . . . . . . . . . . . . . 157

C.3.1 Safebook: a P2P DOSN leveraging real life social trust . . . . . . . . . 157

C.3.2 Overview of the solution . . . . . . . . . . . . . . . . . . . . . . . . . . 159

C.3.3 Solution description . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160

C.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164

C.5 Conclusion and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 169

D PRICE: PRivacy preserving Incentives for Cooperation Enforcement 171
D.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172 D.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
D.2.1 Cooperation enforcement in P2P networks . . . . . . . . . . . . . . . . 173 D.2.2 Credit-based incentive mechanisms . . . . . . . . . . . . . . . . . . . . 173 D.2.3 Security and Privacy Challenges . . . . . . . . . . . . . . . . . . . . . 174 D.3 Solution Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174 D.3.1 Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175 D.3.2 Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175 D.4 Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 D.4.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 D.4.2 Account creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177

Contents

ix

D.4.3 Payment order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 D.4.4 Payment notication . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180 D.5 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 D.5.1 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 D.5.2 Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 D.5.3 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 D.6 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 D.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

Bibliography

191

x

Contents

List of Figures
2.1 OSN customers and their relationships to PII and SNS . . . . . . . . . . . . . 14 2.2 Main functionality of a typical OSN platform . . . . . . . . . . . . . . . . . . 17 2.3 Types of data commonly stored in OSN proles. . . . . . . . . . . . . . . . . . 18
3.1 Impersonation attacks: victim U doesn't have any OSN account, victim V has an account on OSN1 and victim Z on OSN2. The attacker A generates U 's account on OSN2, a copy of V 's account on OSN1 and OSN2, and logs on OSN2 with the credentials of Z . . . . . . . . . . . . . . . . . . . . . . . . . 32
3.2 Main PII related threats in current OSNs. . . . . . . . . . . . . . . . . . . . . 33
5.1 Cyclic relation showing how real life trust between users can build the OSN itself. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
5.2 Safebook overlays (left), main components (center) and Matryoshka (right). . 60 5.3 An example of communication between users with dierent ACPs. . . . . . . 67
5.4 Account creation for user V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5.5 Matryoshka setup for user V . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 5.6 Entrypoint registration for user V 's Matryoshka. . . . . . . . . . . . . . . . . 73 5.7 A V 's prism is leaving ŒòV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5.8 V 's data lookup. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
5.9 Friendship advertisement in Safebook. . . . . . . . . . . . . . . . . . . . . . . 76
5.10 Prole data storage for V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
6.1 online, oine and the corresponding residual life distributions derived from the Skype dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
6.2 Chain residual lifetime with respect to h . . . . . . . . . . . . . . . . . . . . . 83
xi

xii

List of Figures

6.3 Data availability where f = 130, p = 0.53 and fl = f ‚àí 1 (no overlapping
between friend lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.4 Data availability where f = 130, p = 0.53 and fl = f ‚àí ml (full overlapping
between friend lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
6.5 Fragment size evaluation for dierent upload bandwidth c with varying request rate Œª. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
6.6 Maximum size of data retrieved at every request for dierent upload band-
width c with varying request rate Œª. . . . . . . . . . . . . . . . . . . . . . . . 91
7.1 Log-log plot of the degree complementary cumulative distribution of real-life social networks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
7.2 Average clustering coecient of real-life social networks with respect to node degree. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
7.3 Mixing time of real-life social networks. . . . . . . . . . . . . . . . . . . . . . 99
7.4 Ratio of common friends between two nodes V and Œ∏h at social distance h in
the social network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8.1 Overall architecture of Safebook. . . . . . . . . . . . . . . . . . . . . . . . . . 106 8.2 Internal (left) and external (right) message exchange in Safebook . . . . . . . 107 8.3 Account Creation: out of band step on the left, in band step on the right. . . 111 8.4 The Safebook logo: two persons shaking hands represent the process at the
basis of Matryoshka and, more generally, of Safebook. . . . . . . . . . . . . . 112 8.5 Graphical interface of Safebook: on the top-left the Safebook join; on the
top-right the prole page in the podium section; on the middle-left picture sharing in the gallery page; on the middle-right wall posting in the square; on the bottom-left friendship advertisement; on the bottom-right friend browsing in the contacts page. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
A.1 Clients des services de r√©seaux sociaux et leur relations avec les informations personnellement identiables. . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
A.2 Fonctionnalit√© principale d'un typique r√©seau social en ligne. . . . . . . . . . . 133 A.3 Types de donn√©es g√©n√©ralement enregistr√©es dans les prols des r√©seaux soci-
aux en ligne. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134

List of Figures

xiii

A.4 Les attaques d'usurpation d'identit√©: la victime U ne poss√©de aucun compte de reseau social, la victime V a un compte sur OSN1 et la victime Z sur OSN2. L'agresseur A g√©n√®re un compte V sur l'OSN2, une copie du compte de V sur OSN1 et OSN2, et il s'enregistre sur OSN2 avec les informations d'identication de Z . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
A.5 Principales menaces li√©es √† l'access aux informations personnellement identiables dans les OSNs actuelles. . . . . . . . . . . . . . . . . . . . . . . . . . . 136
A.6 la relation cyclique montrant comment la conance entre les utilisateurs dans la vie r√©elle peuve construire l'OSN elle-m√™me. . . . . . . . . . . . . . . . . . 136
A.7 Les recouvrements de Safebook (√† gauche), les composants principaux (au centre) et la Matryoshka (√† droite). . . . . . . . . . . . . . . . . . . . . . . . . 137
A.8 Un exemple de communication entre les utilisateurs avec des di√©rents politiques d'access aux donn√©s partag√©s. . . . . . . . . . . . . . . . . . . . . . . . 138
A.9 Les distributions des temps en ligne, hors ligne et correspondantes √† la vie r√©siduelle provenant de l'ensemble de donn√©es Skype. . . . . . . . . . . . . . . 139
A.10 Dur√©e de vie r√©siduelle de la cha√Æne par rapport √† sa longueur h. . . . . . . . 140
A.11 Taille maximale des donn√©es r√©cup√©r√©es √† chaque demande avec bande pas-
sante c en upload et di√©rents taux de demandes Œª. . . . . . . . . . . . . . . . 141
A.12 Log-log plot de la distribution cumulative complementaire du degr√© dans des reseaux sociaux r√©elles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
A.13 Coecient de clustering moyen dans des reseaux sociaux reelles par rapport au degr√© des connections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
A.14 Temps de m√©lange (en pas) dans des r√©seaux sociaux r√©els. . . . . . . . . . . . 143
A.15 Ratio des amis communs entre les deux noeuds V et Œ∏h √† une distance sociale h dans le reseau social. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
A.16 Architecture globale de Safebook. . . . . . . . . . . . . . . . . . . . . . . . . . 145 A.17 L'√©change interne (√† gauche) et externe (√† droite) de messages en Safebook. . 145 A.18 l'interface graphique de Safebook: sur le coin sup√©rieur gauche comment re-
joindre Safebook; en haut √† droite de la page le prol dans la section podium; au milieu √† gauche le partage de photos dans le page de la galerie; au milieu √† droite l'achage sur le mur dans la page square; en bas √† gauche l'annonce de l'amiti√© et en bas √† droite la navigation dans la page des contacts. . . . . . 146

xiv

List of Figures

B.1 A colluding intruder M in ŒòV . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 B.2 A black hole B in ŒòV (right). . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
C.1 The Matryoshka graph of a user V , from [57] . . . . . . . . . . . . . . . . . . 159
C.2 Data lookup in Safebook, from [57] . . . . . . . . . . . . . . . . . . . . . . . . 159
C.3 Picture publication steps for V , with V 's face fV made publicly available: 1-
picture input; 2- face detection; 3- face tagging; 4- face extraction; 5- face obfuscation; 6- picture and publisher face publication. . . . . . . . . . . . . . 161 C.4 Public picture advertisement: 1- N is informed about P; 2- face detection; 3face tagging; 4- publisher face extraction; 5- face obfuscation; 6- picture and N's face publication according to N's access control policy on her face. . . . . 163 C.5 Average outdegree, average number of 4-hops chains, average number of served Matryoshka for dierent social network graphs when 30% of nodes are on-line. 165 C.6 Unauthorized picture broadcast by friendship relations establishment between
a malicious V and any users Fi, or by recursive collusion with nodes Ci not necessarily belonging to V 's contact list. . . . . . . . . . . . . . . . . . . . . . 166
C.7 Average number of compromised chains when 10% of nodes misbehave for dierent social network graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . 167
C.8 Average number of compromised chains when 25% of nodes misbehave for dierent social network graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . 168
C.9 Spread of information vs usage control: in case of unprotected picture publication, automatic face obfuscation is guaranteed by peer collaboration even when there is software manipulation; in case of encrypted publication, the software manipulation may violate user's privacy, but with limited impact within the DOSN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
D.1 Payment scheme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
D.2 Total transaction time evaluation: TRT T and TL from [110], T from Monte
Carlo techniques (10000 samples). . . . . . . . . . . . . . . . . . . . . . . . . . 184
D.3 Evaluation of the number of notaries t to be contacted for every transaction for dierent online- p and misbehaving- m probabilities. . . . . . . . . . . . . 186
D.4 Evaluation of the bandwidth consumption for dierent transaction rates Œª (per hour) and notaries to be contacted t. . . . . . . . . . . . . . . . . . . . . 187

List of Tables
3.1 Attacks vs. Security Objectives in Online Social Networks . . . . . . . . . . . 28 3.2 Current OSN and their characteristics. . . . . . . . . . . . . . . . . . . . . . . 41 4.1 Current DOSN proposals as an answer to the Big Brother problem in cen-
tralized OSNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 5.1 An example of ACP based on set operations between contacts granted with
user-dened badges. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
7.1 Main characteristics of ve social graphs from Facebook (pŒΩ computed assuming pmal=0.01). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
7.2 Characteristics summary of examined SN graphs. . . . . . . . . . . . . . . . . 101 D.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 D.2 Time statistics in seconds for the three main distributions in gure D.2 . . . . 184
D.3 Coin registry size in MB for dierent values of k . . . . . . . . . . . . . . . . 185
xv

xvi

List of Tables

Acronyms

These are the main acronyms used in this document. The meaning of an acronym is usually indicated once, when it rst occurs in the text.

API

Application Programming Interface

AS

Application Service

CT

Communication and Transport

DHT

Distributed Hash Table

DEK

Data Encryption Key

DOSN Distributed Online Social Network

KDC Key Distribution Center

KEK Key Encryption Key

OSN

Online Social Network

P2P

Peer-to-peer

PII

Personally Identiable Information

SN

Social Network

SNA

Social Network Application

SNP

Social Network Providers

xvii

xviii

SNS

Social Network Services

Acronyms

Notations

Generally, boldface upper-case letters denote matrices and boldface lower-case letters denote vectors (unless stated otherwise). Calligraphic upper-case letters denote sets. The superscript T stands for transpose.

V KV‚àí KV+ KV M MK b AV BV RV SV r sr

a user in the social network
a private key generated by user V a public key generated by user V public-private keypair generated by user V
a message a master key a badge
the ACP of user V the set of all the badges dened by V the set of all the rules dened by V the distributed data storage space of user V a rule in the ACP A a seed associated to a rule r
xix

xx

Notations

Drn FV EVU {M }SKV EKU {M } N ameV

a set of n DEKs associated to rule r the set of all the contacts of V the set of all the DEKs sent by V to U a message M signed by the user V 's private key KV‚àí a message M encrypted with the user U 's public key KU+ a tuple of properties identifying user X

N IdV

node identier of user V

U IdV Cert N IdV , NV+ Cert U IdV , UV+ min

user identier of user V node identier certicate for user V user identier certicate for user V
minimum of following expression

max

maximum of following expression

t

continuous time

P r [¬∑]

probability of argument

p (¬∑)

probability density function

X

a random variable

E [X]

expected value of a random variable X

fi

the ith element of vector f, if the latter is dened

f

arithmetic mean of vector f

\ v‚ààV

set union set element exclusion
an element v in a set V

Notations
V G (V, E) deg (¬∑) c (¬∑) C (¬∑) B (n, p)
Rh ssd ‚àÜx (h) œÑx ( )

xxi
cardinality of a set V a graph composed by a set V of vertexes and and a set E of edges
degree function local clustering function global clustering function
binomial distribution with number of trials n and success probability in each trial p random walk distribution after h hops
steady state distribution variation distance mixing time

xxii

Notations

Chapter 1
Introduction
Social Networking Services (SNS), like Facebook, LinkedIn, or Google+, are a predomi-
nant factor of Internet. Catering for a very large user population with a vast dierence in social, educational and national background, they allow even users with limited technical skills to publish personal information and to communicate with ease.
In general, the Online Social Networks (OSN) resulting from these SNSs are digital
representations of a subset of the relations that their participants, the registered persons or institutions, entertain in the physical world. Spanning participating parties through their relationships, they model the social network as a graph. However, the popularity and broad acceptance of social networking services as platforms for messaging and socialising attracts not only faithful users who are trying to add value to the community, but parties with rather adverse interests, be they commercial or plain malicious, as well.
The main motivation for members to join an OSN, to create a prole, and to use the dierent applications oered by the service, is the possibility to easily share information with selected contacts or with the public for either professional or personal purposes. In the rst case, the OSN is used as a facility geared toward career management or business goals, hence SNS with a more serious image, like XING or LinkedIn, are chosen. As members in this case are aware of the professional impact of the OSN, they usually pay attention to the content of the data they publish about themselves and others. In the case of a more
1

2

Chapter 1 Introduction

private use, they share more personal information like contact data, personal pictures, or videos. Other members in the shared pictures can be marked ( tagged), and links to their respective proles are created automatically.
The core application used by OSN members is the creation and maintenance of their contact lists, which describe the members' milieux and maps them into the digital OSN graph. By informing members automatically on prole changes of their contacts, the SNS thus helps users to stay up to date with news of their contacts and very often the popularity of users is measured in the number of contacts their prole links to.
Analyzing the OSN with respect to their security properties and the privacy of their users, some obvious threats become apparent. Generally, a wealth of personal data on the participants is stored at the providers, especially in the case of OSN targeting nonprofessional purposes. This data is either visible to the public, or, if the user is aware of privacy issues and able to use the settings of the respective SNS, to a somewhat selected group of other members. As proles are attributed to presumably known persons from the real world, they are implicitly valued with the same trust as the presumed owner of the prole. Furthermore, any actions and interactions coupled to a prole are again attributed to the presumed owner of this prole, as well.
Dierent studies have shown that participants clearly represent the weak link for security in OSN and that they are vulnerable to several types of social engineering attacks. This is partially caused by a lack of awareness to the consequences of simple and presumably private actions, like accepting contact requests, or tagging pictures, as well as communication operations like commenting on proles or posting on walls. The low degree of usability of privacy controls oered by the SNS, and nally and most importantly inherent assumptions about other participants and trust in other proles, which are actually a desired characteristic, certainly add to the problem.
By analyzing the privacy problems in current OSN, it becomes apparent that even if all participants were aware of exposures and competent in the use of SNS, and even if a concise set of privacy measures were deployed, the OSN would still be exposed to potential privacy violations by the omniscient service provider: the data, directly or indirectly supplied by all participants, is collected and stored permanently at the databases of the service provider,
which potentially becomes a Big Brother capable of exploiting this data in many ways
that can violate the privacy of individual users or user groups. The importance of this privacy exposure is underlined by the market capitalization of these providers, which reaches

1.1 Research objectives

3

50 billion U.S. Dollars (Facebook Inc, according to the investment of Goldman Sachs and Digital Sky Technologies in 2011)[12], and by the OSN worldwide advertisements revenue, which reached 5 billion U.S. Dollars in 2011 and is estimated to double by 2013 (according to eMarketer [25]).
This thesis claims that the user's privacy can be easily jeopardized due to the centralized architecture of OSNs, and current providers are not likely to address this problem due to their business model. This work considers instead the protection of private data in OSN a pressing topic and proposes a new architecture for OSN with the purpose of privacy by design.
1.1 Research objectives
This thesis assumes the protection of the user's privacy against the omniscient SNS provider to be the main objective for OSN and aims at identifying the main characteristics
an OSN should meet to achieve such an objective and at providing a new architecture for
privacy preserving OSN. As an additional objective, the protection of the user's privacy against malicious users is also addressed.
We dene the objective of privacy as the possibility to hide any information about any user at any time, even to the extent of hiding users' participation and activities within the OSN. Therefore, privacy not only encompasses the protection of personal information which users publish at their proles, but also takes into account the communication between users, that is, it requires that no parties other than directly addressed or explicitly trusted ones should have the possibility to trace communication patterns. The details of messages have to be unobservable, so only the requesting and responding parties should know one another's identity and the content of the request. Access to the content of a user prole may only be granted by the user directly, and this access control has to be as ne-grained as the prole itself.
Together with the objective of privacy, this thesis addresses further security objectives
of integrity and availability , which in OSN come in slightly dierent avors than in
traditional systems. In the context of OSNs, integrity has to be extended beyond the basic goal of protecting users' data and identity against unauthorized modication to cover a variety of attacks such as the creation of personae, bogus proles, cloned proles, or other types of impersonation.

4

Chapter 1 Introduction

Each prole should then be unambiguously associated to an individual in the real world. Availability should prevent denial-of-service attacks that in the context of OSN may aim at seizuring a victim's prole or disrupting the possibility to communicate with the user. Moreover, availability should not only achieve the basic goal of guaranteeing SNS even in face of attacks and faults, but also target robustness against censorship.
1.2 Main contributions
The centralized nature of OSNs allows SNS providers to monitor and intercept user's sensitive data. This problem recently attracted quite some interest in the research community
and the outcome of the research can be summarized in a family of solutions known as Decentralized Online Social Networks (DOSN). Such DOSNs aim at distributing the user's
data with the adoption of a client-server (or cloud) approach, where users do not participate in the storage service and the stored data is always available, or through a peer-to-peer (P2P) approach, where users participate in the storage service and the stored data may not be always available.
Even though the user's shared data is protected by encryption in all the current DOSNs, such solutions are not suitable to achieve our research objectives. Client-server (or cloud) approaches do not always evade the potential control of a single party, as e.g. a company or an organization, on the hosted user's data. Such control evasion might have been achieved if users had set up and maintained their own servers to host their data and that one of other users, thus leading to a P2P-like approach. However, current P2P DOSNs suer from exposures to communication tracing by malicious peers. In the context of OSN, such communication traces are likely to correspond to friendship relationships in the social network, and therefore they can even disclose details on the structure of the social network graph. Among the current P2P-based DOSN approaches, none of them addresses this problem. In addition, current P2P DOSNs often leverage on existing P2P architectures suering from the well known problems of lack of cooperation due to selshness of nodes and denial-of-service attacks due to the creation of multiple peer identities under the control of a malicious party. For these reasons, current P2P DOSNs no not seem suitable for the goal of privacy preserving OSN.
With this work, we hope to provide a basis for new research focusing on privacy in OSN. Business statistics, newspapers and current research let us strongly believe the relevance of

1.2 Main contributions

5

this topic is nowadays very high and will become even more important in the next years. Reliable solutions are therefore needed to accomplish the task of providing privacy to OSN users through the users' education and the proposal and implementation of appropriate OSN architectures.
The rst contribution of this thesis consists in an analysis of Online Social Networks that includes the main OSN actors, the OSN functionalities, the nature of the sensitive data shared by users, and the main threats resulting from potential misuse of such data.
The second contribution of this thesis consists in lling the lack of privacy preserving OSN by proposing a new decentralized architecture for OSN targeting user's privacy as the main goal. Decentralization is based on a new P2P system that leverages the real life trust between OSN members resulting from the OSN application as a natural cooperation enforcement mechanism to build the social network application itself. In the proposed so-
lution, called Safebook , neighbor peers are arranged according to their maintainers' real
life trust that is, according to the social network graph. Nodes maintained by one user's friends store such user's data and serve it even when the user is o-line. As with anonymous routing, data requests and replies are recursively delegated to dierent peers to hide the actual requester's identier and prevent the disclosure of the trust relationships between OSN members. Data condentiality is assured by adoption of encryption techniques and integrity of proles is assured by o-line trusted identication service(s) whose jurisdiction is limited to the purpose of identication only.
The Safebook architecture has been designed with the main goal of preserving user's privacy by the very beginning: prole integrity through adoption of certied identiers that are signed by a trusted identication service, together with data condentiality and integrity through adoption of classical encryption techniques, protect the social network graph vertices as represented in the OSN, i.e. the users'proles; multi-hop routing of messages and further encryption techniques provide communication untraceability and condentiality, and protects the social network graph edges as represented in the OSN, i.e. the user's contact
list. Therefore, Safebook achieves privacy by design .

6

Chapter 1 Introduction

The third contribution of this thesis consists in the evaluation of the feasibility and performance of Safebook. Starting from the online probability of peers, the number of user's friends, and the length of the hop-by-hop trusted paths providing communication untraceability, analytical models estimate the probability of retrieving a target user's data and the maximum size of each message containing such data.
The fourth contribution of this thesis consists in the investigation of the strong relationship between the topological properties of the social network graph and the achievable users' privacy in Online Social Networks. We observe three metrics, namely clustering coecient, degree distribution and mixing time, and show that they give fundamental insights on the privacy degree of both centralized and distributed OSNs.
Further investigation is conducted on the impact of the social network graph topology on both the performance and privacy of Safebook. In Safebook there is a strong trade-o between performance and privacy because delay and reachability are inversely proportional to privacy. In fact, the lower the length of the hop-by-hop trusted paths, the higher the probability of deriving the friendship relationships between Safebook users. Nevertheless, the higher such length, the lower the probability of retrieving data, and the higher the retrieval delay. We observe that the optimal choice for this length depends on the social graph itself.
The fth and last contribution of this thesis consists in the implementation and deployment of Safebook. The Safebook prototype is written in python and can be executed on multiple operating systems such as Windows, Linux and MacOs. A web based user interface helps the user to benet from the available privacy tools such as those allowing her to share data with limitations.
1.3 Thesis organization
The rst part of this thesis discusses the security and privacy issues in Online Social Networks.
Chapter 2 introduces Online Social Networks, provides details on the OSN actors such as the user and the provider, and illustrates the main functionalities of an OSN. Then, the core information stored in OSNs is identied and classied into several main areas.

1.3 Thesis organization

7

Chapter 3 presents privacy, integrity and availability objectives for OSN. A detailed spectrum of attacks that may be perpetrated in OSNs is discussed against these objectives, and countermeasures are proposed to contrast such attacks. However, most of the countermeasures reveal to be ineective against the Social Network Service provider itself, that plays the role of an omniscient centralized entity, a Big Brother . An overview of the main centralized OSNs is also provided.
Chapter 4 gives an overview of the solutions that researchers presented to contrast the Big Brother problem together with their limitations. Characterized by a decentralized approach through client-server, cloud or peer-to-peer architectures, these solutions mostly focus on the protection of the user's prole data rather than that one of the trust relationships between users.
The second part of this thesis introduces a new approach for privacy preserving Online Social Networks.
Chapter 5 motivates the need for a new privacy preserving OSN addressing the objectives of security and privacy presented in Chapter 3 and proposes a new decentralized approach for OSN achieving privacy by design. Such an approach, namely Safebook, targets decentralization and cooperation enforcement with the help of an ad-hoc peer-to-peer network mapping the real life social network graph. The trust relationships established in such an OSN are leveraged to build the OSN itself and provide data storage and communication obfuscation services. Privacy against centralized omniscient entities is achieved thanks to the adoption of a decentralized P2P approach. Privacy against malicious users is achieved thanks to communication obfuscation through anonymous routing techniques, data condentiality and integrity through the use of encryption, integrity of proles'identity through certied identiers.
Chapter 6 analyzes the feasibility of Safebook with the help of real network measurements. Online session times of peers and analytical models are taken as a basis to evaluate the probability of building trusted paths in Safebook and their residual lifetime. Therefore, data availability and the performance of data management operations are evaluated.
Chapter 7 introduces with an analysis of privacy from the graph theory perspective. The basic nding shows that three metrics, namely the degree, the clustering coecient and the mixing time, give fundamental insights on the privacy degree of the OSN regardless of its particular centralized or distributed nature. The chapter further investigates the impact of

8

Chapter 1 Introduction

the social graph topology on the specic OSN architecture proposed in Safebook. Based on the ndings presented in the rst part, on analytical models and on some real social network dumps, the chapter shows a strong trade-o between performance and privacy such that delay and reachability are inversely proportional to privacy.
Chapter 8 presents the prototype of Safebook, an event-driven application composed by dierent managers in charge of building the overlays and running Safebook protocols. All managers communicate through a main dispatcher.Similarly to all current social network services, Safebook is accessible via internet browsers through a user interface implemented under the form of a web page.
Finally, Chapter 9 concludes this thesis and presents the future work.

Part I
Security and Privacy Issues in OSN
9

10

Chapter 2
Online Social Networks
This chapter introduces Online Social Networks. At the beginning, the chapter provides details on the OSN actors such as the user and the provider, and illustrates their relations. Then, the main functionalities of an OSN are discussed. Finally, the core information stored in OSNs is identied and classied into several main areas.
Social Network Services (SNS) are drastically revolutionizing the way people inter-
act, thus becoming de facto a predominant service on the web, today. The impact of this paradigm shift on socioeconomic and technical aspects of collaboration and interaction is comparable to those caused by the deployment of the World Wide Web in the 1990's.
Catering for a broad range of users of all ages, and a vast dierence in social, educational, and national background, SNS allow even users with limited technical skills to publish
Personally Identiable Information (PII) and to communicate with an extreme ease,
sharing interests and activities.
An Online Social Network (OSN) oering, usually centralized, online accessible SNS
contain digital representations of a subset of the relations that their users, both registered persons and institutions, entertain in the physical world. geared towards career management or business contacts; such networks typically provide SNS with a more serious image. In contrast, OSNs with a more private and leisure-oriented background are typically used for
11

12

Chapter 2 Online Social Networks

sharing and exchanging more personal information, like, e.g., contact data, photographs, and videos; OSNs provided by such networks have usually a more youthful interface. The core OSN application is the creation and maintenance of contact lists. Through informing users automatically on prole changes of their contacts, the SNS help users to remain up to date with news of their contacts.
These properties of the SNS have led to the denition of boyd and Ellison [58], according to which Social Network Sites or Online Social Network Services are:
 ... web-based services that allow individuals to (1) construct a public or semi-public prole within a bounded system, (2) articulate a list of other users with whom they share a connection, and (3) view and traverse their list of connections and those made by others within the system.
This denition, however, leaves aside some additional services that become apparent when observing the use of SNS. In particular, the communication of members through direct, sometimes instant message exchange, the annotation of proles (e.g., via comments and recommendations), or the creation of links pointing to other proles (picture tagging). The publication and browsing of images has grown to become a core function of these services [106]. Additionally, SNS typically provide support for a variety of third-party applications featuring advanced interactions between members ranging from simple poking of another member or the support for interest groups for a common topic to likeness testing with other members.
Maintenance and access to the OSN and their services are oered by commercial Social Network Providers (SNP), like Facebook1, LinkedIn 2, Google3, XING4, and the likes.
In general, a large amount of PII provided by the users is stored at the databases being under control of these providers, especially in the case of OSN targeting non-professional purposes. This data is either visible to the public, or, if the user is aware of privacy issues and able to use the settings of the respective SNS, it is accessible by selected group of other users. As proles are attributed to presumably known persons from the real world, they are implicitly valued with the same trust as the assumed owner of the prole. Furthermore, any
1http://www.facebook.com 2http://www.linkedin.com 3https://plus.google.com 4http://www.xing.com

2.1 Social Network Providers and Their Customers

13

actions and interactions coupled to a prole are again attributed to the assumed owner of this prole, as well. A SNP can, together with its SNS, also oer an application programming interface (API),
allowing interested users to program a Social Network Application (SNA), thus extend-
ing and enhancing the functional range of the service.

2.1 Social Network Providers and Their Customers
Social network providers oer social networking services to the users and may further provide additional interfaces and services to other customers. These customers may come from dierent domains and pursue various goals.
In particular, sponsors belong to customers who advertise their services to the users
through the OSN platform. Their advertisements may be of dierent kinds: plain commercial sponsors buy banner space or other marketing services from the SNP to advertise their products; SNS frequently contain market pages at which users can publish classied advertisements (ads), job oers, and the likes, for which they may be billed. Also sponsors may create commercial interest groups or proles inside the OSN.
Another type of OSN customers are third party service providers , who extend the
content and functionality of SNS with their own applications. These applications such as quizzes and games are typically executed on the servers under control of these third parties connected to the SNS via appropriate APIs. Often these applications have extensive access to the personal data of OSN users.
Finally, all sorts of data analysts may act as customers of SNP. These customers
typically have data mining interests and may also get access to the personal information of users and their activities within the OSN. The analysis carried out by data analysts may serve dierent purposes, including scientic research (such as statistics, social behavior, or network-relevant aspects) and non-scientic data mining, typically for commercial purpose such as marketing.
Figure 2.1 illustrates and summarizes the diversity of OSN customers and reects their relationship to the SNS functionality and possible access to the personal information of the OSN users.

14

Chapter 2 Online Social Networks

Figure 2.1: OSN customers and their relationships to PII and SNS
2.2 Functional Overview of Online Social Networks
Even though each OSN is usually tailored to some specic use, the functional range of these platforms is essentially quite similar. Generally speaking, OSN functionality can be classied
into three main types: The networking functions serve the actual purpose of OSN to foster
social relationships amongst users within the virtual platform. In particular, they provide
functionality for building and maintaining the social network graph. The data functions
are responsible for the management of user-provided content and communications amongst the users. Their variety contributes to the enhancement of users' interactions and makes
the platform more attractive. Finally, the access control functions aim to implement the
user-dened privacy measures and to restrict unauthorized access to the user-provided data and information.

2.2 Functional Overview of Online Social Networks

15

2.2.1 Networking functions.
An OSN can be represented as a social graph whose vertexes are constituted by users and whose edges are constituted by social ties such as friendship, kinship and the like (see gure 2.2). OSN users can typically build their proles and establish relationships with each other. The set of networking functions includes all functions that update the vertices and the edges of the social network graph. In particular, the OSN user invokes the prole creation function upon his or her registration to the OSN platform. This function adds a new vertex representing that user in the social network graph. Thereafter, with prole lookup the user can nd other users who are also represented via vertices. Through the call to the relationship link establishment function the user can set up a new relationship with some other user. This function typically sends notication to that user, who in turn can accept or ignore the request. If the user accepts the request then users are added to the contact lists of each other and a new edge representing their relationship is added to the social network graph. The OSN users can also encounter proles for possible relationships thanks to the contact list browsing function, which is realized through the traversal along the edges of the graph. Additional networking functions can be used to remove vertices and edges from the graph, for example upon the deletion of the user's prole.
2.2.2 Data functions.
OSN users can typically advertise themselves via their own proles and communicate with each other using various applications like blogs, forums, polls, chats, and on-line galleries.The prole update function allows the OSN users to maintain details on their own proles and provide fresh information to other users, who may call the prole retrieval function to visit the prole. Communication amongst users via blogs and forums is typically implemented through the post function, which inserts the message in the main prole page which sometimes is called the `wall' or `stream'. This block of information is not limited to plain text and can also contain videos, pictures, or hyperlinks. An OSN user willing to setup multimedia galleries typically calls the upload function, which transfers digital data from the user's device to the OSN database. In case of content depicting other users, the tag function can create a link pointing to their prole. OSN users can typically evaluate content published by other users through the like or dislike functions. These functions can also be considered as a feedback to the publisher from other users. In consequence, the user may either be

16

Chapter 2 Online Social Networks

encouraged, or discouraged to provide similar uploads and posts. Using the comment function OSN users can articulate their point of view in a more explicit way. OSN users can also exchange personal messages. Here, in particular, the write to function simulates the asynchronous oine communication (e.g., e-mail), whereas the chat to function allows for the synchronous real-time communication. An OSN user can send messages to individuals and also to subgroups of users from his or her contact list. The latter subgroup can be dened via the regroup function. Additionally, users may create interest groups, advertise own interest groups to other users, and join interest groups created by other users. The user who creates an interest group obtains administrator rights for this group by default; however, these rights can be changed thereafter, and distributed to other group members.
2.2.3 Access control functions.
OSN users are usually allowed to dene their own privacy settings through some access control functions. In particular, an OSN user may have control over the
‚Ä¢ visibility of her on-line presence within the OSN;
‚Ä¢ visibility of contacts from her contact list;
‚Ä¢ visibility and access to her own prole information;
‚Ä¢ access to her own uploaded content and posted communications.
All these functions usually take as input the information to be protected and the list of proles having the rights to access it. The eligible proles can be clustered into generic groups such as `friends', `friends of friends', `everybody', or user-dened groups, such as `family members', `colleagues' or the like.
For example, the prole lookup function takes as an input a target's prole identier, such as the name of the prole owner, and returns a list of possible candidates. An OSN user can apply output restrictions on this function to partially hide her own presence in the OSN. However, the protected prole would remain reachable due to the prole browsing functionality of the OSN. Nevertheless, sensitive relationships can be hidden from unauthorized users by imposing restrictions on the output of the contact list browsing function. Thus, combined with the restrictions on prole lookup, this constraint can completely hide some prole in the OSN, since this prole will become unreachable from other users outside of the prole's contact list. Note that new contacts could still be added to the prole owner's

2.3 Data contained in Online Social Networks

17

contact list on the initiative of the latter. Another example is the control on the output of the prole retrieval function, which allows the prole owner to control the disclosure of the prole to other users. This allows some OSN user to hide parts of the private prole information from selected partners. Finally, the data related to online or oine indicators, one-to-one or one-to-many communications, such as posts, walls, comments, positive or negative marks, tags and the like can be protected by the means of restrictions on the huge set of the networking and data functions.

Figure 2.2: Main functionality of a typical OSN platform
2.3 Data contained in Online Social Networks
The core information stored in OSN, the self generated and maintained data of the users and their proles can be classied into the following ve types (see gure 2.3):
1. personal contact details, describing the user's identity; 2. connectivity, representing the connections in the social network graph; 3. interests of the user; 4. information on the curriculum vitae of the user; 5. communication, including all interactions with other OSN users of the SNS. These types constitute the personally identiable information which is provided directly by the OSN user. Additional information about the OSN user is often generated and made accessible within the OSN by other users.

18

Chapter 2 Online Social Networks

Figure 2.3: Types of data commonly stored in OSN proles.
Personal contact details describe `who the user is', providing not only some basic in-
formation such as the user's name, picture, gender, birthday, birthplace and marital status, but also some additional meta information with regards to the membership in the OSN, the

2.3 Data contained in Online Social Networks

19

contact information aside of the OSN platform such as (e)mail addresses, phone numbers, instant messaging identiers and personal web sites. Furthermore, it describes the personal prole of the user and may report about sexual, personal, political or religious interests and preferences. Users frequently can include a quick summary about themselves, describing their professional expertise, views and opinions, skills they have to oer, as well as a short text on what they are looking for.
Connectivity describes `whom the user knows', providing the user's contact list, possibly
with annotated information about the type of the relationship (cf. family, colleagues, best friend, sports partner). Especially, OSN platforms with more private and leisure-oriented focus frequently ask the user to provide information on the relationship status, and in consequence the name and prole of their signicant other contact. Users may further ask for recommendations by others. These recommendations may contain very detailed information about the user and shed light on the relationship between the both.
Interests describe `what the user likes and is interested in'. These may contain user's
personal interests, hobbies, and preferences: In particular, information about favorite movies or music style, their sexual, religious, and political views, recreational activities of the user (such as personal pictures and videos showing situations from their personal lives), and their subscription to fan-pages as well as membership in special interest groups inside the OSN.
Information on the curriculum vitae describes the professional career and educa-
tional background, including attended schools, colleges, and universities, advanced studies, academic titles and professional certicates, as well as professional and soft skills. Such information may be very detailed and include the description of job positions the user currently holds or has previously had, including information on the duration and type of the position, the duties and responsibilities fullled in the job, and experiences being collected.
In addition to the description of the career progression, some OSN platforms ask the user to provide information on her membership in professional organizations (past and present), her community and political services (memberships and positions in clubs, associations, political parties, and professional societies), awards and distinctions, as well as recommendations and references.

20

Chapter 2 Online Social Networks

Communication describes `which messages the user has exchanged and with whom'. OSN
platforms generally oer exchange of personal oine messages, asynchronous communication via posts on walls and guestbook entries which the prole owner may hide or disclose to other users, and synchronous communication such as chats. These are examples of direct communications initiated by the user. However, there are also some less direct communications provided by other functionalities of the OSN platforms, such as the utilization of SNS applications (e.g. poking, likeness tests, quizzes), as well as public or targeted invitations to organized events.
Indirect information disclosure about OSN users may occur through posted opinions
and comments, or any type of annotations to proles of other users. Even though the owners of the annotated proles may be able to remove undesired annotations, they need to notice the annotations in the rst place. Since many users do not explicitly search for annotations made by other users about their proles, this indirectly disclosed information may remain publicly accessible over a longer period of time. Similarly, information about users may be disclosed via third party statements about the user made in forums of the interest groups, or as annotations or comments at the proles of other users.
Any form of user-generated digital content may also cause third party information disclosure. For example, some OSN try to prevent users from posting photographs showing people
on their proles if the owner of the prole is not depicted there5. However, this does not
prevent users from posting photographs picturing them together with others. Additionally, many OSN platforms oer tagging of pictured users, whose proles will usually be directly linked to that picture. These tags may contain further comments added by the user who uploads the picture.

2.4 Summary
In this chapter we presented Online Social Networks as digital representations of a social network graph whose vertices correspond to the registered users, and whose edges correspond to a subset of those users' relationships in real life. These OSNs are maintained by usually commercial social network service providers and allow users to easily share even sensitive
5http://www.odnoklassniki.ru

2.4 Summary

21

information, such as the user's personal contact details, her contact list, her interests, her professional and educational background, and her communication traces. Such data, often uniquely identifying a user, is stored at the databases being under control of the SNP. Potential misuse of this data from a malicious SNP or an attacker taking control on it may threaten users' privacy as discussed in the next chapter.

22

Chapter 2 Online Social Networks

Chapter 3
Main threats in OSN
In this chapter we provide an overview of important security objectives for online social networks. First of all we notice that classical requirements (cf. [33]) of condentiality, integrity, and availability, have a special touch when considered in the scope of OSNs. While integrity and availability have only subtle dierences compared to other communication systems, in that they mostly address the content provided by the users, the requirement of condentiality (usually associated with encryption) is no longer sucient and should be extended to the more comprehensive security objective that is privacy.
While potential breach of user privacy and integrity of user-provided contents may lead to economic damages for the users, cause embarrassing situations, and also tarnish their reputation (even in the real world), the missing availability of contents or services may also decrease the attractiveness of the actual OSN platform and harm its provider. It is extremely dicult to cope with all these goals simultaneously. Especially privacy of OSN users is challenging since the amount of personal information is huge and this information may be available not only from a particular OSN platform but also from the web.
23

24

Chapter 3 Main threats in OSN

3.1 Security and privacy objectives
In the following, we describe privacy, integrity and availability objectives for on-line social networks, while also mentioning potential threats with regard to not only the prole owner, but also other users and the system itself.
3.1.1 Privacy
Privacy is a relatively new concept, born and evolving together with the capability of new technologies to share information. Conceived as `the right to be left alone' [119] during the period of newspapers and photographs growth, privacy now refers to the ability of an individual to control and selectively disclose information about him. The importance of privacy is so relevant to have been reported in the Universal Declaration of Human Rights (art.12):
No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honor and reputation. Everyone has the right to the protection of the law against such interference or attacks.
In the internet age, where huge amount of sensitive data can be easily gathered, stored, replicated and correlated, the protection of privacy is even more seen as the main objective for the services provided by an OSN platform [69, 59].
The problem of users'data privacy can be dened as the problem of usage control [93]: usage control ensures access control together with additional control on the later usage of the data, even once information has already been accessed.
Access to the content of a user prole may only be granted by the user directly, and this access control has to be as ne-grained as the prole itself. For example, if the prole contains several information blocks then access to each block has to be managed separately.
In addition, communication privacy calls for inference techniques aiming at deriving any type of information with regard to: (1) anonymity, meaning that users should access resources or services without disclosing their own identities; (2) unobservability, i.e. the requirement that no third party should gather any information about the communicating parties and the content of their communication; (3) unlinkability, which requires that obtaining two messages, no third party should be able to determine whether both messages were sent by the same sender, or to the same receiver; (4) untraceability, which demands

3.1 Security and privacy objectives

25

that no third party can build a history of actions performed by arbitrary users within the system; in other words, it demands both anonymity and unlinkability.
In summary, the objective of privacy is to hide any information about any user at any time, even to the extent of hiding their participation and activities within the OSN in the rst place. Moreover, privacy has to be met by default, i.e. all information on all users and their actions has to be hidden from any other party internal or external to the system, unless explicitly disclosed by the users themselves.
3.1.2 Integrity
In OSN, any unauthorized modication or tampering of user-generated content and prole information have to be prevented (see gure 2.3). This encompasses the protection of real identity of users within the OSN platforms. In this sense, the denition of integrity in such networks is extended in comparison with the conventional detection of modication attempts on data. Moreover, problems with integrity of user proles and their contents may have devastating impact on the objectives put forth with respect to the privacy of OSN users. Since the creation of proles in traditional OSNs is easy, protection of real identities is insucient in today's platforms. In particular, none of the current major OSN providers is able (and perhaps even not interested in) to ensure that a prole is associated to the corresponding individual from the real world.
As users inherently trust the OSN providers, the aforementioned vulnerabilities can be thwarted through the appropriate authentication procedures to assure the existence of real people behind registered OSN proles. Identity checks do not necessarily have to be performed by a centralized service, however, all identication services have to be trusted by all participants.

3.1.3 Availability
The objective of availability for OSN aims at assuring the robustness of the social network services in the face of attacks and faults. The insucient guarantees for availability may prevent users from accessing the service and make the OSN platform less attractive. Especially, for OSNs with professional focus, e.g. OSNs that aid their users to foster business relations or nd new job positions, it is mandatory to keep users' data continuously available.

26

Chapter 3 Main threats in OSN

Therefore, we consider availability of user-generated data and proles as a basic requirement that should be provided by the platforms, even though for leisure-oriented OSN platforms the availability of certain content may appear not of prime importance at rst sight.
In the context of social network services denial-of-service attacks aim at either seizur-
ing a victim's prole (or selected parts of it) or disrupting the possibility to communicate with the user. Such attacks have a direct impact on the availability of users' data. Furthermore, also integrity threats like data pollution and cloning may impair the availability of network services by aecting the quality of the service perceived by the users.
Also distributed services, which are implemented in a decentralized way, possibly via peer-to-peer systems, or which follow other types of service delegation, may be vulnerable to a series of attacks against availability as well. These attacks include black holes, aiming at collecting and discarding a huge amount of messages; selective forwarding, where some trac is forwarded to the destination, but the majority is discarded; and misrouting, which aims to increase the latency of the system or to collect statistics on the network behavior. In any case, attacks on distributed social networks are more eective in case of collusion amongst malicious users or in the presence of Sybil nodes controlled by the attacker, which is not the case for the centralized OSNs.

3.1 Security and privacy objectives

27

In the following, we introduce and discuss the impact of a series of OSN attacks on the above presented security objectives.

28

Chapter 3 Main threats in OSN

Attacks
Plain Impersonation Prole Cloning Prole Hijacking Prole Porting Id Theft Proling Secondary Data Collection Fake Requests Crawling and Harvesting Image Retrieval and Analysis Communication Tracking Fake Proles and Sybil Attacks Group Metamorphosis Ballot Stung and Defamation Censorship Collusion Attacks

Privacy
x x x x x x x x x x x
x

Security Objectives

Integrity

Availability

x

x

x

x

x

x

x

x x

x

x

x

x

Table 3.1: Attacks vs. Security Objectives in Online Social Networks

3.2 Attack Spectrum and Countermeasures

The diversity of available OSN platforms opens doors for a variety of attacks on privacy of the users, integrity of their proles, and the availability of the user-provided contents. In this section, we will highlight main attack types against OSN platforms and discuss their impact on the aimed security objectives. Table 3.1 will serve as a background for our discussion. It illustrates dierent types of attacks and shows their relevance for the mentioned security objectives of privacy, integrity, and availability. We will discuss not only the purpose and

3.2 Attack Spectrum and Countermeasures

29

impact of each attack but also explain the techniques needed to mount it, while referring to some real-world examples, where possible. We note, however, that technical realization behind an attack may strongly depend on the functionality and in particular on the use of dierent protection mechanisms within the OSN platform. Therefore, not every attack technique will have the same impact when used against dierent OSN platforms. Moreover, since OSN providers typically have full control over the network resources, no meaningful protection appears possible if the attacks are mounted by the provider itself.
Plain Impersonation With plain impersonation attack the adversary aims to create fake
proles for real-world users as depicted in gure 3.1. In this sense a real-world user will be impersonated within the OSN platform. The success of this attack strongly depends on the authentication mechanisms deployed in the registration process. Since many OSNs tend to authenticate email addresses by requesting conrmations for the registration emails, this attack can be easily performed if an email address is created in advance. The consequence of plain impersonation is that the adversary can participate in the OSN applications on behalf of the impersonated user with all damaging consequences for the user. A currently very prominent secondary eect of all kinds of impersonation (Sections 3.2  3.2) is the misuse of the trust that users inherently have in messages from their accepted contacts, and especially the `419' scam [1]: impersonating attackers engage in a dialog with contacts of the impersonated individual, and, by producing a credible story, (`My wallet was stolen in London and now I can't pay my ight home') successfully defraud the victim. This attack can be thwarted only through the deployment of stronger authentication techniques. In particular, it is desirable to require some form of real-world identication from the user prior to switching on her account.
Prole Cloning By prole cloning we understand a special type of impersonation attack
that occurs within the same OSN platform [39], as depicted in gure 3.1. The goal of the adversary here is to create a prole for some user that is already in possession of some valid prole in the same network. From the technical point of view this attack can be realized through the registration of the new prole using the same (or similar) content as the existing one. This is feasible in most OSN platforms since each prole is associated with some unique administrative id and an email address used during the registration. Furthermore, users can hide their email address so that OSN users would not be able to distinguish between the original proles and their clones registered with other email addresses. As a consequence the

30

Chapter 3 Main threats in OSN

adversary can create confusion through impersonation of other registered users and possibly gain access to the private information communicated to that users. Moreover, with tools like iCloner [39] prole cloning can be automated. Such tools are able to collect public data of OSNs members, match them, create cloned proles and then send friendship requests on their behalf. A possible solution for OSN providers to prevent prole cloning is to deploy mechanisms that are able to detect similarities between dierent proles, in particular with regard to the personal information that is visible to the OSN users. Since cloned proles typically have later registration date than the original ones, it should be feasible for the OSN provider to distinguish them and remove from the network.
Prole Hijacking The goal of the adversary mounting a prole hijacking attack is to
obtain control over some existing prole within an OSN platform. Many OSN platforms protect user access to their own proles via passwords. Hence, from the technical point of view prole hijacking is successful if the adversary can obtain passwords of other users. This can be done by many means. First, it is a well-known fact that the majority of users choose weak passwords that can be recovered via an automated dictionary attack [64]. However, OSN providers typically deploy protection against such attacks by restricting the number of login attempts or by using techniques that require human interaction such as CAPTCHAs [118]. Nevertheless, there exist eective tools, e.g. as the one included in iCloner [39], that are able to analyze and bypass CAPTCHAs. Alternatively, the adversary may try to obtain passwords via social-engineering attacks such as phishing [73], or obtaining passwords for other online services, relying on the fact that most people use the same passwords across the majority of their accounts at dierent sites. The OSN functionality can be misused to distribute messages aiming to lure users to fake login websites [5]. Finally, we shouldn't forget that OSN providers themselves have full control over the registered proles. Therefore, if some prole appears attractive for the OSN provider to be hijacked the password access to the prole can be changed accordingly.
Prole Porting By prole porting we understand another type of impersonation where
some prole that exists within one OSN platform is cloned into another OSN platform [73, 39], as depicted in gure 3.1. From the technical point of view this attack can be realized via registration of a prole using some new email address. Prole porting is appealing since not every user has her own prole on every available OSN platform. On the other hand, there might be some users that participate in both OSN platforms and thus will not be

3.2 Attack Spectrum and Countermeasures

31

able to distinguish amongst ported proles. The signicance of prole porting (e.g. in comparison to prole cloning) is that users may be completely unaware that their proles have been ported. The impact of prole porting is that the adversary can impersonate users in dierent OSN platforms. Thwarting prole porting is not that easy. In particular, prole similarity detection tools can still be used but only if they can work across multiple OSN platforms. Since every OSN platform is administrated by a dierent provider, the deployment of such tools would require cooperation amongst the providers. This is dicult to achieve, since OSN providers are cautious about granting any form of access to their prole database to competitors.
ID Theft Under ID theft we consider the impersonation of OSN users in the real-world
[39], as depicted by the example of user A impersonating user Z in gure 3.1. An adversary
mounting the ID theft attack should be able to convince anyone about the ownership of some particular OSN prole. In this way, the adversary can possibly misuse the reputation or expertise of the real prole owner for own benet, while leaving the owner unaware of the attack. One way for a successful ID theft attack is to take control over the target prole. This requires the same eort as for the prole hijacking attack. However, this eort seems necessary only if the adversary has to actively use the prole for the ID theft attack, e.g. communicate via the OSN platform. Often it would simply suce to claim the ownership of a prole and perform the actual communication via other channels. In this case, thwarting ID theft attacks by technical means seems impossible. The only solution is to rely on other means of real-world identication such as national identity cards, driver's licenses, etc.
Proling In addition to the maintenance of own proles modern OSNs provide users with
various applications to express themselves via forums, guest books, discussions, polls, multimedia data, etc. These activities are observable by other users within the OSN platform. By proling we understand an attack against any target OSN user aiming to collect information about OSN activities or further attributes of that user, e.g [36], see also gure 3.2. This attack can be typically performed by OSN users, possibly in an automated way, since the collectable information is usually publicly accessible by all OSN users. The risk of proling attacks performed by OSN users can be diminished via ne-grained access control and anonymizing techniques. For example, users should be able to allow access to the personal parts of their prole on the individual basis and not only based on roles (e.g. friends) as realized in many current OSN platforms. However, recent studies, e.g. [89], show that even

32

Chapter 3 Main threats in OSN

if the personal information is hidden, it can still be inferred from public information and social activities of the user. An alternative solution could be to let users decide whether their activities (e.g. discussion comments) should be kept unlinkable to their proles. Although these measures may help to reduce the risk of proling performed by other OSN users, preventing potential proling performed by OSN providers [21] appears to be much more dicult.

Figure 3.1: Impersonation attacks: victim U doesn't have any OSN account, victim V has an account on OSN1 and victim Z on OSN2. The attacker A generates U 's account on OSN2, a copy of V 's account on OSN1 and OSN2, and logs on OSN2 with the credentials of Z .
Secondary Data Collection By secondary data collection we understand an attack that
aims to collect information about the owner of some OSN prole via secondary sources apart of the OSN platform as depicted in gure 3.2. A typical example of secondary data collection is to use some Internet search engine to nd information that can be linked to the
prole owner. More eective is to use some Internet service1 that aggregates all information
it can nd about some particular person. Through such an attack the adversary may obtain much more information about some user than available in the prole and misuse it against the user both in the virtual environment of the OSN platform and in the real life. Another example are recent de-anonymization attacks [121] that misused the group memberships of social network users for their unique identication. Furthermore, the existence of OSNs with public and private proles simplies the secondary data collection as many users tend to
1http://www.123people.com/

3.2 Attack Spectrum and Countermeasures

33

Figure 3.2: Main PII related threats in current OSNs.
have accounts on dierent platforms [126]. There is no meaningful protection against secondary data collection attacks since the data is typically aggregated from dierent locations. Therefore, it appears in responsibility of the user to limit information kept in the prole in order to avoid its linkability with secondary sources.
Fake Requests One of the main objectives of OSN platforms is to establish social con-
tacts. This proceeds via connection requests that can be either accepted or rejected by the users. An adversary with a OSN prole that sends fake requests to other users aims less on the social contact with these users but is more interested to expand its own network. The dissemination of fake requests can be automated. Since many OSN users tend to accept fake requests [39], the adversary can simplify access to their proles and activities and possibly
obtain additional information whose visibility is subject to the available direct or nth-grade
connections. These connections can then be misused for the automated collection and aggregation of information. The actual dissemination of fake requests cannot be prevented since establishment of new connections is an important goal of OSN applications. Therefore, it is desirable that users behave more responsibly upon accepting new connection requests.
Crawling and Harvesting The goal of crawling is to collect and aggregate publicly
available information across multiple OSN proles and applications in an automated way

34

Chapter 3 Main threats in OSN

[39, 36]; see also gure 3.2. Unlike proling this attack does not target any particular user and unlike secondary data collection it is executed within the OSN environment. The expansion of own network connections by the adversary using fake requests can be seen as a preliminary step for crawling. The adversary is simply interested in collecting as much public information within the OSN platform as possible. This information can then be misused for dierent purposes, for example for selling data to marketing agencies, etc. Also it would allow for the oine analysis of social relationships and user activities, thus paving the way for targeted attacks on OSN users. Although some OSN platforms try to protect from crawling through the deployment of CAPTCHAs, the latter can be passed over with the appropriate solving tools [39]. Another attack by which the adversary simultaneously crawls across dierent OSN platforms is called harvesting. Typically harvesting results in larger datasets with larger amount on private information about the OSN users.
Image Retrieval and Analysis Upload of images or other digital content and its dis-
cussion stimulates social interactions of OSN users. However, free accessibility to images and videos bear potential risks to the privacy of users. By image retrieval and analysis we understand an automated attack aiming to collect multimedia data (incl. images, videos, etc.) available with the OSN platform. This attack is typically followed by the subsequent analysis via automated pattern recognition tools (see e.g. [125] for a survey on face recognition) to nd links to the OSN proles of displayed users. Information distilled in this way can reveal more private information about users than they are willing to give. In particular, it may reveal information about friends or colleagues that are not necessarily part of the user's social network, or information about visited locations (location-tracking) shown on the photographs. The analysis of digital content can be further strengthened by considering secondary sources such as search over the Internet. Digital content retrieval attacks can be possibly thwarted through a more restrictive access control policies for the digital content.
Communication Tracking OSN users communicate with each other using diverse OSN
applications. By communication tracking we understand a proling attack aiming to reveal information about communications of the same user. In this way the attacker may collect more information about the user than available in the prole. This attack can be mounted in an automated way by searching for comments left by the target user in various OSN applications.

3.2 Attack Spectrum and Countermeasures

35

Fake Proles and Sybil Attacks In many OSN platforms users can easily create several
proles under possibly dierent identities and contents. Since many OSN platforms lack of proper authentication such creation of fake proles becomes easy [39]. On the technical side, the user has only to create a new email for the registration of a fake account. Fake proles pave the way for Sybil attacks [62] that may serve dierent purposes [80, 8]. For example, owners of fake proles can establish new connections without disclosing their real identities. In this way they may obtain more information about some person than by using some real account. Sybil account may also be created on behalf of the whole groups [4]. Furthermore, Sybil accounts can be misused against the functionality of the OSN platforms. This includes distribution of spam messages [9] or other illicit content such as malware [10] and phishing links [6, 29], illegal advertisement, bias of deployed reputation systems, etc. Creation of fake proles can be seen as a special form of impersonation attacks. One solution for OSN providers to recognize fake proles is to use IP traceback. Indeed, if logins to several proles come from the same IP address then it is likely that some of these proles are fake. However, an attacker may try to avoid IP traceback by using dierent proxies. Therefore, stronger identication and authentication mechanisms for admission of new users would oer a better protection.
Group Metamorphosis A popular application provided by OSN platforms is the estab-
lishment of shared interest groups. These groups are usually administrated by OSN users and provide a platform for more focused discussions, specialized contact establishment, and dissemination of information, which may be interesting for a targeted audience. By group metamorphosis we understand an attack where group administrators change the group sub-
ject to persuade own interests, e.g. political2. Other OSN users who joined the group earlier
may remain unaware of this change, which in turn may have negative impact on their reputation. A possible solution for OSN providers to thwart group metamorphosis attacks is to restrict control of administrators over the interest groups, in particular to prevent them from modifying any information that may have impact on the group as a whole.
Ballot Stung and Defamation OSN platforms serve primarily the contact establish-
ment and interaction amongst users. Hence, attacks biasing public perception and recognition of a target OSN user by others are undesirable. By ballot stung we understand an
2One incident has been reported for facebook, where a multitude of groups have been fostered under general topics and concertedly renamed to support Silvio Berlusconi, in 2009 http://www.repubblica.it/
2009/12/sezioni/politica/giustizia-21/gruppi-facebook/gruppi-facebook.html

36

Chapter 3 Main threats in OSN

attack by which the attacker wishes to increase public interest to some target OSN user. This attack may increase the amount of personal messages or connection requests received by the target user resulting in a DoS attack on the physical resources of the OSN user. The attack may place the victim into the focus of public, possibly embarrassing discussions. On the other hand, ballot stung may increase popularity of the prole belonging to the attacker. This can be achieved through recommendations submitted by the attacker using fake proles. In contrast, defamation attacks aim at decreasing public interest of a target user, in particular by tarnishing the reputation of the latter [23]. In particular, defamation may lead to blacklisting of the user in contact lists of other users and keep the user away from participation in communication applications such as shared interest groups and discussion forums. It may further have negative impact on the user's life in the real world [19]. Another form of defamation is the anti-advertising against companies [22] aiming to damage the reputation of the latter on the market.
Both ballot stung and defamation attacks have to be performed at a large scale in order to have a signicant impact. An attacker may create fake proles and use automated tools to disseminate information needed to increase or decrease interest to a specic OSN user. Another technique is to use the poll application provided by many OSN platforms and let users vote on information related to the victim.
Censorship OSN providers typically have control over the whole data available within
the network. As such they can deliberately manipulate the user-provided information and contents. In some cases this ability is necessary to prevent dissemination of illicit content. On the other hand, censorship when applied without substantial reasons may have negative impact on the OSN users. For example, in OSN platforms focusing on business contacts users often advertise their expertise. In this scenario censorship may be misused to favor some users over their competitors. Censorship may have many facets. It can be performed by active modication of user-provided contents, which might remain unnoticed by the user. Higher impact can be achieved through the target manipulation of search engines within the network. Since censorship can be performed by the OSN provider [20] without involving any other parties, there is little one can do to prevent this threat. Censorship may be applied not only by OSN providers but also by administrators of shared interest groups. They can deliberately modify or drop messages of group members. Although restricting group administrators from modication of other user contents appears to be an eective protection measure, it is unlikely to be used in practice, since this ability contradicts to the

3.2 Attack Spectrum and Countermeasures

37

responsibility of group administrators for the content disseminated within the group.
Collusion Attacks The impact of a crowd can be exhibited in OSNs through a collusion
of users. In this attack several users join their malicious activities in order to damage other OSN users or mount attacks against applications of the OSN platform. In particular, colluding users may start defamation or ballot stung campaigns, increase each over reputations, bias the outcome of public polls or inuence public discussions. Since colluding users have valid OSN proles these attacks do not require creation of fake proles. Furthermore, these attacks are more dicult to recognize than similar attacks mounted via fake proles. The reason is that IP traceback would not help even if colluding users do not deploy any additional proxies.

38

Chapter 3 Main threats in OSN

The analysis of the privacy problems in current OSN demonstrates that even if all participants were aware and competent in the use of SNS, and even if a concise set of privacy measures were deployed, the OSN would still be exposed to potential privacy violations by either the omniscient service provider or an external attacker taking control of the OSN [74, 26].
3.3 The Big Brother problem
The complete PII, directly or indirectly supplied by all participants, is collected and stored permanently at the databases of the providing company, which potentially becomes a Big Brother capable of exploiting this data in many ways that can violate the privacy of individual users or user groups.
The importance of this privacy exposure is underlined by multiple factors. First of all, according to a recent study from comScore [51], one every ve minutes spent on-line is spent in browsing social networking sites, that nowadays reach 82% of the overall on-line population. Secondly, SNS providers make prot through displayed advertisements: emarketer evaluates the worldwide social network advertisement revenue will hit 8 billion US$ in 2012 and 10 billion US$ in 2013 [25]. Finally, the market capitalization of SNS providers was able to reach up to 50 billion US$ as in the case of Facebook Inc, according to the 1.5 billion US$ funding led by Goldman Sachs Group Inc. in January 2011 [12].
In the following, privacy policy aspects of well known OSNs are briey introduced. The main characteristics of such OSNs are reported in table 3.2.
Facebook Appeared in 2004 as a service accessible by Harvard students only, Facebook
reaches now the 55% of the world global audience and accounts for one every seven minutes spent on-line [51]. Owned by Facebook Inc., its value has been always increasing and nowadays is worth 50 billion US$ (according to the investment of Goldman Sachs and Digital Sky Technologies in 2011 [12]).
When a user creates an account in Facebook, according to the terms of service [7], she provides the required information consisting on name, email address, birthday, and gender. While user's name, prole picture, networks, username and User ID are made public, all remaining user generated information can be shared with audience limitations.
Facebook is granted `a non-exclusive, transferable, sub-licensable, royalty-free, worldwide

3.3 The Big Brother problem

39

license to use any IP content' the user posted (IP License). Such a license ends when the user deletes this content, that persists at the SNS provider in backup copies `for a reasonable period of time', `unless it has been shared with others'.
User has the right to create a single personal prole and guarantees she will provide true information. When Facebook provides this information to advertising partners or customers, PII is always removed. In contrast, the user cannot exploit her own information for personal gain.
Content infringing someone else's copyright can be removed by Facebook. In this case, the censored user is provided with the opportunity to appeal.
When user's friends upload pictures showing the user, automatic face recognition suggests the user's name for the tag by default. The user can opt-out from this service in her privacy control panel accessible from her Facebook prole homepage.
Twitter Twitter is a microblogging platform allowing users to send 140 characters long
messages, also known as Tweets. Launched in July 2006, Twitter now has 100 million users and is valued at 8 billion US$ (as of October 2011) [27].
Terms of Service [28] specify tweets are public, and limits on use and storage may be applied at any time without prior notice. However, Twitter also gives its users the opportunity to limit the access on their tweets to people whom they approve.
`The Services may include advertisements, which may be targeted to the Content or information on the Services, queries made through the Services, or other information'.
By submitting, posting or displaying Content on or through the Services, the user grants Twitter a `worldwide, non-exclusive, royalty-free license (with the right to sublicense) to use, copy, reproduce, process, adapt, modify, publish, transmit, display and distribute such Content in any and all media or distribution methods'.
Twitter reserves the `right at all times (but will not have an obligation) to remove or refuse to distribute any Content on the Services and to terminate users or reclaim usernames'.
While non personal information may be shared or disclosed, in the event that Twitter is involved in a bankruptcy, merger, acquisition, reorganization or sale of assets, the user information `may be sold or transferred as part of that transaction'.
Process of account deletion starts after 30 days from the reception of the communication from the user, and may take up to a week.
LinkedIn With the mission of `connect the world's professionals to enable them to be more

40

Chapter 3 Main threats in OSN

productive and successful', LinkedIn is mainly devoted to business-related social networking. This OSN was launched in March 2003 and accounts 135 million users as of November 2011 [16] for a value of 8 billion US$ (May 2011) [18].
To create an account, according to the User Agreement [17], the user should not be a competitor of LinkedIn, nor use the service for reasons that are in competition with the OSN. User agrees in providing accurate information and update it as necessary, and has to avoid transferring her account to another party.
A LinkedIn user grants the SNP `a nonexclusive, irrevocable, worldwide, perpetual, unlimited, assignable, sublicenseable, fully paid up and royalty-free right' `to copy, prepare derivative works of, improve, distribute, publish, remove, retain, add, process, analyze, use and commercialize, in any way now known or in the future discovered, any information ' the user provides ` directly or indirectly to LinkedIn, including, but not limited to, any user generated content, ideas, concepts, techniques or data to the services' `without any further consent, notice and/or compensation' [17].
User's data can be deleted at any time, unless the user shared information or content with others and they have not deleted it, or it was copied or stored by other users. Moreover, user information can be provided in response to customer service inquiries, to send service or promotional communications through email and notices on the LinkedIn website, or to create social ads for the user's network on LinkedIn using the user's prole photo and name.
Google+ Launched in July 2011, Google+ reached 25 million unique visitors in just less
than a month, faster than any other OSN in history [51]. With 90 million users as of December 2011 [13], this OSN is the last essay of its owner Google Inc. whose market value as of the beginning of February 2012 is 155.47 B according to Yahoo [31], to become a competitor in the OSN market.
Google+ users agree on the new privacy policy eective since the 1st of March 2012 [15]. This policy explicits Google `may combine personal information from one service with information, including personal information, from other Google services'. The user is asked to quickly update wrong personal information or delete it. Deletion can be propagated to active servers with some latency and may not be applied to data stored in backup systems. User personal information may be shared with trusted companies, organizations or individuals outside Google whose role is to process the information for Google itself. Additionally, aggregated non-personally identiable information may be shared publicly or with partners like publishers, advertisers or connected sites.

3.4 Summary

41

OSNs
Facebook Twitter LinkedIn
Google Plus

SNP

Characteristics

Unique visitors (million)

Market value (billion US$)

Facebook Inc. Twitter Inc. LinkedIn Corporation Google Inc.

845 (dec 2011) 100 (Oct 2011) 135 (Nov 2011)
90 (Dec 2011)

50 (Jan 2011) 8 (Oct 2011) 8 (May 2011)
155 (Feb 2012)

Table 3.2: Current OSN and their characteristics.

The privacy policy specic to Google+ [14] tells the users `need to have a public Google Prole visible to the world, which at a minimum includes the name chosen for the prole. That name will be used across Google services and in some cases it may replace another name used when sharing content under the Google Account'. Google Prole identity may be shown to people who have the user's email address or other identifying information.
Users may dene groups or circles of people to share information with. According to the default settings, people in circles except the name of the circle will appear to others.
When uploading photos or videos in Google+ the user aiming at hiding the metadata information associated to such a content needs to remove it before the upload. Automatic face recognition is provided as an opt-in functionality and makes easier for the user to tag her contacts in the picture, that remains however a non automated action since the user needs to validate each tag.

3.4 Summary
In this chapter we dened security requirements for OSNs and investigated their main security and privacy issues. We showed they derive, on one hand, from the user's lack of awareness on the consequences of simple actions such as accepting a friend request, and, on the other hand, from the usability of the privacy controls oered by SNS.
However, even if the OSN provided a satisfying set of privacy tools to privacy aware and competent users, the directly or indirectly high valuable shared user's data could still be exploited by the omniscient service provider, as often stated in the subscribed terms of service.

42

Chapter 3 Main threats in OSN

Even considering the commercial bodies that act as social network service providers to be trusted, hackers may be able to compromise their systems to gain access, unsatised employees may abuse their access to the data, or even imprudent publication of seemingly anonymized data may lead to the disclosure of PII.
Researchers realized the importance of this privacy exposure and proposed a set of countermeasures addressing the basis of the problem: the centralized storage of users' data. Their solutions are examined in the next chapter.

Chapter 4
Decentralized OSN
In this chapter we give an overview of the solutions that researchers presented to contrast the Big Brother problem together with their limitations. Characterized by a decentralized approach through client-server, cloud or peer-to-peer architectures, these solutions propose to store all users' data in a distributed fashion.
The Big Brother problem intrinsically aects all the centralized OSNs. In the last years, several solutions [94] have been proposed with the goal of preventing the presence of
any omniscient entity. These solutions, known as Decentralized Online Social Networks
(DOSNs) [65] aim at distributing the user generated contents: in all of them the users' data is made available from multiple locations. Access restriction on such sensitive data is often provided with the adoption of encryption techniques or access control lists.
Current DOSNs can be divided into two main groups:
‚Ä¢ Client-Server based decentralized OSNs; ‚Ä¢ P2P based OSNs.
While in Client-Server based DOSNs every user controls one or more (at least logically) centralized computing and storage services running in a real or virtual infrastructure, in
43

44

Chapter 4 Decentralized OSN

P2P-based DOSNs every user node joins a well known or dedicated P2P network where computing and storage resources are shared among members.
These two categories are discussed further in this chapter.
4.1 Client-Server based Decentralized OSNs
Distributed dedicated server approaches require acquisition or deployment of web space hosting users' sensitive data whose access is restricted to authorized users only. At the benet of guaranteeing full data availability, they often require the OSN user to pay for the storage service, or for the maintenance of proprietary infrastructure. When third party storage service is provided for free, these solutions often lack incentive mechanisms guaranteeing the service reliability.
Yeung et al. [124] propose a framework allowing users to choose one or more trusted
servers to host several resources, each of them identied by a URI, such as their activity log,
their photo album, and, most importantly, their Friend-Of-A-Friend (FOAF)1 information, that can be edited through open protocols such as WebDAV2. In this framework, users
obtain an identity in the form of a URI (a Web ID) pointing to a reference in the user's FOAF le stored on a trusted server, that, in turns, points to their contacts' Web ID. Policy languages such as AIR [75] allow publishers to restrict access to their data, and protocols
such as OpenID [99]3 allow requesters to authenticate and access it. Similarly, in Diaspora 4 several servers called pods host users'accounts, or seeds . Pods can
be run by users or institutions and together form the social network service infrastructure. Newcomers unable to setup their own pod nor to nd place in another user or institution pod
may host their prole in one of the open pods5. Every user generated content is encrypted
with a random key in turn distributed to every authorized user.
In Vis-'a-Vis [107] users store their sensitive data on a paid virtualized cloud-computing
infrastructure, such as the Amazon Elastic Compute Cloud (EC2). The infrastructure is assumed to support a Trusted Platform Module (TPM) proving the customer what software is executing under their account. Vis-'a-Vis is designed to interoperate with existing OSNs
1http://xmlns.com/foaf/spec/ 2http://www.webdav.org 3http://openid.net/specs/openid-authentication-1_1.html 4http://www.joindiaspora.com 5http://podupti.me/

4.2 P2P-based Decentralized OSNs

45

rather than replace them. Existing OSNs are treated as untrusted services storing opaque pointers to the user's data in the cloud while compute utility has access to cleartext data.
In Persona [35] each user is identied using a single public key and stores his encrypted
data with a trusted storage service. Public keys and storage service location are exchanged out of band at the act of friendship establishment. Users interact and publish references to their data through Persona applications, providing a set of APIs over which social network facilities like wall posting or prole publishing operate. Access to user data is controlled through Attribute Based Encryption (ABE), and traditional public key cryptography. The attributes a user has determines what data they can access: private user data is always encrypted with a symmetric key, that is in turn encrypted with an ABE key corresponding to the group that is allowed to read this data.
Lockr [114] decouples OSN social information such as the user's published data from
functionality such as the social network facilities. Users do not further need to reveal a full copy of their social network to every OSN they use, and may decide which OSN provider or storage service can store their sensitive data, and which third party can access it. Users may also decide to store their data themselves. In Lockr, identities are represented by a public/private keypair, while address books by a list of public keys associated to the user's contacts. Access control policy on the user published data is provided through social attestations: digitally signed metadata encapsulating a social relationship. Social attestation proof of ownership is performed with WHPOK [67], a variant of zero-knowledge protocols, so that the digitally signed attestation is never revealed. Dierently from previous solutions, Lockr can also rely on P2P systems such as BitTorrent to verify the attestations and deliver content. In this approach, signed torrent les specify the relationship that downloading peer must have with the torrent's owner.
4.2 P2P-based Decentralized OSNs
In P2P-based approaches OSN members also participate in the setup of a P2P overlay and share data storage and computing facilities. Due to the on-line behavior of peers, these approaches inherently relax the data availability requirements and provide best-eort services. At the benet of no server acquisition or maintenance costs, these approaches often leverage on existing P2P overlay architectures originally conceived for the purpose of le sharing.

46

Chapter 4 Decentralized OSN

On the other hand, prole sharing asks for dierent requirements. In the context of le sharing, few large data objects have to be reliably distributed among requesting peers that in turn distribute the same object again. Noticeably, when appropriate incentive mechanisms enhance the collaboration of peers, the popularity of the content determines its availability. In the absence of such mechanisms, on the contrary, peers often engage in free riding [32, 108, 82] due to their inherent selshness: they immediately disconnect from the network and not even popular content can be made highly available. Additionally, access to le objects in le sharing P2P networks is rarely restricted, and delays in the data transfer are often tolerated. On the contrary, prole sharing asks for restricted and fast access to a very high number of protected published contents. Finally, by relying on existing architectures, current P2P-based approaches suer not only for this le-sharing eect, but also from the security leaks inherent to the adopted P2P architecture.
Peerson [42] achieves decentralization thanks to an external DHT system such as OpenDHT [102], a centrally managed deployment of the Bamboo DHT on PlanetLab6.
The security is assured thanks to the encryption of stored objects, and communications between users are directly peer-to-peer when both are online, while the implementation supports asynchronous messaging when this is not the case. In Peerson, a lookup in the DHT provides the meta-data information of the resource a requesting peer is looking for. Such a metadata can contain the ip address of a target peer to be contacted, or user's notications. Once a target peer's ip is obtained, peers connect directly, then disconnect immediately except when doing instant messaging. Resistance against impersonation attacks is guaranteed by associating each user to a Global Unique Id. Such a GUID is obtained as the result of an hash function applied to a mail address, under the assumption that everyone today has an email address that is unique. Peerson does not assume any kind of trust relationship between peers, but provides access control by encryption and key management.
Lifesocial.KOM 7 [68] is an extendible plugin-based P2P OSN providing totally dis-
tributed P2P-based OSN. Initially conceived as a pure P2P solution, it has been extended to allow users for acquiring storage space at a dedicated server [95]. Reliable storage is delegated to FreePastry [104], a p2p overlay based on PAST [63]. Data objects can either
6http://www.planet-lab.org 7http://ki3.de/lifesocial/

4.2 P2P-based Decentralized OSNs

47

contain nal data or link other objects to be retrieved. Protected data objects are encrypted with symmetric cryptographic keys which are further encrypted with the allowed recipient public key and appended to the object itself.
Prometheus [77] is a P2P service managing social information from multiple sources.
It allows users to select the peers storing sensitive information based on social trust. Built-in public-key cryptography primitives ensure data access control. Prometheus users allow this OSN to collect their social information from social sensors, i.e. applications that report to Prometheus the user's interactions with other users via e-mail, phone, instant messaging et similia. Information collected by these sensors is collected by Prometheus and used to create a social graph where the edges, i.e. the trust relationships, are weighted by the strength of the trust. Both the information of the social graph and that one coming from sensors are stored in an encrypted form and accessible from user's trusted peers. Users' social graph is stored on her trusted peers. Similarly to Lifesocial.KOM Prometheus runs on top of Pastry [104] and uses Past [63] for replicated storage of sensor data. Each user has a group of trusted peers storing replicas of her social subgraph for the purpose of increasing its availability. Prometheus uses Scribe [46], an application-level DHT multicast infrastructure, to manage the communication with the trusted peer group. In Prometheus, every user holds a publicprivate keypair. At the time of registration, newcomer peer connecting from a trusted device is assigned to a unique UID, and species an initial set of trusted peers contributing to the storage of the newcomer's data. While service requests can be sent to any peer, only the trusted peers of a user can provide data about that user.
Finally, Likir relies on the Kademlia [86] DHT to allow for data storage decentralization.
In Likir, the user's peer node is furnished with an identier in the form of an OpenId [99] by a certication service, and communications are encrypted and authenticated by both communicating parties. Together with the presence of a reputation system (RS), the adoption of OpenId mitigates the impact of Sybil attacks and pollution in the retrieved data. Many RS can be adopted in Likir, under the assumption that they exibit a simple API allowing any application to evaluate other user's behavior to single out the misbehaving peers. In this case, when a resource is inserted with a lookup key unrelated to its content, the resource can be marked as invalid and its publisher as a polluter.
Table 4.1 reports the aforementioned solutions for DOSNs with their main characteristics.

48

Chapter 4 Decentralized OSN

DOSNs
FOAF Diaspora Vis-√†-Vis Persona Lockr Peerson Lifesocial.KOM Prometheus Likir

Storage place

Characteristics

Incentives for SNS

Access control on published data

trusted web server
trusted web server
cloud computing infrastructure
trusted web server
trusted web server
OpenDHT

absent
absent
commercial contracts
commercial contracts
commercial contracts absent

Pastry

absent

Pastry / trusted peers
Kademlia

absent / social trust
reputation system

by means of data encryption
by means of data encryption
by means of requester authorization
by means of data encryption
by means of requester authorization
by means of data encryption
by means of data encryption
by means of data encryption
by means of data encryption

Table 4.1: Current DOSN proposals as an answer to the Big Brother problem in centralized OSNs

4.3 Main Limitations

The access restriction on the user's published data by means of encryption or access control lists together with the migration from a full centralized architecture to a decentralized one constitute two signicant steps toward the protection on the user's security and privacy in OSNs. Nevertheless, this thesis claims that these steps are not sucient. As a matter of fact, current DOSNs still allow the data storage service to link a requester's (often anonymous) identier to the target user's prole she is looking for, and derive as a consequence trust relationships between users. A series of works pointed out that the information on the sole social network topology in addition to the data that most users publish in current OSNs is

4.4 Summary

49

sucient to de-anonymize the input topology [92, 121, 34] and retrieve information on the social network. Therefore, current DOSNs just propose their users to choose another Big Brother with a more limited view of the overall network.
Literature on P2P networks already addressed the problem of anonymous communication [103, 49], and proposed solutions that are suitable for le sharing, but reveal to be inadequate in the context of DOSNs. As an example, the well known Onion Routing technique [101], where a sender node recursively encrypts secret content with the public key of the nodes composing the path this content must follow, when adopted in a Friend-to-Friend (F2F) network, where peers cooperate thanks to their friendship, would require the sender to know the social network graph topology, i.e. the information the DOSN itself aims to protect. On the other hand, when the P2P network is not a F2F one, appropriate incentive mechanisms for cooperation among peers are required.
In this thesis we propose a radically new P2P architecture for secure, privacy preserving, distributed OSN to properly target the user's security and privacy in OSN. Such a solution addresses privacy by design, avoids the Big Brother problem and guarantees cooperation between peers.
The main characteristics of this new solution are described in the following chapters.
4.4 Summary
In this chapter, we gave an overview of Distributed Online Social Networks (DOSN). We classied such DOSN approaches in two categories: client-server (or cloud), and peer-to-peer.
Client-server (or cloud) approaches require acquisition or deployment of web space hosting users' sensitive data and do not always evade the potential control of a single party, as e.g. a company or an organization, on such data. At the benet of guaranteeing full data availability, they often require the OSN user to pay for the storage service, or for the maintenance of proprietary infrastructure.
On the other hand, current peer-to-peer approaches inherently relax the data availability requirements and provide best-eort services. Whereas such approaches do not suer from single party control, they expose users to potential communication tracing by malicious peers. In the context of OSN, such communication traces may disclose details on the structure of the social network graph.

50

Chapter 4 Decentralized OSN

We therefore concluded that none of current approaches is suitable to achieve the goal of preserving user's privacy in OSNs

Part II
A privacy preserving distributed OSN leveraging real life trust
51

52

Chapter 5
Safebook
This chapter introduces the design of a newly distributed OSN addressing the security objectives presented in chapter 3. The new mechanism, called Safebook [56, 55], leverages peer-to-peer concepts and capitalizes on the trusted links from the managed social network, thus transferring the trust between the OSN users to the collaborating parties of the system. Decentralization circumvents the need for a central provider and leads to a distribution of data, communication, and control. While the alternative approach of privacy protection based on encryption is considered as a partial solution only, decentralization eliminates the privacy threats resulting from a centralized SNS entirely. However, P2P systems being devoid of any central point of control inherently suer from a lack of trust between the parties. This problem is addressed through leveraging the trust relationships that are available as part of the SN itself. Trust relationships akin to SN, such as `friendship' or `acquaintance' are thus exploited to build trusted links among the nodes of the P2P SNS system.
This chapter begins with the rationale behind Safebook, followed by a description of its main components and functionalities. At the end, the core protocols of Safebook are described in detail following the main steps a newcomer has to take to join the OSN and benet from its services.
53

54
5.1 Rationale

Chapter 5 Safebook

As mentioned in chapter 3, current Online Social Networks severely suer from a large number of security and privacy threats that may lead to irreversible loss of sensitive data, and consequently, to loss of money and reputation. These threats are mainly due to two concurrent factors: users lack awareness regarding the consequences of simple and sometimes presumably private actions, like accepting contact requests, tagging pictures, commenting on proles or leaving wall posts, and SNS providers do not develop, oer or advertise appropriate security and privacy tools.
While the rst factor is probably a consequence of the user's implicit trust in other proles and on the OSN provider itself, the second one is probably due to the OSN business model, where OSN value increases together with the number of its members and the volume of the shared data [40].
One might ask: is it more convenient to propose yet another OSN, or to design and implement a set of security and privacy tools for existing ones?
In current OSNs, the main threat is the lack of protection for the user's data from the SNS provider itself. As a matter of fact, the data directly or indirectly supplied by all participants is collected and stored permanently at the databases of the service provider. This makes it an omniscient entity, that may act as a Big Brother monitoring and tracing users.
Uploading encrypted data to current OSNs may appear as a good solution to prevent the Big Brother problem. Unfortunately, even assuming that users store their data in an encrypted form at the OSN servers, still the monitoring of prole data lookups may reveal to the SNS provider insightful information on the social network graph itself, such as the OSN members' contact list.
Therefore a new architecture for OSNs is needed to address the current security and privacy threats, and this architecture should not propose any central entity storing all users' data.

5.1 Rationale

55

5.1.1 Design principles
As discussed in chapter 4, in order to meet the main privacy objective, distributed data storage for OSNs may be achieved either through a client-server (or cloud) approach, where users do not participate in the storage service and the stored data is always available, or through a peer-to-peer approach, where users participate in the storage service and the stored data may not be always available.
The P2P approach inherently lends itself to the design of an architecture with the main objective of evading control by a single party such as an organization or a company. Hence we decided to opt with the P2P approach taking into account additional advantages thereof such as scalability and fault tolerance.
As a rst design principle, we envision a P2P system and we rely on peer nodes to perform basic OSN operations such as:
‚Ä¢ storage of user's data;
‚Ä¢ lookup of user's data;
‚Ä¢ communication among users.
Nevertheless, P2P system severely suer for a major problem, that is the lack of cooperation among peer nodes. The absence of a-priori trust characterizing any P2P system
increases the intrinsic selshness of nodes, that often engage in free riding [32, 108, 82] and
try to consume as more resources as possible without contributing to the network services. Cooperation enforcement hence poses as a mandatory requirement to eectively setup a distributed P2P OSN.
Cooperation enforcement mechanisms encourage nodes to perform a fair share of both networking and storage operations. Inducing cooperation between nodes can be based either on some reputation or on rewarding mechanisms: reputation mechanisms [41, 88, 105, 61] ensure that each node accepts to cooperate with its neighbors based on their past behavior; credit based schemes [43, 127, 117, 37] provide node collaboration by rewarding cooperating nodes with a certain amount of credits in the form of E-cash [47, 48] or a tradable good/service, that they further can use for their own benet.
However, due to the specic context of P2P OSN where peer nodes are maintained by OSN members, we decided to ll the lack of cooperation among peer nodes with the real life trust between OSN members derived from the OSN itself. Therefore, as a second design

56

Chapter 5 Safebook

principle, we connect peer nodes in such a way that if one peer serves another, the user maintaining the serving peer and that one maintaining the served one are real-life friends.
5.1.2 Idea of the solution
Based on these design principles, we propose a new privacy-preserving distributed OSN and
call it Safebook . In the following, we discuss how we came up with the core design of the
Safebook solution. As a straightforward implementation of the two design principles, a simple P2P system
whereby each user's data is stored and made available by peer nodes operated by users who
are friend of that user (friend nodes ) seems to be a reasonable rst step toward the main
security objective of privacy against a centralized omniscient party. Therefore, we dene a ring structure where each user is at the center of a ring, and her friend nodes hosting the user's data constitute the rst ring.
Nevertheless, such a simple scheme would suer from a further privacy problem that is due to the scheme itself. Since all the social network services pertaining to a user will be provided by this user's friend nodes, tracing of communications by very simple means would disclose the friendship relationships in the social network. The adoption of anonymous communication techniques seems then an obvious second step toward the security objective of protection of social trust links against OSN members. However, such anonymous communication technique should be in line with the design principles previously mentioned. Therefore, we protect the rst ring with a second one consisting of nodes that each are a trusted contact of a node on the rst ring. Further rings are built through similar trust relationships, without requiring nodes on the same ring to have trust relationships with one another, and without requiring transitivity of trust. Data requests are then addressed to the nodes in the outermost ring, and are forwarded to the nodes in the rst one along hop-by-hop trusted links. Data is served by nodes in the innermost ring and replies are sent back along the same paths. Safebook thus consists of the collection of concentric layers of peers nodes organized around each user in order to assure data storage and communication privacy.
Security and privacy of the system might be compromised if malicious users were able to impersonate legitimate ones. In addition to the attacks discussed in chapter 3, malicious users would then be able to intrude into the rings surrounding a target victim and derive the

5.1 Rationale

57

friendship relationship we aim to protect. As a consequence, a third step toward ensuring user authentication has been taken. In Safebook, a Trusted Identication Service (TIS) that does not take part in the OSN provides users with unambiguous certied identiers associated to their real identities. Such TIS does not contrast with the purpose of decentralization, as it can be implemented in a decentralized fashion. TIS is not involved in any communication or data management operation among users, is contacted only once, and can be provided o-line. Finally, classical encryption techniques have been adopted to ensure data condentiality and data integrity.
In summary, Safebook has been designed as an OSN addressing privacy from the very beginning. Privacy against centralized omniscient entities is achieved with the adoption of a decentralized P2P approach. Privacy against malicious users is achieved with communication obfuscation through anonymous routing techniques, data condentiality through the use of encryption, and prole integrity through certied identiers. For these reasons, Safebook achieves privacy by design.
Availability of basic services such as data storage, data lookup and communication is guaranteed by the cooperation among peer nodes. Such cooperation is enforced by real-life trust among OSN members.
Nevertheless, in the specic context of OSN, we realize that the real life trust between users can serve much more than simple cooperation: it can be used to build the online social network itself (see gure 5.1). Therefore, the OSN helps user to establish
friend relationships, and friend nodes provide the basic services of data storage, retrieval and communication, and consequently build the OSN.

Figure 5.1: Cyclic relation showing how real life trust between users can build the OSN itself.

58

Chapter 5 Safebook

The characteristics of Safebook are described in detail in the following sections.

5.2 Main components

59

5.2 Main components
The real life trust between OSN users as in the SN graph is mapped into ring structures
called Matryoshkas , where node neighborhood is based on user friendship. Direct trust
relationships are leveraged for the purpose of data storage and data availability. Since friend nodes are considered honest but curious, data is stored in an encrypted form.
In Safebook, a target prole data can be accessed through hop-by-hop trusted paths
whose endpoints can be retrieved from an additional Peer-to-Peer system maintained by
the OSN users themselves. Dierently from the Matryoshkas, this P2P system is used for indexing purpose only: it does not store user's prole data and does not take into account user's friendship relations.
Safebook can thus be seen as an overlay network composed by two dierent layers:
‚Ä¢ the Social Network Layer consisting of Matryoshkas and providing each member with
a set of functions corresponding to social interactions in the real life, such as prole data retrieval, message exchange et similia;
‚Ä¢ the Peer-to-Peer layer oering the infrastructure to build and to access the Ma-
tryoshkas.
A Safebook user is represented as a host on the Internet, a peer node in the P2P layer and a user in the SN layer (see gure 5.2, left). Dierent identiers are used to address the same
party in each layer: a user Id denotes a node in the SN layer, a node Id in the P2P layer,
nally an IP address in the Internet layer. In addition to Matryoshkas and the P2P system, the last component of Safebook is an o-
line Trusted Identication Service (TIS) (see gure 5.2, center) in charge of generating
the identiers needed to address users in the SN layer and peer nodes in the P2P layer. Since these identiers are issued together with corresponding certicates, they can never be manipulated nor forged.
5.2.1 Matryoshka
A Matryoshka is a friend-of-friend structure providing the user with data storage and communication obfuscation services.
A user V 's Matryoshka ŒòV consists of a group of nodes surrounding V 's node (see gure
5.2, right). The nodes of a Matryoshka are organized into several concentric rings, namely

Chapter 5 Safebook

Figure 5.2: Safebook overlays (left), main components (center) and Matryoshka (right).

60

5.2 Main components

61

shells , and several paths lead from the nodes in the innermost shell ŒõV to the nodes in the outermost shell ‚Ñ¶V . With Œ∏Vj ‚àà ŒòV being a node in the jth shell, with j ‚àà [0, . . . , M axShell],
each Matryoshka further features the following properties:

1. V 's node Œ∏V0 is located at the center of the Matryoshka and is called the core ;

2. if a pair of nodes Œ∏Vj , Œ∏Vj+1
in the social network layer;

is connected, a friendship relation between them exists

3. each node Œ∏V1 , located on the innermost shell ŒõV and called a mirror , is a trusted contact of the core V and stores V 's data in an encrypted form;

4. each node Œ∏VM axShell, located on the outermost shell ‚Ñ¶V and called an entrypoint , acts as a gateway for all the requests destined to V ;

5. each node Œ∏Vj , j ‚àà [2, M axShell ‚àí 1], located on a shell between ŒõV and ‚Ñ¶V , is called a prism of V ;

6. the set of prisms is denoted as ‚àÜV .
In summary V 's Matryoshka ŒòV is the union of the set of mirrors ŒõV , the set of prisms ‚àÜV , the set of entrypoints ‚Ñ¶V and the core V . The number of V 's mirrors represents the number of available partitions of V 's prole data, while there are as many entrypoints as paths that can lead to a mirror. Each ith mirror Œªi ‚àà ŒõV represents the root of a subtree with leaves that are lying in the outermost shell ‚Ñ¶V . The branching of all the subtrees, the span factor , is set by V . The cardinality ¬∑ of the set ‚Ñ¶V in consequence is ‚Ñ¶V = ŒõV SpanM axShell‚àí1.

5.2.2 Peer-to-peer substrate

The P2P substrate of Safebook is a DHT similar to KAD [86, 110] in charge of storing and retrieving the entrypoint references of all the users' Matryoshkas. Such a substrate comprises of all user nodes and allows any node to issue a lookup query to reach the Matryoshka of any user.
The DHT is dened as:

DHT = K, N, R, idn (¬∑) , idr (¬∑) , œÅ (¬∑)

where K is the DHT keyspace, N and R correspond to the set of nodes and the set of resources, respectively, and idn : N ‚Üí K, idr : R ‚Üí K denote the functions associating

62

Chapter 5 Safebook

a node and a resource to their identier respectively. Finally, œÅ : K ‚Üí {N } denotes the
mapping function which outputs the set of peers responsible for a resource given the resource identier.
A resource consist on a list of entrypoint references of a target user's Matryoshka. The
corresponding resource identier DhtK ey is represented by a user identier or by an hash
of the user's attributes such as her full name, her birthday etc.
Redundant copies of (key value) pairs (DhtK ey, resource) can be stored by nodes whose identier matches DhtK ey on a predened amount of rst bits.
Much alike KAD, Safebook implements a greedy routing, minimizing the distance mea-
sured in an XOR-metric between the DhtK ey to locate and the node Id of neighboring nodes.
Due to the privacy-by-design constraint, unlike KAD, the lookup queries are not always processed iteratively: Safebook uses recursive processing with hop-by-hop anonymization as a basic technique to assure the untraceability of requesting parties in case a list of entrypoint reference is queried.
5.2.3 Trusted Identication Service
The TIS is a trusted third party that generates and grants for each Safebook user V a pair of identiers: a node Id (N I dV ), unambiguously identifying V as a peer in the P2P layer, and a user Id (U I dV ) unambiguously identifying V as a user in the social network layer. Both identiers are computed starting from a set of V 's properties such as V 's full name,
birthday, birthplace etc.
A pair of certicates link each identier to a respective public key provided by V . Corresponding private keys are known by V and nobody else.
Since the P2P system allows to retrieve a node IP address given a node Id, the separation of node- and user- identiers is required to prevent malicious users from deriving a victim's IP address. Only trusted contacts of a node are able to link these two identiers, as they serve as mirrors and in consequence know both. TIS constitutes an exception, as it is the only party in Safebook that is able to link the user Id and node Id of users other than their own trusted acquaintances. If compromised, in addition to the users' location, TIS may also disclose users' participation in Safebook. However, the TIS does not possess any user's private keys, therefore it cannot impersonate any victim, nor retrieve her set of trusted contacts or access data content published with restrictions.
While the TIS is a centralized infrastructure and in consequence might appear to break

5.2 Main components

63

the paradigm of a decentralized architecture of Safebook, it can easily be implemented in a distributed fashion. Furthermore, it is an o-line service used only once by each Safebook user and, unlike a central SNS server, it does not threaten the privacy of users, as it is not involved in any communication or data management operation among users or peer nodes.
A collusion of the TIS with the Internet Service Provider would circumvent the concept of separation of identiers. However, this attack is only successful if the ISP controls the access to all users of Safebook, as only the privacy of users using the directly monitored Internet connections can be disclosed. Entirely protecting the privacy against a malicious ISP is only possible when leveraging much more complex concepts of anonymization, which for the sake of eciency is refrained of. Safebook indeed does not provide anonymous communications on the network level.
In the following section we present the main functionalities of Safebook, which allow the users to share their sensitive data with limitations and communicate between them.

64

Chapter 5 Safebook

5.3 Functionalities
The main functionalities of Safebook may be divided into three main categories:
‚Ä¢ data management;
‚Ä¢ key management;
‚Ä¢ communication management.
Each functionality is detailed in the following of this chapter.
5.3.1 Data Management
Data management functionalities allow users to generate, modify and delete sensitive information in the OSN.
In Safebook, data objects, also referred as data items , are user-generated pieces of
information describing the user's prole as detailed in chapter 2.3.
A data item D is represented as a tuple < DId, type, value, version >, where type
describes the nature of the data, such as personal contact details, connectivity, interests etc.
(see gure 2.3), value constitutes its content, and version its current version. A data item identier DI dD unambiguously identies D among all the data objets, and allows for the
basic operations of item storage, retrieval or deletion.
A Distributed Data Storage Space (DDSS) SV is dened for each user based on her
friendship relations. Authorization to store content on such a space comes from the real life
friendship relations of V , and therefore is granted to V only. The size of SV is dynamic: at friendship establishment, each friend Fi of V reserves an
arbitrary amount of her own Local Data Storage Space (LDSS) LFVi for V . The sum of each friend's LDSS allocated for V nally builds V 's DDSS.
Due to the distributed nature of DDSS, data is partitioned into n blocks and for a given amount of redundancy these blocks are coded in n + l fragments such that any n fragments
are sucient to reconstruct the original object.
Before being partitioned, encryption operations may be performed on D to guarantee its
condentiality and limit the access on it.

5.3 Functionalities

65

5.3.2 Key Management
As stated previously, user's data may be encrypted based on the willingness of the owner. Key management functionalities allow users to limit access on their shared sensitive data.
Safebook ensures data condentiality thanks to traditional public-key and symmetric cryptography. Access to the content can be restricted to several user-dened (overlapping) groups of contacts.
In order to minimize the storage overhead at the DDSS, data is encrypted with only one
key, namely the Data Encryption Key (DEK). This DEK needs to be distributed among
all users that are authorized to decrypt the data. The distribution of a DEK requires the
encryption of it with a Key Encryption Key (KEK) which is previously distributed among
members during friendship establishment. Users do not rely on any third party to perform key distribution; they send the keying material to all the group members they manage.
Friends of V access SV within the limits of the Access Control Policy (ACP) dened by V .
Basically, users in Safebook create groups of contacts by dening several attributes, such as `Family', `Colleagues' etc. and associate them to each contact. Data protected under these attributes will then be accessible to all the contacts associated to the appropriate attributes only.
In Safebook, attributes are dened through Badges . Users in Safebook know which
badges they provided to which contact, but cannot know how many badges they received
from a given contact, nor the description of the associated attribute. For instance, V may grant U a `Professional' badge without disclosing the attribute `Professional' to U , and without revealing who among V 's contacts holds this badge too. This happens since, from a system perspective, a badge b corresponds to a set of DEKs used to encrypt the data
accessible to all the contacts provided with that badge. Such a set is dened as:
Dbn = hi (sb) : i ‚àà {1 . . . n} 1
where hi (sb) denotes a well known one-way hash function h () sequentially applied i times to an initial seed sb. The idea of sequential password hashing was originally proposed in [79]
and afterward leveraged to design one-time password authentication systems such as S/Key [72]. Safebook does not perform authentication of requesting users and uses each hash as a
1In this notation, the colon (`:') means `such that'.

66

Chapter 5 Safebook

DEK rather than a one-time password.

When V grants U a badge b, U receives a DEK hi (sb) that does not reveal anything

about the badge attribute nor the list of V 's friends who received that badge too. After the reception of hi (sb), U is able to derive all the keys hj (sb) : j ‚àà {i . . . n} and access all the data stored in SV encrypted with such DEKs.

‚äÜ Dbn

Safebook does not ensure backward secrecy : in a Social Network context, in fact, users

are likely to allow a new group member to access the data previously shared for that group.
When V revokes b from U , V advertises hi‚àí1 (sb) to all the contacts previously granted with b, one by one, except U . Future data previously accessible by contacts granted with b will be encrypted by V with the DEK hi‚àí1 (sb). Previously published data encrypted with hj (sb) (being j ‚àà {i, . . . , n}) will not be encrypted again and will thus still be accessible by U.

Since reversing the hash function h () is computationally infeasible, Safebook ensures forward secrecy as future communication will not be accessible by the leaving member U .
Generally speaking, V denes her ACP by specifying a set of badge rules r ‚àà RV and assigning a seed sr to each rule.
When a contact U is granted with a set of badges BVU from V , a DEK set

EU := hi srjU : rjU ‚àà RVU ‚àÄj ‚àà {1, . . . , RV } , i ‚àà {1, . . . , n}
corresponding to the rules RVU satised by U is sent to him.
Table 5.1 shows an example of ACP.
When revoking a badge b from U , V advertises a new set of DEKs EX to every contact X satisfying one or more rules U was also satisfying before b was revoked from him. From this point on, V encrypts her data with the new DEKs.
Figure 5.3 shows a communication scenario between users in Safebook.

5.3.3 Communication Management
Communication management functionalities allow users to establish unobservable friendship links and to communicate with each other while ensuring condentiality and message integrity.
Communication between two users V and U can take place either in a synchronous or
asynchronous fashion.

5.3 Functionalities

67

Figure 5.3: An example of communication between users with dierent ACPs.

Rule r BP rof BF amily BT eam BP rof ‚à® BF amily

Seed sr sr1 sr2 sr3 sr4

Current exponent i
n-3 n-2 n-1 n-3

Table 5.1: An example of ACP based on set operations between contacts granted with user-dened badges.

In the rst case, both parties exchange messages in real time. Each user stores such messages
in her own DDSS and shares it with trusted contacts if needed.
In the second case, V generates a message for U and stores it in her DDSS SV . Once U looks up for new available V 's data, she retrieves the message. To reply, U follows the same steps: she stores the reply in her own SU , then V retrieves this reply while querying for V 's new

68

Chapter 5 Safebook

data. Message integrity is guaranteed by the use of digital signature, while communication
condentiality is achieved by encrypting messages with a symmetric DEK computed (in case of synchronous communication) or previously shared (in case of asynchronous one) between the sender and receiver.
Communication is obfuscated through multi-hop routing of messages along friend-offriends chains in such a way that information on data requester cannot be retrieved. In case
of synchronous communication, this hides the IP address of communicating parties2 and
therefore their location. In case of asynchronous communication, this also prevents a user
V 's friend Fi storing V 's data from deriving the trust relationships between V and the data requester U .

2However, synchronous communication between trusted parties may be directly established.

5.4 Core protocols

69

5.4 Core protocols

Core functions of Safebook implement three main groups of operations:
‚Ä¢ prole creation , where the user's identity is created and granted with the certicates
issued by the TIS;
‚Ä¢ SNS setup and maintenance , where user's node takes part in the distributed SNS
architecture of Safebook;
‚Ä¢ SN communication and relations management , where user benets from the
SNS.

Each operation calls for the execution of a series of secure protocols aiming at obtaining

credentials, building and keeping the consistency of the Safebook overlays and establishing

secure communication channels. Throughout the description of these protocols, {M }SKX denotes a message M being signed by user X 's private key KX‚àí, and EKY {M } denotes the
message M being encrypted with the user Y 's public key KY+3. The distinct identiers of
Safebook users are associated with keypairs: while NX = NX‚àí, NX+ denotes the keypair for
the node ID, UX = UX‚àí, UX+ denotes the keypair for the user ID of node X 4.

To assure integrity and condentiality, all messages at each hop are signed with the

sender's (X ) node ID private key and encrypted with the receiver's (Y ) node ID public key.

For the sake of clarity, the resulting term ENY
in the remainder of this thesis.

{M }SNX

is simplied and is denoted as M

5.4.1 Prole Creation
The identity creation protocol (see gure 5.4) is responsible for providing a new user V with
the credentials required to participate in Safebook.
In order to join, a new node V must be invited by a registered user A that needs to be an acquaintance in real life. Initially, A sends out-of-band V an invitation request invReq message, signed using the private key UA‚àí. It contains a tuple N ameA of properties that
3More precisely, session keys are used to encrypt the payload. Such keys are advertised at the beginning of the message encrypted with the target node Id public key.
4Each private key associated with a node- or user- identier is generated by the owner of the identier and known to nobody else.

70

Chapter 5 Safebook

identify the user A, the certicate Cert h (N ameA) , UA+ , as granted by the TIS, and the public key T I S+ of the TIS. The invReq message is the only message that is sent in clear
text, since V 's public node- and user- ID keys haven't yet been generated nor certied and
it is sent out of band anyway.
Upon reception of the invReq message, V generates the two keypairs N I dV and U I dV . Subsequently, it starts another out of band process: it creates its own identity tuple N ameV together with a proof of ownership of N ameV , and transmits both together with the public key UV+, in a credReq message, to the TIS. The TIS then generates V 's user ID U I dV and node ID N I dV by applying two distinct keyed hash functions hM K1 (¬∑) and hM K2 (¬∑) on N ameV . Additionally, it generates and signs the registration keys of V DhtK eyV by hashing and signing all permutations of elements in N ameV .
The TIS responds with a credRep message out of band, with the generated identiers and DHT keys, together with the respective certicates Cert U I dV , UV+ , Cert N I dV , NV+ , and Cert DhtKeyV , UV+ .
On reception of credRep, V joins Safebook and hence the P2P substrate and can start
creating her own Matryoshka. Subsequently, all messages sent from and received by V in the P2P overlay are signed using the sender's N ‚àí and encrypted using N + of the receiver.

5.4.2 Social Network Service setup and maintenance
Once created her account, the user V is able to setup her Matryoshka and to get reachable
by other users.
Matryoshka Setup Protocol
The Matryoshka setup protocol (see gure 5.5) allows for the creation of Matryoshkas.
During the rst execution of this protocol, the initiating node V sends the inviting node A a path creation request P athReq. This message contains a registration token RegT ok, a data structure T tlM atr for the number of hops on the created paths, the span factor Span for the tree through the Matryoshka, and a signed random number Rnd. The registration token includes the DHT keys to be registered, in order for V to be found in the OSN, V 's user ID certicate, authenticating U I dV , and the lifetime ExpireT ime of the DHT registration of the DhtKeyV . The T tlM atr is a recursively signed data structure generated by V including

5.4 Core protocols

71

Figure 5.4: Account creation for user V .
a set of decreasing time-to-live values based on the desired hop length from V 's core to one of its ŒòV 's entrypoints. Each node on reception of the P athReq removes one or more of T tlM atr's signatures, thus potentially causing a continuous decrease of the ttl value at each hop. The value in Span indicates to the mirrors and prisms of V how many next hop nodes should be selected in order to guarantee the desired availability of the data that V publishes. Upon receipt of a pathReq message, each mirror of V veries the integrity of the registration token by checking its signature with the key UV+ contained in the TIS certicate. It then removes one or more signatures5 from T tlM atr and selects a next hop B from its friendlist for the path and forwards the updated pathReq. In case the core has set a spanning factor greater than 1, it selects further nodes to forward the updated pathReq in order to achieve the requested branching. This process is recursive: B removes a signature from T tlM atr and forwards the updated pathReq to a number Span of his selected trusted contacts, and
5Removing more signatures allows Matryoshka chains to have dierent lengths. However, the value of a T tlMatr can never be increased to protect against DOS attacks.

72

Chapter 5 Safebook

so on, until, at one node D, the last signature from T tlM atr is removed. D becomes in consequence an entrypoint for the Matryoshka of V . For this purpose it routes one registration request for each key in DhtK ey through the P2P
system.

Figure 5.5: Matryoshka setup for user V .
Since D's reference as a ŒòV 's entrypoint is going to be a public domain information, D can nd a node K, whose node ID is closest enough to the registration key, in an iterative way: D selects from its neighbors the node N1 with the node ID being closest to the registration key, measured using the XOR-metric, as the next hop. N1 provides D with the reference to (one or more) closest node N2 and so on, until a suciently close node K is reached. Such a node K, called dock , is in charge of storing the association (DhtKey,EP T entry) in the P2P system. D then sends K a register message containing the eld EP T entrySND , and the random number RndSUV (see gure 5.6). The RndSUV poses as an authorization and D can claim to be a valid entry point for V . EP T entry is the new

5.4 Core protocols

73

record that K adds to its Entrypoint Table (EPT) and contains the registration token RegT ok, D's node ID certicate, D's ip address and a timestamp time. K then updates its EPT and responds with a pathRep message that is forwarded back to V along the inverse path. Additionally, much alike KAD, in Safebook K stores all registered values in k nodes around the target node of a registration request, the RespArea of docks for a registration key.

Figure 5.6: Entrypoint registration for user V 's Matryoshka.
Matryoshka Update Protocol
User V 's Matryoshka plays a fundamental role in guaranteeing both communication privacy to V and the availability of V 's data to all the other users, without the need for V to be online. For this reason, the structure of ŒòV always automatically has to be kept valid using the
Matryoshka update protocol (see gure 5.7), even in case of node arrival and departure, the latter possibly being due to choice (a user logging out from Safebook) or failure (an Internet

