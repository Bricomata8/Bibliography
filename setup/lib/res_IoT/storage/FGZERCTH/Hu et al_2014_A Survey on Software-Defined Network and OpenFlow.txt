This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
1

A Survey on Software-Defined Network (SDN) and
OpenFlow: From Concept to Implementation
Fei Hu, Qi Hao∗ , Ke Bao
Electrical and Computer Engineering, The University of Alabama, USA fei@eng.ua.edu
∗ Corresponding author qh@eng.ua.edu

Abstract—Software-defined network (SDN) has become one of
the most important architectures for the management of largescale, complex networks which may require re-policing or reconfigurations from time to time. SDN achieves easy re-policing
by decoupling the control plane from data plane. Thus the network routers/switches just simply forward packets by following
the flow table rules set by the control plane. Currently OpenFlow
is the most popular SDN protocol/standard and has a set of
design specifications. Although SDN/OpenFlow is a relatively
new area, it has attracted much attentions from both academia
and industry. In this paper we will conduct a comprehensive
survey of the important topics in SDN/OpenFlow implementation,
including the basic concept, applications, language abstraction,
controller, virtualization, Quality of service (QoS), security, as
well as its integration with wireless and optical networks. We
will compare the pros and cons of different schemes, and discuss
the future research trends in this exciting area. This survey can
help both industry and academia R&D people to understand the
latest progress of SDN/OpenFlow designs.
Index Terms—Software-Defined Network (SDN), OpenFlow,
Network Virtualization, QoS, Security

I. I NTRODUCTION
A. Motivations
Conventional Networks utilize special algorithms implemented on dedicated devices (hardware components) to control
and monitor the data flow in the network, managing routing
paths and determining how different devices are interconnected
in the network. In general these routing algorithms and sets
of rules are implemented in dedicated hardware components
such as Application Specific Integrated Circuits (ASICs) [1].
ASICs are designed for performing specific operations. Packet
forwarding is a simple example. In a conventional network,
upon the reception of a packet by a routing device, it uses a
set of rules embedded in its firmware to find the destination
device as well as the routing path for that packet. Generally
data packets that are supposed to be delivered to the same
destination are handled in similar manner. This operation takes
place in inexpensive routing devices. More expensive routing
devices can treat different packet types in different manners
based on their nature and contents. For example, a Cisco
router allows the users to mark out the priorities of different
flows through customized local router programming. Thus we
can manage the queue sizes in each router directly. Such
a customized local router setup allows more efficient traffic
congestion and prioritization control.
A problem posed by this methodology is the limitation of
the current network devices under high network traffic, which

poses severe limitations on network performance. Issues such
as the increasing demand for scalability, security, reliability
and network speed, can severely hinder the performance of
the current network devices due to the ever increasing network
traffic. Current network devices lack the flexibility to deal
with different packet types with various contents because of
the underlying hardwired implementation of routing rules [2].
Moreover, the networks, which make up the backbone of
the Internet, need to be able to adapt to changes without
being hugely labor intensive in terms of hardware or software
adjustments. However, traditional network operations cannot
be easily re-reprogrammed or re-tasked [3].
A possible solution to this problem is the implementation
of the data handling rules as software modules rather than
embedding them in hardware. This method enables the network administrators to have more control over the network
traffic and therefore has a great potential to greatly improve
the performance of the network in terms of efficient use of
network resources. Such an idea is defined in an innovative
technology, called Software-Defined Networking (SDN) [4].
Its concept was originally proposed by Nicira Networks based
on their earlier development at UCB, Stanford, CMU, Princeton [1]. The goal of SDN is to provide open, user-controlled
management of the forwarding hardware in a network. SDN
exploits the ability to split the data plane from the control
plane in routers and switches [5]. The control plane can send
commands down to the data planes of the hardware (routers
or switches) [6]. This paradigm provides a view of the entire
network, and helps to make changes globally without a devicecentric configuration on each hardware unit [7]. Note that the
control panel could consist of one or multiple controllers,
depending on the scale of the network. If using multiple
controllers, they can form a peer-to-peer high-speed, reliable
distributed network control. In any case, all switches in the
data plane should obtain the consistent view of the data
delivery. The switches in the data plane just simply deliver data
among them by checking the flow tables that are controlled by
the controller(s) in the control panel. This greatly simplifies
the switches tasks since they do not need to perform control
functions.
The concept of SDN is not entirely new. As a matter of
fact, a few decades ago people could use special infrastructure
(such as cloud computing hardware) to decouple the network
operating system (similar to the control functions in SDN
control plane) from computing-intensive applications (similar
to the data delivery in data plane). Today cloud computing

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
2

enables the networked computation and storage without using
local resources. Such a decoupling of control and data plays
a critical role in large-scale, high-speed computing system.
SDN results in improved network performance in terms
of network management, control and data handling. SDN is
a potential solution to the problems faced by conventional
network (Fig.1 [3-5]) and is gaining more acceptance in
applications such as cloud computing. It can be used in data
centers and workload optimized systems [8]. By using SDN,
the administrators have the ability to control the data flow as
well as to alter the characteristics of the switching devices
(or routing devices) in the network from a central location,
with control application implemented as software module
without the need of dealing with each device individually
[10]. This gives the network administrators the ability to
arbitrarily change routing tables (routing paths) in network
routing devices. It also allows an extra layer of control over
the network data since the administrator can assign high/low
priorities to certain data packets or allow/block certain packets
flowing through the network [1-3].
From cloud computing perspective, SDN provides great
benefits. First, it makes cloud provider more easily deploy
different vendors devices. Traditionally the big cloud providers
(such as Google, Amazon, etc.), have to purchase the highperformance switchers/routers from the same vendor in order
to easily re-configure the routing parameters (such as routing
table update period). Different vendors routers have their
own pros and cons. However, it is a headache to customize
each router since each vendor may have its own language
syntax. Now SDN allows a cloud provider to fast re-policy
the routing or resource distribution issues as long as each
vendors routers follow the SDN standard. Second, it enables
a cloud user to more efficiently use the cloud resources or
conduct scientific experiments by creating virtual flow slices.
The OpenFlow protocol is compatible to GENI standard, and
this enables a user to arbitrarily create slices/slivers without
being aware of the physical network infrastructure. No matter
the infrastructure is wireless or wired system, and no matter
how the cloud provider deploys different storage units in
various locations, the concept of virtual flow in a SDN makes
data flow transparently route through all cloud devices.

panel. This results in high speed transmissions and makes more
efficient use of the resources.
(2) Easy network management: The administrators have a
remote control over the network and can change the network
characteristics such as services and connectivity based on the
workload patterns. This enables administrators to have more
efficient and instant access to the configuration modifications.
(3) Multi-tenancy: The concept of the SDN can be expanded
across multiple partitions of the networks such as the data
centers and data clouds. For example, in cloud applications,
multiple data center tenants need to deploy their applications in
virtual machines (VNs) across multiple sites. Cloud operators
need to make sure that all tenants have good cross-site performance isolation for tenant specific traffic optimization. Existing cloud architectures do not support joint intra-tenant and
inter-tenant network control ability. SDN can use decoupled
control/data planes and resource visualization to well support
cross-tenant data center optimization [138].
(4) Virtual application networks: Virtual application networks use the virtualization of network resources (such as traffic queues in each router, distributed storage units, etc.) to hide
the low-level physical details from the users applications. Thus
a user can seamlessly utilize the global resources in a network
for distributed applications without direct management of the
resource separation and migration issues across multiple data
sites. Virtual application networks can be implemented by the
network administrators by using the distributed overlay virtual
network (DOVE) which helps with transparency, automation
and better mobility of the network loads that have been
virtualized [2, 5]. As a matter of fact, a large chunk of SDN is
along the rational of virtualization. Virtualization can hide all
lower level physical network details and allow the users to repolicy the network tasks easily. Virtualization has been used in
many special networks. Within the context of wireless sensor
networks (WSNs), there was a laudable European initiative
called VITRO, which has worked precisely on this. The
concept of virtual WSN [136] separates the applications from
the sensor deployment details. Thus we can run multiple logic
sensing applications over the same set of physical sensors.
This makes the same WSN serve multiple applications.
B. SDN Implementation: Big Picture

C1

C2

C3

D1

D1

D3

Data Plane

Flow table
Packet
switching

Control
Plane

d i g i t a l

C5

C4

Internet
Ӂമ

D4

Control plane &
Data plane are
customized in
each node

D5

Fig. 1. Comparison of traditional network (left) and SDN (right).

SDN is less expensive due to universal, data-forwarding
switching devices that follow certain standards, and provides
more control over network traffic flow as compared to the
conventional network devices. Major advantages of SDNs
include [11-15, 17-19]:
(1) Intelligence and speed: SDNs have the ability to optimize the distribution of the workload via powerful control

Here we briefly summarize the SDN design aspects. In
Sections 2 8, we will provide the details of each design
aspect. Since SDN’s control plane enables software-based
re-policying, its re-programming should also follow general
software design principle [37]. Here we first briefly review
the software design cycle. The design of a software module
typically follows 3 steps: (1) design; (2) coding and compiling;
and (3) unitary tests. SW debuggers are critical tools. (e.g.,
gdb [38]). A next usability level is provided by the integrated development environment (IDEs) such as Eclipse [39].
As a promising software design principle, component-based
software engineering (CBSE) [40] has been proposed in the
4WARD project [41]. The Open Services Gateway initiative
(OSGi) [42] has also been used for a full life cycle of software
design. The Agile SW development methodology proposed

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
3

in [43] has been used to provide better feedback between
different stages than conventional waterfall methodologies
[44].
Regarding controllers, examples include Nox [48] (written
in C), POX [49] (in Python), Trema [50], floodlight [51]
(in Jave), etc. NOX [48] was the first OpenFlow controller
implementation. It is written in C++. An extension of NOX
is implemented in POX [49]. NOX can run in Windows,
Linux, Mac OS, and other platforms. A Java-based controller
implementation is called Beacon [52]. Its extension is Floodlight controller [53]. It can virtualize the SDN control via the
OpenStack [54] architecture. Trema controller is now shipped
with OpenFlow network emulator based on Wireshark [55].
Before practical OpenFlow design, there are some good
simulating tools for initial proof-of-concept, such as NS-2 [56]
with OpenFlow Software Implementation Distribution (OFSID) [57]. Recently, Mininet [58] has become a powerful
emulation tool.
SDN/OpenFlow programming languages have been studied
in some projects. For example, FML [59] enables easy SDN
network policy definitions. Procera [59] defines controller
policies and behaviors. The Frenetic language [60] allows the
programs written for one platform to work in other platforms.
SDN/OpenFlow debuggers have been used to trace the
controller’s program execution status. ndb [61] mimics GNU
debugger gdb [38] and uses breakpoints and back-traces to
monitor the network behaviors. Tremashark [62] plugs Wireshark [55] into Treama [50]. It is now evolving to another
powerful debugging tool called OFRewind [63]. FlowCheck
[64] can check the updating status of flow tables. A more
comprehensive tool called NICE [65], has generated a preliminary version [66], and can be used to analyze the codes and
packet flows. Through the above tools, OpenFlow testbeds are
able to be established worldwide such as GENI [67] in the
U.S.A., Ofelia [68] in the European Union and JGN [69] in
Japan.
C. OpenFlow: A Popular Protocol/Standard of SDN
A number of protocol standards exist on the use of SDN in
real applications. One of the most popular protocol standards
is called OpenFlow [8-10, 16, 20]. OpenFlow is a protocol
that enables the implementation of the SDN concept in both
hardware and software. An important feature of OpenFlow is
that scientists can utilize the existing hardware to design new
protocols and analyze their performance. Now it is becoming
part of commercially available routers and switches as well.
As a standard SDN protocol, OpenFlow was proposed by
Stanford. Regarding testbeds of OpenFlow, many designs have
been proposed for OpenFlow protocols. They use open source
codes to control universal SDN controllers and switches.
Regarding switches, OpenVSwitch (OVS) [45] is one of the
most popular, software-driven OpenFlow switch. Its kernal is
written in Linux 3.3 and its firmware including Pica8 [46] and
Indigo [47] is also available.
OpenFlow is flow-oriented protocol and has switches and
ports abstraction to control the flow [21-27]. In SDN, there
is a software named controller which manages the collection

of switches for traffic control. The controller communicates
with the OpenFlow switch and manages the switch through the
OpenFlow protocol. An OpenFlow switch can have multiple
flow tables, a group table, and an OpenFlow channel (Fig.2
[22-26]). Each flow table contains flow entries and communicates with the controller, and the group table can configure
the flow entries. OpenFlow switches connect to each other via
the OpenFlow ports.
Controller

OpenFlow Protocol

Channel
Flow
table

Flow
table

Flow
table

Group table

OpenFlow Switch
Fig. 2. OpenFlow model.

Initially the data path of the OpenFlow routing devices has
an empty routing table with some fields (such as source IP
address, QoS type, etc.). This table contains several packet
fields such as the destination of different ports (receiving
or transmission), as well as an action field which contains
the code for different actions, such as packet forwarding
or reception, etc. This table can be populated based on the
incoming data packets. When a new packet is received which
has no matching entry in the data flow table, it is forwarded
to the controller to be processed. The controller is responsible
for packet handling decisions, for example, a packet is either
dropped, or a new entry is added into the data flow table on
how to deal with this and similar packets received in the future
[27, 28].
SDN has the capability of programming multiple switches
simultaneously; but it is still a distributed system and, therefore, suffers from conventional complexities such as dropping
packets, delaying of the control packets etc. Current platforms
for SDN, such as NOX and Beacon, enable programming;
but it is still hard to program them in a low level. With
new protocols (such as OpenFlow) becoming more standard in
industry, SDN is becoming easier to implement. The control
plane generates the routing table while the data plane, utilizing
the table to determine where the packets should be sent to
[3]. Many companies utilize OpenFlow protocols within their
data center networks to simplify operations. OpenFlow and
SDN allow data centers and researchers to easily abstract and
manage the large network.
The OpenFlow architecture typically includes the following
3 important components [8-10, 29]:
(1) Switches: OpenFlow defines an open source protocol
to monitor/change the flow tables in different switches and
routers. An OpenFlow switch has at least three components:
a) flow table(s), each with an action field associated with

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
4

each flow entry, b) a communication channel, which provides
link for the transmission of commands and packets between
a controller and the switch, c) the OpenFlow protocol, which
enables an OpenFlow controller able to communicate with any
router/switch.
(2) Controllers: A controller can update (revise, add, or
delete) flow-entries from the flow table on behalf of the
users experiments. A static (versus dynamic) controller can
be a simple software unit running on a computer to statically
(versus dynamically) establish packet path between a group of
test computers during a scientific experiment.
(3) Flow-entries: Each flow-entry includes at least a simple
action (network operation) for that flow item. Most OpenFlow
switches support the following three actions: (a) sending this
flow’s packets to a port, (b) encapsulating this flows packets
and sending to a controller, and (c) dropping this flows packets.
OpenFlow has gone through many standard iterations, and
it is currently on version 1.3; however only version 1.0 is
available for practical software and hardware design. The
second and subsequent versions of OpenFlow changed the
match structures so that the number and bit count of each
header field could be specified. Thus new protocols would be
easier to implement. In [21] a special controller is used to
separate control bits from data bits, which allows for the network infrastructure to be shared more easily. A server is often
utilized for the controller portion of OpenFlow architecture.
Currently, several projects are ongoing that utilize OpenFlow in both Europe and Japan [27, 28]. In Europe, eight
islands are currently interconnected using OpenFlow. In Japan,
there are plans to create a network compatible with the one in
Europe, as well as a testbed that is much more widespread.
The existing OpenFlow standard assumes centralized control, that is, a single-point controller can manage all flow tables
in different switches. This concept works very well in a smallscale, cable-based local area network. When OpenFlow was
proposed, it was tested in a wired campus network. However,
if many switches are deployed in a large area, it is difficult
to use a single-point control. Especially when wireless media
have to be used to connect long-distance devices, a central
control becomes difficult since wireless signals fade away
quickly for a long distance. Single control also has singlepoint failure issue. To solve the above issue, we can use
distributed controllers in different locations. Each controller
only manages the local switches. However, all controllers keep
highly reliable communications for consistent view of the
global status. As an example, Hyperflow [137] uses a logically
centralized but physically distributed control panel to achieve
a synchronized view of the entire SDN.
D. Beyond OpenFlow: Other SDN Standards
Besides OpenFlow (the most popular SDN protocol/standard), there exist other SDN implementations. For
instance, IEEE P1520 standards have defined Programmable
Network Interfaces [148]. It can be seen as an initial model
of SDN, since it also has network programming abstractions.
ForCES (Forwarding and Control Element Separation) [149]
is another standard defined by IETF. It consists of a series of

RFCs for the coverage of different aspects on how to manage
control and data forwarding elements. It proposes the models
to separate IP control and data forwarding, Transport Mapping
layer for the forwarding and control elements, logical function
block library for such a separation, etc. However, ForCES does
not have widespread adoption due to its lack of clear language
abstraction definition and controller-switcher communication
rules.
Note that ForCES has a key difference from OpenFlow:
ForCES defines networking and data forwarding elements
and their communication specifications. However, it does not
change the essential network architecture. OpenFlow changes
the architecture since it requires the routers/switches have
very simply data forwarding function and the routing control
functions should be removed to the upper level controllers.
Therefore, OpenFlow cannot run in traditional routers that do
not support OpenFlow standards, while ForCES can run in
traditional devices since it just adds networking/forwarding
elements.
SoftRouter [150] defines clearly the dynamic binding procedure between the network elements located in control plane
(software-based) and data plane. In this standard, the network
can be described in two different views, i.e., physical view
and routing view. In the physical view, the network is made
up of nodes internetworked by media links. The nodes could
be a forwarding element (FE) or a control element (CE). The
FE is a common router without local sophisticated control
logic. The CE is used to control FE. A CE is a general
server. The routing view of a network reflects the network
topology based on the concept of network element (NE).
An NE is a logical grouping of network interfaces/ports and
the corresponding CEs that control those ports. SoftRouter
includes a few protocols: Discovery protocol (to establish a
binding between FE and CE), FE/CE control protocol, and
CE/CE protocol.
E. 1.5 SDN Applications
In this section we will provide some application examples
on using SDN and OpenFlow.
(1) Internet Research: Updating the Internet brings many
challenges as it is constantly being used; it is difficult to
test new ideas and strategies to solve the problems found
in an existing network. SDN technologies provide a means
for testing ideas for a future Internet without changing the
current network [30]. Since SDN allows the control and data
traffic to be separated with an OpenFlow switch, it is easier
to separate hardware from software. This separation allows
for experimenting with new addressing schemes so that new
Internet architecture schemes can be tested.
Usually, it is difficult to experiment with new types of
networks. Since new types of networks often utilize different
addressing schemes and include other non-standard protocols,
these changes are difficult to incorporate into existing networks. OpenFlow allows for routers, switches, and access points
from many different companies to utilize the separation of
the control and data planes. The devices simply forward data
packets based on defined rules from the controller. If a data

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
5

packet arrives and the device does not have a rule for it, the
device forwards the packet to the controller that determines
what to do with the packet, and if necessary, it sends a new
rule to the device so that it can handle future data packets in
the same manner [21].
(2) Rural Connections: SDN simplifies complex data
center and enterprise networks; it can further be utilized to
simplify rural Wi-Fi networks. The main issues with rural
environments include sparse populations, small profit margins
and resource constraints, and others. SDN is beneficial because
it separates the construction of the network and the configuration of the network by placing the control/management
functionality into the central controller. This separation enables
the rural infrastructure deployment business (which must be
done locally in rural areas) and the Internet Service Provider
(ISP) business (which is typically done remotely in cities)
to be completely separated, i.e., those two businesses are
operated by different entities [31, 32]. Therefore, SDN makes
the management of rural networks much more convenient
than traditional network architecture where the local network
devices need customized control (which means the control of
rural devices must be done in rural areas).
(3) Date Centers Upgrading: Data centers are an integral
part of many companies [33]. For example, Google has a
large number of data centers so they can quickly provide
data when requested. Similarly, many other companies utilize
data centers to provide data to clients in a quick and efficient
manner, but data centers are expensive to maintain. OpenFlow
allows companies to save money in setting up and configuring
networks since it allows switches to be managed from a central
location [34].
Oftentimes, data center networks utilize proprietary architectures and topologies, which creates issues when merging
different networks together; however there is often a need to
merge two divergent networks. SDN brings a solution to this
issue. In [33] the authors propose that a network infrastructure
service based on OpenFlow be utilized to connect data center
networks. They further state that these interconnected data
center networks could solve problems with small latency by
moving workload to underutilized networks. If a network is
busy at a certain time of day, the workload might be able to
be completed sooner in a network of a different time zone or
in a network that is more energy efficient.
In [34] a data center model is created with a large number
of nodes to test performance, throughput and bandwidth. The
model included 192 nodes with 4 regular switches and 2 core
switches with an OpenFlow controller. There was a firewall
between the core switches, OpenFlow controller and the router.
The authors also utilized an application called Mininet to prototype their network and test the performance. Mininet allows
researchers to customize a SDN using OpenFlow protocols.
Further, they utilized several tools to analyze their network
setup including Iperf, Ping, PingAll, PingPair, and CBench.
These tools allow people to check the possible bandwidth,
connectivity, and the speed in which flows can be changed,
respectively. Wireshark was also used to view traffic in the
network.
(4) Mobile Device Offloading: Privacy is important for

business applications because people often work on data that
needs to be kept secure. Some data can be sent among only
a few people while other data does not require the same
level of security. As an example, in [35] the authors utilized
an Enterprise-Centric Offloading System (ECOS) to address
these concerns. ECOS was designed to offload data to idle
computers while ensuring that applications with additional security requirements are only offloaded on approved machines.
Performance was also taken into consideration for different
users and applications [35]. SDN is utilized to control the
network and select resources. The resources selected must be
able to meet the security requirements. The controller will
determine if such a device is available for offloading that meets
the security requirements while maintaining energy savings.
If no such device exists, data is not allowed to be offloaded
from the mobile device. If energy savings is not necessary,
then any resource with enough capacity is utilized if available.
OpenFlow switches are utilized so that the controller can
regulate the flows. ECOS was able to offload while taking
into account security requirements without an overly complex
scheme.
(5) Wireless Virtual Machines: Applications running on
wireless virtual machines in businesses are becoming increasingly common. These virtual machines allow the companies
to be more flexible and have lower operational costs. In order
to extract the full potential from a virtual machine, there are
needs for making them more portable. The main issue is how
to maintain the virtual machines IP address in the process.
The current methods of handling virtual machines were not
efficient. The solutions proposed in [36] include using a mobile
IP or dynamic DNS. The main issue with both solutions is
that someone has to manually reconfigure the network settings
after removing the virtual machine. This limits businesses and
data centers from easily porting their virtual machines to new
locations.
An application named CrossRoads was developed by [36]
in order to solve the mobility issue for virtual machines.
CrossRoads is designed to allow mobility of both live and
offline virtual machines. CrossRoads has three main purposes.
The first purpose is to be able to take care of traffic from
data centers as well as external users. The second purpose is
to make use of OpenFlow with the assumption that each data
center utilizes an OpenFlow controller. The third purpose is
to make use of pseudo addresses for IP and MAC addresses
in order to have the addresses remain constant when porting
while allowing the real IP to change accordingly.
The basic implementation of their software was to create
rules for finding the virtual machines in different networks.
The CrossRoads controller would keep track of the real IP
and MAC addresses for the controllers in each data center
as well as the virtual machines in its own network. When
a request is sent for an application running on a particular
virtual machine, a request is broadcasted to the controllers.
If the controller receives a request for a virtual machine that
is not in its table, then it broadcasts the request to the other
controllers; the controller who has the virtual machines real IP
address then sends out the pseudo MAC address to the original
controller, and the original controller can update its table in

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
6

TABLE I
A COMPARISON OF DIFFERENT SDN APPLICATIONS .
Applications

Use
OpenFlow

Net.
Traffic
amount

For Data Center

Network Scalability

Mobile
Platform

QoS support

For
Cloud

Internet Research [30]

Yes

Yes

Excellent

Yes

All QoS metrics

No

Rural Networking [31]
Changing Silicon [32]
Data Centers [33]

No
No
Yes

Depends on applications
Low
Medium
High

Allow
Hardware
Change
Yes

No
Yes
Yes

Poor
N/P
Very Good

No
No
No

No
No
No

No
Yes
No

Cloud [34]

Yes

High

Yes

Excellent

Yes

Yes

No

Mobile Apps [35]
Virtual Machines [36]

Yes
Yes

Low
Depends

No
Yes

Good
Very Good

Yes
Yes

Low throughput
Low data rate
Latency is a concern
Typically Realtime
Long Delay
Real-time

No
Yes

No
No

case it gets another request in the near future.
Comparisons: SDN has been shown to be a valuable
resource in many different types of applications. SDN allows
users to quickly adapt networks to new situations as well as
test new protocols. Table 1 shows the differences among some
typical SDN applications. As one can see, OpenFlow was utilized in most of the applications for its versatility. Data centers
continue to become an important part of the Internet and many
large companies. The column mobile applications refers to
cell phones, tablets, and other non-traditional media formats
rather than laptops and other typical computing platforms. A
few of the applications utilize the cloud. Hardware changes
are difficult to implement in conventional networks. This is
mainly because they require a system to be shut down during
upgrade. But SDN provides conveniences for such upgrades
due to its separation of data and control planes.
F. Road Map
Fig.3 shows the organization of this paper. After the concept
is explained (section 1), sections 2 8 will survey the most
important aspects in SDN/OpenFlow design. Since SDN aims
to enable easy re-policying, the network programming is a
must (section 2). SDN simplifies all switches as data forwarders only and leave complex control in controllers (section
3). Due to the dynamic network resources deployment, it is
critical to provide the users an accurate network resource
management via the virtualization tools (section 4). Then we
move to the important SDN performance issue - QoS (section
5). We will explain different schemes that can support the
QoS requirements. Any network has threats and attacks. SDN
is not an exception. Section 6 will explain the security and
fault tolerance aspects in SDN designs. Then we introduce the
ideas of implementing SDN/Openflow in two most important
network types - wireless and optical networks (section 7).
Section 8 introduces a SDN design example. To help the
readers understand unsolved challenging research issues, we
will point out the next-step research directions in this exciting
field (section 9). Finally, section 10 concludes the entire paper.
The reason of covering the three aspects (QoS, security, and
wireless/optical) besides the basic SDN issues (sections 2 4)
is due to the following factors: First, for any new network
architecture, the first concern is its performance, which mainly

includes the end-to-end delay, throughput, jitter, etc. Therefore,
it is critical to evaluate its QoS support capabilities. This is
the reason that we use an individual section (section 5) to
cover SDNs QoS support issues; Second, security is always a
top concern for a user before he or she uses a new network
model. There are many new attacks raised for any new network
architecture. Therefore, we will use another section (section 6)
to cover SDN security considerations; Finally, today two most
typical network media are wireless transmissions and optical
fiber. SDN eventually needs to face the design challenges when
used for those cases. Therefore, in section 7 we discuss SDN
extensions in wireless and optical links.

Motivation,
Concept,
Applications

Design
principles

What?

How?

Section 1





Language (section 2)
Controller (section 3)
Virtualization (section 4)

Research
Trends

Quality of service (section 5)

Next?

Security (section 6)

Section 9

OpenFlow for Wireless & Optical (section 7)
A Complete design example (section 8)

Fig. 3. Organization of this survey

II. L ANGUAGE A BSTRACTIONS FOR SDN
A. Language Abstractions
In SDN the control function consists of two parts, i.e., the
controller with the program and the set of rules implemented
on the routing/switching devices (Fig.4). This has an implication of making the programmer not worry about the low-level
details in the switch hardware. The SDN programmers can just
write the specification that captures the intended forwarding
behavior of the network instead of writing programs dealing
with the low-level details such as the events and the forwarding
rules of the network. This enables the interactions between
the controllers and switches. A compiler transforms these
specifications into code segments for both controllers and
switches. As an example, a SDN programming tool called
NetCore [70] allows descriptions of the network rules and
policies which cannot be implemented directly on the switches.
Another important fact about NetCore is that it has a clear

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
7

formal set of rules that provide a basis for reasoning about
program execution status.

provides an ideal platform for exploring such abstractions, as
the compiler can be used to perform the tedious bookkeeping
for implementing network policy updates [71].

Application Layer

B. Language abstraction tools: Frenetic project

Business Applications

API

Control Layer

SDN
Control
Software

API

API

Network
Services

Control Data Plane Interface
e.g. OpenFlow

Infrastructure Layer
Network Device

Network Device

Network Device

Fig. 4. Programming of the SDN and language Abstraction

Here we introduce two important language abstractions in
SDN programming:
(1) Network Query Abstractions: In SDNs each switch
stores counters for different forwarding rules. They are for
the counts of the total number of packets and data segments
processed using those rules. For traffic monitoring the controller has the ability to check different counters associated
with different forwarding rules. This enables the programmers
to monitor the fine details of implementation on the switches.
This is a tedious job and makes the program complicated.
Therefore an added level of abstraction will help the programmers. To support applications whose correct operation involves
a monitoring component, Frenetic [71] includes an embedded
query language that provides effective abstractions for reading
network state. This language is similar to SQL and includes
segments for selecting, filtering, splitting, merging and aggregating the streams of packets. Another special feature of this
language is that it enables the queries to be composed with
forwarding policies. A compiler produces the control messages
needed to query and tabulate the counters on switches.
(2) Consistent Update Abstractions: Since SDNs are
event-driven networks, the programs in SDNs need to update
the data forwarding policy from time to time because of the
changes in the network topology, failures in the communication links, etc. An ideal solution is the automatic update of
all the SDN switches in one time; but in reality it is not
easy to implement. One good solution is to allow certain
level of abstraction, and then send these changes from one
node to another. An example is the per-packet consistency
which ensures that each packet just uses the same, latest
policy (instead of a combination of both the old and new
policy). This preserves all features that can be represented by
individual packets and the paths they take through the SDN.
Those properties subsume important structural invariants such
as basic connectivity and free-of-loop, and link access control
policies. Per-flow consistency ensures that a group of related
packets are processed with the same flow policy. Frenetic

SDN requires efficient language abstraction tools to achieve
network re-programming. As an example, the Frentic project
aims to provide simple and higher level of abstraction with
three purposes, i.e., (i) Monitoring of data traffic, (ii) Managing (creating and composition) packet forwarding policies, (iii)
Ensuring the consistency when updating those policies [72].
By providing these abstractions the network programming
becomes easy and efficient without a need of worrying about
the low-level programming details.
Frenetic project utilizes a language that supports an
application-level query scheme for subscribing to a data
stream. It collects information about the state of the SDN,
including traffic statistics and topology changes. The runtime system is responsible for managing the polling switch
counters, gathering statistics, and reacting to the events. In
the Frenetic project the specification of the packet forwarding
rules in the network is defined by the use of a high-level policy
language which can easily define the rules and is convenient to
programmers. Different modules can be responsible for different operations such as the routing, discovery of the topology of
the network, workload balancing, and access control, etc. This
modular design is used to register each module’s task with the
run time system which is responsible for composing, automatic
compilation and optimization of the programmer’s requested
tasks. To update the global configuration of the network,
Frenetic project provides a higher level of abstraction. This
feature enables the programmers to configure the network
without going physically to each routing device for installing
or changing packet forwarding rules. Usually, such a process
is very tedious and is prone to errors. The run-time system
makes sure that during the updating process only one set of
rules is applied to them, i.e. either the old policy or the new
one but not both of the rules. This makes sure that there is
no violations for the important invariants such as connectivity,
control parameters of the loops and the access control when
the Open-Flow switches from one policy to another [72].
To illustrate Frenetic language syntax, here we use an
example. In MAC learning applications, an Ethernet switch
performs interface query to find a suitable output port to
deliver the frames. Frenetic SQL (Structure Query Language)
is as follows:
Select (packets) *
GroupBy ([srcmac]) *
SplitWhen ([inport]) *
Limit (1)
Here Select(packets) is used to receive actual packets (instead of traffic statistics). The GroupBy([srcmac]) divides the
packets into groups based on a header field called sercmac.
Such a field makes sure that we receive all packets with the
same MAC address. SplitWhen([inport]) means that we only
receive the packets that appear in a new ingress port on the

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
8

switch. Limit(1) means that the program just wants to receive
the first packet in order to update the flow table in data plane.
In a nut shell, Frenetic language project is an aggregation
of simple yet powerful modules that provide an added level
of abstraction to the programmer for controlling the routing
devices. This added layer of abstraction runs on the compiler
and the run time system, and is vital for the efficient code
execution.
C. Language Abstraction Tool: FlowVisor
The virtualization layer helps in the development and
operation of the SDN slice on the top of shared network
infrastructures. A potential solution is the concept of AutoSlice [74]. It provides the manufacturer with the ability to
redesign the SDN for different applications while the operator
intervention is minimized. Simultaneously the programmers
have the ability to build the programmable network pieces
which enable the development of different services based on
the SND working principles.
Flow Visor is considered to be a fundamental building
block for SDN virtualization and is used to partition the
data flow tables in switches using the OpenFlow protocol by
dividing it into the so-called flow spaces. Thus switches can
be manipulated concurrently by several software controllers.
Nevertheless, the instantiation of an entire SDN topology
is non-trivial, as it involves numerous operations, such as
mapping virtual SDN (vSDN) topologies, installing auxiliary
flow entries for tunneling and enforcing flow table isolation.
Such operations need a lot of management recourses.
The goal is to develop a virtualization layer which is called
SDN hypervisor. It enables the automation of the deployment
process and the operation of the vSDN topologies with the
minimum interaction of the administrator. vSDNs focuses on
the scalability aspects of the hypervisor design of the network.
In [75] an example is presented in which a network infrastructure is assumed to provide vSDN topologies to several
tenants. The vSDN of each tenant takes care of a number
of things such as the bandwidth of the link, its location and
the switching speed (capacity), etc. The assumption is that
every tenant uses switches that follow OpenFlow protocol
standards with a flow table partitioned into a number of
segments. The proposed distributed hypervisor architecture has
the capability of handling a large amount of data flow tables
for several clients. There are two very important modules
in the hypervisor: Management Module (MM) and Multiple
Controller Proxies (CPX). These modules are designed in such
a manner that it distributes the load control over all the tenants.
The goal of the MM portion is to optimize global parameters. The transport control message translation is used to enable
the tenants to have the access to the packet processing set of
rules within a specific SDN layer without having to disturb
the simultaneous users. Upon the reception of a request, MM
inquires the vSDN about the resources available in the network
with every SDN domain and then accordingly assigns a set of
logical resources to each CPX.
As a next step each CPX initializes the allocated segment
of the topology by installing flow entries in its domain, which

unambiguously bind traffic to a specific logical context using
tagging. As the clients are required to be isolated from each
other, every CPX is responsible to do a policy control on the
data flow table access and make sure that all the entries in
these tables are mapped into segments that are not overlapping.
CPX is responsible for controlling the routing switches. Also
the CPX takes care of all the data communication between the
client controller and the forwarding plane.
A new entry into the switch has to follow certain steps
(Ididnotseemanysteps). First, the proxy creates a control message for addition of new entry into the switch flow table in
such a manner that all references (addresses) to memories
are replaced by the corresponding physical entries, and corresponding traffic controlling actions are added into the packet.
The Proxy is responsible for maintaining the status of each
virtual node in a given SDN. As a result the CPX has the
ability to independently transfer virtual resources within its
domain to optimize inter-domain resource allocation.
If there are a number of clients in the network, a large
number of flow tables are needed in the memory of a routing
switch. The task of CPX is to make sure that all the flow
tables are virtually isolated, all packet processing takes place
in a correct order, and all the actions are carried out in case a
connected group of virtual nodes is being mapped to the same
routing device.
In the OpenFlow routing devices, there is a problem on the
scalability of the platform due to the large flow table size.
There could be a large number of entries in the flow table.
To deal with such situation, an auxiliary software data paths
(ASD) is used in the substrate network [75]. For every SDN
domain, an ASD is assigned. The server has enough memory
to store all the logical flow tables which are needed by the
corresponding ASD compared to the limited space on the
OpenFlow routing devices. Although the software-based data
path has some advantages, there is still a huge gap between the
OpenFlow protocol and the actual hardware components. To
overcome these limitations, the Zipf property of the aggregate
traffic [76], i.e., the small fraction of flows, is responsible for
the traffic forwarding. In this technique ASDs are used for
handling heavy data traffic while only a very small amount of
high volume traffic is cached in the dedicated routing devices.
Language example of FlowVisor: Here we provide an example on how FlowVisor creates a slice.
# Topology
Example topo = nxtopo.NXTopo ( )
Example topo.add switch (name = ”A”, ports [1,2,3,4])
Example topo.add switch (name = ”B”, ports [1,2,3,4])
Example topo.add link (( ”A”, 4), (”B”, 4))
# Mappings
P map = ”A” : ”S2”, ”B”: ”S3”
Q map = identity port map (Example topo, P map)
Maps = (P map, Q map)
# predicates
Preds = \
([ (p, header (”srcport”, 80))
For p in Example topo.edge ports (”A”) +
[(p, header (”dstport”, 80))

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
9

For p in Exam topo.edge ports (”B”) ])
# slice constructor
Slice = Slice (Example topo, phys topo, maps, preds)
In the above example, we first define a network topology
called Example topo, which has two switches: A and B.
The switches have 3 edge ports each. Then we define the
switch→port mappings. Switch A maps to S2, and B maps to
S3. Then we associate a predicate with each edge port. The
predicates can map traffic (web only) to the slice. The last line
officially creates a slice [143].
III. C ONTROLLER
The control plane can be managed by a central controller
or multiple ones. It gives a global view of the SDN status
to upper application layer. In this section, we look into the
architecture and performance of controller in software defined
networks.

A. Types of Controllers
While SDN is suitable for some deployment environments
(such as homes [77, 78], data centers [79], and the enterprise
[80]), delegating control to a remote system has raised a
number of questions on control-plane scaling implications of
such an approach. Two of the most often voiced concerns
are: (a) how fast the controller can respond to data path
requests; and (b) how many data path requests it can handle
per second. For software controller, there are four publiclyavailable OpenFlow controllers: NOX, NOX-MT, Beacon, and
Maestro [81].
A typical OpenFlow controler is NOX-MT [81]. NOX [48]
whose measured performance motivated several recent proposals on improving control plane efficiency has a very low flow
setup throughput and large flow setup latency. Fortunately, this
is not an intrinsic limitation of the SDN control plane: NOX
is not optimized for performance and is single-threaded.
NOX-MT is a slightly modified multi-threaded successor
of NOX. With simple tweaks we are able to significantly
improve NOXs throughput and response time. The techniques
used to optimize NOX are quite well-known: I/O batching to
minimize the overhead of I/O, porting the I/O handling harness
to Boost Asynchronous I/O (ASIO) library (which simplifies
multi-threaded operation), and using a fast multiprocessoraware malloc implementation that scales well in a multi-core
machine.
Despite these modifications, NOX-MT is far from perfect.
It does not address many of NOXs performance deficiencies,
including but not limited to: heavy use of dynamic memory
allocation and redundant memory copies on a per-request basis, and using locking while robust wait-free alternatives exist.
Addressing these issues would significantly improve NOXs
performance. However, they require fundamental changes to
the NOX code base. NOX-MT was the first effort in enhancing
controller performance. The SDN controllers can be optimized
to be very fast.

B. Methods to Enhance Controllers Performance
We can make OpenFlow network more scalable by designing a multi-level controller architecture. With carefully
deployed controllers, we can avoid throughput bottleneck in
real networks. For example, in [82] authors have measured
the flow rate in a HP ProCurve (model # 5406zl) switch,
which is over 250 flows per second. In the meantime, in [83]
authors reported that for a data center with over 1000 servers,
it could face a flow arrival rate of 100k flows/second, and in
[84] they reported a peak rate of 10M flows per second for an
100-switch network. The above example shows that current
switches cannot handle the application flow rate demands.
Therefore, we need to invent an efficient protocol which can
minimize the switch-to-controller communications.
The data plane should be made simple. Currently OpenFlow
assigns routing tasks to the central controller for flow setup.
And the low-level switches have to communicate with the
controller very frequently in order to obtain the instructions on
how to handle incoming packets. This strategy can consume
the controllers processing power and also congest switchcontroller links. Eventually they cause a serious bottleneck
in terms of the scalability of OpenFlow.
However, recent measurements of some deployment environments suggest that these numbers are far from sufficient. This causes relatively poor controller performance
and high network demands to address perceived architectural
inefficiencies. But there has been no in-depth study on the
performance of a traditional SDN controller. Most results were
gathered from systems that were not optimized for throughput
performance. To underscore this point, researchers were able
to improve the performance of NOX, an open source controller
for OpenFlow networks, by more than 30 times in throughput
[85].
In most SDN designs the central controller(s) can perform
all the programming tasks. This model certainly brings the
scalability issue to the control plane. A better control plane
should be able to make the packet handling rate scalable with
the number of CPUs. It is better to always have the network
status in packet level available to the controllers. Study from
Tootoonchian et al. [85] implements a Glasgow Haskell Compiler (GHC) based runtime system. It can allocate/deallocate
memory units, schedule different event handlers, and reduce
the interrupts or system calls in order to decrease the runtime
system load. They have showed the possibility of using a single
controller to communicate with 5000 switches, and achieving
the flow rate of up to 14M per second! The switch-controller
communication delay is less than 10ms in the worst case.
In [86] a partition/aggregate scheme is used to handle TCP
congestion issue.
C. Advanced Controller Design
Here we introduce an advanced method for high-speed
control functions in control plane. In [145], a mechanism
called Control-Message Quenching (CMQ) is proposed to
reduce the flow setup delay and improve the SDN throughput
among switches/routers. There are huge number of flows
that need to be handled by the controllers. The inability of

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
10

OpenFlow to process so many flows policy management is
due to the inefficient design of control-data plane interfaces.
Especially, there exist frequent switch-controller communications: the switches have to consult the controller frequently
for instructions on how to handle new incoming packets.
The basic idea of CMQ is to ask any switch to send only one
packet-in message during each RTT (round-trip-time), for each
source-destination pair, upon multiple flow table misses. Thus
we do not need to bother the controllers each time we receive
the packets with the same source/destination. Each switch
should maintain a dynamically updated table with all learned,
unique source-destination pairs. For each incoming packet that
cannot find its source-destination pair, i.e., table-miss occurs,
the switch will insert such a new pair into the table, and query
the controller. Such a pair table will be maintained periodically
in case the network topology changes, which can detected by
the control plane.
A problem with existing SDN controller is that the SDN
flow tables typically cannot scale well when there are more
than 1000 entries [146]. This is mainly because the tables often
include wildcards, and thus need ternary content-addressable
memory (TCAM), as well as complex, slow data structures.
In [146] a scheme called Palette, can decompose a large SDN
table into small ones and distribute them to the whole SDN
without damaging the policy semantics. It can also reduce the
table size by sharing resources among different flows. The
graph-theory based on model is used to distribute the small
tables to proper switches.
There could exist multiple controllers in the SDN. In [147]
a load balancing strategy called BalanceFlow, is proposed to
achieve controller load balancing. Through cross-controller
communications, a controller is selected as super-controller,
which can tune the flow requests received by each controller
without introducing much delay. Note that each controller
should publish its load information periodically to allow supercontroller to partition the loads properly.

OpenFlow offers common instructions, but lacks standard
management tools. FlowVisor only has access to the data
plane, so the control plane and network controllers have to be
managed by the users of the infrastructure. On the other hand,
it can ensure a logical traffic isolation but with a constant
level, which means that it lacks flexibility. Facing these
challenges, researchers try to establish their own architecture
based on OpenFlow or FlowVisor for an improved network
virtualization.
FlowVisor can be pre-installed on the commercial hardware,
and can provide the network administrator with comprehensive
rules to manage the network, rather than adjusting the physical
routers and switches. FlowVisor creates slices of network
resources and acts as the controlling proxy of each slice to
different controllers as shown in Fig.5. The slices may be
switch ports, Ethernet addresses, IP addresses, etc, and they
are isolated and cannot control other traffic. It can dynamically
manage these slices and distribute them to different OpenFlow
controllers, and enables different virtual networks to share the
same physical network resources.
OpenFlow switch

OpenFlow switch

OpenFlow switch

FlowVisor
Switch ports

Ethernet
addresses IP addresses

FlowVisor
Switch ports

OpenFlow controller

Ethernet IP addresses
addresses

OpenFlow controller

OpenFlow controller

Fig. 5. The FlowVisor acts as proxy and provides slices.

IV. N ETWORK V IRTUALIZATION
A. Virtualization Strategies
As technology develops, the modern network becomes
larger and more capable of providing all kinds of new services. The cloud computing, and some frameworks such as
GENI, FIRE, G-Lab, F-Lab and AKARI, utilize the large-scale
experimental facilities from networks. However, resources are
always limited and users demands keep increasing as well. The
sharing of network hardware resources among users becomes
necessary because it could utilize the existing infrastructure
more efficiently and satisfy users demands. Network virtualization in SDN is a good way to provide different users with
infrastructure sharing capabilities [87]. The term OpenFlow
often comes with network virtualization these years. The
FlowVisor, the controller software, is a middleware between
OpenFlow controllers and switches. FlowVisor decomposes
the given network into virtual slices, and delegates the control
of each slice to a specific controller [88].
Both OpenFlow and FlowVisor have their limitations in
terms of network management, flexibility, isolation and QoS.

B. Virtualization Models
In the context of OpenFlow there are different virtualization models in the view of translation model [89] (Fig.6).
Translation aims to find 1:1 mapping relationship between
the physical SDN facilities and the virtual resources. The
translation unit is located between the application layer and
the physical hardware. According to their placements we could
classify them into five models:
(1) FlowVisor: FlowVisor is the translation unit that delegates a protocol and controls various physical switches or
controllers. It has full control of the virtualization tasks.
(2) Tanslation unit: it is in the OpenFlow instance of the
switch, and it performs translation among different controllers
at the protocol level.
(3) Multiple OpenFlow instances running on one switch are
connected to one controller. Translation is executed between
the data forwarding unit (such as a switch) and an OpenFlow
instance.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
11

Fig. 6. Various translating functions (C1,C2,C3: different Controllers; OFI OpenFlow Instance)

(4) Multiple OpenFlow instances still running on a single
switch, but the switchs datapath is partitioned into a few
parallel ones, one per instance. It translates by adjusting the
ports connected to the different parallel data paths.
(5) Multiple translation units are used, and at least one is
for virtualization on the switch level, and another one for
interconnecting some virtual switches.
C. Virtualization Architectures

Management Framework
Controller
Management

……

Mapping

Fig. 8. Integrated OpenFlow management framework.

A MAC layer network virtualization scheme with new
MAC addressing mode is proposed in [91]. Since it uses
a centralized MAC addressing, it could overcome the SDN
scalability problems. This system efficiently supports Cloud
computing and sharing of the infrastructures as shown in Fig.9.
User application 1

User application 2

Physical
Network
Virtual resource 1-1

Virtual resource 1-2

Physical resource 1

Fig. 7. System design of FlowN

In [87] it present a system called FlowN that extends the
NOX version 1.0 OpenFlow controller, and embeds a MySQL

Virtual Switch
Instance 2

Tenant 2
Applicaon

Virtual Switch
Instance 1

Database

Tenant 1
Applicaon

Mapping
switches

Mapping
switches

The flexibility in the network virtualization denotes the
scalability and the control level to the network. It usually
conflicts with the isolation demand.
Container Based
Applicaon
Virtualizaon

Virtual Switch
Instance 2

(1)Flexibility:

Virtual Network Management

Virtual Switch
Instance 1

OpenFlow
Controller 2

OpenFlow
Controller 1

Some systems have been proposed to address the
OpenFlow-based network virtualization limitations. These
methods can be classified as three types: (1) Improve the
OpenFlow controller. OpenFlow controller is a software, and
it can be modified by users to satisfy their special demands.
(2) Improve the FlowVisor. The FlowVisor itself already
has basic management function, and it can be improved to
overcome some limitations. (3) To add new abstraction layer
upon OpenFlow switch. Researchers add new layers or new
components to manage the virtual network. In the following
we will focus on some performance requirements for a SDN
virtualizer.

version 14.14 based database with the virtual-to-physical mappings as shown in Fig.7. This FlowN is a scalable virtual
network and provides tenants a full control of the virtual
network tenants can write their own controller application and
define arbitrary network topology. With the container based
architecture, the controller software that interacts with the
physical switches is shared among tenant applications, and so
that the resources could be saved when the controller becomes
more and more complex these days.
This system is evaluated in two experiments by increasing
the number of the nodes: one measures the latency of the
packets arriving at the controller, and the other measures the
fault time of the link used by multiple tenants. When the
number of nodes is large, the system has the similar latency as
FlowVisor does but is more flexible; and its fault time could
be small even the number of network nodes is large.
In [90] an efficient network virtualization framework is
proposed. Its major features include: (1) monitor multiple
instances of OpenFlow switches, (2) set up controllers and
SDN applications, and (3) achieve QoS performance. It can
easily configure the parameters of different switches, and
monitor the network topology to see any node changes. It uses
OpenNMS as the management tool since it is open source.
It has virtual controller management as shown in Fig.8. The
prototype is successfully tested on the testbed consisting of
six PCs, one switch and one OpenFlow switch.

Virtual resource 2-1

Virtual resource 2-2

Physical resource 2

OpenFlow
controller

Management
based on
FlowVisor

OpenFlow
switch

Fig. 9. OpenFlow network virtualization for Cloud computing.

The virtualization of the LANs could be used to virtualize
the network, but it has more complexity and overhead, and is

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
12

not good at scalability. Thus the virtualization of MAC layer
functions could be used, and is realized in [91] by reserving
part of the remaining MAC address for the virtual nodes. This
system reduces IP and control overhead, but the security issues
need to be solved. Details of the system are provided, but the
prototype is not tested in experiment.

between the switch and the controller. The QoS tools are
applied to make fair resource allocation. It provides strict
isolation between different sub-domains in a large SDN. It
also allows future protocol extensions. However, there is no
prototype tested in the system.

(2) Isolation:
In order to ensure all the tenants of the virtual network
can share the infrastructure without collision, the isolation
problem must be addressed. The isolation may be in different
levels or places, just like address space. A research network
named EHU-OEF is proposed in [88] (Fig.10). This network
uses L2PNV, which means Layer-2 Prefix-based Network
Virtualization, to separate various resource slices and allows
users to have multiple virtual networks based on the MAC
address settings. L2PNV has made some specific flow rules
as well as some customized controller modules. It can also
change FlowVisor.
Research slice 1

Local layer 2
address 1

Research slice 2

Local layer 2
address 2

Other slice

Local layer 2
address 3

Fig. 11. A full virtualization system. (MC: master controller; C1, C2, C3:
regular controllers; OS: operating system; OFI: OpenFlow instance.) [89].

Production slice
OpenFlow
controller 1

OpenFlow
controller 2

OpenFlow
controller n

Slice 1

Slice 2

Slice n

Global layer 2
address

Slice identification
Memory
isolator

EHU-OEF
OpenFlow
protocol

Interfaces
isolator

Processing
isolator

Slice isolator

Resources
allocator

Mapping
Hardware switch

OpenFlow switch
OpenFlow
instance 2

OpenFlow
instance 1
Resercher

Non technical user

Fig. 10. EHU-OEF: an integrated OpenFlow management framework.

EHU-OEF can well isolate different slices in the flow
table, and the flow traffic can be distinguished based on the
MAC addresses. Moreover, the NOX controllers use their
module ecosystem to easily manage different slices. This
solution has the benefit since it can deal with longer MAC
header such as in virtual LAN (VLAN) cases. It can also be
used to test other non-IP protocols by simply changing the
addressing schemes. The EHU-OEF prototype is tested on the
platform composed of seven NEC switches (IP8800/S3640),
four Linksys WRT54GL, and two NetFPGAs. It is the first
OpenFlow-based SDN infrastructure in Europe and allows
experimental and application-oriented data traffic in the same
network without conflict.
In [89] a SDN virtualization system is proposed with fair
resource allocation in the data/control planes as shown in
Fig.11. All SDN tenants obtain the network resource by
enforcing the resource allocations in the central controller, the
datapath of the forwarding elements, and the control channel

Fig. 12. Network virtualization using Slice Isolator [92]

In [92] the isolation issue is solved among slices in different
virtual switches. It makes all slices share the network resources
in a fair way while allowing the isolation adaptation according
to the expected QoS performance. It also allows multi-level
isolation (see Fig. 12). A Slice Isolator is located above the
switches and OpenFlow abstraction layer, and is designed as
a model focusing on (a) Interface isolation; (b) Processing
isolation; and (c) Memory isolation.
Evaluations of the system show that the isolation levels have
significant impact on the performance and flexibility. The time
for reconfiguring the hardware traffic manager increases fast
when the isolation level goes up. High isolation level also
leads to latency. So the best isolation level can be determined
based on the update time and latency to achieve required
performance.
(3) Efficient Management:
Network virtualization management is involved with the
mapping, layer abstraction or system design to make sure
the virtualized network can satisfy different demands. It is
the integration of the flexibility, isolation, and convenience. A

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
13

Management Application

XML File Virtual Network
discription

virtualization, so we compare these presented systems with
FlowVisor (the last column). Most of the presented systems,
no matter whether it is based on FlowVisor or it is built
totally in a new scheme, not only have equivalent abilities to
FlowVisor, but have one or more advantages over FlowVisor
such as flexibility, adjustable isolation levels, etc.

LibNetVirt

OpenFlow

Fig. 13. LibNetVirt architecture.

network virtualization architecture allowing management tools
to be independent of the underlying technologies is presented
in [93]. The paper proposes an abstraction deployed as a
library, with a unified interface towards the underlying network
specific drivers. The prototype is built on top of an OpenFlowenabled network as shown in Fig.13. It uses the single router
abstraction to describe a network, and has feasibility for
creating isolated virtual networks in a programmatic and ondemand fashion.In this system the management tools can be
independent of the working cloud platform so that different
technologies can be integrated, and the system focuses on
reduce the time of creating the virtual network. The prototype
named LibNetVirt is separated in two different parts: generic
interface and drivers. The generic interface is a set of functions
that allow interacting with the virtual network and executing
the operations in the specific driver. A driver is an element
that communicates to manipulate the VN in the physical
equipment.
A scheme [94] as shown in Fig.14, enables the creation of
different isolated, virtual experimental sub-systems based on
the same physical infrastructure. This system implements a
novel optical FlowVisor, and has cross-layer for management
and high isolation for multiple users.
This architecture provides several abstraction layers for
the management: (a) The Flexible Infrastructure Virtualization Layer (FVL) is composed of virtualized slicing and
partitioning of the infrastructure. (b) The Slice Control and
Management Layer (SCML) can monitor the status of slices.
(c) The Slice Federation Layer (SFL) can aggregates multiple slices into one integrated experimental system. (d) The
Experiment Control and Management Layer (ECML) aims to
set up experiment-specific slice parameters. It uses extended
OpenFlow controller to achieve various actions.
The architecture is tested on the platform composed of
eight NEC IP8800 OpenFlow-based switches and four Calient
DiamondWave optical switch. The result shows that the setup
time of establishing the flow path increases even for a large
number of hops.
There are other aspects of the network virtualization designs. We compare the above discussed systems with respect
to their focus points in Table 2.
FlowVisor becomes the standard scheme of the network

Smart Object/Intelligent
Things

Sensor/Things
Server
Others

Virtualizaon

MPLS

Common
Plaorm

VPN

Network virtualization not only enables infrastructure sharing, but also provides better ways to utilize the infrastructure
or to reduce the cost. Virtualization can greatly reduce the
network upgrading cost for large-scale wireless or wired
infrastructures. For example, a mobile network virtualization
scheme is designed in [95]. It has lower cost than classical
network and SDN network. A case study with a German
network is given there. The considered capital expenditures
can be reduced by 58.04% when using the SDN-based network
instead of the classical one. A qualitative cost evaluation shows
that the continuous cost of infrastructure, maintenance cost,
costs for repair, cost of service provisioning are lower.

OpenFlow

Drivers

D. Discussions

Infrastructure
as Service

Generic Interface

Fig. 15. Abstraction layers of the virtual network [96]

It is reported in [96] that the OpenFlow-based micro-sensor
networks (its network components are shown in Fig. 15) can
be seamlessly interfaced to the Internet of Things or cloud
computing applications. In traditional sensor networks, some
sensors away from the access point may not be reached.
However, by using the virtualization we form a new concept called flow-sensors, which enables smooth data transfer
between all sensors. A flow-sensor is a sensor with local
flow table and wireless communications to controllers. Fig. 16
shows an example of the advantages of a flow sensor network
over a conventional sensor network. In a conventional sensor
network, the sensors 1 and 2 cannot communicate with each
other without the access point, so node 4 is too far and is
lost; within the flow sensor network, node 4 can talk to node
8, so that node 4 can be accessed. In [96] it shows that the
flow sensor can have 39% higher reachability than a common
sensor. This is extremely useful in large-scale sensor network
(>100 sensors).
V. Q UALITY OF S ERVICE (Q O S)
In past decades, the Internet Engineering Task Force (IETF) has defined two types of Quality of Service (QoS)
architectures, IntServ (integrated services) and Diffserv (differentiated services). The IntServ is difficult to implement in
todays large networks due to too much operation overhead in
different routers. OpenFlow can provide fine-granularity QoS

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
14

Infrastructure 1

FVL
(virtualization slices 1)

Infrastructure 3

SCML

IBM

Infrastructure 2

FVL
(virtualization slices 2)

SCML

FVL
(virtualization slices 3)

SCML

SFL

ECML

User 1

SFL

ECML

User 2

Infrastructure 4

Fig. 14. Cross-layer experimental infrastructure virtualization
TABLE II
T HE COMPARISON OF THE REPORTED NETWORK VIRTUALIZATION SYSTEMS .

Network 1

System
FlowN [87]

Flexibility
Very High

Isolation
Very good

Management
Not so hard

Integrated system [90]
MAC addressing system [91]

High
High

Good
Good

Very easy
Not so hard

EHU-OEF [88]
Adaptable isolation system [92]
LibNetVirt [93]
Cross-layer experimental
infrastructure virtualization [94]

Very High
High
General

Excellent
Excellent
Average

Easy
Easy
Very Easy

General

Average

Very Easy

6

Network 1
7

5

8
4

2

Typical sensor network

5

8
4

1
3

Network 2

Outdoor access point

Network 2

√

Outdoor access point

1
3

−
−

Later on we will survey other QoS supporting schemes such
as special operating system support for SDN QoS, QoSFlow,
and so on.

6

7

FlowVisor
−(means it has equivalent
functions to FlowVisor)
−
√
(means it has better
performance
than FlowVisor)
√

2

Flow sensor network

Fig. 16. Typical sensor network and flow sensor network [96]

support (delay, jitter, throughput, etc.) [103]. This is because
OpenFlow can well control packet-level or flow-level data
delivery via its controllers. Such a fine-granularity means that
OpenFlow allows the users to specify how to handle individual
flows, which corresponds to IntServ in IETF definitions. Of
course the user can also aggregate individual flows into classes
(i.e., Diffserc). As a matter of fact, OpenFlow provides a series
of programming tools to create/recycle slices (a slice is a
virtual flow). The user can define how to allocate network
resources (queues, routers, switches, etc.) to different slices
with different priorities.
There are very few works targeting SDN QoS supporting
issues. Among the few QoS models in SDN/OpenFlow, OpenQoS [97, 98] is one of the most typical solutions. It has a comprehensive controller architecture to support scalable video
streaming in SDNs. We therefore summarize its principle first.

A. OpenFlow QoS Model
Streaming multimedia applications such as Internet conferencing, IPTV, etc., all require a strict QoS (delay /jitter)
control. As an example, the Scalable Video Coding (SVC)
[102] encodes a video segment into two parts: a base layer
and one or more enhancement layers. It is important to
guarantee the QoS of the base layer since it has the detailed
pixel information. However, current Internet structure cannot
achieve high QoS for base layers due to hard-to-control TCP
connections. Moreover, Internet tends to search the shortest
path. Once that shortest path is congested, a large percentage
of packets are dropped. However, OpenFlow does not stick
to the shortest path. By programming the controllers, we can
easily adjust the flow delivery rules. In [97] they proposed an
OpenFlow-based video delivery scheme which uses dynamic
QoS model to guarantee the best QoS for SVC base layer data.
QoS Optimization Model: In [97] an interesting OpenFlow
QoS model is proposed. The basic principle is as follows: it
formulates the dynamic QoS routing as a Constrained Shortest
path (CSP) problem. For video applications, it employs delay
variation as the constraint in the optimization function. It first
represent the entire SDN as a simple graph. It then defines
a cost function based on the delay variation constraint. The
CSP problem aims to find the best path to minimize the cost

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
15

function. To meet the packet loss constraint, it also defines
a combined constraint with the weighted sum of packet loss
measure and delay variation. The solution supports both level1 and level-2 QoS routes. Its results show that the average
quality of video streams is improved by 14% if only the
base layer is rerouted. By rerouting the video data in the
enhancement layer together with the base layer, the quality
is further improved by another 6.5%.

B. Controller Architecture for QoS Optimization
The controller proposed in [98] has the functions of route
calculation and route management. Fig.17 illustrates the controller architecture with various sub-functions. The controller
has powerful capabilities to specify QoS requirements. It can
also directly control the flow table in order to differentiate
between different priorities of traffic. The communications
between the controller and the switches may be secured by
some standards such as SSL.

C. QoSFlow Architecture
In its current version, OpenFlow is not able to configure
QoS parameters in a dynamic and on-demand manner (i.e.,
it does this manually). In order to deal with QoS problems
in dynamic approach, a framework called QoSFlow (Fig.18)
that enables QoS management in OpenFlow environment is
proposed in [139]. QoSFlow allows the management of traffic
class and queues through rules or policy. It manages QoS
resources (e.g., bandwidth, queue size) without changing the
SDN architecture. All actions are invoked by an OpenFlow
controller and in a dynamic and on-demand manner (not
manually).
QoSFlow Controller

JSON

QoSFlow
Manager

QoSFlow
Agent

Network
Administrator

QoSFlow
Monitor

QoS
Database
Client

NOX
QoSFlow API + NOX API

QoSFlow Datapath
ROUTE
CALCULATION

Routers

QoS CONTRACT
MANAGEMENT

netlink

Users
QoS
MANAGEMENT

OpenFlowQoS
(QoSFlow API + OpenFlow API)

ROUTE
MANAGEMENT

QoS Contracts
NET
MANAGEMENT

Measurement

Input
Ports

Linux Kernel’s Queueing
Disciplines and Queues

Output
Ports

User Space
Kernel Space

Packets Flow

Fig. 18. QoSFlow modules [139]

SECURITY
WEB-BASED QoS CONTRACT
ENTRY INTERFACE

OPENFLOW
NETWORK INTERFACE

h!ps
PUBLIC
INTERNET

SSL
OPENFLOW
NETWORK

Fig. 17. controller subsystems to support QoS [97].

Note that the forward layer has to implement the policing
functions in order to ensure that the clients obey the Service
Level Agreements (SLAs) specified in their QoS contracts.
The following three extra features should exist in the above
architecture: (1) Resource monitoring: The forwarders should
comprehensively monitor their available network resources
and report periodically to the controller. The controller may
poll the forwarder for such profile. (2) Resource signaling:
Each forwarder should use signaling messages to communicate
with the controller on the current resource consumption so that
certain actions can be taken by the controller, such as updating
the flow table, changing QoS parameters, etc. (3) Resource
reservation: From time to time the controller may command
a forwarder to reserve certain resources for future QoS needs
[101]. This includes the reservation of buffer size, memory
space, CPU calculation time, and other resource requirements.

QoSFlow is an extension of the standard OpenFlow controller which provides multimedia delivery with QoS. The
QoSFlow controller is based on NOX, which is responsible
for managing/monitoring actions and controlling signaling
messages. The new controller, besides NOX API, contains
the following new components: QoSFlow agent, QoSFlow
manager, QoSFlow monitor, and DB-QoSFlow client. These
four modules have been designed to extend the NOX API
with QoS features called QoSFlow API. QoS Agent is responsible for creating a communication module between an
administrator management tool and the other two QoSFlow
components: the manager and monitor QoSFlow. By using
JSON interface, the agent is able to receive policies, manage or
monitor commands from a third-part administrator application.
The QoSFlow monitor and manager components, respectively,
monitor and manage the QoS of OpenFlow domains. Fig.19
shows its controller architecture.
The QoSFlow data-path component is responsible for creating all low-level actions on the switch ports. This component
allows OpenFlow to get all the required information to run
management commands created by either the administrators
tool or through header packet information. In QoS management tool, the actions are processed in the QoSFlow Agent.
When receiving those actions, it checks the type of the received requests in order to select the next procedure. This new
message is automatically sent to controllers through NOX. The
QoS actions can be applied automatically through the packet
header information. In order to support fine-granularity QoS,

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
16

Video/audio applications
Controler-Serive
Interface

Service Layer

Standard OpenFlow controller
Topology
Management

Control Layer

Route
Calculation

Route
Management

Other controllers

Traffic
Policing

Call
Admission

Controller-Controller
Interface

Controller- Controller
Interface

Other controllers

Flow
Management

Controler-Forward
Interface
OpenFlow routers /switches

Fig. 19. QoSFlow controller architecture [139]

the incoming traffic is grouped as data flows and multimedia
flows, where the multimedia flows are dynamically placed on
QoS guaranteed routes and the data flows remain on their
traditional shortest-path routing approach.
D. Operating System for QoS Optimization
NOX, the standard network operating system, can be used
for packet-level or flow-level control. However, it does not
have the necessary APIs for QoS support. For instance, it does
not support QoS-oriented virtual network management, or endto-end QoS performance monitoring. In [100] an QoS-aware
Network Operating System (QNOX) is proposed to support
general OpenFlow QoS functions.
The QNOX system includes the following modules: WDM/ASON, IP, MPLS-TP. Here WDM/ASON can monitor
large network traffic status. QoS-aware Open Virtual Network
Programming interface (QOVNPI) allows a client to request
any type of QoS performance. The service element (SE) can
be used for QoS demand definitions, such as the required
network bandwidth, memory overhead, preferred server locations, packet loss rates, delay bounds, and security levels.
The SLA (service level agreement) and SLS (service level
specification) modules can be used to assess the OpenFlow
resource availability, that is, to check whether the network can
meet the clients QoS demands. Obviously QNOX can define
fine-granularity of QoS, such as packet-level delay or loss rate.
Based on the experimental results in [100], QNOX can quickly
calculate the routing path in less than 100ms even with over
100 nodes in the SDN. The SLA/SLS can find all network
resources in less than 1s.
E. Other QoS Supporting Strategies in SDN/OpenFlow
In [140] a SDN QoS scheme called PolicyCop is proposed to implement an open, vendor agnostic QoS policy
management architecture. It has a special software interface
for specifying QoS-based Service Level Agreements (SLAs).
PolicyCop uses the control plane of SDNs to monitor the
compliances of the QoS policies and can automatically adjusts
the control plane rules as well as flow table in the data plane
based on the dynamic network traffic statistics.
In [141] an OpenFlow QoS enhancement scheme is proposed to allow the creation or change of the behavior of the

existing routing queues. It suggests that an OpenFlow capable
switch report the queue status to the control plane. It has
a module called Queue Manager plug-in which allows the
uniform configuration of QoS capabilities in each OpenFlow
switch. Such an idea is implemented in Ofelia testbed. Its implementation is based on OpenNMS, an open-source network
management system.
In [142], an Iterative Parallel Grouping Algorithm (IPGA)
is proposed to manage the prioritized flow scheduling issue, It
has an inherent nature of parallelism for efficient execution in
OpenFlow systems. Its algorithm is based on a M-ary multirooted tree, a Fat-tree used in most data center networks. It
assumes that the SDN switches have two layers: lower pod
switches (edge switches) and upper pod switches (aggregation
switches). It formulates the flow scheduling issue as a linear
binary optimization problem.
VI. SDN S ECURITY
A. Intrusion Detection
SDN creates some new targets for potential security attacks,
such as the SDN controller and the virtual infrastructure [105].
Besides all the traditional networks’ attacking places (such as
routers, servers, etc.), SDN has some new target points such as:
(1) SDN controller: Here traditional attacks listed above also
exist; (2) Virtual infrastructure: it could have traditional attacks
on the hypervisor, virtual switch and VM (virtual machine); (3)
OpenFlow Network: attacks could occur in OpenFlow protocol
for openflow enabled devices.
In the following paragraphs, we will describe some typical
OpenFlow/SDN safety (such as failure recovery) issues and
security schemes. Here safety refers to the schemes that
overcome natural faults, and security means to overcome
intentional attacks.
A network intrusion detection and countermeasure selection
(NICE) scheme is investigated in [108]. It aims to achieve the
security in a virtual networks such as SDN and cloud computing. Cloud Security Alliance (CSA) survey shows cloud
computing security is the top concern among different types
of networks. The conventional patch-based security schemes
do not work well in cloud data centers since the users could
have full access to those centers. In [108] the attack graph
based analytical models are used for intrusion detection. NICE
includes two important phases:
(1) It uses an intrusion detection agent called NICE-A to
capture the traffic in each cloud server. A Scenario Attack
Graph (SAG) can be established and updated each time the
NICE-A scans the network. Based on the pattern analysis of
the SAG, the NICE-A knows whether or not it should act.
(2) Deep Packet Inspection (DPI) is activated if the virtual
machine (VM) enters inspection state. It can use SAG to find
security threats and VM vulnerabilities.
NICE runs low-overhead security software in each cloud
server. It includes 3 software modules an attack analyzer,
a network controller, and a VM profiling server. The VM
profiling server can monitor the network state in real-time,
and construct the operation profile for all services and ports.
It also takes care of the connectivity issues between VMs.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
17

The attack analyzer can deduce the event correlations among
different SAG nodes. It then finds potential security holes and
detect an occurring threat. The network controller can control
all configurations in each hardware device and software unit
based on OpenFlow protocols. As we can see, NICE fits SDN
very well.

B. Modular Security
Although OpenFlow (OF) decouples the data plane and control plane and thus greatly simplifies the hardware operations,
it also brings single-point security issues: once the controller is
attacked, all low-level switches are misled and cannot correctly
deliver the packets.
FRESCO-DB [109], a database module, can simplify the
SDN security key management. It defines unified session key
format and IP reputation model. Inspired by Click router
design, it uses a modular and composable security protocols.
It consists of two important parts: (1) Application layer: it
uses APIs and interpreter to support modular applications; (2)
SEK (security enforcement kernel), can be used to perform
all policy-related actions. Diverse security policies, such as
DROP, REDIRECT, QUARANTINE, can be enforced by
Security applications developed in FRESCO scripts, to react
to network threats by simply setting an action variable. The
above two parts are built into NOX. A network user can use
FRESCO script language to define various security modules.
Regarding the implementation of FRESCO, Python is used to
implement the Application Layer prototype (total around 3000
lines of codes), and runs as an OpenFlow application on NOX.

C. SDN Traffic Anomaly Detection
In [110] it proposes 4 different OpenFlow traffic anomaly detection algorithms. Each of them is evaluated in real
networks including both home and business networks. In the
following we summarize the ideas of those 4 traffic anomaly
detection algorithms:
(1) Threshold Random Walk with Credit Based Rate Limiting (TRW-CB) algorithm: As we know, a TCP connection
can be established in a much higher success rate if the server
is not attacked. By using sequential hypothesis testing (i.e.
likelihood ratio test), it analyzes each connection status and
attempt to detect the worm infections.
(2) Rate-Limiting: A virus infection can cause many connection request within very short time, while a benign traffic flow
will never have such a high request rate. This is the principle
of rate-limiting, that is, we check the request rate and detect
a malicious event.
(3) Maximum Entropy Detector: Maximum entropy calculations can be used to find traffic statistical features. By using a
baseline distribution, maximum entropy model can be used to
classify the packets into different categories, and each category
could be detected as benign or abnormal.
(4) NETAD: It acts like a firewall or filter. It simply scans
the packet header and blocks any suspicious packet based on
the packet attributions.

D. Language-Based Security
Analyzing how to program SDN in a secure and reliable
manner is discussed in [111]. The solution involves development of a new programming model that supports the concept
of a network slice. The isolation of the traffic of one program
from another is achieved with help of slices. They also
isolate one type of traffic from other. They have developed
a semantics for slices, and illustrate new kinds of formal
modular reasoning principles that network programmers can
now exploit. It provides definitions of end-to-end security
properties that slices entail and verify the correctness of a compiler for an idealized core calculus in a slice-based network
programming. They have also described their implementation
which is equipped with a translation validation framework
that automatically verifies compiled programs using the Z3
theorem prover.
It is challenging today to implement isolation in networks.
Most systems still use manual setup to block suspicious traffic.
Such a setup is often labor-intensive and vendor-specific.
In [111], it suggests that using a high-level programming
language to set up the data delivery policies and isolate
different domains. It leaves the error-prone low-level device
configurations to the SDN compilers. Such a scheme overcomes the shortcoming of NOX, which cannot easily isolate
different subnetworks when security holes are detected.
The language-based security [111] relieves the programmers
from complicated security programming due to the use of slice
isolation concept. A slice is defined as a virtual connection
consisting of routers, switches, communication ports or links.
The slices have been defined with both attributes and actions
in [111]. A slice can be isolated from another if running them
side by side in the same network does not result in slice leaking
packets into the other slice. They defined several intuitive
security properties like isolation and developed an operational
condition called separation that implies the isolation property.
Finally, they formalized a compilation algorithm and proved
that it establishes separation and isolation.

E. Loop Detection Problem
The routing loops make packets never reach the final
destination. In [112] it presents a dynamic algorithm which
is built on header space analysis, and allows the detection of
loops in SDNs. There the network model has been illustrated
as a directed graph. Hence concepts of header space analysis
has been translated into the language of graph theory. Rule
graphs and the dynamic loop detection problem are studied in
[112]. They have shown how to model a network as a directed
graph. By analyzing the reachability and connectivity of the
topology graph, a node-to-node, no-loop path can always be
found. A dynamic strongly connected component algorithm is
proposed in [112] to allow us to keep track of edge insertions
and deletions. It can also be used to detect loops in a routing
path.
A comparison of all the above SDN security schemes is
presented in the tabular form below:

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
18

TABLE III
A COMPARISON OF DIFFERENT SDN SECURITY SCHEMES .
Sources
Uses OpenFlow/NOX
Introduce new architecture
based on OpenFlow/NOX
Experiments (E) or real networks (R)
Software (S) or Hardware (H)
Introduces new language for SDN

[106]
Yes
Yes

[107]
Yes
No

[108]
Yes
Yes

[109]
Yes
No

[110]
No
No

[111]
Yes
Yes

[102]
Yes
Yes

E
S
No

E
S
No

R
S
No

E
S
No

E
S
Yes

E
S
No

E
S
No

F. SDN Safety Issue: Failure Recovery
In order to build a trustworthy SDN, we need to make a
SDN resistant to both external failures (security issues) and
internal failures (safety issues) [151]. Here external failures
refer to external, intentional attacks by adversaries. The above
discussed security solutions aim to detect and overcome external attacks. The internal failures refer to natural faults due
to some system-related shortcomings or unintentional human
factors. We regard those internal failures as safety issues.
For example, a SDN could fail if the communication link
between the controller and the switches has outages due
to bandwidth unavailability. Thus all controllers’ commands
cannot be delivered to the switches’ flow tables. If the switchto-switch path has link failure, many packets can get lost.
Therefore, some type of link quality monitoring and path
recovery schemes are needed to overcome the link failure.
There could be many of other safety issues in a SDN. For
example, the controller may not be able to synchronously
update all switches’ flow tables due to schedule management
failure. The switch may not be able to timely report traffic
delivery status to the controller (thus the controller may not
update the flow table for quite a while). When using multiple
controllers in a SDN, the controllers may not be able to keep
the consistent control due to communication delay. In the
following discussion, we will illustrate some existing schemes
that aim to address the SDN safety issues.
In [106] a fast failure recovery scheme is proposed for
OpenFlow networks. It investigated the switch-over frequency
and packet loss rate in its evaluation. It uses NOX software to
recover services.
In OpenFlow network we can immediately or proactively
add a flow entry to the table after a failure occurred. The total
recovery time is determined by the lifetime of the flow entries.
In [106] two values of timeouts are defined, one is called idle
timeout, which means the time interval that a flow entry should
be removed if not used for certain time (that is, no packet for
that type of flow entry is passing through a switch); the other
one is hard timeout, which is the maximum time interval that
a flow entry can stay. No matter which timeout occurs, it will
trigger the failure recovery.
Note that the system cannot be recovered if the controller
has no idea on what type of failure occurred. The controller
may just randomly add a flow entry in the table if the
failure type is not recognized. In [106] NOX has been used
to implement L2-learning scheme for failure detection. It is
written in C++ (called L2-lerarning switch) or in Python (it is
called L2-learning Pyswitch).
If a failure occurs, the incorrect flow entries should be

erased from all switches, and new entries should be immediately added to each switch. The controller should have robust
schemes to detect the failure, and find new routing path to
deliver the flows. The controller will check the old routing
path associated with the failed links. If the old path is still
usable, it will not establish a new path. Otherwise, new path
needs to be added to the flow entries and old entries should
be removed immediately.
In [106] Ubuntu 9.04 is used to install Open vSwitch
1.1.0 and NOX 0.9.0. Over 10K ping packets were sent
out at the pace of one packet every 10ms. The packet loss
rate is calculated by counting the number of received ping
packets. Hard timeout is set to 20 seconds, and idle timeout
is 10s. The routing loops are avoided by using spanning tree
algorithms. The path reestablishment scheme in [106] is faster
than conventional MAC re-convergence or ARP. It only uses
12 ms to recover from a link failure.
In [107] a scheme is called Operations, Administration, and
maintenance (OAM) tool is used to re-establish a new path. To
minimize the path switching time, it uses a proactive approach,
that is, a backup path is pre-stored in the flow table in case
a path fails. This scheme makes path recovery time less than
50ms. In addition, some probing packets are periodically sent
in the network. If it is not received by a node, the system
knows that a path failure occurs. If it takes a long time to
receive the probing packet, a failure is also detected. Thus
[107] provides an efficient way to recover from path failure.
VII. O PEN F LOW FOR W IRELESS AND O PTICAL
N ETWORKS
A. Overview
Why OpenFlow for wireless networks? Wireless infrastructure is more hybrid and complicated than wired ones.
Many wireless standards, such as Wi-Fi, Wi-Max, cellular
networks, etc., are all co-operating in the same backbone
for providing anywhere Internet access. Managing such a
heterogeneous wireless infrastructure is a big challenge. To
make things worse, different wireless products have their
own lower layer (physical/MAC layers) specifications, and are
very difficult to re-configure for dynamic mobile applications.
For example, Wi-Max forwards data in a point-to-point style
in microwave frequency; while Wi-Fi uses one-to-many star
topology in free frequency (2.45GHz). OpenFlow can offload
the wireless MAC layer operations to virtual machines, and
uses software-defined network programming to achieve high
flexibility and reconfigurability. OpenFlow decouples lower
layer wireless transmission from higher layer control; thus it

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
19

makes wireless data forwarding reach higher rate ( Gbits/sec).
This can fully explore 802.11 potential data rate.
The network virtualization in OpenFlow can significantly
improve the scalability of the wireless virtual LAN tagging and
firewall filtering operations. When the networks are moving to
cloud computing, it becomes harder and harder to manage
the dynamic and distributed cloud servers. OpenFlow can
easily update the cloud policies over a dynamic deployment
environment. However, it needs some innovative designs if
applying SDN/OpenFlow to wireless world since the original
SDN motivation was to use wired, high-speed switches to
perform dump data forwarding, and to use reliable wires
(not wireless) to achieve stable communications among SDN
control plane units. If we shift everything to wireless media,
how do we allocate different wireless channels for switchto-switch or controller-to-controller communications? What if
those radio channels are not available from time to time due to
signal fading and shadowing? Some studies are solving those
issues [113-118]. Later on we will use two examples (wireless
sensor networks and wireless mesh networks) to explain how
we can integrate OpenFlow with wireless technologies.
Why OpenFlow for optical networks? There is a great
deal of benefits when adopting SDN/OpenFlow for optical
network control: (1) Current optical networks have difficulties
to react independently to requests from client systems distributed at the network edge. SDN provides programmable,
abstracted interface for flexible application re-configurations
in optical control units. (2) Existing optical networks cannot
easily upgrade the software in each optical switch due to the
embedded software nature. OpenFlow could easily upgrade
services due to its separation of control and data planes. (3) SDN/OpenFlow allows multi-level abstraction via its networked
re-programming and virtualization technologies. This makes
optical network stack suit easily adapt to different network
topologies. (4) The cost of optical hardware is typically high,
especially the photonics and associated electronic components.
SDN/OpenFlow could reduce those costs due to its ’dump’
hardware operations - just simply following the flow table.
B. OpenFlow for Wireless Sensor Networks
Wireless sensor networks (WSN) have become important
platforms for environmental monitoring. There are many sensor hardware designs such as CrossBow, Imotes, etc. However,
all those sensor products cannot be easily programmed due to
vendor-specific SDK (software development kit) and the tight
integration of hardware and software in one sensor node.
Moreover, those sensors are difficult to re-task [119, 120]
if a new environmental monitoring mission is required. For
example, how can we re-program 100 sensors in a lake WSN
to detect a new type of pollution? Obviously today we need
to take each sensor out of the water and change the programs
embedded into the sensor hardware. This is not realistic in
large-scale WSN with so many nodes.
Although some over-the-air programming techniques are
used for some vendors sensor boards, their data sensing and
forwarding schemes are still vendor-specific. For example,
they may use different operating systems, or different programming languages. The programmer needs to check different

manuals to get familiar with the API functions. It will be better
if the user just simply configure a network controller based on
universal networked operating system. The sensor hardware
and embedded stack protocols could be decoupled such that
the users do not need to worry about the data forwarding
details in each sensor, and just simply configure the controllers
flow table. The data forwarding rules do not necessarily follow
the specific MAC layer protocols (such as Zigbee, 802.11, or
other protocols).
SDN/OpenFlow can well solve the above issues. It makes
each sensor just simply forward the sensor data based on the
specified flow table and rules. All those rules can be easily
changed through controllers programming. Since all nodes
follow universal operating system (such as NOX), the retasking can be easily achieved by following standard scripts
programming. A Software-Defined WSN architecture, called
sensor openflow [120], can be used to address key technical
challenges mentioned above. We illustrate its main ideas in
Fig.20.
It has three layers: the application layer has all sensor data
query related applications such as local data processing; the
control plane and data plane are totally separate: the former
can remotely re-configure the sensor parameters, and the
latter can check the flow table and perform the corresponding
actions. Its main idea is to make the large-scale sensor network
easy-to-manage via programmable control plane and usercustomizable flow table. Sensors are no longer applicationdependent and the sensor data query policies can be easily
reset. Sensor OpenFlow allows policy changes in an easy style
since a programmer can simply change the controllers software
instead of dealing with the wireless sensors.
Application layer

Sensor data reporting

Sensing and filtering

Responding to query

Local data mining

Data fusion

Control Plane

Sensor re-configuration

Data compression

Sensor query strategy control

Data Plane
... ... Event ID

Sensor ID

Sensor Actions

Other flow table fields

... ... #Fire_event

#101 ~ #110

Report location & temp

Such as reporting interval

Fig. 20. SDN-based sensor networks

C. OpenFlow for Wireless Mesh Networks
OpenFlow could be very useful for wireless mesh network (WMN) management. Today WMN is often used in
community networks or military applications for re-tasking
from time to time. For example, an Internet provider may
re-program a community mesh network to set up different
IPTV services. A military center may want to re-configure
a wireless network to adapt to different surveillance scenarios. Existing mesh network nodes are full fledged with
all physical to application layer functionalities. The network
manager needs to setup each mesh node individually since
each node may have vendor-specific programming features or
proprietary device management profiles. Overall, today it is

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
20

very difficult to perform rapid re-tasking or policy changes
in the heterogeneous mesh clients (such as laptops, PDAs,
phones, etc.) in a mesh network. OpenFlow decouples network
control and hardware communications completely, and leave
only basic data forwarding functions in each node, while the
entire network can be easily re-programmed through a standard network OS (such as NOX) running in a control panel.
As long as different vendors products support OpenFlows flow
table managements, a mesh network can be easily re-tasked
through a standard network control script programming.
To make OpenFlow appliable to WMN, we need to overcome a few challenges [121-122]:
• Challenge 1: Fading channel: Unlike Standford OpenFlow testbed where fixed wired network is the backbone,
WMN has wireless channels everywhere (issues: radio
fading, hidden terminal problem, wireless broadcast nature, etc.).
• Challenge 2: Dynamic Topology: Due to WMN link
variations and nodes membership dynamics, the network
topology changes at a much higher pace than in wired
network. The OpenFlow needs to build a control plane
to perform autonomous topology discovery and swiftly
react on changes of the WMN topology.
• Challenge 3: In-band or out-band control: OpenFlow
often adopts out-of-band signaling, that is, the channel
to NOX is separate from the actually data forwarding
network. However, in WMN we may not have different
RF channels for separate control. On the other hand, using
in-band control would decrease data network throughout.
Fig.21 shows the basic principle of using OpenFlow for
WMN control. The WMN has both mesh routers and mesh
clients. A radio channel control strategy is achieved by the
control panel for router-to-router, router-to-client, and clientto-client communications. The control server in control plane
can perform mobility management, routing strategy, and channel assignment.
•Mobile Control
•Roung Control
•Rule Learning
•Channel Assignment

Control Server

To NOX

OpenFlow Control Path
Internet
OpenFlow Data Path

WMN
Control Rule
Database

Flow Table

CISCO SYSTEMS

CISCO SYSTEMS

CISCO SYSTEMS

iMac

CISCO SYSTEMS

CISCO SYSTEMS

WMN Hardware (mesh routers or mesh access
points or mobile nodes )

channels are used for controller-to-server communications
since the controllers commands cannot be lost even there is
signal fading.
D. OpenFlow for Optical Networks
Today optical networks have become the fastest Internet data
transmission approaches due to the high-speed light propagation in optical fibers. Typically an optical network consist
of nodes such as Wavelength Cross-Connects (WXC), Reconfigurable Optical Add-Drop Multiplexers (ROADM), and
Photonic Cross-Connects (PXC) [123]. Current optical nodes
can be controlled by Element Management System (EMS) and
the Network Management System (NMS), which uses either
manual or semi-static style for lightpath provisioning [124].
Although this approach is reliable, it is difficult to design
a control plane technique to achieve a control of dynamic
wavelength paths in metro/backbone optical networks. Such
a control plane should be able to reduce operational expense,
shorten the data transmission latency, and should be highly
scalable to the network traffic. An important optical control
scheme is called Generalized Multi-Protocol Label Switching
(GMPLS) [125]. It is a distributed packet forwarding control
scheme. However, It has not been popularly used in optical
network products [126]. One important reason is its complex
control scheme that is not suitable to dynamic control of both
IP and optical layers via a unified control plane (UCP).
SDN architecture, in particular, the OpenFlow protocol,
could become a solution to the above issue. Although the initial purpose of using OpenFlow is to create a re-programmable
network, it can also serve as a promising candidate for a UCP
solution in hybrid networks [127]. It has been studied in optical
network enhancements [128-130]. But it is still in the early
stage for real networking.
In [124] an Openflow based PXC architecture is proposed.
It uses a concept called virtual Ethernet interfaces (veths) to
connect to each OpenFlow switch. Those veths look ”virtual”
from the viewpoint of the PXC physical interfaces. Thus
the control plane can easily manage all PXC interfaces. The
virtual OpenFlow switch is also called OpenFlow agent. The
integrated OpenFlow agent and the PXC is called OpenFlowenabled PXC (OF-PXC). It can be managed by a NOX
controller. When the packets are received by the NOX, it can
either insert a new record to the flow table (if this is the first
packet) or decides which veth to forward the data.

䙊ؑຄ

WMN topology

Fig. 21. OpenFlow for WMN management

In [121] an OpenFlow-enabled mesh routing scheme is
proposed. It has OpenFlow-enabled routers, clients and gateways. Each node has multiple radio cards for multi-radio
communications. The data path uses local sockets to talk with
the control plane units. The control path communicates with
NOX via secure channel. Connection to Internet is achieved
through mesh gateways.
In [121] the in-band wireless communications are used
between the controller and the switches. The high-quality

VIII. A N E XAMPLE OF C OMPLETE SDN S YSTEM
To illustrate a complete SDN system, here we use a good
reference solution called MobileFlow [144] which uses a
SDN architecture to implement a mobile network. A softwaredefined mobile network (SDMN) provides maximum flexibility, openness, and programmability to future carrier. It designs a
special SDN data plane called MobileFlow forwarding engine
(MFFE). All MFFEs are interconnected by an underlying
IP/Ethernet transport network. Its SDN control plane has
MobileFlow controller (MFC). The MFC has mobility management entity (MME)

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
21

As shown in Fig.22, it has MobileFlow and OpenFlow levels
for the management convenience. In both of them the control
plane is decoupled from the data plane. The data forwarding
function in MFFE is fully defined in software, while the
control software can steer the user flows to different service
enables (such as video caching & optimization). Those services can be distributed throughout the mobile network. Note
that the users traffic can go through both MobileFlow level and
OpenFlow level, or, it just goes through the OpenFlow level
and reaches the Internet. Fig.24 also shows the OpenFlowbased decoupling of the IP/Ethernet transport network in the
lower level. This is because in some cases the user traffic may
not go through the mobile network infrastructure (and just
stays in the wired network, no wireless).

regular OpenFlow level. Thus it can directly use OpenFlow
language syntax for network definition. For example, it can
use the following language abstraction to monitor a port 80
traffic:
Def switch join (switch)):
P = inport:2, tp src:80
Install (switch, p, DEFAULT, [ ])
Query stats (switch, p)
Such a high-level language can run in NOX and interpreted
by all OpenFlow-compatible routers. Overall, the MobileFlow
system is a complete SDN/OpenFlow implementation in mobile applications. It allows flexible re-configuration of mobile
channel allocation, QoS parameters, mobile access, and service
roaming between wireless networks.

Control Plane
MobileFlow Controller

Mobile Apps… …

.
. Different types
. of gateways

Internet

OF Control interface

Video cache &
optimization

……

OF Data Fwd Engine

OF Control interface
OF Data Fwd Engine

OF:
Openflow

IX. R ESEARCH T RENDS
There are still many questions on how to make the SDN
more efficient, how to optimize it across all the network sets,
and how to achieve tradeoffs between different implementations. There is a need to have quantitative metrics/approach for
evaluating the performance and efficiency of the SDN such as
its scalability, availability and latency. In the following we
point out some important future research topics.

Fig. 22. Software defined mobile network

MobileFlow Controller: Such a controller can perform
network-level management including topology auto-discovery,
device monitoring, topological resource view, topology virtualization, etc. More importantly, it can handle all mobilityrelated activities, such as mobility anchoring, service migration, channel handoff, etc. A network operator can freely
use MFFEs from different vendors. The operator can also
use MFFEs to adopt novel mobile network architectures. The
system supports m:1 mapping between MobileFlow applications and NFFEs since each mobile application belongs to a
different control plane, and therefore enabling multitenancy.
Mobile Management: Supporting mobility based on 3GPP
or other systems can be easily realized by introducing the
mobile applications above the northbound interface of the
MFC. The MFC cab send out flow control rules to each
MFFEs involved in handling the particular flow. The channel
handoff (i.e., communication frequency switching) can be
easily implemented in each MFC when the QoS requirements
are not met in the multimedia applications.
Testbed implementation: It uses COTS x86 based generalpurpose servers and OpenFlow-supported routers/switches
from different vendors. It enables the software-based definition
of different mobile networks (3G, 4G, etc.) with different
characteristics (radio coverage, bandwidth, radio frequency,
etc.). It supports virtualization for both control- and dataplane resources. The same MFFE can be reused by different
types of virtual networks. Each virtual mobile network can
evolve and be upgraded solely by replacing the corresponding
virtual machine software units in the control plane servers. The
MFFEs remain intact. The entire testbed is interconnected via
COTS LAN switches.
Note that the above system adds MobileFlow level above

A. Intelligent Flow Table / Rules Management
It is true that the motivation of designing SDN/OpenFlow
is to simplify the network switches’ operations: instead of
using vendor-dependent, embedded software in each switch,
SDN only assumes ’dump’ data forwarding functionalities in
each switch. The switch just simply checks the flow table to
determine how to forward each received data packet.
The tricky part is: although the switches do not analyze the
traffic, they can always report forwarding results to the higher
layer - OpenFlow controller. The results could be simple
success or failure for a data forwarding operation, or some
error messages (such as switch failure), or other forwarding
status data. In the current OpenFlow specifications, they do not
specify how to handle those feedback data. They just point out
that the flow table should be set up based on a set of rules
defined by the controller. But the issue is: since the switches
could have high traffic burden, it will slow down their data
forwarding operations if (1) network traffic is heavy, and/or (2)
the flow table is large and has complex rules. It is important
to perform self-learning in the controllers based on the pattern
analysis of the traffic flowing through each switch.
We believe that the future trend of SDN/OpenFlow will
include high intelligence in flow table / rules control. We
illustrate our idea in Fig.23. The network controller can learn
what’s going on based on the feedback from the switches. For
example, if the switches report a long delay for a sourcedestination IP pair, it indicates a possible routing loop or
switch congestion somewhere. When the controller analyzes
the statistical patterns from the switches’ feedback data, it can
use any of the recent learning tools (such as Bayesian learning,
reinforced learning, etc.) to deduce the optimal ’actions’ in
the future in order to obtain a higher accumulative reward.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
22

The reward could be defined based on the QoS performance
metrics. The ’actions’ could be any packet handling operations
or any policy changes.
Statistical analysis could be based on any traffic pattern
data mining schemes. Through dimension reduction, we could
extract the intrinsic features from complex, multi-attribute
traffic data. Since some dimensions are not useful in pattern
recognition, they could be removed by using Principle Component Analysis (PCA), Non-negative Matrix Factorization
(NMF), or other dimension reduction schemes.

Application layer (scientists'
experiments; data query; Internet
surfing; environment monitoring...)

OpenFlow
Protocol

OpenFlow
Protocol
OpenFlow
Controller

The switches report data forwarding
status to the controller for analysis

Policy#1
#1
Policy
#1
Policy

ØSta!s!cal Learning
ØReinforced Learning
ØBayesian Learning
ØTraﬃc Analysis
Ø………

Fig. 23. Intelligent flow table / rules management

B. Scalable Controller Management
With the application of SDN/OpenFlow in larger networks,
the network controllers could become a performance bottleneck due to large amount of incoming signaling messages
and forwarding requests. Those controllers do not necessarily
be deployed in the same sub-net since a company network
may cross multiple places (even in different countries, such
as IBM, Intel, etc.). The controllers located in a distributed
network may compete for common computing resources (such
as communication channels).
To manage the coordination issue of large-scale controllerto-controller communication system, a carefully designed
scheduling strategy with collision avoidance should be used.
On one hand, SDN administrators want to see a virtually
consistent controller system. On the other hand, they need
to design a virtual-to-physical mapping model to manage
the physically distributed controllers. Perhaps a tree-based
hierarchical management scheme could be used to coordinate
those controllers. The higher level controllers should be able
to handle more heavy requests. The root controller then communicates with NOX on the global requests. Fault tolerance
techniques could be used for controllers system. Even one
controller is down, others should be able to compensate for the
missing operations. By using fault tolerance model, we could
figure out the optimal controller deployment strategy, such as
which controller should be deployed in which sub-net.
Resource sharing strategies should also be made among
controllers. By using a queueing model with shared resource
pool, we could calculate the controller serving time and
waiting time.
Note that the flow table could handle the packets in different
granularity levels. It could define the packet forwarding in

individual packet level; or, it could define the flow-level
forwarding actions. The controllers must be able to manage
different granularity levels in order to accurately adjust the
flow table status (such as adding or deleting the forwarding
rules).
C. Highly Flexible Language Abstractions
The SDN programming language should be able to adapt
to frequent flow rules changes. It should also be suitable to
policy changes due to network topology change, regular SDN
maintenance, emergent failures, etc. An SDN programmer
would like to use a good language to perform policy changes
atomically to each switch. However, atomic change is difficult
to implement since it needs the disruption of the entire network
during policy change [29]. The future SDN language should
at least achieve two levels of abstractions if the atomic level
cannot be achieved:
(1) In packet level, the language should be able to specify
the policy changes for all packets that meet similar attributes.
It needs to make sure that all packets belonging to the same
context are delivered with the same structural invariants such
as loop-freedom.
(2) In flow-level, the language should allow the definitions
of flow-oriented rules/policies, such as ququeing models, delivery order, load balancing, etc. The compliers and run-time
system should be able to respond to the aggregated flow-level
rule changes.
Another language abstraction trend is to support modular
programming, that is, it should allow the handling of isolation
issues between multiple programs that control different portions of the traffic. Each piece of program has different tasks,
some target host monitoring, some for failure recovery, some
for virtualization, and so on. How do we make all pieces of
program interface to each other in a transparent way? This
needs a high level of abstraction for SDN programming.
D. Low-cost Fine-granularity QoS Implementation
As we know, QoS strategies include class-based differentiated service (DS) and fine-grained integrated service (IS).
SDN/OpenFlow could define packet-level or flow-level priorities and performance metric. Therefore, it can be used to
support IS. Although some IS-oriented OpenFlow QoS models
are defined [98, 99], not many practical implementations are
conducted. The main challenges include:
(1) The integration of multimedia coding with OpenFlow
QoS management: There are many video encoding standards.
Especially some standards such as H.264+/SVC can support
priority-based coding, that is, different video data layers could
be assigned different priorities, and the enhancement layer
has the most important video data. OpenFlow could support
such video streaming by controlling different flows in different
policies. However, the detailed flow rules need to be integrated
with different video encoding standards, which needs further
research;
(2) Load balancing: Content Distribution Networks (CDNs)
need load balancing capability in order to distribute the heavy

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
23

authentication between experimenters and slices, key escrow
issue, etc.
Load Balancer
1

2

3

4

5

6

25 26 27 28 29 30

1

2

3

4

5

6

25 26 27 28 29 30

7

8

9

10 11 12

13 14 15 16 17 18

19 20 21 22 23 24

31 32 33 34 35 36

37 38 39 40 41 42

43 44 45 46 47 48

Load Balancer

9 10 11 12

13 14 15 16 17 18

19 20 21 22 23 24

31 32 33 34 35 36

7

8

37 38 39 40 41 42

43 44 45 46 47 48

Client

Fig. 24. Load Balancing: Integrate server balancer selection with path
selection [98]

workload across the network elements. While most of conventional load balancing strategies for multimedia streaming (live
or on-demand) over CDNs rely on server-based load balancing,
OpenFlow allows the load balancing actions in each possible
flow path (Fig.24). The future research needs to define the
detailed procedure in OpenFlow controller in order to achieve
such an integrated server balancer selection and path selection.
(3) Use Cross-layer design style to optimize QoS: Many
QoS optimization schemes are based on cross-layer designs
[131-133]. However, OpenFlow removes the boundaries of
traditional Internet, and uses open, programmable model. Then
the issue is: how do we implement cross-layer design style in
OpenFlow in order to share all available network parameters
in different places for QoS optimization?

E. Resilient Security in SDN
SDN/OpenFlow uses network virtualization technology to
simplify the resource management of the large network. It
enables the definition of virtual slices/slivers for different
physical utilities (such as hard disk, memory, etc.). A slice
could include several slivers. Each slice/sliver pair could be
assigned a unique ID. Due to resource limitations, some
malicious OpenFlow terminals may use attacks to try to
overuse the resource slice/slivers. Therefore, we need to create
a scale security scheme that can overcome the resource access
attacks in slice/sliver establishment.
Some SDN security challenges include: (1) Scalability issues: If many slivers are needed in a slice, it has high overhead
to generate/distribute different session keys for different slivers. (2) Sliver deactivation: When a sliver deactivates a sliver,
we need to make sure none of the stored data can be decoded
independently by that user (this is called forward secrecy).
Here we suggest a possible security solution based on
ID-based cryptography [135]. While conventional public key
schemes use random string to generate public key, ID-based
crypto generates public keys from user IDs. Thus, it makes
key management in SDN much easier since we don’t need to
distribute public keys to SDN users. Moreover, the encryption/decryption can be done offline (thus a key generation
center is not needed). To implement the above ID-based
security, some issues need to be addressed such as mutual

F. Robust Wireless Integration
Although OpenFlow has been well developed in wired, local
network, there are very few studies on its performance in
wireless networks. All the existing wireless network OpenFlow designs [113-118] have not overcome the following two
challenging issues:
(1) Integrated management of channel access and data
forwarding: Many wireless networks support multi-channel
communications among routers and clients, especially in cognitive radios. Therefore, each wireless node needs to detect
available channels, and select the high-quality ones. Moreover,
the nodes can change physical characteristics for optimal
link radio communications. Thus in a wireless networks the
OpenFlow data panel must perform efficient channel sensing/access. However, the existing OpenFlow standards only
define data forwarding functions in the hardware. We will
need to significantly improve the existing OpenFlow model
(including its control/data panels task division, FlowVisor
control, network visualization, etc.) by designing a brandnew flow-table management scheme. Such a scheme may use
reinforcement learning to simultaneously manage two flow
tables one for real-time data forwarding and another for multichannel sensing/selection.
(2) Conflict-free Scheduling of Control traffic and data
traffic: Unlike wired OpenFlow model that can use cables
to easily achieve control/data packet communications among
nodes, wireless network uses unreliable wireless links for
both control panel communications and data panel packet
forwarding. The control panel demands a high-quality channel
for loss-free delivery, while the data panel should use other
available channels for routing. Therefore, a carefully designed
channel allocation and packet scheduling scheme is required
for conflict-free control/data traffic delivery in routers and
nodes.
X. C ONCLUSIONS
In this paper we have comprehensively surveyed the design
issues for SDN/OpenFlow. Especially we have covered all
important issues in concrete network implementation including
language abstraction, controller design, virtualization scheme,
QoS support, security issues, and wireless/optical network
integration.
Below we briefly summarize some important aspects for
highlight: SDNs have many applications including developing
new protocols prior to implementing them in real networks,
increasing connectivity in rural environments, making both
cloud based and regular data centers better, and supporting
mobile device offloading. As the Internet continues to grow
and becomes available to increasing more people, networks
will need to be able to adapt to ever changing circumstances.
SDNs allow the data and control planes to be separated, and
hence to be easier for improvements.
Network virtualization based on OpenFlow is a successful
implementation of Software Defined Networking, and its development offers users a great deal of convenient services. We

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
24

have reviewed different virtualization architectures that focus
on the improvement of the network flexibility, isolation and
management. It can be seen that embedding additional module
or abstraction layer on the top of OpenFlow or FlowVisor
provides solutions to these challenges. Utilizing the database
can also help to simplify the creation of the abstraction layer.
QoS is an import issue in many applications especially in
streaming media,VoIP, Videoconferencing, and so on. Many
experiments have been conducted to make OpenFlow support
QoS control. However, these designs are still under testing
phase, and need to be further examined. Many designs are
related to optimization problems, such as dynamic rerouting
for SVC, dynamic QoS re-negotiation for multimedia flows,
etc. And the solution needs heavy calculations in reality as the
dimension increases. It also needs a comprehensive test before
being applied to real world applications. Many experiments
are actually under a small scale of tests to verify the proposed
design, and no large-scale experiments have been performed
yet.
Security and privacy are always important in any network.
OpenFlow brings many new security challenges due to the
virtual network management. It is important to design new
low-overhead security/privacy schemes to protect the virtualto-physical mapping protocols in SDN/OpenFlow.
We have also pointed out some important unsolved research
issues in this exciting field. Those issues may serve as the thesis/dissertation topics for graduate students. SDN/OpenFlow
is a relatively new field, and many practical design issues
are waiting for in-depth investigations. We believe that this
comprehensive survey could help R&D people to understand
the state-of-the-art in SDN/OpenFlow.
XI. ACKNOWLEDGMENT
We sincerely thank the following people for their help with
this survey: Ashley Gerrity, Muhammad Farooq, Ting Zhang,
Rui Ma, Colby Dickerson, Xingang Fu, Nagaraj Hegde, (they
are all with ECE department at the University of Alabama),
and Athanasios V. Vasilakos (University of Western Macedonia in Greece). They have provided valuable comments and
inputs on some of the above discussed topics. We also appreciate the editor and reviewers’ time and effort for reviewing
this paper.
R EFERENCES
[1] S. Ortiz, “Software-Defined Networking: On the Verge of a Breakthrough?” Computer, vol. 46, no. 7, pp. 10-12, 2013.
[2] H. Kim and N. Feamster, “Improving network management with
software defined networking,” IEEE Communications Mag., Vol. 51,
No. 2, pp. 114-119, 2013.
[3] K. Bakshi, “Considerations for Software Defined Networking (SDN):
Approaches and use cases,” in Proc. of IEEE Aerospace Conf., 2013 ,
pp. 1-9.
[4] S. Agarwal, M. Kodialam, and T. V. Lakshman, “Traffic engineering
in software defined networks,” in Proc. of IEEE INFOCOM, 2013, pp.
2211-2219.
[5] S. Fang, Y. Yu, C. H. Foh, and K. M. M. Aung, “A Loss-Free Multipathing Solution for Data Center Network Using Software-Defined
Networking Approach,” IEEE Trans. on Magnetics, vol. 49, no. 6, pp.
2723- 2730, 2013.
[6] S.H. Yeganeh, A. Tootoonchian, and Y. Ganjali, “On scalability of
software-defined networking,” IEEE Communications Mag., vol. 51,
no. 2, pp. 136-141, 2013.

[7] S. Das, G. Parulkar, N. McKeown, P. Singh, D. Getachew, and L. Ong,
“Packet and circuit network convergence with OpenFlow,” in Proc. of
Optical Fiber Communication Conference and Exposition, Mar. 2010,
pp. 1-3.
[8] R. Sherwood, M. Chan, and A. Covington, “Carving research slices
out of your production networks with openflow,” ACM SIGCOMM
Computer Communication Review, vol. 40, no. 1, pp. 129-130, 2010.
[9] OpenFlow, http://www.openflow.org/.
[10] Open Networking Foundation, https://www.opennetworking.org/.
[11] C. S. Li and W. Liao, “Software Defined Networks”, Editorial, IEEE
Comm. Mag., Feb. 2013.
[12] M. Casado, T. Koponen, S. Shenker, and A. Tootoonchian, “Fabric: a
retrospective on evolving SDN,” in Proc. of Workshop on Hot Topics
in Software Defined Networking, Aug. 2012, pp. 85-90.
[13] Y. Kanaumi, S. Saito, and E. Kawai, “Toward large-scale programmable
metworks: lessons learned through the operation and management of a
wide-area Openflow-based network,” in Proc. of Int. Conf. on Network
and Services Management, Oct. 2010, pp. 330-333.
[14] H. Fei, Network Innovation through OpenFlow and SDN: Principles
and Design, Taylor & Francis LLC, CRC Press, to appear in 2014.
[15] B. Lantz, B. Heller, and N. McKeown, “A network in a laptop:
rapid prototyping for software-defined networks,” in Proc. of ACM
SIGCOMM Workshop on Hot Topics in Networks, New York, NY, USA,
2010, pp. 19:1-6.
[16] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,
J. Rexford, S. Shenker, and J. Turner, “Openflow: enabling innovation
in campus networks,” ACM SIGCOMM Computer Communication
Review, vol. 38, no. 2, pp. 69-74, 2008.
[17] T. D. Nadeau and P. Pan, “Software Driven Networks Problem Statement,” IETF Internet-Draft (work-in-progress), draft-nadeau-sdnproblem-statement-01, Oct. 2011.
[18] M. Yu, J. Rexford, M. Freedman, and J. Wang, “Scalable flow-based
networking with difane,” ACM SIGCOMM Computer Communication
Review, vol. 41, pp. 351-362, 2010.
[19] K. Yap, M. Kobayashi, R. Sherwood, T. Huang, M. Chan, N. Handigol,
and N. McKeown, “Openroads: Empowering research in mobile networks,” ACM SIGCOMM Computer Communication Review, vol. 40,
no. 1, pp. 125-126, 2010.
[20] P. Dely, A. Kassler, and N. Bayer, “Openflow for wireless mesh
networks,” in Proc. of Int. Conf. on Computer Communications and
Networks, pp. 1-6, 2011.
[21] Y. Hu, W. Wang, X. Gong, X. Que, and S. Cheng, “Reliabilityaware controller placement for Software-Defined Networks,” in Proc.
of IFIP/IEEE International Symposium on Integrated Network Management, 2013, pp. 672-675.
[22] P. T. Congdon, P. Mohapatra, M. Farrens, and V. Akella, “Simultaneously reducing latency and power consumption in OpenFlow switches,”
IEEE/ACM Trans. on Networking, vol. PP, no. 99, pp. 1-14, 2013.
[23] A. Khan and N. Dave, “Enabling hardware exploration in softwaredefined networking: a flexible, portable OpenFlow switch,” in Proc.
of Annual Int. Symp. on Field-Programmable Custom Computing
Machines, 2013, pp. 145-148.
[24] “The
OpenFlow
switch
consortium,”
[Online]
http://www.openflow.org/.
[25] Y. Kanaumi, “OpenFlow switch demonstration at GENI conference 3rd
on JGN2plus/APAN”, The 27th APAN Meeting, Mar. 2009.
[26] “OpenFlow switch specification, version 1.0.0,” [Online]
http://www.openflow.org/documents/openflow-spec-v1.0.0.pdf
[27] “OpenFlow in Europe − linking infrastructure and applications,”
[Online] http://www.fp7-ofelia.eu/
[28] Y. Kanaumi, “Large-scale OpenFlow testbed in Japan,” The 31st APAN
Meeting, Feb. 2011.
[29] N. Foster, M. J. Freedman, A. Guha, and R. Horrison, “Languages for
software-defined networks,” IEEE Communication Mag. Feature Topic
in Software Defined Networks, vol. 51, no. 2, pp. 128-134, Feb. 2013.
[30] F. de O. Silva, J. H. de S. Pereira, P. F. Rosa, and S. T. Kofuji,
“Enabling future Internet architecture research and experimentation by
using software defined networking,” in Proc. of European Workshop
on Software Defined Networking, pp. 73-78, Oct. 2012.
[31] S. Hasan, Y. Ben-David, C. Scott, E. Brewer, and S. Shenker, “Enhancing rural connectivity with software defined networks”, in Proc.
of ACM Symposium on Computing for Development, 2013, no. 49:1-2.
[32] R. Narayanan, S. Kotha, G. Lin, A. Khan, S. Rizvi, W. Javed, H. Khan,
and S. Khayam , “Macroflows and microflows: enabling rapid network
innovation through a split SDN data plane”, in Proc. of European
Workshop on Software Defined Networking , 2012, pp. 79-84.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
25

[33] B. Boughzala, R. Ben Ali, M. Lemay, Y. Lemieux, and O. Cherkaoui,
[63]
“OpenFlow supporting inter-domain virtual machine migration”, in
Proc. of Int. Conf. Wireless and Optical Communications Networks
(WOCN), 2011, pp. 1-7.
[34] C. Baker, A. Anjum, R. Hill, N. Bessis, and S. L. Kiani, “Improving
[64]
cloud datacenter scalability, agility and performance using OpenFlow,”
in Proc. of Int. Conf. on Intelligent Networking and Collaborative
Systems, 2012, pp. 20-27.
[35] A. Gember, C. Dragga, A. Akella, “ECOS: leveraging software-defined
[65]
networks to support mobile application offloading,” in Proc. of the
eighth ACM/IEEE symposium on Architectures for networking and
communications systems, 2012, pp. 199-210.
[66]
[36] Vijay Mann, Anilkumar Vishnoi, Kalapriya Kannan, Shivkumar Kalyanaraman, ”CrossRoads: seamless VM mobility across data centers
through software defined networking” in Proc. of IEEE Network
[67]
Operations and Management Symposium, 2012, pp. 88-96.
[68]
[37] P. A. A. Gutirrez and D. R. Lopez, “An OpenFlow Network Design
Cycle,” Network Innovation through OpenFlow and SDN: Principles
[69]
and Design, Taylor & Francis LLC, CRC Press, to appear in 2014.
[38] R. Stallman, R. Pesch, and S. Shebs, Debugging with GDB: the Source
[70]
Level Debugger, Boston, USA: GNU Press, 2002.
[39] The Eclipse Foundation, [online] http://www.eclipse.org.
[40] G. T. Heineman and W. T. Councill, Eds, Component-Based Software
[71]
Engineering: Putting the Pieces Together, Boston, USA: AddisonWesley Longman Publishing, 2001.
[41] L. M. Correia, Ed, Architecture and Design for the Future Internet,
Spinger, 2011.
[72]
[42] A. de C. Alves, OSGi Application Frameworks, Manning Publications,
2009.
[43] J. Highsmith and A. Cockburn, “Agile software development: The
Business of Innovation,” Computer, vol. 34, no. 9, pp. 120-122, Sept.
[73]
2001.
[44] Kai Petersen, Claes Wohlin, and Dejan Baca, “The waterfall model in
large-scale development,” in Proc. of Int. Conf. on Product-Focused
Software Process Improvement, 2009, pp. 386-400.
[74]
[45] OpenVSwitch, [online] http://openvswitch.org/development/openflow1-x-plan.
[46] Pica8
Open
Network
Fabric,
[online]
[75]
http://www.pica8.org/solutions/openflow.php.
[47] Indigo
−
Open
Source
OpenFlow
Switches,
[online]
http://www.openflowhub.org/display/Indigo/.
[48] NOX, [online] http://www.noxrepo.org/nox/about-nox/.
[76]
[49] POX, [online] http://www.noxrepo.org/pox/about-pox/.
[50] Trema: Full-Stack OpenFlow Framework in Ruby and C, [online]
https://github.com/trema/.
[77]
[51] Floodlight:
a
Java-based
OpenFlow
Controller,
[online]
http://floodlight.openflowhub.org/.
[52] David Erickson, [online] https://openflow.stanford.edu/display/Beacon/Home.[78]
[53] Floodlight
Is
An
Open
SDN
Controller,
[online]
http://floodlight.openflowhub.org/.
[79]
[54] OpenStack: Open source software for building private and public
clouds, [online] http://www.openstack.org/, 2012.
[55] A. Orebaugh, G. Ramirez, J. Burke, and L. Pesce, Wireshark &
[80]
Ethereal Network Protocol Analyzer Toolkit (Jay Beale’s Open Source
Security), Syngress Publishing, 2006.
[56] ns3. http://www.nsnam.org.
[81]
[57] J. Pelkey, Openflow software implementation distribution, [online]
http://code.nsnam.org/jpelkey3/openflow.
[58] B. Lantz, B. Heller, and N. McKeown, “A network in a laptop:
[82]
rapid prototyping for software-defined networks,” in Proc. of ACM
SIGCOMM Workshop on Hot Topics in Networks, Hotnets-IX, 2010,
pp. 19:1-6.
[59] T. L. Hinrichs, N. S. Gude, M. Casado, J. C. Mitchell, and S.
[83]
Shenker, “Practical declarative network management,” In Proc. of ACM
Workshop on Research on Enterprise Networking, 2009, pp. 1-10.
[60] N. Foster, R. Harrison, M. J. Freedman, C. Monsanto, J. Rexford, A.
[84]
Story, and D. Walker, “Frenetic: a network programming language,” in
Proc. of ACM SIGPLAN Int. Conf. on Functional programming, 2011,
pp. 279-291.
[85]
[61] N. Handigol, B. Heller, V. Jeyakumar, D. Mazires, and N. McKeown,
“Where is the debugger for my software-defined network?” In Proc.
of Workshop on Hot Topics in Software Defined Networks, 2012, pp.
55-60.
[86]
[62] Y. Chiba and Y. Nakazawa, “Tremashark: A bridge
for
printing
various
events
on
wireshark,”
[online]
http://github.com/trema/trema.gitmaster/tremashark.

A. Wundsam, D. Levin, S. Seetharaman, and A. Feldmann, “Ofrewind:
enabling record and replay troubleshooting for networks,” in Proc. of
USENIX Conf. on USENIX Annual Technical Conference, 2011, pp.
29-29.
E. Al-Shaer and S. Al-Haj, “FlowChecker: configuration analysis and
verification of federated openflow infrastructures,” in Proc. of ACM
workshop on Assurable and Usable Security Configuration, 2010, pp.
37-44.
M. Canini, D. Venzano, P. Pereni, D. Kostic, and J. Rexford, “A NICE
way to test openflow applications”, in Proc. of USENIX Conference on
Networked Systems Design and Implementation, 2012, pp. 10-10.
M. Canini, D. Venzano, P. Pereni, D. Kostic, and J. Rexford,
“A NICE way to test OpenFlow controller applications,” [online]
http://code.google.com/p/nice-of/.
GENI: exploring networks of the future, [online] http://www.geni.net.
Ofelia: OpenFlow test facility in Europe, [online] http://www.fp7ofelia.eu.
JGN-x
Utilization
Procedure.
[online]
http://www.jgn.nict.go.jp/english/info/technologies/openflow.html.
M., Christopher and A. Story, “Language Abstractions for SoftwareDefined Networks,” IEEE Comm. Mag., vol. 51, no. 2, pp. 128-134,
2013.
K., Daisuke, K. Suzuki, and H. Shimonishi, “A design and implementation of OpenFlow Controller handling IP multicast with Fast
Tree Switching,” in Proc. of IEEE/IPSJ International Symposium on
Applications and the Internet, 2012, pp. 60-67.
N. Foster, A. Guha, M. Reitblatt, A. Story, M. J. Freedman, N. P.
Katta, C. Monsanto, J. Reich, J. Rexford, C. Schlesinger, D. Walker,
and R. Harrison, “Languages for software-defined networks,” IEEE
Communications Mag., vol.51, no.2, pp. 128-134, Feb. 2013.
H. Kudou, M. Shimamura, T. Ikenaga, and M. Tsuru, “Effects of
routing granularity on communication performance in OpenFlow networks,” in Proc. of IEEE Pacific Rim Conference on Communications,
Computers and Signal Processing (PacRim), 2011, pp. 590-595.
Z. Bozakov and P. Papadimitriou, “AutoSlice: automated and scalable
slicing for software-defined networks,” in Proc. of ACM CoNEXT
Student Proceedings, 2012, pp. 3-4.
G. Schaffrath, C. Werle, P. Papadimitriou, A. Feldmann, R. Bless,
A. Greenhalgh, A. Wundsam, M. Kind, O. Maennel, and L. Mathy,
“Network Virtualization Architecture: Proposal and Initial Prototype,”
in Proc. ACM SIGCOMM VISA, 2009, pp xx-xx.
N. Sarrar, et al., “Leveraging’s Zipf’s Law for traffic offloading”, in
Proc. of ACM SIGCOMM Computer Communication Review, 2012, pp.
16-22.
Y. Yiakoumis, K.-K. Yap, S. Katti, G. Parulkar, and N. Mckeown,
“Slicing home networks,” in Proc. of ACM SIGCOMM workshop on
Home networks, 2011, pp. 1-6.
S. Sundaresan, W. de Donato, N. Feamster, R. Teixeira, S. Crawford,
and A. Pescap’e, “Broadband internet performance: a view from the
gateway,” in Proc. of the ACM SIGCOMM, Aug. 2011, pp. 134-145.
M. Al-fares, A. Loukissas, and A. Vahdat, “A scalable, commodity
data center network architecture,” in Proc. of the ACM SIGCOMM
Conference on Data Communication, 2008, pp. 63-74.
M. Casdo, M. J. Freeman, J. Pettit, J. Luo, N. Mckeown, N. Mckeown,
and S. Shenker, “Ethane: taking control of the enterprise,” in Proc. of
ACM SIGCOMM Computer Communication Review, 2007, pp. 1-12.
Z. Cai, A. L. Cox, and T. S. E. NG, “Maestro: A system for scalable
OpenFlow control,” Tech. Rep. TR10-11, Rice University - Department
of Computer Science, Dec. 2010.
A. R. Curtis, J. C. Mogul, J. Tourrilhes, P. Yalagandula, P. Sharma,
and S. Banerjee, “DevoFlow: Scaling flow management for highperformance networks,” in Proc. of ACM SIGCOMM Conf., 2011, pp.
254-265.
S. Kandula, S. Sengupta, A. Greenberg, P. Patel, and R. Chaiken, “The
nature of data center traffic: Measurements and analysis,” in Proc. of
ACM Internet Measurement Conf., 2009, pp. 202-208.
T. Benson, A. Akella, and D. A. Maltz, “Network traffic characteristics
of data centers in the wild,” in Proc. of ACM Internet Measurement
Conf., 2010, pp. 267-280.
A. Tootoonchian, S. Gorbunov, Y. Ganjali, and M. Casado, “On
controller performance in software-defined networks,” in Proc. of
USENIX Workshop on Hot Topics in Management of Internet, Cloud,
and Enterprise Networks and Services, 2012, pp. 10-10.
M. Casado, M. J. Freedman, J., Pettit, J. Luo, N. Mckeown, and S.
Shenker, “Ethane: taking control of the enterprise,” in Proc. of ACM
SIGCOMM Computer Communication Review, 2007, pp. 1-12.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
26

[87] D. Drutskoy, Software-defined Network Virtualization, Master Thesis,
Princeton University, 2012.
[88] J. Matias, B. Tornero, A. Mendiola, E. Jacob, and N. Toledo, “Implementing Layer 2 Network Virtualization Using OpenFlow: Challenges
and Solutions,” in Proc. of European Workshop on Software Defined
Networking, Oct. 2012, pp.30-35.
[89] P. Skoldstrom, K. Yedavalli, “Network virtualization and resource
allocation in OpenFlow-based wide area networks,” in Proc. IEEE Int.
Conf. on Communications, Jun. 2012, pp. 6622-6626.
[90] B. Sonkoly, A. Gulyas, F. Nemeth, J. Czentye, K. Kurucz, B. Novak,
and G. Vaszkun, “OpenFlow virtualization framework with advanced
capabilities,” in Proc. European Workshop on Software Defined Networking, Oct. 2012, pp. 18-23
[91] J. Matias, E. Jacob, D. Sanchez, Y. Demchenko, “An OpenFlow Based
Network Virtualization Framework for the Cloud,” in Proc. of IEEE
3rd International Conf. on Cloud Computing Technology and Science,
2011, pp. 672-678.
[92] M. El-azzab, I. L. Bedhiaf, Y. Lemieux, O. Cherkaoui, “Slices Isolator
for a Virtualized Openflow Node,” in Proc. of Int. Symp. on Network
Cloud Computing and Applications, 21-23 Nov. 2011, pp. 121-126.
[93] D. Turull, M. Hidell, and P. Sjodin, “libNetVirt: The network virtualization library,” in Proc. of IEEE Int. Conf. on Communications, Jun.
2012, pp. 5543-5547.
[94] R. Nejbati, S. Azodolmolky, and D. Simeonidou, “Role of network
virtualization in future Internet innovation,” in Proc. of European Conf.
on Networks and Optical Communications, Jun. 2012, pp. 1-4.
[95] B. Naudts, M. Kind, F. Westphal, S. Verbrugge, D. Colle, and M.
Pickavet, “Techno-economic analysis of software defined networking
as architecture for the virtualization of a mobile network,” in Proc. of
European Workshop on Software Defined Networking, Oct. 2012, pp.
67-72.
[96] A. Mahmud, R. Rahmani, and T. Kanter, “Deployment of flow-sensors
in internet of things’ virtualization via OpenFlow,” in Proc. of FTRA
Int. Conf. on Mobile, Ubiquitous, and Intelligent Computing, Jun. 2012,
pp. 195-200.
[97] H. E. Egilmez, B. Gorkemli, A. M. Tekalp, and S. Civanlar, “Scalable
video streaming over OpenFlow networks: an optimization framework
for QoS routing,” in Proc. of IEEE Int. Conf. on Image Processing,
2011, pp. 2241-2244.
[98] H. E. Egilmez, S. T. Dane, K. T. Bagci, and A. M. Tekalp, “OpenQoS:
An OpenFlow controller design for multimedia delivery with endto-end Quality of Service over software-defined networks,” in Proc.
of Asia-Pacific Signal & Information Processing Association Annual
Summit and Conf., Dec. 2012, pp. 1-8.
[99] H. E. Egilmez, S. Civanlar, A. M. Tekalp, “An optimization framework
for QoS-enabled adaptive video streaming over OpenFlow networks,”
in IEEE Trans. on Multimedia, vol. 15, no. 3, Apr. 2013, pp.710-715.
[100] K. Jeong, J. Kim, and Y.-T. Kim, “QoS-aware network operating
system for software defined networking with generalized OpenFlows,”
in IEEE/IFIP Workshop on Management of the Future Internet, 2012,
pp. 1167-1174.
[101] A. Kassler, L. Skorin-Kapov, O. Dobrijevic, M. Matijasevic, and P.
Dely, “Towards QoE-driven multimedia service negotiation and path
optimization with software defined networking,” in Proc. of Int. Conf.
on Software, Telecommunications and Computer Networks, Sept. 2012,
pp. 1-5.
[102] H. Sun, A. Vetro, and J. Xin, “An overview of scalable video streaming,” Wireless Communications and Mobile Computing, vol. 7, no. 2,
pp. 159-172, Feb. 2007.
[103] S. Jivorasetkul and M. Shimamura, “End-to-end header compression
over software-defined networks: a low latency network architecture,”
in Proc. of Int. Conf. on Intelligent Networking and Collaborative
Systems, 2012.
[104] E.-S. M. El-Alfy “A review of network security,” IEEE Distributed
Systems Online, vol. 8, no. 7, Jul. 2007.
[105] ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking, Aug. 2013.
[106] S. Sharma, D. Staessens, D. Colle, M. Pickavet, and P. Demeester,
“Enabling fast failure recovery in OpenFlow networks,” in Proc. of
Int. Workshop on the Design of Reliable Communication Networks,
2011, pp. 164-171.
[107] J. Kempf, E. Bellagamba, A. Kern, and D. Jocha, “Scalable fault
management for OpenFlow,” in Proc. of IEEE Int. Conf. on Communications, Jun. 2012, pp. 6606-6610.
[108] C.-J. Chung, P. Khatkar, T. Xing, J. Lee, and D. Huang, “NICE:
network intrusion detection and countermeasure selection in virtual

[109]

[110]
[111]
[112]
[113]
[114]
[115]

[116]

[117]
[118]

[119]
[120]
[121]
[122]

[123]
[124]

[125]
[126]
[127]

[128]

[129]

[130]

network systems,” IEEE Trans. on Dependable and Secure Computing,
vol. 99, no. 1, Jan. 2013.
S. Shin, P. Porras, V. Yegneswaran, M. Fong, G. Gu, and M. Tyson,
“FRESCO: modular composable security services for software-defined
networks,” in Proc. of Network and Distributed System Security Symp.,
2013.
S. A. Mehdi, J. Khalid, and S. A. Khayam, “Revisiting traffic anomaly
detection using software defined networking,” in Proc. of Int. Conf. on
Recent Advances in Intrusion Detection, 2011, pp. 161-180.
C. Schlesinger, “Language-Based security for software-defined networks,” [online] http://www.cs.princeton.edu/ cschlesi/isolation.pdf.
D. Kordalewski and R. Robere, “A dynamic algorithm for
loop detection in software defined networks”, 2012. [online]
http://www.cs.toronto.edu/ robere/paper/networkgraph-1214.pdf
S. Costanzo, L. Galluccio, G. Morabito, and S. Palazzo, “Software
defined wireless networks: unbridling SDNs,” in Proc. of European
Workshop on Software Defined Networking, 2012, pp. 1-6.
M. Mendonca, K. Obraczka, and T. Turletti, “The case for softwaredefined networking in heterogeneous networked environments,” in
Proc. of ACM conf. on CoNEXT Student Workshop, 2012, pp. 59-60.
K. Yap, M. Kobayashi, R. Sherwood, T. Huang, M. Chan, N. Handigol, and N. McKeown, “Openroads: empowering research in mobile
networks,” ACM SIGCOMM Computer Communication Review, vol.
40, no. 1, pp. 125-126, 2010.
K. Yap, R. Sherwood, M. Kobayashi, T. Huang, M. Chan, N. Handigol,
N. McKeown, and G. Parulkar, “Blueprint for introducing innovation
into wireless mobile networks,” in Proc. of ACM SIGCOMM workshop
on Virtualized Infrastructure Systems and Architectures, 2010, pp. 2532.
L. E. Li, Z. M. Mao, and J. Rexford, “Toward software-defined
cellular networks,” in Proc. European Workshop on Software Defined
Networking, Oct. 2012, pp. 7-12.
A. Gember, C. Dragga, and A. Akella, “ECOS: leveraging softwaredefined networks to support mobile application offloading,” in Proc. of
ACM/IEEE symposium on Architectures for Networking and Communications Systems, 2012, pp. 199-210.
A. Mahmud, and R. Rahmani, “Exploitation of OpenFlow in wireless
sensor networks,” in Proc. Int. Conf. on Computer Science and Network
Technology, 2011, pp. 594-600.
T. Luo, H.-P. Tan, and T. Q. S. Quek, “Sensor OpenFlow: enabling
software-defined wireless sensor networks”, IEEE Communications
Letters, vol. 16, no. 11, pp. 1896-1899, 2012.
P. Dely, A. Kassler, and N. Bayer, “OpenFlow for Wireless Mesh
Networks,” in Proc. of Int. Conf. on Computer Communications and
Networks, 2011, pp. 1-6.
J. Chung, G. Gonzalez, I. Armuelles, T. Robles, R. Alcarria, and A.
Morales, “Experiences and Challenges in Deploying OpenFlow over
Real Wireless Mesh Networks,” IEEE Latin America Trans. (Revista
IEEE America Latina) , vol. 11, no. 3, pp. 955-961, May 2013.
L. Y. Ong, “OpenFlow/SDN and Optical Networks,” in Network
Innovation through OpenFlow and SDN: Principles and Design, Taylor
& Francis LLC, CRC Press, to appear in 2014.
L. Liu, H. Guo, and T. Tsuritani, “OpenFlow/SDN for metro/backbone
optical networks,” in Network Innovation through OpenFlow and SDN:
Principles and Design, Taylor & Francis LLC, CRC Press, to appear
in 2014.
E. Mannie, Ed., Generalized Multi-Protocol Label Switching (GMPLS)
Architecture, IETF RFC, 2004.
S. Das, G. Parulka, and N. Mckeown, “Why OpenFlow/SDN can
succeed where GMPLS failed,” in European Conference and Exhibition
on Optical Communications, Sep. 2012, pp Tu.1.D.1.
L. Liu, T. Tsuritani, I. Morita, H. Guo, and J. Wu, “Experimental
validation and performance evaluation of OpenFlow-based wavelength
path control in transparent optical networks,” Opt. Express, vol. 19, no.
27, pp. 26578-26593, Dec. 2011.
L. Liu, D. Zhang, T. Tsuritani, R. Vilalta, R. Casellas, L. Hong, I.
Morita, H. Guo, J. Wu, R. Martnez, and R. Muoz, “Field trial of an
OpenFlow-based unified control plane for multi-layer multi-granularity
optical switching networks,” IEEE/OSA J. Lightw. Technol., vol. 31, no.
4, pp. 506-514, Feb. 2013.
S. Azodolmolky, R. Nejabati, E. Escalona, R. Jayakumar, N. Efstathiou,
and D. Simeonidou, “Integrated OpenFlow-GMPLS control plane: an
overlay model for software defined packet over optical networks,”
Optical Express, vol. 19, no. 26, pp. B421-B428, 2011.
M. Channegowda, P. Kostecki, N. Efstathiou, S. Azodolmolky, R.
Nejabati, P. Kaczmarek, A. Autenrieth, J. Elbers, and D. Simeonidou,
“Experimental demonstration of an OpenFlow based software-defined

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
27

[131]

[132]

[133]

[134]

[135]

[136]

[137]

[138]

[139]

[140]

[141]

[142]

[143]

[144]

[145]

[146]

[147]

[148]

[149]

optical network employing packet, fixed and flexible DWDM grid technologies on an international multi-domain testbed,” Optical Express,
vol. 21, no. 5, pp. 5487-5498, 2013.
C. H. Liu, A. Gkelias, Y. Hou, and K. K. Leung, “Cross-layer design
for QoS in wireless mesh networks,” Wirel. Pers. Commun., vol. 51,
no. 3, pp. 593-613, Nov. 2009.
L. Qiu and M. Song, “QoS oriented cross-layer design for supporting
multimedia services in cooperative networks,” in Proc. of Int. Conf. on
Service Sciences, 2010, pp. 314-318.
J. Chen, T. Lv, and H. Zheng, “Cross-layer design for QoS wireless
communications,” in Proc. of Int. Symp. on Circuits and Systems, 2004,
vol.2, pp. 217-20.
D. Li, X. Hong, and D. Witt, “ProtoGENI, a prototype GENI under
security vulnerabilities: an experiment-based security study,” IEEE
Systems Journal, vol. 7, no. 3, pp. 478-488, Sep. 2013.
M. Smith, C. Schridde, B. Agel, B. Freisleben, “Identity-based cryptography for securing mobile phone calls,” in Proc. of Int. Conf. on
Advanced Information Networking and Applications Workshops, 2009,
pp. 365-370.
Lambros Sarakis,Theodore Zahariadis,Helen-Catherine Leligou,Mischa
Dohler, “A Framework for Service Provisioning in Virtual Sensor
Networks,” in EURASIP Journal on Wireless Communications and
Networking, Special Issue on Recent Advances in Mobile Lightweight
Wireless Systems, April 2012:135.
Amin Tootoonchian, Yashar Ganjali, “HyperFlow: a distributed control plane for OpenFlow,” in Proceedings of the 2010 internet network management conference on Research on enterprise networking(INM/WREN’10) USENIX Association, Berkeley, CA, USA, , 2010,33.
Zhongjin Liu, Yong Li, Li Su, Depeng Jin, and Lieguang Zeng,
“M2cloud: software defined multi-site data center network control
framework for multi-tenant,” in SIGCOMM Comput. Commun. Rev.43,
4, 2013, pp. 517-518.
Airton Ishimori, Fernando Farias, Igor Furtado, Eduardo
Cerqueira, Antnio Abelm, “Automatic QoS Management on
OpenFlow Software-Dened Networks” in downloadable from:
http://siti.ulusofona.pt/aigaion/index.php/attachments/single/362. 2012
Bari, Md.Faizul Chowdhury, Shihabur Rahman ; Ahmed, Reaz ;
Boutaba, Raouf “PolicyCop: An Autonomic QoS Policy Enforcement
Framework for Software Defined Networks,” in 2013 IEEE SDN for
Future Networks and Services (SDN4FNS), 2013, pp. 1-7.
Sonkoly, B. ; Gulyas, A. ; Nemeth, F. ; Czentye, J. ; Kurucz, K. ; Novak,
B. ; Vaszkun, G. , “On QoS Support to Ofelia and OpenFlow,” in
2012 European Workshop on Software Defined Networking (EWSDN),
Publication , 2012, pp. 109-133.
Bo-Yu Ke ; Po-Lung Tien ; Yu-Lin Hsiao, “Identity-based cryptography
for securing mobile phone calls,” in Proc. of Int. Conf. on Advanced
Information Networking and Applications Workshops, 2013, pp. 217218.
Stephen Gutz, Alec Story, Cole Schlesinger, Nate Foster., “Splendid
isolation: a slice abstraction for software-defined networks,” in In
Proceedings of the first workshop on Hot topics in software defined
networks (HotSDN ’12). ACM, New York, NY, USA, , 2012, pp. 79-84.
Pentikousis, K.; Yan Wang; Weihua Hu, “Mobileflow: Toward
software-defined mobile networks,” in Communications Magazine,
IEEE, vol.51, no.7 July 2013, pp. 44-53.
Tie Luo; Hwee-Pink Tan; Quan, P.C.; Yee Wei Law; Jiong Jin,
“Enhancing responsiveness and scalability for OpenFlow networks via
control-message quenching,” CT Convergence (ICTC), 2012 International Conference vol., no., pp.348,353, 15-17 Oct. 2012.
Kanizo, Y.; Hay, D.; Keslassy, I., “Palette: Distributing tables in
software-defined networks,” in INFOCOM, 2013 Proceedings IEEE,
vol., no., pp.545,549, 14-19 April 2013.
Yannan Hu ; Wendong Wang ; Xiangyang Gong ; Xirong Que ;
Shiduan Cheng, “BalanceFlow: Controller load balancing for OpenFlow networks,” in 2012 IEEE 2nd International Conference on Cloud
Computing and Intelligent Systems (CCIS), Volume: 02, Publication
Year: 2012 , Page(s): 780 785..
Biswas, A. A. Lazar, J. F. Huard, K. S. Lim, S. Mahjoub, L. F. Pau,
M. Suzuki, S. Torstensson, W. Wang, and S. Weinstein, “The IEEE
P1520 Standards Initiative for Programmable Network Interfaces,”
IEEE Commun. Mag.,Vol. 36, no. 10, 1998, pp. 6470.
A. Doria, J. H. Salim, R. Haas, H. Khosravi, W. Wang, L. Dong,
R. Gopal, and J. Halpern, “Forwarding and Control Element Separation (ForCES) Protocol Specification,” in [Online]. Available:
http://tools.ietf.org/html/rfc5810

[150] T. V. Lakshman, T. Nandagopal, R. Ramjee, K. Sabnani, and T. Woo,
“The SoftRouter Architecture,” in Proc. ACM SIGCOMM Workshop
on Hot Topics in Networking, 2004.
[151] On the difference between security and safety: a reference answer is provided in WiKi: ”http://wiki.answers.com/Q/1 Explain the
difference between safety and security?#slide=1”,

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE
permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

