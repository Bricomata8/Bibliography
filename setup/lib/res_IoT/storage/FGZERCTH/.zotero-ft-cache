This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
1
A Survey on Software-Deﬁned Network (SDN) and OpenFlow: From Concept to Implementation
Fei Hu, Qi Hao∗, Ke Bao Electrical and Computer Engineering, The University of Alabama, USA fei@eng.ua.edu
∗Corresponding author qh@eng.ua.edu

Abstract—Software-deﬁned network (SDN) has become one of the most important architectures for the management of largescale, complex networks which may require re-policing or reconﬁgurations from time to time. SDN achieves easy re-policing by decoupling the control plane from data plane. Thus the network routers/switches just simply forward packets by following the ﬂow table rules set by the control plane. Currently OpenFlow is the most popular SDN protocol/standard and has a set of design speciﬁcations. Although SDN/OpenFlow is a relatively new area, it has attracted much attentions from both academia and industry. In this paper we will conduct a comprehensive survey of the important topics in SDN/OpenFlow implementation, including the basic concept, applications, language abstraction, controller, virtualization, Quality of service (QoS), security, as well as its integration with wireless and optical networks. We will compare the pros and cons of different schemes, and discuss the future research trends in this exciting area. This survey can help both industry and academia R&D people to understand the latest progress of SDN/OpenFlow designs.
Index Terms—Software-Deﬁned Network (SDN), OpenFlow, Network Virtualization, QoS, Security
I. INTRODUCTION
A. Motivations
Conventional Networks utilize special algorithms implemented on dedicated devices (hardware components) to control and monitor the data ﬂow in the network, managing routing paths and determining how different devices are interconnected in the network. In general these routing algorithms and sets of rules are implemented in dedicated hardware components such as Application Speciﬁc Integrated Circuits (ASICs) [1]. ASICs are designed for performing speciﬁc operations. Packet forwarding is a simple example. In a conventional network, upon the reception of a packet by a routing device, it uses a set of rules embedded in its ﬁrmware to ﬁnd the destination device as well as the routing path for that packet. Generally data packets that are supposed to be delivered to the same destination are handled in similar manner. This operation takes place in inexpensive routing devices. More expensive routing devices can treat different packet types in different manners based on their nature and contents. For example, a Cisco router allows the users to mark out the priorities of different ﬂows through customized local router programming. Thus we can manage the queue sizes in each router directly. Such a customized local router setup allows more efﬁcient trafﬁc congestion and prioritization control.
A problem posed by this methodology is the limitation of the current network devices under high network trafﬁc, which

poses severe limitations on network performance. Issues such as the increasing demand for scalability, security, reliability and network speed, can severely hinder the performance of the current network devices due to the ever increasing network trafﬁc. Current network devices lack the ﬂexibility to deal with different packet types with various contents because of the underlying hardwired implementation of routing rules [2]. Moreover, the networks, which make up the backbone of the Internet, need to be able to adapt to changes without being hugely labor intensive in terms of hardware or software adjustments. However, traditional network operations cannot be easily re-reprogrammed or re-tasked [3].
A possible solution to this problem is the implementation of the data handling rules as software modules rather than embedding them in hardware. This method enables the network administrators to have more control over the network trafﬁc and therefore has a great potential to greatly improve the performance of the network in terms of efﬁcient use of network resources. Such an idea is deﬁned in an innovative technology, called Software-Deﬁned Networking (SDN) [4]. Its concept was originally proposed by Nicira Networks based on their earlier development at UCB, Stanford, CMU, Princeton [1]. The goal of SDN is to provide open, user-controlled management of the forwarding hardware in a network. SDN exploits the ability to split the data plane from the control plane in routers and switches [5]. The control plane can send commands down to the data planes of the hardware (routers or switches) [6]. This paradigm provides a view of the entire network, and helps to make changes globally without a devicecentric conﬁguration on each hardware unit [7]. Note that the control panel could consist of one or multiple controllers, depending on the scale of the network. If using multiple controllers, they can form a peer-to-peer high-speed, reliable distributed network control. In any case, all switches in the data plane should obtain the consistent view of the data delivery. The switches in the data plane just simply deliver data among them by checking the ﬂow tables that are controlled by the controller(s) in the control panel. This greatly simpliﬁes the switches tasks since they do not need to perform control functions.
The concept of SDN is not entirely new. As a matter of fact, a few decades ago people could use special infrastructure (such as cloud computing hardware) to decouple the network operating system (similar to the control functions in SDN control plane) from computing-intensive applications (similar to the data delivery in data plane). Today cloud computing

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
2

enables the networked computation and storage without using local resources. Such a decoupling of control and data plays a critical role in large-scale, high-speed computing system.
SDN results in improved network performance in terms of network management, control and data handling. SDN is a potential solution to the problems faced by conventional network (Fig.1 [3-5]) and is gaining more acceptance in applications such as cloud computing. It can be used in data centers and workload optimized systems [8]. By using SDN, the administrators have the ability to control the data ﬂow as well as to alter the characteristics of the switching devices (or routing devices) in the network from a central location, with control application implemented as software module without the need of dealing with each device individually [10]. This gives the network administrators the ability to arbitrarily change routing tables (routing paths) in network routing devices. It also allows an extra layer of control over the network data since the administrator can assign high/low priorities to certain data packets or allow/block certain packets ﬂowing through the network [1-3].
From cloud computing perspective, SDN provides great beneﬁts. First, it makes cloud provider more easily deploy different vendors devices. Traditionally the big cloud providers (such as Google, Amazon, etc.), have to purchase the highperformance switchers/routers from the same vendor in order to easily re-conﬁgure the routing parameters (such as routing table update period). Different vendors routers have their own pros and cons. However, it is a headache to customize each router since each vendor may have its own language syntax. Now SDN allows a cloud provider to fast re-policy the routing or resource distribution issues as long as each vendors routers follow the SDN standard. Second, it enables a cloud user to more efﬁciently use the cloud resources or conduct scientiﬁc experiments by creating virtual ﬂow slices. The OpenFlow protocol is compatible to GENI standard, and this enables a user to arbitrarily create slices/slivers without being aware of the physical network infrastructure. No matter the infrastructure is wireless or wired system, and no matter how the cloud provider deploys different storage units in various locations, the concept of virtual ﬂow in a SDN makes data ﬂow transparently route through all cloud devices.

panel. This results in high speed transmissions and makes more efﬁcient use of the resources.
(2) Easy network management: The administrators have a remote control over the network and can change the network characteristics such as services and connectivity based on the workload patterns. This enables administrators to have more efﬁcient and instant access to the conﬁguration modiﬁcations.
(3) Multi-tenancy: The concept of the SDN can be expanded across multiple partitions of the networks such as the data centers and data clouds. For example, in cloud applications, multiple data center tenants need to deploy their applications in virtual machines (VNs) across multiple sites. Cloud operators need to make sure that all tenants have good cross-site performance isolation for tenant speciﬁc trafﬁc optimization. Existing cloud architectures do not support joint intra-tenant and inter-tenant network control ability. SDN can use decoupled control/data planes and resource visualization to well support cross-tenant data center optimization [138].
(4) Virtual application networks: Virtual application networks use the virtualization of network resources (such as trafﬁc queues in each router, distributed storage units, etc.) to hide the low-level physical details from the users applications. Thus a user can seamlessly utilize the global resources in a network for distributed applications without direct management of the resource separation and migration issues across multiple data sites. Virtual application networks can be implemented by the network administrators by using the distributed overlay virtual network (DOVE) which helps with transparency, automation and better mobility of the network loads that have been virtualized [2, 5]. As a matter of fact, a large chunk of SDN is along the rational of virtualization. Virtualization can hide all lower level physical network details and allow the users to repolicy the network tasks easily. Virtualization has been used in many special networks. Within the context of wireless sensor networks (WSNs), there was a laudable European initiative called VITRO, which has worked precisely on this. The concept of virtual WSN [136] separates the applications from the sensor deployment details. Thus we can run multiple logic sensing applications over the same set of physical sensors. This makes the same WSN serve multiple applications.

Control plane &

C1

C2 C3 Data plane are

D1

D1 D3

customized in

each node

C4

C5

InterӁമ net
D4

D5

Data Plane
Flow table Packet
switching

Control Plane
d i gi ta l

Fig. 1. Comparison of traditional network (left) and SDN (right).
SDN is less expensive due to universal, data-forwarding switching devices that follow certain standards, and provides more control over network trafﬁc ﬂow as compared to the conventional network devices. Major advantages of SDNs include [11-15, 17-19]:
(1) Intelligence and speed: SDNs have the ability to optimize the distribution of the workload via powerful control

B. SDN Implementation: Big Picture
Here we brieﬂy summarize the SDN design aspects. In Sections 2 8, we will provide the details of each design aspect. Since SDN’s control plane enables software-based re-policying, its re-programming should also follow general software design principle [37]. Here we ﬁrst brieﬂy review the software design cycle. The design of a software module typically follows 3 steps: (1) design; (2) coding and compiling; and (3) unitary tests. SW debuggers are critical tools. (e.g., gdb [38]). A next usability level is provided by the integrated development environment (IDEs) such as Eclipse [39]. As a promising software design principle, component-based software engineering (CBSE) [40] has been proposed in the 4WARD project [41]. The Open Services Gateway initiative (OSGi) [42] has also been used for a full life cycle of software design. The Agile SW development methodology proposed

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
3

in [43] has been used to provide better feedback between different stages than conventional waterfall methodologies [44].
Regarding controllers, examples include Nox [48] (written in C), POX [49] (in Python), Trema [50], ﬂoodlight [51] (in Jave), etc. NOX [48] was the ﬁrst OpenFlow controller implementation. It is written in C++. An extension of NOX is implemented in POX [49]. NOX can run in Windows, Linux, Mac OS, and other platforms. A Java-based controller implementation is called Beacon [52]. Its extension is Floodlight controller [53]. It can virtualize the SDN control via the OpenStack [54] architecture. Trema controller is now shipped with OpenFlow network emulator based on Wireshark [55].
Before practical OpenFlow design, there are some good simulating tools for initial proof-of-concept, such as NS-2 [56] with OpenFlow Software Implementation Distribution (OFSID) [57]. Recently, Mininet [58] has become a powerful emulation tool.
SDN/OpenFlow programming languages have been studied in some projects. For example, FML [59] enables easy SDN network policy deﬁnitions. Procera [59] deﬁnes controller policies and behaviors. The Frenetic language [60] allows the programs written for one platform to work in other platforms.
SDN/OpenFlow debuggers have been used to trace the controller’s program execution status. ndb [61] mimics GNU debugger gdb [38] and uses breakpoints and back-traces to monitor the network behaviors. Tremashark [62] plugs Wireshark [55] into Treama [50]. It is now evolving to another powerful debugging tool called OFRewind [63]. FlowCheck [64] can check the updating status of ﬂow tables. A more comprehensive tool called NICE [65], has generated a preliminary version [66], and can be used to analyze the codes and packet ﬂows. Through the above tools, OpenFlow testbeds are able to be established worldwide such as GENI [67] in the U.S.A., Ofelia [68] in the European Union and JGN [69] in Japan.
C. OpenFlow: A Popular Protocol/Standard of SDN
A number of protocol standards exist on the use of SDN in real applications. One of the most popular protocol standards is called OpenFlow [8-10, 16, 20]. OpenFlow is a protocol that enables the implementation of the SDN concept in both hardware and software. An important feature of OpenFlow is that scientists can utilize the existing hardware to design new protocols and analyze their performance. Now it is becoming part of commercially available routers and switches as well.
As a standard SDN protocol, OpenFlow was proposed by Stanford. Regarding testbeds of OpenFlow, many designs have been proposed for OpenFlow protocols. They use open source codes to control universal SDN controllers and switches. Regarding switches, OpenVSwitch (OVS) [45] is one of the most popular, software-driven OpenFlow switch. Its kernal is written in Linux 3.3 and its ﬁrmware including Pica8 [46] and Indigo [47] is also available.
OpenFlow is ﬂow-oriented protocol and has switches and ports abstraction to control the ﬂow [21-27]. In SDN, there is a software named controller which manages the collection

of switches for trafﬁc control. The controller communicates with the OpenFlow switch and manages the switch through the OpenFlow protocol. An OpenFlow switch can have multiple ﬂow tables, a group table, and an OpenFlow channel (Fig.2 [22-26]). Each ﬂow table contains ﬂow entries and communicates with the controller, and the group table can conﬁgure the ﬂow entries. OpenFlow switches connect to each other via the OpenFlow ports.
Controller
OpenFlow Protocol

Channel

Flow Flow table table

Flow table

Group table
OpenFlow Switch

Fig. 2. OpenFlow model.

Initially the data path of the OpenFlow routing devices has an empty routing table with some ﬁelds (such as source IP address, QoS type, etc.). This table contains several packet ﬁelds such as the destination of different ports (receiving or transmission), as well as an action ﬁeld which contains the code for different actions, such as packet forwarding or reception, etc. This table can be populated based on the incoming data packets. When a new packet is received which has no matching entry in the data ﬂow table, it is forwarded to the controller to be processed. The controller is responsible for packet handling decisions, for example, a packet is either dropped, or a new entry is added into the data ﬂow table on how to deal with this and similar packets received in the future [27, 28].
SDN has the capability of programming multiple switches simultaneously; but it is still a distributed system and, therefore, suffers from conventional complexities such as dropping packets, delaying of the control packets etc. Current platforms for SDN, such as NOX and Beacon, enable programming; but it is still hard to program them in a low level. With new protocols (such as OpenFlow) becoming more standard in industry, SDN is becoming easier to implement. The control plane generates the routing table while the data plane, utilizing the table to determine where the packets should be sent to [3]. Many companies utilize OpenFlow protocols within their data center networks to simplify operations. OpenFlow and SDN allow data centers and researchers to easily abstract and manage the large network.
The OpenFlow architecture typically includes the following 3 important components [8-10, 29]:
(1) Switches: OpenFlow deﬁnes an open source protocol to monitor/change the ﬂow tables in different switches and routers. An OpenFlow switch has at least three components: a) ﬂow table(s), each with an action ﬁeld associated with

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
4

each ﬂow entry, b) a communication channel, which provides link for the transmission of commands and packets between a controller and the switch, c) the OpenFlow protocol, which enables an OpenFlow controller able to communicate with any router/switch.
(2) Controllers: A controller can update (revise, add, or delete) ﬂow-entries from the ﬂow table on behalf of the users experiments. A static (versus dynamic) controller can be a simple software unit running on a computer to statically (versus dynamically) establish packet path between a group of test computers during a scientiﬁc experiment.
(3) Flow-entries: Each ﬂow-entry includes at least a simple action (network operation) for that ﬂow item. Most OpenFlow switches support the following three actions: (a) sending this ﬂow’s packets to a port, (b) encapsulating this ﬂows packets and sending to a controller, and (c) dropping this ﬂows packets.
OpenFlow has gone through many standard iterations, and it is currently on version 1.3; however only version 1.0 is available for practical software and hardware design. The second and subsequent versions of OpenFlow changed the match structures so that the number and bit count of each header ﬁeld could be speciﬁed. Thus new protocols would be easier to implement. In [21] a special controller is used to separate control bits from data bits, which allows for the network infrastructure to be shared more easily. A server is often utilized for the controller portion of OpenFlow architecture.
Currently, several projects are ongoing that utilize OpenFlow in both Europe and Japan [27, 28]. In Europe, eight islands are currently interconnected using OpenFlow. In Japan, there are plans to create a network compatible with the one in Europe, as well as a testbed that is much more widespread.
The existing OpenFlow standard assumes centralized control, that is, a single-point controller can manage all ﬂow tables in different switches. This concept works very well in a smallscale, cable-based local area network. When OpenFlow was proposed, it was tested in a wired campus network. However, if many switches are deployed in a large area, it is difﬁcult to use a single-point control. Especially when wireless media have to be used to connect long-distance devices, a central control becomes difﬁcult since wireless signals fade away quickly for a long distance. Single control also has singlepoint failure issue. To solve the above issue, we can use distributed controllers in different locations. Each controller only manages the local switches. However, all controllers keep highly reliable communications for consistent view of the global status. As an example, Hyperﬂow [137] uses a logically centralized but physically distributed control panel to achieve a synchronized view of the entire SDN.
D. Beyond OpenFlow: Other SDN Standards
Besides OpenFlow (the most popular SDN protocol/standard), there exist other SDN implementations. For instance, IEEE P1520 standards have deﬁned Programmable Network Interfaces [148]. It can be seen as an initial model of SDN, since it also has network programming abstractions.
ForCES (Forwarding and Control Element Separation) [149] is another standard deﬁned by IETF. It consists of a series of

RFCs for the coverage of different aspects on how to manage control and data forwarding elements. It proposes the models to separate IP control and data forwarding, Transport Mapping layer for the forwarding and control elements, logical function block library for such a separation, etc. However, ForCES does not have widespread adoption due to its lack of clear language abstraction deﬁnition and controller-switcher communication rules.
Note that ForCES has a key difference from OpenFlow: ForCES deﬁnes networking and data forwarding elements and their communication speciﬁcations. However, it does not change the essential network architecture. OpenFlow changes the architecture since it requires the routers/switches have very simply data forwarding function and the routing control functions should be removed to the upper level controllers. Therefore, OpenFlow cannot run in traditional routers that do not support OpenFlow standards, while ForCES can run in traditional devices since it just adds networking/forwarding elements.
SoftRouter [150] deﬁnes clearly the dynamic binding procedure between the network elements located in control plane (software-based) and data plane. In this standard, the network can be described in two different views, i.e., physical view and routing view. In the physical view, the network is made up of nodes internetworked by media links. The nodes could be a forwarding element (FE) or a control element (CE). The FE is a common router without local sophisticated control logic. The CE is used to control FE. A CE is a general server. The routing view of a network reﬂects the network topology based on the concept of network element (NE). An NE is a logical grouping of network interfaces/ports and the corresponding CEs that control those ports. SoftRouter includes a few protocols: Discovery protocol (to establish a binding between FE and CE), FE/CE control protocol, and CE/CE protocol.
E. 1.5 SDN Applications
In this section we will provide some application examples on using SDN and OpenFlow.
(1) Internet Research: Updating the Internet brings many challenges as it is constantly being used; it is difﬁcult to test new ideas and strategies to solve the problems found in an existing network. SDN technologies provide a means for testing ideas for a future Internet without changing the current network [30]. Since SDN allows the control and data trafﬁc to be separated with an OpenFlow switch, it is easier to separate hardware from software. This separation allows for experimenting with new addressing schemes so that new Internet architecture schemes can be tested.
Usually, it is difﬁcult to experiment with new types of networks. Since new types of networks often utilize different addressing schemes and include other non-standard protocols, these changes are difﬁcult to incorporate into existing networks. OpenFlow allows for routers, switches, and access points from many different companies to utilize the separation of the control and data planes. The devices simply forward data packets based on deﬁned rules from the controller. If a data

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
5

packet arrives and the device does not have a rule for it, the device forwards the packet to the controller that determines what to do with the packet, and if necessary, it sends a new rule to the device so that it can handle future data packets in the same manner [21].
(2) Rural Connections: SDN simpliﬁes complex data center and enterprise networks; it can further be utilized to simplify rural Wi-Fi networks. The main issues with rural environments include sparse populations, small proﬁt margins and resource constraints, and others. SDN is beneﬁcial because it separates the construction of the network and the conﬁguration of the network by placing the control/management functionality into the central controller. This separation enables the rural infrastructure deployment business (which must be done locally in rural areas) and the Internet Service Provider (ISP) business (which is typically done remotely in cities) to be completely separated, i.e., those two businesses are operated by different entities [31, 32]. Therefore, SDN makes the management of rural networks much more convenient than traditional network architecture where the local network devices need customized control (which means the control of rural devices must be done in rural areas).
(3) Date Centers Upgrading: Data centers are an integral part of many companies [33]. For example, Google has a large number of data centers so they can quickly provide data when requested. Similarly, many other companies utilize data centers to provide data to clients in a quick and efﬁcient manner, but data centers are expensive to maintain. OpenFlow allows companies to save money in setting up and conﬁguring networks since it allows switches to be managed from a central location [34].
Oftentimes, data center networks utilize proprietary architectures and topologies, which creates issues when merging different networks together; however there is often a need to merge two divergent networks. SDN brings a solution to this issue. In [33] the authors propose that a network infrastructure service based on OpenFlow be utilized to connect data center networks. They further state that these interconnected data center networks could solve problems with small latency by moving workload to underutilized networks. If a network is busy at a certain time of day, the workload might be able to be completed sooner in a network of a different time zone or in a network that is more energy efﬁcient.
In [34] a data center model is created with a large number of nodes to test performance, throughput and bandwidth. The model included 192 nodes with 4 regular switches and 2 core switches with an OpenFlow controller. There was a ﬁrewall between the core switches, OpenFlow controller and the router. The authors also utilized an application called Mininet to prototype their network and test the performance. Mininet allows researchers to customize a SDN using OpenFlow protocols. Further, they utilized several tools to analyze their network setup including Iperf, Ping, PingAll, PingPair, and CBench. These tools allow people to check the possible bandwidth, connectivity, and the speed in which ﬂows can be changed, respectively. Wireshark was also used to view trafﬁc in the network.
(4) Mobile Device Ofﬂoading: Privacy is important for

business applications because people often work on data that needs to be kept secure. Some data can be sent among only a few people while other data does not require the same level of security. As an example, in [35] the authors utilized an Enterprise-Centric Ofﬂoading System (ECOS) to address these concerns. ECOS was designed to ofﬂoad data to idle computers while ensuring that applications with additional security requirements are only ofﬂoaded on approved machines. Performance was also taken into consideration for different users and applications [35]. SDN is utilized to control the network and select resources. The resources selected must be able to meet the security requirements. The controller will determine if such a device is available for ofﬂoading that meets the security requirements while maintaining energy savings. If no such device exists, data is not allowed to be ofﬂoaded from the mobile device. If energy savings is not necessary, then any resource with enough capacity is utilized if available. OpenFlow switches are utilized so that the controller can regulate the ﬂows. ECOS was able to ofﬂoad while taking into account security requirements without an overly complex scheme.
(5) Wireless Virtual Machines: Applications running on wireless virtual machines in businesses are becoming increasingly common. These virtual machines allow the companies to be more ﬂexible and have lower operational costs. In order to extract the full potential from a virtual machine, there are needs for making them more portable. The main issue is how to maintain the virtual machines IP address in the process. The current methods of handling virtual machines were not efﬁcient. The solutions proposed in [36] include using a mobile IP or dynamic DNS. The main issue with both solutions is that someone has to manually reconﬁgure the network settings after removing the virtual machine. This limits businesses and data centers from easily porting their virtual machines to new locations.
An application named CrossRoads was developed by [36] in order to solve the mobility issue for virtual machines. CrossRoads is designed to allow mobility of both live and ofﬂine virtual machines. CrossRoads has three main purposes. The ﬁrst purpose is to be able to take care of trafﬁc from data centers as well as external users. The second purpose is to make use of OpenFlow with the assumption that each data center utilizes an OpenFlow controller. The third purpose is to make use of pseudo addresses for IP and MAC addresses in order to have the addresses remain constant when porting while allowing the real IP to change accordingly.
The basic implementation of their software was to create rules for ﬁnding the virtual machines in different networks. The CrossRoads controller would keep track of the real IP and MAC addresses for the controllers in each data center as well as the virtual machines in its own network. When a request is sent for an application running on a particular virtual machine, a request is broadcasted to the controllers. If the controller receives a request for a virtual machine that is not in its table, then it broadcasts the request to the other controllers; the controller who has the virtual machines real IP address then sends out the pseudo MAC address to the original controller, and the original controller can update its table in

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
6

Applications
Internet Research [30] Rural Networking [31] Changing Silicon [32] Data Centers [33] Cloud [34] Mobile Apps [35] Virtual Machines [36]

Use OpenFlow
Yes
No No Yes
Yes
Yes Yes

TABLE I A COMPARISON OF DIFFERENT SDN APPLICATIONS.

Net. Trafﬁc amount

For Data Center

Network Scalability

Mobile Platform

QoS support

For Cloud

Depends on ap- Yes

plications

Low

No

Medium

Yes

High

Yes

High

Yes

Low

No

Depends

Yes

Excellent
Poor N/P Very Good
Excellent
Good Very Good

Yes

All QoS metrics No

No

Low throughput No

No

Low data rate

No

No

Latency is a con- No

cern

Yes

Typically Real- Yes

time

Yes

Long Delay

No

Yes

Real-time

Yes

Allow Hardware Change Yes
No Yes No
No
No No

case it gets another request in the near future. Comparisons: SDN has been shown to be a valuable
resource in many different types of applications. SDN allows users to quickly adapt networks to new situations as well as test new protocols. Table 1 shows the differences among some typical SDN applications. As one can see, OpenFlow was utilized in most of the applications for its versatility. Data centers continue to become an important part of the Internet and many large companies. The column mobile applications refers to cell phones, tablets, and other non-traditional media formats rather than laptops and other typical computing platforms. A few of the applications utilize the cloud. Hardware changes are difﬁcult to implement in conventional networks. This is mainly because they require a system to be shut down during upgrade. But SDN provides conveniences for such upgrades due to its separation of data and control planes.
F. Road Map
Fig.3 shows the organization of this paper. After the concept is explained (section 1), sections 2 8 will survey the most important aspects in SDN/OpenFlow design. Since SDN aims to enable easy re-policying, the network programming is a must (section 2). SDN simpliﬁes all switches as data forwarders only and leave complex control in controllers (section 3). Due to the dynamic network resources deployment, it is critical to provide the users an accurate network resource management via the virtualization tools (section 4). Then we move to the important SDN performance issue - QoS (section 5). We will explain different schemes that can support the QoS requirements. Any network has threats and attacks. SDN is not an exception. Section 6 will explain the security and fault tolerance aspects in SDN designs. Then we introduce the ideas of implementing SDN/Openﬂow in two most important network types - wireless and optical networks (section 7). Section 8 introduces a SDN design example. To help the readers understand unsolved challenging research issues, we will point out the next-step research directions in this exciting ﬁeld (section 9). Finally, section 10 concludes the entire paper.
The reason of covering the three aspects (QoS, security, and wireless/optical) besides the basic SDN issues (sections 2 4) is due to the following factors: First, for any new network architecture, the ﬁrst concern is its performance, which mainly

includes the end-to-end delay, throughput, jitter, etc. Therefore, it is critical to evaluate its QoS support capabilities. This is the reason that we use an individual section (section 5) to cover SDNs QoS support issues; Second, security is always a top concern for a user before he or she uses a new network model. There are many new attacks raised for any new network architecture. Therefore, we will use another section (section 6) to cover SDN security considerations; Finally, today two most typical network media are wireless transmissions and optical ﬁber. SDN eventually needs to face the design challenges when used for those cases. Therefore, in section 7 we discuss SDN extensions in wireless and optical links.

Motivation, Concept,
Applications
What?
Section 1

Design
principles
How? 

Language (section 2) Controller (section 3) Virtualization (section 4) Quality of service (section 5) Security (section 6) OpenFlow for Wireless & Optical (section 7) A Complete design example (section 8)

Research Trends Next?
Section 9

Fig. 3. Organization of this survey

II. LANGUAGE ABSTRACTIONS FOR SDN
A. Language Abstractions
In SDN the control function consists of two parts, i.e., the controller with the program and the set of rules implemented on the routing/switching devices (Fig.4). This has an implication of making the programmer not worry about the low-level details in the switch hardware. The SDN programmers can just write the speciﬁcation that captures the intended forwarding behavior of the network instead of writing programs dealing with the low-level details such as the events and the forwarding rules of the network. This enables the interactions between the controllers and switches. A compiler transforms these speciﬁcations into code segments for both controllers and switches. As an example, a SDN programming tool called NetCore [70] allows descriptions of the network rules and policies which cannot be implemented directly on the switches. Another important fact about NetCore is that it has a clear

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
7

formal set of rules that provide a basis for reasoning about provides an ideal platform for exploring such abstractions, as

program execution status.

the compiler can be used to perform the tedious bookkeeping

for implementing network policy updates [71].

Application Layer

Business Applications

Control Layer

API
SDN Control Software

API

API

Network Services

Infrastructure Layer

Control Data Plane Interface e.g. OpenFlow

Network Device Network Device Network Device

Fig. 4. Programming of the SDN and language Abstraction
Here we introduce two important language abstractions in SDN programming:
(1) Network Query Abstractions: In SDNs each switch stores counters for different forwarding rules. They are for the counts of the total number of packets and data segments processed using those rules. For trafﬁc monitoring the controller has the ability to check different counters associated with different forwarding rules. This enables the programmers to monitor the ﬁne details of implementation on the switches. This is a tedious job and makes the program complicated. Therefore an added level of abstraction will help the programmers. To support applications whose correct operation involves a monitoring component, Frenetic [71] includes an embedded query language that provides effective abstractions for reading network state. This language is similar to SQL and includes segments for selecting, ﬁltering, splitting, merging and aggregating the streams of packets. Another special feature of this language is that it enables the queries to be composed with forwarding policies. A compiler produces the control messages needed to query and tabulate the counters on switches.
(2) Consistent Update Abstractions: Since SDNs are event-driven networks, the programs in SDNs need to update the data forwarding policy from time to time because of the changes in the network topology, failures in the communication links, etc. An ideal solution is the automatic update of all the SDN switches in one time; but in reality it is not easy to implement. One good solution is to allow certain level of abstraction, and then send these changes from one node to another. An example is the per-packet consistency which ensures that each packet just uses the same, latest policy (instead of a combination of both the old and new policy). This preserves all features that can be represented by individual packets and the paths they take through the SDN. Those properties subsume important structural invariants such as basic connectivity and free-of-loop, and link access control policies. Per-ﬂow consistency ensures that a group of related packets are processed with the same ﬂow policy. Frenetic

B. Language abstraction tools: Frenetic project
SDN requires efﬁcient language abstraction tools to achieve network re-programming. As an example, the Frentic project aims to provide simple and higher level of abstraction with three purposes, i.e., (i) Monitoring of data trafﬁc, (ii) Managing (creating and composition) packet forwarding policies, (iii) Ensuring the consistency when updating those policies [72]. By providing these abstractions the network programming becomes easy and efﬁcient without a need of worrying about the low-level programming details.
Frenetic project utilizes a language that supports an application-level query scheme for subscribing to a data stream. It collects information about the state of the SDN, including trafﬁc statistics and topology changes. The runtime system is responsible for managing the polling switch counters, gathering statistics, and reacting to the events. In the Frenetic project the speciﬁcation of the packet forwarding rules in the network is deﬁned by the use of a high-level policy language which can easily deﬁne the rules and is convenient to programmers. Different modules can be responsible for different operations such as the routing, discovery of the topology of the network, workload balancing, and access control, etc. This modular design is used to register each module’s task with the run time system which is responsible for composing, automatic compilation and optimization of the programmer’s requested tasks. To update the global conﬁguration of the network, Frenetic project provides a higher level of abstraction. This feature enables the programmers to conﬁgure the network without going physically to each routing device for installing or changing packet forwarding rules. Usually, such a process is very tedious and is prone to errors. The run-time system makes sure that during the updating process only one set of rules is applied to them, i.e. either the old policy or the new one but not both of the rules. This makes sure that there is no violations for the important invariants such as connectivity, control parameters of the loops and the access control when the Open-Flow switches from one policy to another [72].
To illustrate Frenetic language syntax, here we use an example. In MAC learning applications, an Ethernet switch performs interface query to ﬁnd a suitable output port to deliver the frames. Frenetic SQL (Structure Query Language) is as follows:
Select (packets) * GroupBy ([srcmac]) * SplitWhen ([inport]) * Limit (1)
Here Select(packets) is used to receive actual packets (instead of trafﬁc statistics). The GroupBy([srcmac]) divides the packets into groups based on a header ﬁeld called sercmac. Such a ﬁeld makes sure that we receive all packets with the same MAC address. SplitWhen([inport]) means that we only receive the packets that appear in a new ingress port on the

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
8

switch. Limit(1) means that the program just wants to receive the ﬁrst packet in order to update the ﬂow table in data plane.
In a nut shell, Frenetic language project is an aggregation of simple yet powerful modules that provide an added level of abstraction to the programmer for controlling the routing devices. This added layer of abstraction runs on the compiler and the run time system, and is vital for the efﬁcient code execution.
C. Language Abstraction Tool: FlowVisor
The virtualization layer helps in the development and operation of the SDN slice on the top of shared network infrastructures. A potential solution is the concept of AutoSlice [74]. It provides the manufacturer with the ability to redesign the SDN for different applications while the operator intervention is minimized. Simultaneously the programmers have the ability to build the programmable network pieces which enable the development of different services based on the SND working principles.
Flow Visor is considered to be a fundamental building block for SDN virtualization and is used to partition the data ﬂow tables in switches using the OpenFlow protocol by dividing it into the so-called ﬂow spaces. Thus switches can be manipulated concurrently by several software controllers. Nevertheless, the instantiation of an entire SDN topology is non-trivial, as it involves numerous operations, such as mapping virtual SDN (vSDN) topologies, installing auxiliary ﬂow entries for tunneling and enforcing ﬂow table isolation. Such operations need a lot of management recourses.
The goal is to develop a virtualization layer which is called SDN hypervisor. It enables the automation of the deployment process and the operation of the vSDN topologies with the minimum interaction of the administrator. vSDNs focuses on the scalability aspects of the hypervisor design of the network. In [75] an example is presented in which a network infrastructure is assumed to provide vSDN topologies to several tenants. The vSDN of each tenant takes care of a number of things such as the bandwidth of the link, its location and the switching speed (capacity), etc. The assumption is that every tenant uses switches that follow OpenFlow protocol standards with a ﬂow table partitioned into a number of segments. The proposed distributed hypervisor architecture has the capability of handling a large amount of data ﬂow tables for several clients. There are two very important modules in the hypervisor: Management Module (MM) and Multiple Controller Proxies (CPX). These modules are designed in such a manner that it distributes the load control over all the tenants.
The goal of the MM portion is to optimize global parameters. The transport control message translation is used to enable the tenants to have the access to the packet processing set of rules within a speciﬁc SDN layer without having to disturb the simultaneous users. Upon the reception of a request, MM inquires the vSDN about the resources available in the network with every SDN domain and then accordingly assigns a set of logical resources to each CPX.
As a next step each CPX initializes the allocated segment of the topology by installing ﬂow entries in its domain, which

unambiguously bind trafﬁc to a speciﬁc logical context using tagging. As the clients are required to be isolated from each other, every CPX is responsible to do a policy control on the data ﬂow table access and make sure that all the entries in these tables are mapped into segments that are not overlapping. CPX is responsible for controlling the routing switches. Also the CPX takes care of all the data communication between the client controller and the forwarding plane.
A new entry into the switch has to follow certain steps (Ididnotseemanysteps). First, the proxy creates a control message for addition of new entry into the switch ﬂow table in such a manner that all references (addresses) to memories are replaced by the corresponding physical entries, and corresponding trafﬁc controlling actions are added into the packet. The Proxy is responsible for maintaining the status of each virtual node in a given SDN. As a result the CPX has the ability to independently transfer virtual resources within its domain to optimize inter-domain resource allocation.
If there are a number of clients in the network, a large number of ﬂow tables are needed in the memory of a routing switch. The task of CPX is to make sure that all the ﬂow tables are virtually isolated, all packet processing takes place in a correct order, and all the actions are carried out in case a connected group of virtual nodes is being mapped to the same routing device.
In the OpenFlow routing devices, there is a problem on the scalability of the platform due to the large ﬂow table size. There could be a large number of entries in the ﬂow table. To deal with such situation, an auxiliary software data paths (ASD) is used in the substrate network [75]. For every SDN domain, an ASD is assigned. The server has enough memory to store all the logical ﬂow tables which are needed by the corresponding ASD compared to the limited space on the OpenFlow routing devices. Although the software-based data path has some advantages, there is still a huge gap between the OpenFlow protocol and the actual hardware components. To overcome these limitations, the Zipf property of the aggregate trafﬁc [76], i.e., the small fraction of ﬂows, is responsible for the trafﬁc forwarding. In this technique ASDs are used for handling heavy data trafﬁc while only a very small amount of high volume trafﬁc is cached in the dedicated routing devices.
Language example of FlowVisor: Here we provide an example on how FlowVisor creates a slice.
# Topology Example topo = nxtopo.NXTopo ( ) Example topo.add switch (name = ”A”, ports [1,2,3,4]) Example topo.add switch (name = ”B”, ports [1,2,3,4]) Example topo.add link (( ”A”, 4), (”B”, 4)) # Mappings P map = ”A” : ”S2”, ”B”: ”S3” Q map = identity port map (Example topo, P map) Maps = (P map, Q map) # predicates Preds = \ ([ (p, header (”srcport”, 80)) For p in Example topo.edge ports (”A”) + [(p, header (”dstport”, 80))

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
9

For p in Exam topo.edge ports (”B”) ]) # slice constructor Slice = Slice (Example topo, phys topo, maps, preds)
In the above example, we ﬁrst deﬁne a network topology called Example topo, which has two switches: A and B. The switches have 3 edge ports each. Then we deﬁne the switch→port mappings. Switch A maps to S2, and B maps to S3. Then we associate a predicate with each edge port. The predicates can map trafﬁc (web only) to the slice. The last line ofﬁcially creates a slice [143].
III. CONTROLLER
The control plane can be managed by a central controller or multiple ones. It gives a global view of the SDN status to upper application layer. In this section, we look into the architecture and performance of controller in software deﬁned networks.
A. Types of Controllers
While SDN is suitable for some deployment environments (such as homes [77, 78], data centers [79], and the enterprise [80]), delegating control to a remote system has raised a number of questions on control-plane scaling implications of such an approach. Two of the most often voiced concerns are: (a) how fast the controller can respond to data path requests; and (b) how many data path requests it can handle per second. For software controller, there are four publiclyavailable OpenFlow controllers: NOX, NOX-MT, Beacon, and Maestro [81].
A typical OpenFlow controler is NOX-MT [81]. NOX [48] whose measured performance motivated several recent proposals on improving control plane efﬁciency has a very low ﬂow setup throughput and large ﬂow setup latency. Fortunately, this is not an intrinsic limitation of the SDN control plane: NOX is not optimized for performance and is single-threaded.
NOX-MT is a slightly modiﬁed multi-threaded successor of NOX. With simple tweaks we are able to signiﬁcantly improve NOXs throughput and response time. The techniques used to optimize NOX are quite well-known: I/O batching to minimize the overhead of I/O, porting the I/O handling harness to Boost Asynchronous I/O (ASIO) library (which simpliﬁes multi-threaded operation), and using a fast multiprocessoraware malloc implementation that scales well in a multi-core machine.
Despite these modiﬁcations, NOX-MT is far from perfect. It does not address many of NOXs performance deﬁciencies, including but not limited to: heavy use of dynamic memory allocation and redundant memory copies on a per-request basis, and using locking while robust wait-free alternatives exist. Addressing these issues would signiﬁcantly improve NOXs performance. However, they require fundamental changes to the NOX code base. NOX-MT was the ﬁrst effort in enhancing controller performance. The SDN controllers can be optimized to be very fast.

B. Methods to Enhance Controllers Performance
We can make OpenFlow network more scalable by designing a multi-level controller architecture. With carefully deployed controllers, we can avoid throughput bottleneck in real networks. For example, in [82] authors have measured the ﬂow rate in a HP ProCurve (model # 5406zl) switch, which is over 250 ﬂows per second. In the meantime, in [83] authors reported that for a data center with over 1000 servers, it could face a ﬂow arrival rate of 100k ﬂows/second, and in [84] they reported a peak rate of 10M ﬂows per second for an 100-switch network. The above example shows that current switches cannot handle the application ﬂow rate demands. Therefore, we need to invent an efﬁcient protocol which can minimize the switch-to-controller communications.
The data plane should be made simple. Currently OpenFlow assigns routing tasks to the central controller for ﬂow setup. And the low-level switches have to communicate with the controller very frequently in order to obtain the instructions on how to handle incoming packets. This strategy can consume the controllers processing power and also congest switchcontroller links. Eventually they cause a serious bottleneck in terms of the scalability of OpenFlow.
However, recent measurements of some deployment environments suggest that these numbers are far from sufﬁcient. This causes relatively poor controller performance and high network demands to address perceived architectural inefﬁciencies. But there has been no in-depth study on the performance of a traditional SDN controller. Most results were gathered from systems that were not optimized for throughput performance. To underscore this point, researchers were able to improve the performance of NOX, an open source controller for OpenFlow networks, by more than 30 times in throughput [85].
In most SDN designs the central controller(s) can perform all the programming tasks. This model certainly brings the scalability issue to the control plane. A better control plane should be able to make the packet handling rate scalable with the number of CPUs. It is better to always have the network status in packet level available to the controllers. Study from Tootoonchian et al. [85] implements a Glasgow Haskell Compiler (GHC) based runtime system. It can allocate/deallocate memory units, schedule different event handlers, and reduce the interrupts or system calls in order to decrease the runtime system load. They have showed the possibility of using a single controller to communicate with 5000 switches, and achieving the ﬂow rate of up to 14M per second! The switch-controller communication delay is less than 10ms in the worst case. In [86] a partition/aggregate scheme is used to handle TCP congestion issue.
C. Advanced Controller Design
Here we introduce an advanced method for high-speed control functions in control plane. In [145], a mechanism called Control-Message Quenching (CMQ) is proposed to reduce the ﬂow setup delay and improve the SDN throughput among switches/routers. There are huge number of ﬂows that need to be handled by the controllers. The inability of

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
10

OpenFlow to process so many ﬂows policy management is due to the inefﬁcient design of control-data plane interfaces. Especially, there exist frequent switch-controller communications: the switches have to consult the controller frequently for instructions on how to handle new incoming packets.
The basic idea of CMQ is to ask any switch to send only one packet-in message during each RTT (round-trip-time), for each source-destination pair, upon multiple ﬂow table misses. Thus we do not need to bother the controllers each time we receive the packets with the same source/destination. Each switch should maintain a dynamically updated table with all learned, unique source-destination pairs. For each incoming packet that cannot ﬁnd its source-destination pair, i.e., table-miss occurs, the switch will insert such a new pair into the table, and query the controller. Such a pair table will be maintained periodically in case the network topology changes, which can detected by the control plane.
A problem with existing SDN controller is that the SDN ﬂow tables typically cannot scale well when there are more than 1000 entries [146]. This is mainly because the tables often include wildcards, and thus need ternary content-addressable memory (TCAM), as well as complex, slow data structures. In [146] a scheme called Palette, can decompose a large SDN table into small ones and distribute them to the whole SDN without damaging the policy semantics. It can also reduce the table size by sharing resources among different ﬂows. The graph-theory based on model is used to distribute the small tables to proper switches.
There could exist multiple controllers in the SDN. In [147] a load balancing strategy called BalanceFlow, is proposed to achieve controller load balancing. Through cross-controller communications, a controller is selected as super-controller, which can tune the ﬂow requests received by each controller without introducing much delay. Note that each controller should publish its load information periodically to allow supercontroller to partition the loads properly.
IV. NETWORK VIRTUALIZATION
A. Virtualization Strategies
As technology develops, the modern network becomes larger and more capable of providing all kinds of new services. The cloud computing, and some frameworks such as GENI, FIRE, G-Lab, F-Lab and AKARI, utilize the large-scale experimental facilities from networks. However, resources are always limited and users demands keep increasing as well. The sharing of network hardware resources among users becomes necessary because it could utilize the existing infrastructure more efﬁciently and satisfy users demands. Network virtualization in SDN is a good way to provide different users with infrastructure sharing capabilities [87]. The term OpenFlow often comes with network virtualization these years. The FlowVisor, the controller software, is a middleware between OpenFlow controllers and switches. FlowVisor decomposes the given network into virtual slices, and delegates the control of each slice to a speciﬁc controller [88].
Both OpenFlow and FlowVisor have their limitations in terms of network management, ﬂexibility, isolation and QoS.

OpenFlow offers common instructions, but lacks standard management tools. FlowVisor only has access to the data plane, so the control plane and network controllers have to be managed by the users of the infrastructure. On the other hand, it can ensure a logical trafﬁc isolation but with a constant level, which means that it lacks ﬂexibility. Facing these challenges, researchers try to establish their own architecture based on OpenFlow or FlowVisor for an improved network virtualization.
FlowVisor can be pre-installed on the commercial hardware, and can provide the network administrator with comprehensive rules to manage the network, rather than adjusting the physical routers and switches. FlowVisor creates slices of network resources and acts as the controlling proxy of each slice to different controllers as shown in Fig.5. The slices may be switch ports, Ethernet addresses, IP addresses, etc, and they are isolated and cannot control other trafﬁc. It can dynamically manage these slices and distribute them to different OpenFlow controllers, and enables different virtual networks to share the same physical network resources.

OpenFlow switch

OpenFlow switch

OpenFlow switch

FlowVisor

Switch ports

Ethernet addresses

IP addresses

FlowVisor

Switch ports

Ethernet addresses

IP addresses

OpenFlow controller

OpenFlow controller

OpenFlow controller

Fig. 5. The FlowVisor acts as proxy and provides slices.

B. Virtualization Models
In the context of OpenFlow there are different virtualization models in the view of translation model [89] (Fig.6). Translation aims to ﬁnd 1:1 mapping relationship between the physical SDN facilities and the virtual resources. The translation unit is located between the application layer and the physical hardware. According to their placements we could classify them into ﬁve models:
(1) FlowVisor: FlowVisor is the translation unit that delegates a protocol and controls various physical switches or controllers. It has full control of the virtualization tasks.
(2) Tanslation unit: it is in the OpenFlow instance of the switch, and it performs translation among different controllers at the protocol level.
(3) Multiple OpenFlow instances running on one switch are connected to one controller. Translation is executed between the data forwarding unit (such as a switch) and an OpenFlow instance.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
11

Fig. 6. Various translating functions (C1,C2,C3: different Controllers; OFI OpenFlow Instance)
(4) Multiple OpenFlow instances still running on a single switch, but the switchs datapath is partitioned into a few parallel ones, one per instance. It translates by adjusting the ports connected to the different parallel data paths.
(5) Multiple translation units are used, and at least one is for virtualization on the switch level, and another one for interconnecting some virtual switches.
C. Virtualization Architectures
Some systems have been proposed to address the OpenFlow-based network virtualization limitations. These methods can be classiﬁed as three types: (1) Improve the OpenFlow controller. OpenFlow controller is a software, and it can be modiﬁed by users to satisfy their special demands. (2) Improve the FlowVisor. The FlowVisor itself already has basic management function, and it can be improved to overcome some limitations. (3) To add new abstraction layer upon OpenFlow switch. Researchers add new layers or new components to manage the virtual network. In the following we will focus on some performance requirements for a SDN virtualizer.

version 14.14 based database with the virtual-to-physical mappings as shown in Fig.7. This FlowN is a scalable virtual network and provides tenants a full control of the virtual network tenants can write their own controller application and deﬁne arbitrary network topology. With the container based architecture, the controller software that interacts with the physical switches is shared among tenant applications, and so that the resources could be saved when the controller becomes more and more complex these days.
This system is evaluated in two experiments by increasing the number of the nodes: one measures the latency of the packets arriving at the controller, and the other measures the fault time of the link used by multiple tenants. When the number of nodes is large, the system has the similar latency as FlowVisor does but is more ﬂexible; and its fault time could be small even the number of network nodes is large.
In [90] an efﬁcient network virtualization framework is proposed. Its major features include: (1) monitor multiple instances of OpenFlow switches, (2) set up controllers and SDN applications, and (3) achieve QoS performance. It can easily conﬁgure the parameters of different switches, and monitor the network topology to see any node changes. It uses OpenNMS as the management tool since it is open source. It has virtual controller management as shown in Fig.8. The prototype is successfully tested on the testbed consisting of six PCs, one switch and one OpenFlow switch.

Controller Management

Management Framework Virtual Network Management

Virtual Switch Instance 2
Virtual Switch Instance 1
Virtual Switch Instance 2
Virtual Switch Instance 1
OpenFlow Controller 2
OpenFlow Controller 1

(1)Flexibility:

The ﬂexibility in the network virtualization denotes the scalability and the control level to the network. It usually conﬂicts with the isolation demand.

Mapping switches

Mapping switches

Database
Mapping

Container Based ApplicaƟon VirtualizaƟon

Tenant 1 ApplicaƟon
Tenant 2 ApplicaƟon

Fig. 8. Integrated OpenFlow management framework.
A MAC layer network virtualization scheme with new MAC addressing mode is proposed in [91]. Since it uses a centralized MAC addressing, it could overcome the SDN scalability problems. This system efﬁciently supports Cloud computing and sharing of the infrastructures as shown in Fig.9.

……

Physical Network

User application 1

User application 2

OpenFlow controller

Virtual resource 1-1 Virtual resource 1-2 Virtual resource 2-1 Virtual resource 2-2

Management based on FlowVisor

Fig. 7. System design of FlowN

Physical resource 1

Physical resource 2

Fig. 9. OpenFlow network virtualization for Cloud computing.

OpenFlow switch

In [87] it present a system called FlowN that extends the The virtualization of the LANs could be used to virtualize NOX version 1.0 OpenFlow controller, and embeds a MySQL the network, but it has more complexity and overhead, and is

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
12

not good at scalability. Thus the virtualization of MAC layer functions could be used, and is realized in [91] by reserving part of the remaining MAC address for the virtual nodes. This system reduces IP and control overhead, but the security issues need to be solved. Details of the system are provided, but the prototype is not tested in experiment.

between the switch and the controller. The QoS tools are applied to make fair resource allocation. It provides strict isolation between different sub-domains in a large SDN. It also allows future protocol extensions. However, there is no prototype tested in the system.

(2) Isolation:

In order to ensure all the tenants of the virtual network can share the infrastructure without collision, the isolation problem must be addressed. The isolation may be in different levels or places, just like address space. A research network named EHU-OEF is proposed in [88] (Fig.10). This network uses L2PNV, which means Layer-2 Preﬁx-based Network Virtualization, to separate various resource slices and allows users to have multiple virtual networks based on the MAC address settings. L2PNV has made some speciﬁc ﬂow rules as well as some customized controller modules. It can also change FlowVisor.

Fig. 11. A full virtualization system. (MC: master controller; C1, C2, C3: regular controllers; OS: operating system; OFI: OpenFlow instance.) [89].

Research slice 1 Research slice 2 Other slice Production slice

OpenFlow controller 1

OpenFlow controller 2

OpenFlow controller n

Slice 1

Slice 2

Slice n

Local layer 2 Local layer 2 Local layer 2 Global layer 2

address 1

address 2

address 3

address

EHU-OEF
OpenFlow protocol

Memory isolator

Slice identification

Interfaces isolator

Processing isolator

Slice isolator

Mapping

Resources allocator

Resercher

OpenFlow switch
OpenFlow instance 1
Non technical user

OpenFlow instance 2

Fig. 10. EHU-OEF: an integrated OpenFlow management framework.

EHU-OEF can well isolate different slices in the ﬂow table, and the ﬂow trafﬁc can be distinguished based on the MAC addresses. Moreover, the NOX controllers use their module ecosystem to easily manage different slices. This solution has the beneﬁt since it can deal with longer MAC header such as in virtual LAN (VLAN) cases. It can also be used to test other non-IP protocols by simply changing the addressing schemes. The EHU-OEF prototype is tested on the platform composed of seven NEC switches (IP8800/S3640), four Linksys WRT54GL, and two NetFPGAs. It is the ﬁrst OpenFlow-based SDN infrastructure in Europe and allows experimental and application-oriented data trafﬁc in the same network without conﬂict.
In [89] a SDN virtualization system is proposed with fair resource allocation in the data/control planes as shown in Fig.11. All SDN tenants obtain the network resource by enforcing the resource allocations in the central controller, the datapath of the forwarding elements, and the control channel

Hardware switch
Fig. 12. Network virtualization using Slice Isolator [92]
In [92] the isolation issue is solved among slices in different virtual switches. It makes all slices share the network resources in a fair way while allowing the isolation adaptation according to the expected QoS performance. It also allows multi-level isolation (see Fig. 12). A Slice Isolator is located above the switches and OpenFlow abstraction layer, and is designed as a model focusing on (a) Interface isolation; (b) Processing isolation; and (c) Memory isolation.
Evaluations of the system show that the isolation levels have signiﬁcant impact on the performance and ﬂexibility. The time for reconﬁguring the hardware trafﬁc manager increases fast when the isolation level goes up. High isolation level also leads to latency. So the best isolation level can be determined based on the update time and latency to achieve required performance.
(3) Efﬁcient Management:
Network virtualization management is involved with the mapping, layer abstraction or system design to make sure the virtualized network can satisfy different demands. It is the integration of the ﬂexibility, isolation, and convenience. A

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
13

Management Application
XML File Virtual Network discription

LibNetVirt Generic Interface

VPN

Drivers MPLS OpenFlow

Fig. 13. LibNetVirt architecture.

network virtualization architecture allowing management tools to be independent of the underlying technologies is presented in [93]. The paper proposes an abstraction deployed as a library, with a uniﬁed interface towards the underlying network speciﬁc drivers. The prototype is built on top of an OpenFlowenabled network as shown in Fig.13. It uses the single router abstraction to describe a network, and has feasibility for creating isolated virtual networks in a programmatic and ondemand fashion.In this system the management tools can be independent of the working cloud platform so that different technologies can be integrated, and the system focuses on reduce the time of creating the virtual network. The prototype named LibNetVirt is separated in two different parts: generic interface and drivers. The generic interface is a set of functions that allow interacting with the virtual network and executing the operations in the speciﬁc driver. A driver is an element that communicates to manipulate the VN in the physical equipment.
A scheme [94] as shown in Fig.14, enables the creation of different isolated, virtual experimental sub-systems based on the same physical infrastructure. This system implements a novel optical FlowVisor, and has cross-layer for management and high isolation for multiple users.
This architecture provides several abstraction layers for the management: (a) The Flexible Infrastructure Virtualization Layer (FVL) is composed of virtualized slicing and partitioning of the infrastructure. (b) The Slice Control and Management Layer (SCML) can monitor the status of slices. (c) The Slice Federation Layer (SFL) can aggregates multiple slices into one integrated experimental system. (d) The Experiment Control and Management Layer (ECML) aims to set up experiment-speciﬁc slice parameters. It uses extended OpenFlow controller to achieve various actions.
The architecture is tested on the platform composed of eight NEC IP8800 OpenFlow-based switches and four Calient DiamondWave optical switch. The result shows that the setup time of establishing the ﬂow path increases even for a large number of hops.
There are other aspects of the network virtualization designs. We compare the above discussed systems with respect to their focus points in Table 2.
FlowVisor becomes the standard scheme of the network

Infrastructure as Service OpenFlow Common Plaƞorm
VirtualizaƟon

virtualization, so we compare these presented systems with FlowVisor (the last column). Most of the presented systems, no matter whether it is based on FlowVisor or it is built totally in a new scheme, not only have equivalent abilities to FlowVisor, but have one or more advantages over FlowVisor such as ﬂexibility, adjustable isolation levels, etc.
D. Discussions
Network virtualization not only enables infrastructure sharing, but also provides better ways to utilize the infrastructure or to reduce the cost. Virtualization can greatly reduce the network upgrading cost for large-scale wireless or wired infrastructures. For example, a mobile network virtualization scheme is designed in [95]. It has lower cost than classical network and SDN network. A case study with a German network is given there. The considered capital expenditures can be reduced by 58.04% when using the SDN-based network instead of the classical one. A qualitative cost evaluation shows that the continuous cost of infrastructure, maintenance cost, costs for repair, cost of service provisioning are lower.
Smart Object/Intelligent Things
Sensor/Things
Server
Others
Fig. 15. Abstraction layers of the virtual network [96]
It is reported in [96] that the OpenFlow-based micro-sensor networks (its network components are shown in Fig. 15) can be seamlessly interfaced to the Internet of Things or cloud computing applications. In traditional sensor networks, some sensors away from the access point may not be reached. However, by using the virtualization we form a new concept called ﬂow-sensors, which enables smooth data transfer between all sensors. A ﬂow-sensor is a sensor with local ﬂow table and wireless communications to controllers. Fig. 16 shows an example of the advantages of a ﬂow sensor network over a conventional sensor network. In a conventional sensor network, the sensors 1 and 2 cannot communicate with each other without the access point, so node 4 is too far and is lost; within the ﬂow sensor network, node 4 can talk to node 8, so that node 4 can be accessed. In [96] it shows that the ﬂow sensor can have 39% higher reachability than a common sensor. This is extremely useful in large-scale sensor network (>100 sensors).
V. QUALITY OF SERVICE (QOS)
In past decades, the Internet Engineering Task Force (IETF) has deﬁned two types of Quality of Service (QoS) architectures, IntServ (integrated services) and Diffserv (differentiated services). The IntServ is difﬁcult to implement in todays large networks due to too much operation overhead in different routers. OpenFlow can provide ﬁne-granularity QoS

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
14

Infrastructure 1

Infrastructure 3
IBM

FVL (virtualization slices 1)

SCML

FVL (virtualization slices 2)

SCML

SFL

ECML

User 1

Infrastructure 2

Infrastructure 4

FVL (virtualization slices 3)

SCML

SFL

ECML

User 2

Fig. 14. Cross-layer experimental infrastructure virtualization

TABLE II THE COMPARISON OF THE REPORTED NETWORK VIRTUALIZATION SYSTEMS.

System FlowN [87]
Integrated system [90] MAC addressing system [91]
EHU-OEF [88] Adaptable isolation system [92] LibNetVirt [93] Cross-layer experimental infrastructure virtualization [94]

Flexibility Very High
High High
Very High High General
General

Isolation Very good
Good Good
Excellent Excellent Average
Average

Management Not so hard
Very easy Not so hard
Easy Easy Very Easy
Very Easy

FlowVisor −(means it has equivalent functions to FlowVisor) −√
(means it has better p√erformance than FlowVisor)
− −
√

Network 1

6 7

Network 1

6 7

5

5

8

Outdoor access point 8

Outdoor access point

Later on we will survey other QoS supporting schemes such as special operating system support for SDN QoS, QoSFlow, and so on.

4
3 Network 2

1 2

4
3 Network 2

1 2

Typical sensor network

Flow sensor network

Fig. 16. Typical sensor network and ﬂow sensor network [96]

support (delay, jitter, throughput, etc.) [103]. This is because OpenFlow can well control packet-level or ﬂow-level data delivery via its controllers. Such a ﬁne-granularity means that OpenFlow allows the users to specify how to handle individual ﬂows, which corresponds to IntServ in IETF deﬁnitions. Of course the user can also aggregate individual ﬂows into classes (i.e., Diffserc). As a matter of fact, OpenFlow provides a series of programming tools to create/recycle slices (a slice is a virtual ﬂow). The user can deﬁne how to allocate network resources (queues, routers, switches, etc.) to different slices with different priorities.
There are very few works targeting SDN QoS supporting issues. Among the few QoS models in SDN/OpenFlow, OpenQoS [97, 98] is one of the most typical solutions. It has a comprehensive controller architecture to support scalable video streaming in SDNs. We therefore summarize its principle ﬁrst.

A. OpenFlow QoS Model
Streaming multimedia applications such as Internet conferencing, IPTV, etc., all require a strict QoS (delay /jitter) control. As an example, the Scalable Video Coding (SVC) [102] encodes a video segment into two parts: a base layer and one or more enhancement layers. It is important to guarantee the QoS of the base layer since it has the detailed pixel information. However, current Internet structure cannot achieve high QoS for base layers due to hard-to-control TCP connections. Moreover, Internet tends to search the shortest path. Once that shortest path is congested, a large percentage of packets are dropped. However, OpenFlow does not stick to the shortest path. By programming the controllers, we can easily adjust the ﬂow delivery rules. In [97] they proposed an OpenFlow-based video delivery scheme which uses dynamic QoS model to guarantee the best QoS for SVC base layer data.
QoS Optimization Model: In [97] an interesting OpenFlow QoS model is proposed. The basic principle is as follows: it formulates the dynamic QoS routing as a Constrained Shortest path (CSP) problem. For video applications, it employs delay variation as the constraint in the optimization function. It ﬁrst represent the entire SDN as a simple graph. It then deﬁnes a cost function based on the delay variation constraint. The CSP problem aims to ﬁnd the best path to minimize the cost

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
15

function. To meet the packet loss constraint, it also deﬁnes a combined constraint with the weighted sum of packet loss measure and delay variation. The solution supports both level1 and level-2 QoS routes. Its results show that the average quality of video streams is improved by 14% if only the base layer is rerouted. By rerouting the video data in the enhancement layer together with the base layer, the quality is further improved by another 6.5%.
B. Controller Architecture for QoS Optimization
The controller proposed in [98] has the functions of route calculation and route management. Fig.17 illustrates the controller architecture with various sub-functions. The controller has powerful capabilities to specify QoS requirements. It can also directly control the ﬂow table in order to differentiate between different priorities of trafﬁc. The communications between the controller and the switches may be secured by some standards such as SSL.

C. QoSFlow Architecture
In its current version, OpenFlow is not able to conﬁgure QoS parameters in a dynamic and on-demand manner (i.e., it does this manually). In order to deal with QoS problems in dynamic approach, a framework called QoSFlow (Fig.18) that enables QoS management in OpenFlow environment is proposed in [139]. QoSFlow allows the management of trafﬁc class and queues through rules or policy. It manages QoS resources (e.g., bandwidth, queue size) without changing the SDN architecture. All actions are invoked by an OpenFlow controller and in a dynamic and on-demand manner (not manually).

JSON
Network Administrator

QoSFlow Controller

QoSFlow Agent

QoSFlow Manager
QoSFlow Monitor

QoS Database
Client

NOX QoSFlow API + NOX API

QoS CONTRACT MANAGEMENT
QoS MANAGEMENT

Routers Users QoS Contracts Measurement
SECURITY

ROUTE CALCULATION
ROUTE MANAGEMENT
NET MANAGEMENT

WEB-BASED QoS CONTRACT ENTRY INTERFACE
hƩps
PUBLIC INTERNET

OPENFLOW NETWORK INTERFACE
SSL
OPENFLOW NETWORK

Fig. 17. controller subsystems to support QoS [97].
Note that the forward layer has to implement the policing functions in order to ensure that the clients obey the Service Level Agreements (SLAs) speciﬁed in their QoS contracts. The following three extra features should exist in the above architecture: (1) Resource monitoring: The forwarders should comprehensively monitor their available network resources and report periodically to the controller. The controller may poll the forwarder for such proﬁle. (2) Resource signaling: Each forwarder should use signaling messages to communicate with the controller on the current resource consumption so that certain actions can be taken by the controller, such as updating the ﬂow table, changing QoS parameters, etc. (3) Resource reservation: From time to time the controller may command a forwarder to reserve certain resources for future QoS needs [101]. This includes the reservation of buffer size, memory space, CPU calculation time, and other resource requirements.

QoSFlow Datapath

Input Ports

OpenFlowQoS (QoSFlow API + OpenFlow API)
netlink
Linux Kernel’s Queueing Disciplines and Queues

Output Ports

Packets Flow

User Space Kernel Space

Fig. 18. QoSFlow modules [139]

QoSFlow is an extension of the standard OpenFlow controller which provides multimedia delivery with QoS. The QoSFlow controller is based on NOX, which is responsible for managing/monitoring actions and controlling signaling messages. The new controller, besides NOX API, contains the following new components: QoSFlow agent, QoSFlow manager, QoSFlow monitor, and DB-QoSFlow client. These four modules have been designed to extend the NOX API with QoS features called QoSFlow API. QoS Agent is responsible for creating a communication module between an administrator management tool and the other two QoSFlow components: the manager and monitor QoSFlow. By using JSON interface, the agent is able to receive policies, manage or monitor commands from a third-part administrator application. The QoSFlow monitor and manager components, respectively, monitor and manage the QoS of OpenFlow domains. Fig.19 shows its controller architecture.
The QoSFlow data-path component is responsible for creating all low-level actions on the switch ports. This component allows OpenFlow to get all the required information to run management commands created by either the administrators tool or through header packet information. In QoS management tool, the actions are processed in the QoSFlow Agent. When receiving those actions, it checks the type of the received requests in order to select the next procedure. This new message is automatically sent to controllers through NOX. The QoS actions can be applied automatically through the packet header information. In order to support ﬁne-granularity QoS,

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
16

Other controllers Controller-Controller
Interface
Controller-Controller Interface
Other controllers

Service Layer

Video/audio applications
Controler-Serive Interface

Flow Management

Call Admission

Traffic Policing

Standard OpenFlow controller

Topology Management

Route Calculation

Route Management

Control Layer

Controler-Forward Interface

OpenFlow routers /switches

Fig. 19. QoSFlow controller architecture [139]

the incoming trafﬁc is grouped as data ﬂows and multimedia ﬂows, where the multimedia ﬂows are dynamically placed on QoS guaranteed routes and the data ﬂows remain on their traditional shortest-path routing approach.
D. Operating System for QoS Optimization
NOX, the standard network operating system, can be used for packet-level or ﬂow-level control. However, it does not have the necessary APIs for QoS support. For instance, it does not support QoS-oriented virtual network management, or endto-end QoS performance monitoring. In [100] an QoS-aware Network Operating System (QNOX) is proposed to support general OpenFlow QoS functions.
The QNOX system includes the following modules: WDM/ASON, IP, MPLS-TP. Here WDM/ASON can monitor large network trafﬁc status. QoS-aware Open Virtual Network Programming interface (QOVNPI) allows a client to request any type of QoS performance. The service element (SE) can be used for QoS demand deﬁnitions, such as the required network bandwidth, memory overhead, preferred server locations, packet loss rates, delay bounds, and security levels. The SLA (service level agreement) and SLS (service level speciﬁcation) modules can be used to assess the OpenFlow resource availability, that is, to check whether the network can meet the clients QoS demands. Obviously QNOX can deﬁne ﬁne-granularity of QoS, such as packet-level delay or loss rate. Based on the experimental results in [100], QNOX can quickly calculate the routing path in less than 100ms even with over 100 nodes in the SDN. The SLA/SLS can ﬁnd all network resources in less than 1s.
E. Other QoS Supporting Strategies in SDN/OpenFlow
In [140] a SDN QoS scheme called PolicyCop is proposed to implement an open, vendor agnostic QoS policy management architecture. It has a special software interface for specifying QoS-based Service Level Agreements (SLAs). PolicyCop uses the control plane of SDNs to monitor the compliances of the QoS policies and can automatically adjusts the control plane rules as well as ﬂow table in the data plane based on the dynamic network trafﬁc statistics.
In [141] an OpenFlow QoS enhancement scheme is proposed to allow the creation or change of the behavior of the

existing routing queues. It suggests that an OpenFlow capable switch report the queue status to the control plane. It has a module called Queue Manager plug-in which allows the uniform conﬁguration of QoS capabilities in each OpenFlow switch. Such an idea is implemented in Ofelia testbed. Its implementation is based on OpenNMS, an open-source network management system.
In [142], an Iterative Parallel Grouping Algorithm (IPGA) is proposed to manage the prioritized ﬂow scheduling issue, It has an inherent nature of parallelism for efﬁcient execution in OpenFlow systems. Its algorithm is based on a M-ary multirooted tree, a Fat-tree used in most data center networks. It assumes that the SDN switches have two layers: lower pod switches (edge switches) and upper pod switches (aggregation switches). It formulates the ﬂow scheduling issue as a linear binary optimization problem.
VI. SDN SECURITY
A. Intrusion Detection
SDN creates some new targets for potential security attacks, such as the SDN controller and the virtual infrastructure [105]. Besides all the traditional networks’ attacking places (such as routers, servers, etc.), SDN has some new target points such as: (1) SDN controller: Here traditional attacks listed above also exist; (2) Virtual infrastructure: it could have traditional attacks on the hypervisor, virtual switch and VM (virtual machine); (3) OpenFlow Network: attacks could occur in OpenFlow protocol for openﬂow enabled devices.
In the following paragraphs, we will describe some typical OpenFlow/SDN safety (such as failure recovery) issues and security schemes. Here safety refers to the schemes that overcome natural faults, and security means to overcome intentional attacks.
A network intrusion detection and countermeasure selection (NICE) scheme is investigated in [108]. It aims to achieve the security in a virtual networks such as SDN and cloud computing. Cloud Security Alliance (CSA) survey shows cloud computing security is the top concern among different types of networks. The conventional patch-based security schemes do not work well in cloud data centers since the users could have full access to those centers. In [108] the attack graph based analytical models are used for intrusion detection. NICE includes two important phases:
(1) It uses an intrusion detection agent called NICE-A to capture the trafﬁc in each cloud server. A Scenario Attack Graph (SAG) can be established and updated each time the NICE-A scans the network. Based on the pattern analysis of the SAG, the NICE-A knows whether or not it should act.
(2) Deep Packet Inspection (DPI) is activated if the virtual machine (VM) enters inspection state. It can use SAG to ﬁnd security threats and VM vulnerabilities.
NICE runs low-overhead security software in each cloud server. It includes 3 software modules an attack analyzer, a network controller, and a VM proﬁling server. The VM proﬁling server can monitor the network state in real-time, and construct the operation proﬁle for all services and ports. It also takes care of the connectivity issues between VMs.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
17

The attack analyzer can deduce the event correlations among different SAG nodes. It then ﬁnds potential security holes and detect an occurring threat. The network controller can control all conﬁgurations in each hardware device and software unit based on OpenFlow protocols. As we can see, NICE ﬁts SDN very well.
B. Modular Security
Although OpenFlow (OF) decouples the data plane and control plane and thus greatly simpliﬁes the hardware operations, it also brings single-point security issues: once the controller is attacked, all low-level switches are misled and cannot correctly deliver the packets.
FRESCO-DB [109], a database module, can simplify the SDN security key management. It deﬁnes uniﬁed session key format and IP reputation model. Inspired by Click router design, it uses a modular and composable security protocols. It consists of two important parts: (1) Application layer: it uses APIs and interpreter to support modular applications; (2) SEK (security enforcement kernel), can be used to perform all policy-related actions. Diverse security policies, such as DROP, REDIRECT, QUARANTINE, can be enforced by Security applications developed in FRESCO scripts, to react to network threats by simply setting an action variable. The above two parts are built into NOX. A network user can use FRESCO script language to deﬁne various security modules. Regarding the implementation of FRESCO, Python is used to implement the Application Layer prototype (total around 3000 lines of codes), and runs as an OpenFlow application on NOX.
C. SDN Trafﬁc Anomaly Detection
In [110] it proposes 4 different OpenFlow trafﬁc anomaly detection algorithms. Each of them is evaluated in real networks including both home and business networks. In the following we summarize the ideas of those 4 trafﬁc anomaly detection algorithms:
(1) Threshold Random Walk with Credit Based Rate Limiting (TRW-CB) algorithm: As we know, a TCP connection can be established in a much higher success rate if the server is not attacked. By using sequential hypothesis testing (i.e. likelihood ratio test), it analyzes each connection status and attempt to detect the worm infections.
(2) Rate-Limiting: A virus infection can cause many connection request within very short time, while a benign trafﬁc ﬂow will never have such a high request rate. This is the principle of rate-limiting, that is, we check the request rate and detect a malicious event.
(3) Maximum Entropy Detector: Maximum entropy calculations can be used to ﬁnd trafﬁc statistical features. By using a baseline distribution, maximum entropy model can be used to classify the packets into different categories, and each category could be detected as benign or abnormal.
(4) NETAD: It acts like a ﬁrewall or ﬁlter. It simply scans the packet header and blocks any suspicious packet based on the packet attributions.

D. Language-Based Security
Analyzing how to program SDN in a secure and reliable manner is discussed in [111]. The solution involves development of a new programming model that supports the concept of a network slice. The isolation of the trafﬁc of one program from another is achieved with help of slices. They also isolate one type of trafﬁc from other. They have developed a semantics for slices, and illustrate new kinds of formal modular reasoning principles that network programmers can now exploit. It provides deﬁnitions of end-to-end security properties that slices entail and verify the correctness of a compiler for an idealized core calculus in a slice-based network programming. They have also described their implementation which is equipped with a translation validation framework that automatically veriﬁes compiled programs using the Z3 theorem prover.
It is challenging today to implement isolation in networks. Most systems still use manual setup to block suspicious trafﬁc. Such a setup is often labor-intensive and vendor-speciﬁc. In [111], it suggests that using a high-level programming language to set up the data delivery policies and isolate different domains. It leaves the error-prone low-level device conﬁgurations to the SDN compilers. Such a scheme overcomes the shortcoming of NOX, which cannot easily isolate different subnetworks when security holes are detected.
The language-based security [111] relieves the programmers from complicated security programming due to the use of slice isolation concept. A slice is deﬁned as a virtual connection consisting of routers, switches, communication ports or links. The slices have been deﬁned with both attributes and actions in [111]. A slice can be isolated from another if running them side by side in the same network does not result in slice leaking packets into the other slice. They deﬁned several intuitive security properties like isolation and developed an operational condition called separation that implies the isolation property. Finally, they formalized a compilation algorithm and proved that it establishes separation and isolation.
E. Loop Detection Problem
The routing loops make packets never reach the ﬁnal destination. In [112] it presents a dynamic algorithm which is built on header space analysis, and allows the detection of loops in SDNs. There the network model has been illustrated as a directed graph. Hence concepts of header space analysis has been translated into the language of graph theory. Rule graphs and the dynamic loop detection problem are studied in [112]. They have shown how to model a network as a directed graph. By analyzing the reachability and connectivity of the topology graph, a node-to-node, no-loop path can always be found. A dynamic strongly connected component algorithm is proposed in [112] to allow us to keep track of edge insertions and deletions. It can also be used to detect loops in a routing path.
A comparison of all the above SDN security schemes is presented in the tabular form below:

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
18

TABLE III A COMPARISON OF DIFFERENT SDN SECURITY SCHEMES.

Sources Uses OpenFlow/NOX Introduce new architecture based on OpenFlow/NOX Experiments (E) or real networks (R) Software (S) or Hardware (H) Introduces new language for SDN

[106] Yes Yes
E S No

[107] Yes No
E S No

[108] Yes Yes
R S No

[109] Yes No
E S No

[110] No No
E S Yes

[111] Yes Yes
E S No

[102] Yes Yes
E S No

F. SDN Safety Issue: Failure Recovery
In order to build a trustworthy SDN, we need to make a SDN resistant to both external failures (security issues) and internal failures (safety issues) [151]. Here external failures refer to external, intentional attacks by adversaries. The above discussed security solutions aim to detect and overcome external attacks. The internal failures refer to natural faults due to some system-related shortcomings or unintentional human factors. We regard those internal failures as safety issues. For example, a SDN could fail if the communication link between the controller and the switches has outages due to bandwidth unavailability. Thus all controllers’ commands cannot be delivered to the switches’ ﬂow tables. If the switchto-switch path has link failure, many packets can get lost. Therefore, some type of link quality monitoring and path recovery schemes are needed to overcome the link failure.
There could be many of other safety issues in a SDN. For example, the controller may not be able to synchronously update all switches’ ﬂow tables due to schedule management failure. The switch may not be able to timely report trafﬁc delivery status to the controller (thus the controller may not update the ﬂow table for quite a while). When using multiple controllers in a SDN, the controllers may not be able to keep the consistent control due to communication delay. In the following discussion, we will illustrate some existing schemes that aim to address the SDN safety issues.
In [106] a fast failure recovery scheme is proposed for OpenFlow networks. It investigated the switch-over frequency and packet loss rate in its evaluation. It uses NOX software to recover services.
In OpenFlow network we can immediately or proactively add a ﬂow entry to the table after a failure occurred. The total recovery time is determined by the lifetime of the ﬂow entries. In [106] two values of timeouts are deﬁned, one is called idle timeout, which means the time interval that a ﬂow entry should be removed if not used for certain time (that is, no packet for that type of ﬂow entry is passing through a switch); the other one is hard timeout, which is the maximum time interval that a ﬂow entry can stay. No matter which timeout occurs, it will trigger the failure recovery.
Note that the system cannot be recovered if the controller has no idea on what type of failure occurred. The controller may just randomly add a ﬂow entry in the table if the failure type is not recognized. In [106] NOX has been used to implement L2-learning scheme for failure detection. It is written in C++ (called L2-lerarning switch) or in Python (it is called L2-learning Pyswitch).
If a failure occurs, the incorrect ﬂow entries should be

erased from all switches, and new entries should be immediately added to each switch. The controller should have robust schemes to detect the failure, and ﬁnd new routing path to deliver the ﬂows. The controller will check the old routing path associated with the failed links. If the old path is still usable, it will not establish a new path. Otherwise, new path needs to be added to the ﬂow entries and old entries should be removed immediately.
In [106] Ubuntu 9.04 is used to install Open vSwitch 1.1.0 and NOX 0.9.0. Over 10K ping packets were sent out at the pace of one packet every 10ms. The packet loss rate is calculated by counting the number of received ping packets. Hard timeout is set to 20 seconds, and idle timeout is 10s. The routing loops are avoided by using spanning tree algorithms. The path reestablishment scheme in [106] is faster than conventional MAC re-convergence or ARP. It only uses 12 ms to recover from a link failure.
In [107] a scheme is called Operations, Administration, and maintenance (OAM) tool is used to re-establish a new path. To minimize the path switching time, it uses a proactive approach, that is, a backup path is pre-stored in the ﬂow table in case a path fails. This scheme makes path recovery time less than 50ms. In addition, some probing packets are periodically sent in the network. If it is not received by a node, the system knows that a path failure occurs. If it takes a long time to receive the probing packet, a failure is also detected. Thus [107] provides an efﬁcient way to recover from path failure.
VII. OPENFLOW FOR WIRELESS AND OPTICAL NETWORKS
A. Overview
Why OpenFlow for wireless networks? Wireless infrastructure is more hybrid and complicated than wired ones. Many wireless standards, such as Wi-Fi, Wi-Max, cellular networks, etc., are all co-operating in the same backbone for providing anywhere Internet access. Managing such a heterogeneous wireless infrastructure is a big challenge. To make things worse, different wireless products have their own lower layer (physical/MAC layers) speciﬁcations, and are very difﬁcult to re-conﬁgure for dynamic mobile applications. For example, Wi-Max forwards data in a point-to-point style in microwave frequency; while Wi-Fi uses one-to-many star topology in free frequency (2.45GHz). OpenFlow can ofﬂoad the wireless MAC layer operations to virtual machines, and uses software-deﬁned network programming to achieve high ﬂexibility and reconﬁgurability. OpenFlow decouples lower layer wireless transmission from higher layer control; thus it

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
19

makes wireless data forwarding reach higher rate ( Gbits/sec). This can fully explore 802.11 potential data rate.
The network virtualization in OpenFlow can signiﬁcantly improve the scalability of the wireless virtual LAN tagging and ﬁrewall ﬁltering operations. When the networks are moving to cloud computing, it becomes harder and harder to manage the dynamic and distributed cloud servers. OpenFlow can easily update the cloud policies over a dynamic deployment environment. However, it needs some innovative designs if applying SDN/OpenFlow to wireless world since the original SDN motivation was to use wired, high-speed switches to perform dump data forwarding, and to use reliable wires (not wireless) to achieve stable communications among SDN control plane units. If we shift everything to wireless media, how do we allocate different wireless channels for switchto-switch or controller-to-controller communications? What if those radio channels are not available from time to time due to signal fading and shadowing? Some studies are solving those issues [113-118]. Later on we will use two examples (wireless sensor networks and wireless mesh networks) to explain how we can integrate OpenFlow with wireless technologies.
Why OpenFlow for optical networks? There is a great deal of beneﬁts when adopting SDN/OpenFlow for optical network control: (1) Current optical networks have difﬁculties to react independently to requests from client systems distributed at the network edge. SDN provides programmable, abstracted interface for ﬂexible application re-conﬁgurations in optical control units. (2) Existing optical networks cannot easily upgrade the software in each optical switch due to the embedded software nature. OpenFlow could easily upgrade services due to its separation of control and data planes. (3) SDN/OpenFlow allows multi-level abstraction via its networked re-programming and virtualization technologies. This makes optical network stack suit easily adapt to different network topologies. (4) The cost of optical hardware is typically high, especially the photonics and associated electronic components. SDN/OpenFlow could reduce those costs due to its ’dump’ hardware operations - just simply following the ﬂow table.
B. OpenFlow for Wireless Sensor Networks
Wireless sensor networks (WSN) have become important platforms for environmental monitoring. There are many sensor hardware designs such as CrossBow, Imotes, etc. However, all those sensor products cannot be easily programmed due to vendor-speciﬁc SDK (software development kit) and the tight integration of hardware and software in one sensor node.
Moreover, those sensors are difﬁcult to re-task [119, 120] if a new environmental monitoring mission is required. For example, how can we re-program 100 sensors in a lake WSN to detect a new type of pollution? Obviously today we need to take each sensor out of the water and change the programs embedded into the sensor hardware. This is not realistic in large-scale WSN with so many nodes.
Although some over-the-air programming techniques are used for some vendors sensor boards, their data sensing and forwarding schemes are still vendor-speciﬁc. For example, they may use different operating systems, or different programming languages. The programmer needs to check different

manuals to get familiar with the API functions. It will be better if the user just simply conﬁgure a network controller based on universal networked operating system. The sensor hardware and embedded stack protocols could be decoupled such that the users do not need to worry about the data forwarding details in each sensor, and just simply conﬁgure the controllers ﬂow table. The data forwarding rules do not necessarily follow the speciﬁc MAC layer protocols (such as Zigbee, 802.11, or other protocols).
SDN/OpenFlow can well solve the above issues. It makes each sensor just simply forward the sensor data based on the speciﬁed ﬂow table and rules. All those rules can be easily changed through controllers programming. Since all nodes follow universal operating system (such as NOX), the retasking can be easily achieved by following standard scripts programming. A Software-Deﬁned WSN architecture, called sensor openﬂow [120], can be used to address key technical challenges mentioned above. We illustrate its main ideas in Fig.20.
It has three layers: the application layer has all sensor data query related applications such as local data processing; the control plane and data plane are totally separate: the former can remotely re-conﬁgure the sensor parameters, and the latter can check the ﬂow table and perform the corresponding actions. Its main idea is to make the large-scale sensor network easy-to-manage via programmable control plane and usercustomizable ﬂow table. Sensors are no longer applicationdependent and the sensor data query policies can be easily reset. Sensor OpenFlow allows policy changes in an easy style since a programmer can simply change the controllers software instead of dealing with the wireless sensors.

Application layer
Control Plane Data Plane
... ... Event ID ... ... #Fire_event

Sensor data reporting Responding to query Data fusion
Sensor re-configuration

Sensing and filtering Local data mining Data compression
Sensor query strategy control

Sensor ID #101 ~ #110

Sensor Actions Report location & temp

Other flow table fields Such as reporting interval

Fig. 20. SDN-based sensor networks
C. OpenFlow for Wireless Mesh Networks OpenFlow could be very useful for wireless mesh net-
work (WMN) management. Today WMN is often used in community networks or military applications for re-tasking from time to time. For example, an Internet provider may re-program a community mesh network to set up different IPTV services. A military center may want to re-conﬁgure a wireless network to adapt to different surveillance scenarios. Existing mesh network nodes are full ﬂedged with all physical to application layer functionalities. The network manager needs to setup each mesh node individually since each node may have vendor-speciﬁc programming features or proprietary device management proﬁles. Overall, today it is

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
20

very difﬁcult to perform rapid re-tasking or policy changes in the heterogeneous mesh clients (such as laptops, PDAs, phones, etc.) in a mesh network. OpenFlow decouples network control and hardware communications completely, and leave only basic data forwarding functions in each node, while the entire network can be easily re-programmed through a standard network OS (such as NOX) running in a control panel. As long as different vendors products support OpenFlows ﬂow table managements, a mesh network can be easily re-tasked through a standard network control script programming.
To make OpenFlow appliable to WMN, we need to overcome a few challenges [121-122]:
• Challenge 1: Fading channel: Unlike Standford OpenFlow testbed where ﬁxed wired network is the backbone, WMN has wireless channels everywhere (issues: radio fading, hidden terminal problem, wireless broadcast nature, etc.).
• Challenge 2: Dynamic Topology: Due to WMN link variations and nodes membership dynamics, the network topology changes at a much higher pace than in wired network. The OpenFlow needs to build a control plane to perform autonomous topology discovery and swiftly react on changes of the WMN topology.
• Challenge 3: In-band or out-band control: OpenFlow often adopts out-of-band signaling, that is, the channel to NOX is separate from the actually data forwarding network. However, in WMN we may not have different RF channels for separate control. On the other hand, using in-band control would decrease data network throughout.
Fig.21 shows the basic principle of using OpenFlow for WMN control. The WMN has both mesh routers and mesh clients. A radio channel control strategy is achieved by the control panel for router-to-router, router-to-client, and clientto-client communications. The control server in control plane can perform mobility management, routing strategy, and channel assignment.

•Mobile Control •RouƟng Control •Rule Learning •Channel Assignment

Control Server

To NOX

Internet

OpenFlow Control Path

WMN Control Rule
Database

CISCOSYSTEMS

CISCOSYSTEMS

CISCOSYSTEMS

iMac

CISCOSYSTEMS

CISCOSYSTEMS

䙊ؑຄ
WMN topology

OpenFlow Data Path

Flow Table

WMN Hardware (mesh routers or mesh access points or mobile nodes )

Fig. 21. OpenFlow for WMN management

In [121] an OpenFlow-enabled mesh routing scheme is proposed. It has OpenFlow-enabled routers, clients and gateways. Each node has multiple radio cards for multi-radio communications. The data path uses local sockets to talk with the control plane units. The control path communicates with NOX via secure channel. Connection to Internet is achieved through mesh gateways.
In [121] the in-band wireless communications are used between the controller and the switches. The high-quality

channels are used for controller-to-server communications since the controllers commands cannot be lost even there is signal fading.
D. OpenFlow for Optical Networks
Today optical networks have become the fastest Internet data transmission approaches due to the high-speed light propagation in optical ﬁbers. Typically an optical network consist of nodes such as Wavelength Cross-Connects (WXC), Reconﬁgurable Optical Add-Drop Multiplexers (ROADM), and Photonic Cross-Connects (PXC) [123]. Current optical nodes can be controlled by Element Management System (EMS) and the Network Management System (NMS), which uses either manual or semi-static style for lightpath provisioning [124]. Although this approach is reliable, it is difﬁcult to design a control plane technique to achieve a control of dynamic wavelength paths in metro/backbone optical networks. Such a control plane should be able to reduce operational expense, shorten the data transmission latency, and should be highly scalable to the network trafﬁc. An important optical control scheme is called Generalized Multi-Protocol Label Switching (GMPLS) [125]. It is a distributed packet forwarding control scheme. However, It has not been popularly used in optical network products [126]. One important reason is its complex control scheme that is not suitable to dynamic control of both IP and optical layers via a uniﬁed control plane (UCP).
SDN architecture, in particular, the OpenFlow protocol, could become a solution to the above issue. Although the initial purpose of using OpenFlow is to create a re-programmable network, it can also serve as a promising candidate for a UCP solution in hybrid networks [127]. It has been studied in optical network enhancements [128-130]. But it is still in the early stage for real networking.
In [124] an Openﬂow based PXC architecture is proposed. It uses a concept called virtual Ethernet interfaces (veths) to connect to each OpenFlow switch. Those veths look ”virtual” from the viewpoint of the PXC physical interfaces. Thus the control plane can easily manage all PXC interfaces. The virtual OpenFlow switch is also called OpenFlow agent. The integrated OpenFlow agent and the PXC is called OpenFlowenabled PXC (OF-PXC). It can be managed by a NOX controller. When the packets are received by the NOX, it can either insert a new record to the ﬂow table (if this is the ﬁrst packet) or decides which veth to forward the data.
VIII. AN EXAMPLE OF COMPLETE SDN SYSTEM
To illustrate a complete SDN system, here we use a good reference solution called MobileFlow [144] which uses a SDN architecture to implement a mobile network. A softwaredeﬁned mobile network (SDMN) provides maximum ﬂexibility, openness, and programmability to future carrier. It designs a special SDN data plane called MobileFlow forwarding engine (MFFE). All MFFEs are interconnected by an underlying IP/Ethernet transport network. Its SDN control plane has MobileFlow controller (MFC). The MFC has mobility management entity (MME)

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
21

As shown in Fig.22, it has MobileFlow and OpenFlow levels for the management convenience. In both of them the control plane is decoupled from the data plane. The data forwarding function in MFFE is fully deﬁned in software, while the control software can steer the user ﬂows to different service enables (such as video caching & optimization). Those services can be distributed throughout the mobile network. Note that the users trafﬁc can go through both MobileFlow level and OpenFlow level, or, it just goes through the OpenFlow level and reaches the Internet. Fig.24 also shows the OpenFlowbased decoupling of the IP/Ethernet transport network in the lower level. This is because in some cases the user trafﬁc may not go through the mobile network infrastructure (and just stays in the wired network, no wireless).

Control Plane MobileFlow Controller Mobile Apps… …
Internet

. . Different types . of gateways

OF Control interface OF Data Fwd Engine

Video cache & … …
optimization

OF Control interface OF Data Fwd Engine

OF: Openflow

Fig. 22. Software deﬁned mobile network
MobileFlow Controller: Such a controller can perform network-level management including topology auto-discovery, device monitoring, topological resource view, topology virtualization, etc. More importantly, it can handle all mobilityrelated activities, such as mobility anchoring, service migration, channel handoff, etc. A network operator can freely use MFFEs from different vendors. The operator can also use MFFEs to adopt novel mobile network architectures. The system supports m:1 mapping between MobileFlow applications and NFFEs since each mobile application belongs to a different control plane, and therefore enabling multitenancy.
Mobile Management: Supporting mobility based on 3GPP or other systems can be easily realized by introducing the mobile applications above the northbound interface of the MFC. The MFC cab send out ﬂow control rules to each MFFEs involved in handling the particular ﬂow. The channel handoff (i.e., communication frequency switching) can be easily implemented in each MFC when the QoS requirements are not met in the multimedia applications.
Testbed implementation: It uses COTS x86 based generalpurpose servers and OpenFlow-supported routers/switches from different vendors. It enables the software-based deﬁnition of different mobile networks (3G, 4G, etc.) with different characteristics (radio coverage, bandwidth, radio frequency, etc.). It supports virtualization for both control- and dataplane resources. The same MFFE can be reused by different types of virtual networks. Each virtual mobile network can evolve and be upgraded solely by replacing the corresponding virtual machine software units in the control plane servers. The MFFEs remain intact. The entire testbed is interconnected via COTS LAN switches.
Note that the above system adds MobileFlow level above

regular OpenFlow level. Thus it can directly use OpenFlow language syntax for network deﬁnition. For example, it can use the following language abstraction to monitor a port 80 trafﬁc:
Def switch join (switch)): P = inport:2, tp src:80 Install (switch, p, DEFAULT, [ ]) Query stats (switch, p)
Such a high-level language can run in NOX and interpreted by all OpenFlow-compatible routers. Overall, the MobileFlow system is a complete SDN/OpenFlow implementation in mobile applications. It allows ﬂexible re-conﬁguration of mobile channel allocation, QoS parameters, mobile access, and service roaming between wireless networks.
IX. RESEARCH TRENDS
There are still many questions on how to make the SDN more efﬁcient, how to optimize it across all the network sets, and how to achieve tradeoffs between different implementations. There is a need to have quantitative metrics/approach for evaluating the performance and efﬁciency of the SDN such as its scalability, availability and latency. In the following we point out some important future research topics.
A. Intelligent Flow Table / Rules Management
It is true that the motivation of designing SDN/OpenFlow is to simplify the network switches’ operations: instead of using vendor-dependent, embedded software in each switch, SDN only assumes ’dump’ data forwarding functionalities in each switch. The switch just simply checks the ﬂow table to determine how to forward each received data packet.
The tricky part is: although the switches do not analyze the trafﬁc, they can always report forwarding results to the higher layer - OpenFlow controller. The results could be simple success or failure for a data forwarding operation, or some error messages (such as switch failure), or other forwarding status data. In the current OpenFlow speciﬁcations, they do not specify how to handle those feedback data. They just point out that the ﬂow table should be set up based on a set of rules deﬁned by the controller. But the issue is: since the switches could have high trafﬁc burden, it will slow down their data forwarding operations if (1) network trafﬁc is heavy, and/or (2) the ﬂow table is large and has complex rules. It is important to perform self-learning in the controllers based on the pattern analysis of the trafﬁc ﬂowing through each switch.
We believe that the future trend of SDN/OpenFlow will include high intelligence in ﬂow table / rules control. We illustrate our idea in Fig.23. The network controller can learn what’s going on based on the feedback from the switches. For example, if the switches report a long delay for a sourcedestination IP pair, it indicates a possible routing loop or switch congestion somewhere. When the controller analyzes the statistical patterns from the switches’ feedback data, it can use any of the recent learning tools (such as Bayesian learning, reinforced learning, etc.) to deduce the optimal ’actions’ in the future in order to obtain a higher accumulative reward.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
22

The reward could be deﬁned based on the QoS performance metrics. The ’actions’ could be any packet handling operations or any policy changes.
Statistical analysis could be based on any trafﬁc pattern data mining schemes. Through dimension reduction, we could extract the intrinsic features from complex, multi-attribute trafﬁc data. Since some dimensions are not useful in pattern recognition, they could be removed by using Principle Component Analysis (PCA), Non-negative Matrix Factorization (NMF), or other dimension reduction schemes.

Application layer (scientists' experiments; data query; Internet surfing; environment monitoring...)
OpenFlow Protocol

OpenFlow Protocol
OpenFlow Controller

PPPooolliliciccyyy###111

The switches report data forwarding status to the controller for analysis

StaƟsƟcal Learning Reinforced Learning Bayesian Learning
Traﬃc Analysis ………

Fig. 23. Intelligent ﬂow table / rules management

B. Scalable Controller Management
With the application of SDN/OpenFlow in larger networks, the network controllers could become a performance bottleneck due to large amount of incoming signaling messages and forwarding requests. Those controllers do not necessarily be deployed in the same sub-net since a company network may cross multiple places (even in different countries, such as IBM, Intel, etc.). The controllers located in a distributed network may compete for common computing resources (such as communication channels).
To manage the coordination issue of large-scale controllerto-controller communication system, a carefully designed scheduling strategy with collision avoidance should be used. On one hand, SDN administrators want to see a virtually consistent controller system. On the other hand, they need to design a virtual-to-physical mapping model to manage the physically distributed controllers. Perhaps a tree-based hierarchical management scheme could be used to coordinate those controllers. The higher level controllers should be able to handle more heavy requests. The root controller then communicates with NOX on the global requests. Fault tolerance techniques could be used for controllers system. Even one controller is down, others should be able to compensate for the missing operations. By using fault tolerance model, we could ﬁgure out the optimal controller deployment strategy, such as which controller should be deployed in which sub-net.
Resource sharing strategies should also be made among controllers. By using a queueing model with shared resource pool, we could calculate the controller serving time and waiting time.
Note that the ﬂow table could handle the packets in different granularity levels. It could deﬁne the packet forwarding in

individual packet level; or, it could deﬁne the ﬂow-level forwarding actions. The controllers must be able to manage different granularity levels in order to accurately adjust the ﬂow table status (such as adding or deleting the forwarding rules).
C. Highly Flexible Language Abstractions
The SDN programming language should be able to adapt to frequent ﬂow rules changes. It should also be suitable to policy changes due to network topology change, regular SDN maintenance, emergent failures, etc. An SDN programmer would like to use a good language to perform policy changes atomically to each switch. However, atomic change is difﬁcult to implement since it needs the disruption of the entire network during policy change [29]. The future SDN language should at least achieve two levels of abstractions if the atomic level cannot be achieved:
(1) In packet level, the language should be able to specify the policy changes for all packets that meet similar attributes. It needs to make sure that all packets belonging to the same context are delivered with the same structural invariants such as loop-freedom.
(2) In ﬂow-level, the language should allow the deﬁnitions of ﬂow-oriented rules/policies, such as ququeing models, delivery order, load balancing, etc. The compliers and run-time system should be able to respond to the aggregated ﬂow-level rule changes.
Another language abstraction trend is to support modular programming, that is, it should allow the handling of isolation issues between multiple programs that control different portions of the trafﬁc. Each piece of program has different tasks, some target host monitoring, some for failure recovery, some for virtualization, and so on. How do we make all pieces of program interface to each other in a transparent way? This needs a high level of abstraction for SDN programming.
D. Low-cost Fine-granularity QoS Implementation
As we know, QoS strategies include class-based differentiated service (DS) and ﬁne-grained integrated service (IS). SDN/OpenFlow could deﬁne packet-level or ﬂow-level priorities and performance metric. Therefore, it can be used to support IS. Although some IS-oriented OpenFlow QoS models are deﬁned [98, 99], not many practical implementations are conducted. The main challenges include:
(1) The integration of multimedia coding with OpenFlow QoS management: There are many video encoding standards. Especially some standards such as H.264+/SVC can support priority-based coding, that is, different video data layers could be assigned different priorities, and the enhancement layer has the most important video data. OpenFlow could support such video streaming by controlling different ﬂows in different policies. However, the detailed ﬂow rules need to be integrated with different video encoding standards, which needs further research;
(2) Load balancing: Content Distribution Networks (CDNs) need load balancing capability in order to distribute the heavy

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
23

authentication between experimenters and slices, key escrow issue, etc.

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
Load Balancer

Load Balancer
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48

Client

Fig. 24. Load Balancing: Integrate server balancer selection with path selection [98]
workload across the network elements. While most of conventional load balancing strategies for multimedia streaming (live or on-demand) over CDNs rely on server-based load balancing, OpenFlow allows the load balancing actions in each possible ﬂow path (Fig.24). The future research needs to deﬁne the detailed procedure in OpenFlow controller in order to achieve such an integrated server balancer selection and path selection.
(3) Use Cross-layer design style to optimize QoS: Many QoS optimization schemes are based on cross-layer designs [131-133]. However, OpenFlow removes the boundaries of traditional Internet, and uses open, programmable model. Then the issue is: how do we implement cross-layer design style in OpenFlow in order to share all available network parameters in different places for QoS optimization?
E. Resilient Security in SDN
SDN/OpenFlow uses network virtualization technology to simplify the resource management of the large network. It enables the deﬁnition of virtual slices/slivers for different physical utilities (such as hard disk, memory, etc.). A slice could include several slivers. Each slice/sliver pair could be assigned a unique ID. Due to resource limitations, some malicious OpenFlow terminals may use attacks to try to overuse the resource slice/slivers. Therefore, we need to create a scale security scheme that can overcome the resource access attacks in slice/sliver establishment.
Some SDN security challenges include: (1) Scalability issues: If many slivers are needed in a slice, it has high overhead to generate/distribute different session keys for different slivers. (2) Sliver deactivation: When a sliver deactivates a sliver, we need to make sure none of the stored data can be decoded independently by that user (this is called forward secrecy).
Here we suggest a possible security solution based on ID-based cryptography [135]. While conventional public key schemes use random string to generate public key, ID-based crypto generates public keys from user IDs. Thus, it makes key management in SDN much easier since we don’t need to distribute public keys to SDN users. Moreover, the encryption/decryption can be done ofﬂine (thus a key generation center is not needed). To implement the above ID-based security, some issues need to be addressed such as mutual

F. Robust Wireless Integration
Although OpenFlow has been well developed in wired, local network, there are very few studies on its performance in wireless networks. All the existing wireless network OpenFlow designs [113-118] have not overcome the following two challenging issues:
(1) Integrated management of channel access and data forwarding: Many wireless networks support multi-channel communications among routers and clients, especially in cognitive radios. Therefore, each wireless node needs to detect available channels, and select the high-quality ones. Moreover, the nodes can change physical characteristics for optimal link radio communications. Thus in a wireless networks the OpenFlow data panel must perform efﬁcient channel sensing/access. However, the existing OpenFlow standards only deﬁne data forwarding functions in the hardware. We will need to signiﬁcantly improve the existing OpenFlow model (including its control/data panels task division, FlowVisor control, network visualization, etc.) by designing a brandnew ﬂow-table management scheme. Such a scheme may use reinforcement learning to simultaneously manage two ﬂow tables one for real-time data forwarding and another for multichannel sensing/selection.
(2) Conﬂict-free Scheduling of Control trafﬁc and data trafﬁc: Unlike wired OpenFlow model that can use cables to easily achieve control/data packet communications among nodes, wireless network uses unreliable wireless links for both control panel communications and data panel packet forwarding. The control panel demands a high-quality channel for loss-free delivery, while the data panel should use other available channels for routing. Therefore, a carefully designed channel allocation and packet scheduling scheme is required for conﬂict-free control/data trafﬁc delivery in routers and nodes.
X. CONCLUSIONS
In this paper we have comprehensively surveyed the design issues for SDN/OpenFlow. Especially we have covered all important issues in concrete network implementation including language abstraction, controller design, virtualization scheme, QoS support, security issues, and wireless/optical network integration.
Below we brieﬂy summarize some important aspects for highlight: SDNs have many applications including developing new protocols prior to implementing them in real networks, increasing connectivity in rural environments, making both cloud based and regular data centers better, and supporting mobile device ofﬂoading. As the Internet continues to grow and becomes available to increasing more people, networks will need to be able to adapt to ever changing circumstances. SDNs allow the data and control planes to be separated, and hence to be easier for improvements.
Network virtualization based on OpenFlow is a successful implementation of Software Deﬁned Networking, and its development offers users a great deal of convenient services. We

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
24

have reviewed different virtualization architectures that focus on the improvement of the network ﬂexibility, isolation and management. It can be seen that embedding additional module or abstraction layer on the top of OpenFlow or FlowVisor provides solutions to these challenges. Utilizing the database can also help to simplify the creation of the abstraction layer.
QoS is an import issue in many applications especially in streaming media,VoIP, Videoconferencing, and so on. Many experiments have been conducted to make OpenFlow support QoS control. However, these designs are still under testing phase, and need to be further examined. Many designs are related to optimization problems, such as dynamic rerouting for SVC, dynamic QoS re-negotiation for multimedia ﬂows, etc. And the solution needs heavy calculations in reality as the dimension increases. It also needs a comprehensive test before being applied to real world applications. Many experiments are actually under a small scale of tests to verify the proposed design, and no large-scale experiments have been performed yet.
Security and privacy are always important in any network. OpenFlow brings many new security challenges due to the virtual network management. It is important to design new low-overhead security/privacy schemes to protect the virtualto-physical mapping protocols in SDN/OpenFlow.
We have also pointed out some important unsolved research issues in this exciting ﬁeld. Those issues may serve as the thesis/dissertation topics for graduate students. SDN/OpenFlow is a relatively new ﬁeld, and many practical design issues are waiting for in-depth investigations. We believe that this comprehensive survey could help R&D people to understand the state-of-the-art in SDN/OpenFlow.
XI. ACKNOWLEDGMENT
We sincerely thank the following people for their help with this survey: Ashley Gerrity, Muhammad Farooq, Ting Zhang, Rui Ma, Colby Dickerson, Xingang Fu, Nagaraj Hegde, (they are all with ECE department at the University of Alabama), and Athanasios V. Vasilakos (University of Western Macedonia in Greece). They have provided valuable comments and inputs on some of the above discussed topics. We also appreciate the editor and reviewers’ time and effort for reviewing this paper.
REFERENCES
[1] S. Ortiz, “Software-Deﬁned Networking: On the Verge of a Breakthrough?” Computer, vol. 46, no. 7, pp. 10-12, 2013.
[2] H. Kim and N. Feamster, “Improving network management with software deﬁned networking,” IEEE Communications Mag., Vol. 51, No. 2, pp. 114-119, 2013.
[3] K. Bakshi, “Considerations for Software Deﬁned Networking (SDN): Approaches and use cases,” in Proc. of IEEE Aerospace Conf., 2013 , pp. 1-9.
[4] S. Agarwal, M. Kodialam, and T. V. Lakshman, “Trafﬁc engineering in software deﬁned networks,” in Proc. of IEEE INFOCOM, 2013, pp. 2211-2219.
[5] S. Fang, Y. Yu, C. H. Foh, and K. M. M. Aung, “A Loss-Free Multipathing Solution for Data Center Network Using Software-Deﬁned Networking Approach,” IEEE Trans. on Magnetics, vol. 49, no. 6, pp. 2723- 2730, 2013.
[6] S.H. Yeganeh, A. Tootoonchian, and Y. Ganjali, “On scalability of software-deﬁned networking,” IEEE Communications Mag., vol. 51, no. 2, pp. 136-141, 2013.

[7] S. Das, G. Parulkar, N. McKeown, P. Singh, D. Getachew, and L. Ong,

“Packet and circuit network convergence with OpenFlow,” in Proc. of

Optical Fiber Communication Conference and Exposition, Mar. 2010,

pp. 1-3.

[8] R. Sherwood, M. Chan, and A. Covington, “Carving research slices

out of your production networks with openﬂow,” ACM SIGCOMM

Computer Communication Review, vol. 40, no. 1, pp. 129-130, 2010.

[9] OpenFlow, http://www.openﬂow.org/.

[10] Open Networking Foundation, https://www.opennetworking.org/.

[11] C. S. Li and W. Liao, “Software Deﬁned Networks”, Editorial, IEEE

Comm. Mag., Feb. 2013.

[12] M. Casado, T. Koponen, S. Shenker, and A. Tootoonchian, “Fabric: a

retrospective on evolving SDN,” in Proc. of Workshop on Hot Topics

in Software Deﬁned Networking, Aug. 2012, pp. 85-90.

[13] Y. Kanaumi, S. Saito, and E. Kawai, “Toward large-scale programmable

metworks: lessons learned through the operation and management of a

wide-area Openﬂow-based network,” in Proc. of Int. Conf. on Network

and Services Management, Oct. 2010, pp. 330-333.

[14] H. Fei, Network Innovation through OpenFlow and SDN: Principles

and Design, Taylor & Francis LLC, CRC Press, to appear in 2014.

[15] B. Lantz, B. Heller, and N. McKeown, “A network in a laptop:

rapid prototyping for software-deﬁned networks,” in Proc. of ACM

SIGCOMM Workshop on Hot Topics in Networks, New York, NY, USA,

2010, pp. 19:1-6.

[16] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,

J. Rexford, S. Shenker, and J. Turner, “Openﬂow: enabling innovation

in campus networks,” ACM SIGCOMM Computer Communication

Review, vol. 38, no. 2, pp. 69-74, 2008.

[17] T. D. Nadeau and P. Pan, “Software Driven Networks Problem S-

tatement,” IETF Internet-Draft (work-in-progress), draft-nadeau-sdn-

problem-statement-01, Oct. 2011.

[18] M. Yu, J. Rexford, M. Freedman, and J. Wang, “Scalable ﬂow-based

networking with difane,” ACM SIGCOMM Computer Communication

Review, vol. 41, pp. 351-362, 2010.

[19] K. Yap, M. Kobayashi, R. Sherwood, T. Huang, M. Chan, N. Handigol,

and N. McKeown, “Openroads: Empowering research in mobile net-

works,” ACM SIGCOMM Computer Communication Review, vol. 40,

no. 1, pp. 125-126, 2010.

[20] P. Dely, A. Kassler, and N. Bayer, “Openﬂow for wireless mesh

networks,” in Proc. of Int. Conf. on Computer Communications and

Networks, pp. 1-6, 2011.

[21] Y. Hu, W. Wang, X. Gong, X. Que, and S. Cheng, “Reliability-

aware controller placement for Software-Deﬁned Networks,” in Proc.

of IFIP/IEEE International Symposium on Integrated Network Man-

agement, 2013, pp. 672-675.

[22] P. T. Congdon, P. Mohapatra, M. Farrens, and V. Akella, “Simultane-

ously reducing latency and power consumption in OpenFlow switches,”

IEEE/ACM Trans. on Networking, vol. PP, no. 99, pp. 1-14, 2013.

[23] A. Khan and N. Dave, “Enabling hardware exploration in software-

deﬁned networking: a ﬂexible, portable OpenFlow switch,” in Proc.

of Annual Int. Symp. on Field-Programmable Custom Computing

Machines, 2013, pp. 145-148.

[24] “The

OpenFlow

switch

consortium,”

[Online]

http://www.openﬂow.org/.

[25] Y. Kanaumi, “OpenFlow switch demonstration at GENI conference 3rd

on JGN2plus/APAN”, The 27th APAN Meeting, Mar. 2009.

[26] “OpenFlow switch speciﬁcation, version 1.0.0,” [Online]

http://www.openﬂow.org/documents/openﬂow-spec-v1.0.0.pdf

[27] “OpenFlow in Europe − linking infrastructure and applications,”

[Online] http://www.fp7-ofelia.eu/

[28] Y. Kanaumi, “Large-scale OpenFlow testbed in Japan,” The 31st APAN

Meeting, Feb. 2011.

[29] N. Foster, M. J. Freedman, A. Guha, and R. Horrison, “Languages for

software-deﬁned networks,” IEEE Communication Mag. Feature Topic

in Software Deﬁned Networks, vol. 51, no. 2, pp. 128-134, Feb. 2013.

[30] F. de O. Silva, J. H. de S. Pereira, P. F. Rosa, and S. T. Kofuji,

“Enabling future Internet architecture research and experimentation by

using software deﬁned networking,” in Proc. of European Workshop

on Software Deﬁned Networking, pp. 73-78, Oct. 2012.

[31] S. Hasan, Y. Ben-David, C. Scott, E. Brewer, and S. Shenker, “En-

hancing rural connectivity with software deﬁned networks”, in Proc.

of ACM Symposium on Computing for Development, 2013, no. 49:1-2.

[32] R. Narayanan, S. Kotha, G. Lin, A. Khan, S. Rizvi, W. Javed, H. Khan,

and S. Khayam , “Macroﬂows and microﬂows: enabling rapid network

innovation through a split SDN data plane”, in Proc. of European

Workshop on Software Deﬁned Networking , 2012, pp. 79-84.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
25

[33] B. Boughzala, R. Ben Ali, M. Lemay, Y. Lemieux, and O. Cherkaoui, [63] A. Wundsam, D. Levin, S. Seetharaman, and A. Feldmann, “Ofrewind:

“OpenFlow supporting inter-domain virtual machine migration”, in

enabling record and replay troubleshooting for networks,” in Proc. of

Proc. of Int. Conf. Wireless and Optical Communications Networks

USENIX Conf. on USENIX Annual Technical Conference, 2011, pp.

(WOCN), 2011, pp. 1-7.

29-29.

[34] C. Baker, A. Anjum, R. Hill, N. Bessis, and S. L. Kiani, “Improving [64] E. Al-Shaer and S. Al-Haj, “FlowChecker: conﬁguration analysis and

cloud datacenter scalability, agility and performance using OpenFlow,”

veriﬁcation of federated openﬂow infrastructures,” in Proc. of ACM

in Proc. of Int. Conf. on Intelligent Networking and Collaborative

workshop on Assurable and Usable Security Conﬁguration, 2010, pp.

Systems, 2012, pp. 20-27.

37-44.

[35] A. Gember, C. Dragga, A. Akella, “ECOS: leveraging software-deﬁned [65] M. Canini, D. Venzano, P. Pereni, D. Kostic, and J. Rexford, “A NICE

networks to support mobile application ofﬂoading,” in Proc. of the

way to test openﬂow applications”, in Proc. of USENIX Conference on

eighth ACM/IEEE symposium on Architectures for networking and

Networked Systems Design and Implementation, 2012, pp. 10-10.

communications systems, 2012, pp. 199-210.

[66] M. Canini, D. Venzano, P. Pereni, D. Kostic, and J. Rexford,

[36] Vijay Mann, Anilkumar Vishnoi, Kalapriya Kannan, Shivkumar Kalya-

“A NICE way to test OpenFlow controller applications,” [online]

naraman, ”CrossRoads: seamless VM mobility across data centers

http://code.google.com/p/nice-of/.

through software deﬁned networking” in Proc. of IEEE Network [67] GENI: exploring networks of the future, [online] http://www.geni.net.

Operations and Management Symposium, 2012, pp. 88-96.

[68] Ofelia: OpenFlow test facility in Europe, [online] http://www.fp7-

[37] P. A. A. Gutirrez and D. R. Lopez, “An OpenFlow Network Design

ofelia.eu.

Cycle,” Network Innovation through OpenFlow and SDN: Principles [69] JGN-x

Utilization

Procedure.

[online]

and Design, Taylor & Francis LLC, CRC Press, to appear in 2014.

http://www.jgn.nict.go.jp/english/info/technologies/openﬂow.html.

[38] R. Stallman, R. Pesch, and S. Shebs, Debugging with GDB: the Source Level Debugger, Boston, USA: GNU Press, 2002.

[70] M., Christopher and A. Story, “Language Abstractions for SoftwareDeﬁned Networks,” IEEE Comm. Mag., vol. 51, no. 2, pp. 128-134,

[39] The Eclipse Foundation, [online] http://www.eclipse.org.

2013.

[40] G. T. Heineman and W. T. Councill, Eds, Component-Based Software Engineering: Putting the Pieces Together, Boston, USA: Addison-

[71] K., Daisuke, K. Suzuki, and H. Shimonishi, “A design and implementation of OpenFlow Controller handling IP multicast with Fast

Wesley Longman Publishing, 2001.

Tree Switching,” in Proc. of IEEE/IPSJ International Symposium on

[41] L. M. Correia, Ed, Architecture and Design for the Future Internet,

Applications and the Internet, 2012, pp. 60-67.

Spinger, 2011.

[72] N. Foster, A. Guha, M. Reitblatt, A. Story, M. J. Freedman, N. P.

[42] A. de C. Alves, OSGi Application Frameworks, Manning Publications,

Katta, C. Monsanto, J. Reich, J. Rexford, C. Schlesinger, D. Walker,

2009.

and R. Harrison, “Languages for software-deﬁned networks,” IEEE

[43] J. Highsmith and A. Cockburn, “Agile software development: The

Communications Mag., vol.51, no.2, pp. 128-134, Feb. 2013.

Business of Innovation,” Computer, vol. 34, no. 9, pp. 120-122, Sept. [73] H. Kudou, M. Shimamura, T. Ikenaga, and M. Tsuru, “Effects of

2001.

routing granularity on communication performance in OpenFlow net-

[44] Kai Petersen, Claes Wohlin, and Dejan Baca, “The waterfall model in

works,” in Proc. of IEEE Paciﬁc Rim Conference on Communications,

large-scale development,” in Proc. of Int. Conf. on Product-Focused

Computers and Signal Processing (PacRim), 2011, pp. 590-595.

Software Process Improvement, 2009, pp. 386-400.

[74] Z. Bozakov and P. Papadimitriou, “AutoSlice: automated and scalable

[45] OpenVSwitch, [online] http://openvswitch.org/development/openﬂow-

slicing for software-deﬁned networks,” in Proc. of ACM CoNEXT

1-x-plan.

Student Proceedings, 2012, pp. 3-4.

[46] Pica8

Open

Network

Fabric,

[online] [75] G. Schaffrath, C. Werle, P. Papadimitriou, A. Feldmann, R. Bless,

http://www.pica8.org/solutions/openﬂow.php.

A. Greenhalgh, A. Wundsam, M. Kind, O. Maennel, and L. Mathy,

[47] Indigo − Open Source OpenFlow Switches, [online]

“Network Virtualization Architecture: Proposal and Initial Prototype,”

http://www.openﬂowhub.org/display/Indigo/.

in Proc. ACM SIGCOMM VISA, 2009, pp xx-xx.

[48] NOX, [online] http://www.noxrepo.org/nox/about-nox/.

[76] N. Sarrar, et al., “Leveraging’s Zipf’s Law for trafﬁc ofﬂoading”, in

[49] POX, [online] http://www.noxrepo.org/pox/about-pox/.

Proc. of ACM SIGCOMM Computer Communication Review, 2012, pp.

[50] Trema: Full-Stack OpenFlow Framework in Ruby and C, [online]

16-22.

https://github.com/trema/.

[77] Y. Yiakoumis, K.-K. Yap, S. Katti, G. Parulkar, and N. Mckeown,

[51] Floodlight: a Java-based OpenFlow Controller, [online]

“Slicing home networks,” in Proc. of ACM SIGCOMM workshop on

http://ﬂoodlight.openﬂowhub.org/.

Home networks, 2011, pp. 1-6.

[52] David Erickson, [online] https://openﬂow.stanford.edu/display/Beacon/Home[.78] S. Sundaresan, W. de Donato, N. Feamster, R. Teixeira, S. Crawford,

[53] Floodlight Is An Open SDN Controller, [online]

and A. Pescap’e, “Broadband internet performance: a view from the

http://ﬂoodlight.openﬂowhub.org/.

gateway,” in Proc. of the ACM SIGCOMM, Aug. 2011, pp. 134-145.

[54] OpenStack: Open source software for building private and public [79] M. Al-fares, A. Loukissas, and A. Vahdat, “A scalable, commodity

clouds, [online] http://www.openstack.org/, 2012.

data center network architecture,” in Proc. of the ACM SIGCOMM

[55] A. Orebaugh, G. Ramirez, J. Burke, and L. Pesce, Wireshark &

Conference on Data Communication, 2008, pp. 63-74.

Ethereal Network Protocol Analyzer Toolkit (Jay Beale’s Open Source [80] M. Casdo, M. J. Freeman, J. Pettit, J. Luo, N. Mckeown, N. Mckeown,

Security), Syngress Publishing, 2006.

and S. Shenker, “Ethane: taking control of the enterprise,” in Proc. of

[56] ns3. http://www.nsnam.org.

ACM SIGCOMM Computer Communication Review, 2007, pp. 1-12.

[57] J. Pelkey, Openﬂow software implementation distribution, [online] [81] Z. Cai, A. L. Cox, and T. S. E. NG, “Maestro: A system for scalable

http://code.nsnam.org/jpelkey3/openﬂow.

OpenFlow control,” Tech. Rep. TR10-11, Rice University - Department

[58] B. Lantz, B. Heller, and N. McKeown, “A network in a laptop:

of Computer Science, Dec. 2010.

rapid prototyping for software-deﬁned networks,” in Proc. of ACM [82] A. R. Curtis, J. C. Mogul, J. Tourrilhes, P. Yalagandula, P. Sharma,

SIGCOMM Workshop on Hot Topics in Networks, Hotnets-IX, 2010,

and S. Banerjee, “DevoFlow: Scaling ﬂow management for high-

pp. 19:1-6.

performance networks,” in Proc. of ACM SIGCOMM Conf., 2011, pp.

[59] T. L. Hinrichs, N. S. Gude, M. Casado, J. C. Mitchell, and S.

254-265.

Shenker, “Practical declarative network management,” In Proc. of ACM [83] S. Kandula, S. Sengupta, A. Greenberg, P. Patel, and R. Chaiken, “The

Workshop on Research on Enterprise Networking, 2009, pp. 1-10.

nature of data center trafﬁc: Measurements and analysis,” in Proc. of

[60] N. Foster, R. Harrison, M. J. Freedman, C. Monsanto, J. Rexford, A.

ACM Internet Measurement Conf., 2009, pp. 202-208.

Story, and D. Walker, “Frenetic: a network programming language,” in [84] T. Benson, A. Akella, and D. A. Maltz, “Network trafﬁc characteristics

Proc. of ACM SIGPLAN Int. Conf. on Functional programming, 2011,

of data centers in the wild,” in Proc. of ACM Internet Measurement

pp. 279-291.

Conf., 2010, pp. 267-280.

[61] N. Handigol, B. Heller, V. Jeyakumar, D. Mazires, and N. McKeown, [85] A. Tootoonchian, S. Gorbunov, Y. Ganjali, and M. Casado, “On

“Where is the debugger for my software-deﬁned network?” In Proc.

controller performance in software-deﬁned networks,” in Proc. of

of Workshop on Hot Topics in Software Deﬁned Networks, 2012, pp.

USENIX Workshop on Hot Topics in Management of Internet, Cloud,

55-60.

and Enterprise Networks and Services, 2012, pp. 10-10.

[62] Y. Chiba and Y. Nakazawa, “Tremashark: A bridge [86] M. Casado, M. J. Freedman, J., Pettit, J. Luo, N. Mckeown, and S.

for printing various events on wireshark,” [online]

Shenker, “Ethane: taking control of the enterprise,” in Proc. of ACM

http://github.com/trema/trema.gitmaster/tremashark.

SIGCOMM Computer Communication Review, 2007, pp. 1-12.

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
26

[87] D. Drutskoy, Software-deﬁned Network Virtualization, Master Thesis, Princeton University, 2012.
[88] J. Matias, B. Tornero, A. Mendiola, E. Jacob, and N. Toledo, “Implementing Layer 2 Network Virtualization Using OpenFlow: Challenges and Solutions,” in Proc. of European Workshop on Software Deﬁned Networking, Oct. 2012, pp.30-35.
[89] P. Skoldstrom, K. Yedavalli, “Network virtualization and resource allocation in OpenFlow-based wide area networks,” in Proc. IEEE Int. Conf. on Communications, Jun. 2012, pp. 6622-6626.
[90] B. Sonkoly, A. Gulyas, F. Nemeth, J. Czentye, K. Kurucz, B. Novak, and G. Vaszkun, “OpenFlow virtualization framework with advanced capabilities,” in Proc. European Workshop on Software Deﬁned Networking, Oct. 2012, pp. 18-23
[91] J. Matias, E. Jacob, D. Sanchez, Y. Demchenko, “An OpenFlow Based Network Virtualization Framework for the Cloud,” in Proc. of IEEE 3rd International Conf. on Cloud Computing Technology and Science, 2011, pp. 672-678.
[92] M. El-azzab, I. L. Bedhiaf, Y. Lemieux, O. Cherkaoui, “Slices Isolator for a Virtualized Openﬂow Node,” in Proc. of Int. Symp. on Network Cloud Computing and Applications, 21-23 Nov. 2011, pp. 121-126.
[93] D. Turull, M. Hidell, and P. Sjodin, “libNetVirt: The network virtualization library,” in Proc. of IEEE Int. Conf. on Communications, Jun. 2012, pp. 5543-5547.
[94] R. Nejbati, S. Azodolmolky, and D. Simeonidou, “Role of network virtualization in future Internet innovation,” in Proc. of European Conf. on Networks and Optical Communications, Jun. 2012, pp. 1-4.
[95] B. Naudts, M. Kind, F. Westphal, S. Verbrugge, D. Colle, and M. Pickavet, “Techno-economic analysis of software deﬁned networking as architecture for the virtualization of a mobile network,” in Proc. of European Workshop on Software Deﬁned Networking, Oct. 2012, pp. 67-72.
[96] A. Mahmud, R. Rahmani, and T. Kanter, “Deployment of ﬂow-sensors in internet of things’ virtualization via OpenFlow,” in Proc. of FTRA Int. Conf. on Mobile, Ubiquitous, and Intelligent Computing, Jun. 2012, pp. 195-200.
[97] H. E. Egilmez, B. Gorkemli, A. M. Tekalp, and S. Civanlar, “Scalable video streaming over OpenFlow networks: an optimization framework for QoS routing,” in Proc. of IEEE Int. Conf. on Image Processing, 2011, pp. 2241-2244.
[98] H. E. Egilmez, S. T. Dane, K. T. Bagci, and A. M. Tekalp, “OpenQoS: An OpenFlow controller design for multimedia delivery with endto-end Quality of Service over software-deﬁned networks,” in Proc. of Asia-Paciﬁc Signal & Information Processing Association Annual Summit and Conf., Dec. 2012, pp. 1-8.
[99] H. E. Egilmez, S. Civanlar, A. M. Tekalp, “An optimization framework for QoS-enabled adaptive video streaming over OpenFlow networks,” in IEEE Trans. on Multimedia, vol. 15, no. 3, Apr. 2013, pp.710-715.
[100] K. Jeong, J. Kim, and Y.-T. Kim, “QoS-aware network operating system for software deﬁned networking with generalized OpenFlows,” in IEEE/IFIP Workshop on Management of the Future Internet, 2012, pp. 1167-1174.
[101] A. Kassler, L. Skorin-Kapov, O. Dobrijevic, M. Matijasevic, and P. Dely, “Towards QoE-driven multimedia service negotiation and path optimization with software deﬁned networking,” in Proc. of Int. Conf. on Software, Telecommunications and Computer Networks, Sept. 2012, pp. 1-5.
[102] H. Sun, A. Vetro, and J. Xin, “An overview of scalable video streaming,” Wireless Communications and Mobile Computing, vol. 7, no. 2, pp. 159-172, Feb. 2007.
[103] S. Jivorasetkul and M. Shimamura, “End-to-end header compression over software-deﬁned networks: a low latency network architecture,” in Proc. of Int. Conf. on Intelligent Networking and Collaborative Systems, 2012.
[104] E.-S. M. El-Alfy “A review of network security,” IEEE Distributed Systems Online, vol. 8, no. 7, Jul. 2007.
[105] ACM SIGCOMM Workshop on Hot Topics in Software Deﬁned Networking, Aug. 2013.
[106] S. Sharma, D. Staessens, D. Colle, M. Pickavet, and P. Demeester, “Enabling fast failure recovery in OpenFlow networks,” in Proc. of Int. Workshop on the Design of Reliable Communication Networks, 2011, pp. 164-171.
[107] J. Kempf, E. Bellagamba, A. Kern, and D. Jocha, “Scalable fault management for OpenFlow,” in Proc. of IEEE Int. Conf. on Communications, Jun. 2012, pp. 6606-6610.
[108] C.-J. Chung, P. Khatkar, T. Xing, J. Lee, and D. Huang, “NICE: network intrusion detection and countermeasure selection in virtual

network systems,” IEEE Trans. on Dependable and Secure Computing, vol. 99, no. 1, Jan. 2013. [109] S. Shin, P. Porras, V. Yegneswaran, M. Fong, G. Gu, and M. Tyson, “FRESCO: modular composable security services for software-deﬁned networks,” in Proc. of Network and Distributed System Security Symp., 2013. [110] S. A. Mehdi, J. Khalid, and S. A. Khayam, “Revisiting trafﬁc anomaly detection using software deﬁned networking,” in Proc. of Int. Conf. on Recent Advances in Intrusion Detection, 2011, pp. 161-180. [111] C. Schlesinger, “Language-Based security for software-deﬁned networks,” [online] http://www.cs.princeton.edu/ cschlesi/isolation.pdf. [112] D. Kordalewski and R. Robere, “A dynamic algorithm for loop detection in software deﬁned networks”, 2012. [online] http://www.cs.toronto.edu/ robere/paper/networkgraph-1214.pdf [113] S. Costanzo, L. Galluccio, G. Morabito, and S. Palazzo, “Software deﬁned wireless networks: unbridling SDNs,” in Proc. of European Workshop on Software Deﬁned Networking, 2012, pp. 1-6. [114] M. Mendonca, K. Obraczka, and T. Turletti, “The case for softwaredeﬁned networking in heterogeneous networked environments,” in Proc. of ACM conf. on CoNEXT Student Workshop, 2012, pp. 59-60. [115] K. Yap, M. Kobayashi, R. Sherwood, T. Huang, M. Chan, N. Handigol, and N. McKeown, “Openroads: empowering research in mobile networks,” ACM SIGCOMM Computer Communication Review, vol. 40, no. 1, pp. 125-126, 2010. [116] K. Yap, R. Sherwood, M. Kobayashi, T. Huang, M. Chan, N. Handigol, N. McKeown, and G. Parulkar, “Blueprint for introducing innovation into wireless mobile networks,” in Proc. of ACM SIGCOMM workshop on Virtualized Infrastructure Systems and Architectures, 2010, pp. 2532. [117] L. E. Li, Z. M. Mao, and J. Rexford, “Toward software-deﬁned cellular networks,” in Proc. European Workshop on Software Deﬁned Networking, Oct. 2012, pp. 7-12. [118] A. Gember, C. Dragga, and A. Akella, “ECOS: leveraging softwaredeﬁned networks to support mobile application ofﬂoading,” in Proc. of ACM/IEEE symposium on Architectures for Networking and Communications Systems, 2012, pp. 199-210. [119] A. Mahmud, and R. Rahmani, “Exploitation of OpenFlow in wireless sensor networks,” in Proc. Int. Conf. on Computer Science and Network Technology, 2011, pp. 594-600. [120] T. Luo, H.-P. Tan, and T. Q. S. Quek, “Sensor OpenFlow: enabling software-deﬁned wireless sensor networks”, IEEE Communications Letters, vol. 16, no. 11, pp. 1896-1899, 2012. [121] P. Dely, A. Kassler, and N. Bayer, “OpenFlow for Wireless Mesh Networks,” in Proc. of Int. Conf. on Computer Communications and Networks, 2011, pp. 1-6. [122] J. Chung, G. Gonzalez, I. Armuelles, T. Robles, R. Alcarria, and A. Morales, “Experiences and Challenges in Deploying OpenFlow over Real Wireless Mesh Networks,” IEEE Latin America Trans. (Revista IEEE America Latina) , vol. 11, no. 3, pp. 955-961, May 2013. [123] L. Y. Ong, “OpenFlow/SDN and Optical Networks,” in Network Innovation through OpenFlow and SDN: Principles and Design, Taylor & Francis LLC, CRC Press, to appear in 2014. [124] L. Liu, H. Guo, and T. Tsuritani, “OpenFlow/SDN for metro/backbone optical networks,” in Network Innovation through OpenFlow and SDN: Principles and Design, Taylor & Francis LLC, CRC Press, to appear in 2014. [125] E. Mannie, Ed., Generalized Multi-Protocol Label Switching (GMPLS) Architecture, IETF RFC, 2004. [126] S. Das, G. Parulka, and N. Mckeown, “Why OpenFlow/SDN can succeed where GMPLS failed,” in European Conference and Exhibition on Optical Communications, Sep. 2012, pp Tu.1.D.1. [127] L. Liu, T. Tsuritani, I. Morita, H. Guo, and J. Wu, “Experimental validation and performance evaluation of OpenFlow-based wavelength path control in transparent optical networks,” Opt. Express, vol. 19, no. 27, pp. 26578-26593, Dec. 2011. [128] L. Liu, D. Zhang, T. Tsuritani, R. Vilalta, R. Casellas, L. Hong, I. Morita, H. Guo, J. Wu, R. Martnez, and R. Muoz, “Field trial of an OpenFlow-based uniﬁed control plane for multi-layer multi-granularity optical switching networks,” IEEE/OSA J. Lightw. Technol., vol. 31, no. 4, pp. 506-514, Feb. 2013. [129] S. Azodolmolky, R. Nejabati, E. Escalona, R. Jayakumar, N. Efstathiou, and D. Simeonidou, “Integrated OpenFlow-GMPLS control plane: an overlay model for software deﬁned packet over optical networks,” Optical Express, vol. 19, no. 26, pp. B421-B428, 2011. [130] M. Channegowda, P. Kostecki, N. Efstathiou, S. Azodolmolky, R. Nejabati, P. Kaczmarek, A. Autenrieth, J. Elbers, and D. Simeonidou, “Experimental demonstration of an OpenFlow based software-deﬁned

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2014.2326417, IEEE Communications Surveys & Tutorials
27

optical network employing packet, ﬁxed and ﬂexible DWDM grid technologies on an international multi-domain testbed,” Optical Express, vol. 21, no. 5, pp. 5487-5498, 2013. [131] C. H. Liu, A. Gkelias, Y. Hou, and K. K. Leung, “Cross-layer design for QoS in wireless mesh networks,” Wirel. Pers. Commun., vol. 51, no. 3, pp. 593-613, Nov. 2009. [132] L. Qiu and M. Song, “QoS oriented cross-layer design for supporting multimedia services in cooperative networks,” in Proc. of Int. Conf. on Service Sciences, 2010, pp. 314-318. [133] J. Chen, T. Lv, and H. Zheng, “Cross-layer design for QoS wireless communications,” in Proc. of Int. Symp. on Circuits and Systems, 2004, vol.2, pp. 217-20. [134] D. Li, X. Hong, and D. Witt, “ProtoGENI, a prototype GENI under security vulnerabilities: an experiment-based security study,” IEEE Systems Journal, vol. 7, no. 3, pp. 478-488, Sep. 2013. [135] M. Smith, C. Schridde, B. Agel, B. Freisleben, “Identity-based cryptography for securing mobile phone calls,” in Proc. of Int. Conf. on Advanced Information Networking and Applications Workshops, 2009, pp. 365-370. [136] Lambros Sarakis,Theodore Zahariadis,Helen-Catherine Leligou,Mischa Dohler, “A Framework for Service Provisioning in Virtual Sensor Networks,” in EURASIP Journal on Wireless Communications and Networking, Special Issue on Recent Advances in Mobile Lightweight Wireless Systems, April 2012:135. [137] Amin Tootoonchian, Yashar Ganjali, “HyperFlow: a distributed control plane for OpenFlow,” in Proceedings of the 2010 internet network management conference on Research on enterprise networking(INM/WREN’10) USENIX Association, Berkeley, CA, USA, , 2010,33. [138] Zhongjin Liu, Yong Li, Li Su, Depeng Jin, and Lieguang Zeng, “M2cloud: software deﬁned multi-site data center network control framework for multi-tenant,” in SIGCOMM Comput. Commun. Rev.43, 4, 2013, pp. 517-518. [139] Airton Ishimori, Fernando Farias, Igor Furtado, Eduardo Cerqueira, Antnio Abelm, “Automatic QoS Management on OpenFlow Software-Dened Networks” in downloadable from: http://siti.ulusofona.pt/aigaion/index.php/attachments/single/362. 2012
[140] Bari, Md.Faizul Chowdhury, Shihabur Rahman ; Ahmed, Reaz ; Boutaba, Raouf “PolicyCop: An Autonomic QoS Policy Enforcement Framework for Software Deﬁned Networks,” in 2013 IEEE SDN for Future Networks and Services (SDN4FNS), 2013, pp. 1-7.
[141] Sonkoly, B. ; Gulyas, A. ; Nemeth, F. ; Czentye, J. ; Kurucz, K. ; Novak, B. ; Vaszkun, G. , “On QoS Support to Ofelia and OpenFlow,” in 2012 European Workshop on Software Deﬁned Networking (EWSDN), Publication , 2012, pp. 109-133.
[142] Bo-Yu Ke ; Po-Lung Tien ; Yu-Lin Hsiao, “Identity-based cryptography for securing mobile phone calls,” in Proc. of Int. Conf. on Advanced Information Networking and Applications Workshops, 2013, pp. 217218.
[143] Stephen Gutz, Alec Story, Cole Schlesinger, Nate Foster., “Splendid isolation: a slice abstraction for software-deﬁned networks,” in In Proceedings of the ﬁrst workshop on Hot topics in software deﬁned networks (HotSDN ’12). ACM, New York, NY, USA, , 2012, pp. 79-84.
[144] Pentikousis, K.; Yan Wang; Weihua Hu, “Mobileﬂow: Toward software-deﬁned mobile networks,” in Communications Magazine, IEEE, vol.51, no.7 July 2013, pp. 44-53.
[145] Tie Luo; Hwee-Pink Tan; Quan, P.C.; Yee Wei Law; Jiong Jin, “Enhancing responsiveness and scalability for OpenFlow networks via control-message quenching,” CT Convergence (ICTC), 2012 International Conference vol., no., pp.348,353, 15-17 Oct. 2012.
[146] Kanizo, Y.; Hay, D.; Keslassy, I., “Palette: Distributing tables in software-deﬁned networks,” in INFOCOM, 2013 Proceedings IEEE, vol., no., pp.545,549, 14-19 April 2013.
[147] Yannan Hu ; Wendong Wang ; Xiangyang Gong ; Xirong Que ; Shiduan Cheng, “BalanceFlow: Controller load balancing for OpenFlow networks,” in 2012 IEEE 2nd International Conference on Cloud Computing and Intelligent Systems (CCIS), Volume: 02, Publication Year: 2012 , Page(s): 780 785..
[148] Biswas, A. A. Lazar, J. F. Huard, K. S. Lim, S. Mahjoub, L. F. Pau, M. Suzuki, S. Torstensson, W. Wang, and S. Weinstein, “The IEEE P1520 Standards Initiative for Programmable Network Interfaces,” IEEE Commun. Mag.,Vol. 36, no. 10, 1998, pp. 6470.
[149] A. Doria, J. H. Salim, R. Haas, H. Khosravi, W. Wang, L. Dong, R. Gopal, and J. Halpern, “Forwarding and Control Element Separation (ForCES) Protocol Speciﬁcation,” in [Online]. Available: http://tools.ietf.org/html/rfc5810

[150] T. V. Lakshman, T. Nandagopal, R. Ramjee, K. Sabnani, and T. Woo, “The SoftRouter Architecture,” in Proc. ACM SIGCOMM Workshop on Hot Topics in Networking, 2004.
[151] On the difference between security and safety: a reference answer is provided in WiKi: ”http://wiki.answers.com/Q/1 Explain the difference between safety and security?#slide=1”,

1553-877X (c) 2013 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

