See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/273564489
Traffic Flow Prediction With Big Data: A Deep Learning Approach
Article in IEEE Transactions on Intelligent Transportation Systems · January 2014
DOI: 10.1109/TITS.2014.2345663

CITATIONS
58
5 authors, including:
Lv Yisheng Chinese Academy of Sciences 34 PUBLICATIONS 158 CITATIONS
SEE PROFILE
Wenwen Kang Chinese Academy of Sciences 7 PUBLICATIONS 61 CITATIONS
SEE PROFILE

READS
6,516
Yanjie Duan Chinese Academy of Sciences 7 PUBLICATIONS 59 CITATIONS
SEE PROFILE

Some of the authors of this publication are also working on these related projects: map matching View project

All content following this page was uploaded by Lv Yisheng on 14 April 2015.
The user has requested enhancement of the downloaded file. All in-text references underlined in blue are added to the original document and are linked to publications on ResearchGate, letting you access and read them immediately.

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 16, NO. 2, APRIL 2015

865

Trafﬁc Flow Prediction With Big Data: A Deep Learning Approach
Yisheng Lv, Yanjie Duan, Wenwen Kang, Zhengxi Li, and Fei-Yue Wang, Fellow, IEEE

Abstract—Accurate and timely trafﬁc ﬂow information is important for the successful deployment of intelligent transportation systems. Over the last few years, trafﬁc data have been exploding, and we have truly entered the era of big data for transportation. Existing trafﬁc ﬂow prediction methods mainly use shallow trafﬁc prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the trafﬁc ﬂow prediction problem based on deep architecture models with big trafﬁc data. In this paper, a novel deep-learning-based trafﬁc ﬂow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic trafﬁc ﬂow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the ﬁrst time that a deep architecture model is applied using autoencoders as building blocks to represent trafﬁc ﬂow features for prediction. Moreover, experiments demonstrate that the proposed method for trafﬁc ﬂow prediction has superior performance.
Index Terms—Deep learning, stacked autoencoders (SAEs), trafﬁc ﬂow prediction.
I. INTRODUCTION
A CCURATE and timely trafﬁc ﬂow information is currently strongly needed for individual travelers, business sectors, and government agencies [1]. It has the potential to help road users make better travel decisions, alleviate trafﬁc congestion, reduce carbon emissions, and improve trafﬁc operation efﬁciency. The objective of trafﬁc ﬂow prediction is to provide such trafﬁc ﬂow information. Trafﬁc ﬂow prediction has gained more and more attention with the rapid development and deployment of intelligent transportation systems (ITSs). It is regarded as a critical element for the successful deployment of ITS subsystems, particularly advanced traveler information systems, advanced trafﬁc management systems, advanced public transportation systems, and commercial vehicle operations.
Manuscript received May 24, 2014; revised July 10, 2014; accepted July 20, 2014. Date of publication September 9, 2014; date of current version March 27, 2015. This work was supported in part by the National Natural Science Foundation of China under Grants 61233001, 61203166, 71232006, 61104054, and 61273326. The Associate Editor for this paper was J. Zhang.
Y. Lv, Y. Duan, W. Kang, and F.-Y. Wang are with State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: yisheng.lv@ ia.ac.cn; duanyanjie2012@ia.ac.cn; kangwenwen2012@ia.ac.cn; feiyue@ ieee.org).
Z. Li is with North China University of Technology, Beijing 100144, China (e-mail: lzx@ncut.edu.cn).
Color versions of one or more of the ﬁgures in this paper are available online at http://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/TITS.2014.2345663

Trafﬁc ﬂow prediction heavily depends on historical and real-time trafﬁc data collected from various sensor sources, including inductive loops, radars, cameras, mobile Global Positioning System, crowd sourcing, social media, etc. With the widespread traditional trafﬁc sensors and new emerging trafﬁc sensor technologies, trafﬁc data are exploding, and we have entered the era of big data transportation. Transportation management and control is now becoming more data driven [2], [3]. Although there have been already many trafﬁc ﬂow prediction systems and models, most of them use shallow trafﬁc models and are still somewhat unsatisfying. This inspires us to rethink the trafﬁc ﬂow prediction problem based on deep architecture models with such rich amount of trafﬁc data.
Recently, deep learning, which is a type of machine learning method, has drawn a lot of academic and industrial interest [4]. It has been applied with success in classiﬁcation tasks, natural language processing, dimensionality reduction, object detection, motion modeling, and so on [5]–[9]. Deep learning algorithms use multiple-layer architectures or deep architectures to extract inherent features in data from the lowest level to the highest level, and they can discover huge amounts of structure in the data. As a trafﬁc ﬂow process is complicated in nature, deep learning algorithms can represent trafﬁc features without prior knowledge, which has good performance for trafﬁc ﬂow prediction.
In this paper, we propose a deep-learning-based trafﬁc ﬂow prediction method. Herein, a stacked autoencoder (SAE) model is used to learn generic trafﬁc ﬂow features, and it is trained in a layerwise greedy fashion. To the best of the authors’ knowledge, it is the ﬁrst time that the SAE approach is used to represent trafﬁc ﬂow features for prediction. The spatial and temporal correlations are inherently considered in the modeling. In addition, it demonstrates that the proposed method for trafﬁc ﬂow prediction has superior performance.
The rest of this paper is organized as follows. Section II reviews the studies on short-term trafﬁc ﬂow prediction. Section III presents the deep learning approach with autoencoders as building blocks for trafﬁc ﬂow prediction. Section IV discusses the experimental results. Concluding remarks are described in Section V.
II. LITERATURE REVIEW
Trafﬁc ﬂow prediction has been long regarded as a key functional component in ITSs. Over the past few decades, a number of trafﬁc ﬂow prediction models have been developed to assist in trafﬁc management and control for improving transportation efﬁciency ranging from route guidance and vehicle

1524-9050 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

866

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 16, NO. 2, APRIL 2015

routing to signal coordination. The evolution of trafﬁc ﬂow can be considered a temporal and spatial process. The trafﬁc ﬂow prediction problem can be stated as follows. Let Xit denote the observed trafﬁc ﬂow quantity during the tth time interval at the ith observation location in a transportation network. Given a sequence {Xit} of observed trafﬁc ﬂow data, i = 1, 2, . . . , m, t = 1, 2, . . . , T , the problem is to predict the trafﬁc ﬂow at time interval (t + Δ) for some prediction horizon Δ.
As early as 1970s, the autoregressive integrated moving average (ARIMA) model was used to predict short-term freeway trafﬁc ﬂow [10]. Since then, an extensive variety of models for trafﬁc ﬂow prediction have been proposed by researchers from different areas, such as transportation engineering, statistics, machine learning, control engineering, and economics. Previous prediction approaches can be grouped into three categories, i.e., parametric techniques, nonparametric methods, and simulations. Parametric models include time-series models, Kalman ﬁltering models, etc. Nonparametric models include k-nearest neighbor (k-NN) methods, artiﬁcial neural networks (ANNs), etc. Simulation approaches use trafﬁc simulation tools to predict trafﬁc ﬂow.
A widely used technique to the problem of trafﬁc ﬂow prediction is based on time-series methods. Levin and Tsao applied Box–Jenkins time-series analyses to predict expressway trafﬁc ﬂow and found that the ARIMA (0, 1, 1) model was the most statistically signiﬁcant for all forecasting [11]. Hamed et al. applied an ARIMA model for trafﬁc volume prediction in urban arterial roads [12]. Many variants of ARIMA were proposed to improve prediction accuracy, such as KohonenARIMA (KARIMA) [13], subset ARIMA [14], ARIMA with explanatory variables (ARIMAX) [15], vector autoregressive moving average (ARMA) and space–time ARIMA [16], and seasonal ARIMA (SARIMA) [17]. Except for the ARIMA-like time-series models, other types of time-series models were also used for trafﬁc ﬂow prediction [18].
Due to the stochastic and nonlinear nature of trafﬁc ﬂow, researchers have paid much attention to nonparametric methods in the trafﬁc ﬂow forecasting ﬁeld. Davis and Nihan used the k-NN method for short-term freeway trafﬁc forecasting and argued that the k-NN method performed comparably with but not better than the linear time-series approach [19]. Chang et al. presented a dynamic multiinterval trafﬁc volume prediction model based on the k-NN nonparametric regression [20]. El Faouzi developed a kernel smoother for the autoregression function to do short-term trafﬁc ﬂow prediction, in which functional estimation techniques were applied [21]. Sun et al. used a local linear regression model for short-term trafﬁc forecasting [22]. A Bayesian network approach was proposed for trafﬁc ﬂow forecasting in [23]. An online learning weighted support vector regression (SVR) was presented in [24] for short-term trafﬁc ﬂow predictions. Various ANN models were developed for predicting trafﬁc ﬂow [25]–[34].
To obtain adaptive models, some works explore hybrid methods, in which they combine several techniques. Tan et al. proposed an aggregation approach for trafﬁc ﬂow prediction based on the moving average (MA), exponential smoothing (ES), ARIMA, and neural network (NN) models. The MA, ES, and ARIMA models were used to obtain three relevant time

series that were the basis of the NN in the aggregation stage [35]. Zargari et al. developed different linear genetic programming, multilayer perceptron, and fuzzy logic (FL) models for estimating 5-min and 30-min trafﬁc ﬂow rates [36]. Cetin and Comert combined the ARIMA model with the expectation— maximization and cumulative sum algorithms [37]. An adaptive hybrid fuzzy rule-based system approach was proposed for modeling and predicting urban trafﬁc ﬂow [38].
In addition to the methods aforementioned, the Kalman ﬁltering method [39], [40], stochastic differential equations [41], the online change-point-based model [42], the type-2 FL approach [43], the variational inﬁnite-mixture model [44], simulations [45], and dynamic trafﬁc assignment [46], [47] were also applied in predicting short-term trafﬁc ﬂow.
Comparison studies of trafﬁc ﬂow prediction models have been reported in literature. The linear regression, the historical average, the ARIMA, and the SARIMA were assessed in [48], in which it was concluded that these algorithms perform reasonably well during normal operating conditions but do not respond well to external system changes. The SARIMA models and the nonparametric regression forecasting methods were evaluated in [49]. It was found that the proposed heuristic forecast generation methods improved the performance of nonparametric regression, but they did not equal the performance of the SARIMA models. The multivariate state-space models and the ARIMA models were compared in [50], and it showed that the performance of the multivariate state-space models is better than that of the ARIMA models. Stathopoulos and Karlaftis [50] also pointed out that different model speciﬁcations are appropriate for different time periods of the day. Lippi et al. [51] compared SVR models and SARIMA models, and they concluded that the proposed seasonal support vector regressor is highly competitive when performing forecasts during the most congested periods. Chen et al. [52] reported the performance results for the ARMA, ARIMA, SARIMA, SVR, Bayesian network, ANN, k-NN, Naïve I, and Naïve II models at different aggregation time scales, which were set at 3, 5, 10, and 15 min, respectively. A series of research is dedicated to the comparison of NNs and other techniques such as the historical average, the ARIMA models, and the SARIMA models [53]–[55]. Interestingly, it could be found that nonparametric techniques obviously outperform simple statistical techniques such as the historical average and smoothing techniques, but there are contradicting results on whether nonparametric methods can yield better or comparable results compared with the advanced forms of statistical approaches such as the SARIMA. Detailed reviews on the short-term trafﬁc ﬂow forecast can be found in [56] and [57].
In summary, a large number of trafﬁc ﬂow prediction algorithms have been developed due to the growing need for realtime trafﬁc ﬂow information in ITSs, and they involve various techniques in different disciplines. However, it is difﬁcult to say that one method is clearly superior over other methods in any situation. One reason for this is that the proposed models are developed with a small amount of separate speciﬁc trafﬁc data, and the accuracy of trafﬁc ﬂow prediction methods is dependent on the trafﬁc ﬂow features embedded in the collected spatiotemporal trafﬁc data. Moreover, in general, literature

LV et al.: TRAFFIC FLOW PREDICTION WITH BIG DATA: DEEP LEARNING APPROACH

867

Fig. 1. Autoencoder.

shows promising results when using NNs, which have good prediction power and robustness.
Although the deep architecture of NNs can learn more powerful models than shallow networks, existing NN-based methods for trafﬁc ﬂow prediction usually only have one hidden layer. It is hard to train a deep-layered hierarchical NN with a gradient-based training algorithm. Recent advances in deep learning have made training the deep architecture feasible since the breakthrough of Hinton et al. [58], and these show that deep learning models have superior or comparable performance with state-of-the-art methods in some areas. In this paper, we explore a deep learning approach with SAEs for trafﬁc ﬂow prediction.

Fig. 2. Layerwise training of SAEs.
restrictions such as sparsity constraints are imposed, this is not a problem [60]. When sparsity constraints are added to the objective function, an autoencoder becomes a sparse autoencoder, which considers the sparse representation of the hidden layer. To achieve the sparse representation, we will minimize the reconstruction error with a sparsity constraint as

III. METHODOLOGY
Here, a SAE model is introduced. The SAE model is a stack of autoencoders, which is a famous deep learning model. It uses autoencoders as building blocks to create a deep network [59].

A. Autoencoder
An autoencoder is an NN that attempts to reproduce its input, i.e., the target output is the input of the model. Fig. 1 gives an illustration of an autoencoder, which has one input layer, one hidden layer, and one output layer. Given a set of training samples {x(1), x(2), x(3), . . .}, where x(i) ∈ Rd, an autoencoder ﬁrst encodes an input x(i) to a hidden representation y(x(i)) based on (1), and then it decodes representation y(x(i)) back into a reconstruction z(x(i)) computed as in (2), as shown in

y(x) = f (W1x + b)

(1)

z(x) = g (W2y(x) + c)

(2)

where W1 is a weight matrix, b is an encoding bias vector, W2 is a decoding matrix, and c is a decoding bias vector; we consider logistic sigmoid function 1/(1 + exp(−x)) for f (x) and g(x) in this paper.
By minimizing reconstruction error L(X, Z), we can obtain the model parameters, which are here denoted as θ, as

1N θ = arg min L(X, Z) = arg min

x(i) −z x(i)

2
. (3)

θ

θ

2
i=1

One serious issue concerned with an autoencoder is that if the size of the hidden layer is the same as or larger than the input layer, this approach could potentially learn the identity function. However, current practice shows that if nonlinear autoencoders have more hidden units than the input or if other

HD

SAO = L(X, Z) + γ KL(ρ ρˆj)

(4)

j=1

where γ is the weight of the sparsity term, HD is the number of

hidden units, ρ is a sparsity parameter and is typically a small

value close to zero, ρˆj = (1/N )

N i=1

yj (x(i))

is

the

average

activation of hidden unit j over the training set, and KL(ρ ρˆj)

is the Kullback–Leibler (KL) divergence, which is deﬁned as

KL(ρ

ρˆj) = ρ log

ρ ρˆj

+ (1 − ρ) log

1−ρ 1 − ρˆj .

The KL divergence has the property that KL(ρ ρˆj) = 0 if ρ = ρˆj. It provides the sparsity constraint on the coding. The backpropagation (BP) algorithm can be used to solve this optimization problem.

B. SAEs
A SAE model is created by stacking autoencoders to form a deep network by taking the output of the autoencoder found on the layer below as the input of the current layer [59]. More clearly, considering SAEs with l layers, the ﬁrst layer is trained as an autoencoder, with the training set as inputs. After obtaining the ﬁrst hidden layer, the output of the kth hidden layer is used as the input of the (k + 1)th hidden layer. In this way, multiple autoencoders can be stacked hierarchically. This is illustrated in Fig. 2.
To use the SAE network for trafﬁc ﬂow prediction, we need to add a standard predictor on the top layer. In this paper, we put a logistic regression layer on top of the network for supervised trafﬁc ﬂow prediction. The SAEs plus the predictor comprise the whole deep architecture model for trafﬁc ﬂow prediction. This is illustrated in Fig. 3.

868

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 16, NO. 2, APRIL 2015

— Use the output of the kth hidden layer as the input of the (k + 1)th hidden layer. For the ﬁrst hidden layer, the input is the training set.
— Find encoding parameters {W1k+1, bk1+1}lk−=10 for the (k + 1)th hidden layer by minimizing the objective function.
Step 2) Fine-tuning the whole network
— Initialize {W1l+1, bl1+1} randomly or by supervised training.
— Use the BP method with the gradient-based optimization technique to change the whole network’s parameters in a top–down fashion.

Fig. 3. Deep architecture model for trafﬁc ﬂow prediction. A SAE model is used to extract trafﬁc ﬂow features, and a logistic regression layer is applied for prediction.
C. Training Algorithm
It is straightforward to train the deep network by applying the BP method with the gradient-based optimization technique. Unfortunately, it is known that deep networks trained in this way have bad performance. Recently, Hinton et al. have developed a greedy layerwise unsupervised learning algorithm that can train deep networks successfully. The key point to using the greedy layerwise unsupervised learning algorithm is to pretrain the deep network layer by layer in a bottom–up way. After the pretraining phase, ﬁne-tuning using BP can be applied to tune the model’s parameters in a top–down direction to obtain better results at the same time. The training procedure is based on the works in [58] and [59], which can be stated as follows.
1) Train the ﬁrst layer as an autoencoder by minimizing the objective function with the training sets as the input.
2) Train the second layer as an autoencoder taking the ﬁrst layer’s output as the input.
3) Iterate as in 2) for the desired number of layers. 4) Use the output of the last layer as the input for the
prediction layer, and initialize its parameters randomly or by supervised training. 5) Fine-tune the parameters of all layers with the BP method in a supervised way. This procedure is summarized in Algorithm 1.
Algorithm 1. Training SAEs
Given training samples X and the desired number of hidden layers l, Step 1) Pretrain the SAE
— Set the weight of sparsity γ, sparsity parameter ρ, initialize weight matrices and bias vectors randomly.
— Greedy layerwise training hidden layers.

IV. EXPERIMENTS
A. Data Description
The proposed deep architecture model was applied to the data collected from the Caltrans Performance Measurement System (PeMS) database as a numerical example. The trafﬁc data are collected every 30 s from over 15 000 individual detectors, which are deployed statewide in freeway systems across California [61]. The collected data are aggregated 5-min interval each for each detector station. In this paper, the trafﬁc ﬂow data collected in the weekdays of the ﬁrst three months of the year 2013 were used for the experiments. The data of the ﬁrst two months were selected as the training set, and the remaining one month’s data were selected as the testing set. For freeways with multiple detectors, the trafﬁc data collected by different detectors are aggregated to get the average trafﬁc ﬂow of this freeway. Note that we separately treat two directions of the same freeway among all the freeways, in which three are one-way. Fig. 4 is a plot of a typical freeway’s trafﬁc ﬂow over time for weekdays of some week.

B. Index of Performance
To evaluate the effectiveness of the proposed model, we use three performance indexes, which are the mean absolute error (MAE), the mean relative error (MRE), and the RMS error (RMSE). They are deﬁned as

1 MAE =
n

n

|fi − fˆi|

i=1

1 MRE =

n

|fi − fˆi|

n
i=1

fi

RMSE =

1

1n n

|fi − fˆi| 2 2

i=1

where fi is the observed trafﬁc ﬂow, and fˆi is the predicted trafﬁc ﬂow.

LV et al.: TRAFFIC FLOW PREDICTION WITH BIG DATA: DEEP LEARNING APPROACH

869

Fig. 4. Typical daily trafﬁc ﬂow pattern. (a) Monday. (b) Tuesday. (c) Wednesday. (d) Thursday. (e) Friday.

C. Determination of the Structure of a SAE Model
With regard to the structure of a SAE network, we need to determine the size of the input layer, the number of hidden layers, and the number of hidden units in each hidden layer. For the input layer, we use the data collected from all freeways as the input; thus, the model can be built from the perspective of a transportation network considering the spatial correlations of trafﬁc ﬂow. Furthermore, considering the temporal relationship of trafﬁc ﬂow, to predict the trafﬁc ﬂow at time interval t, we should use the trafﬁc ﬂow data at previous time intervals, i.e., Xt−1, Xt−2, . . . , Xt−r. Therefore, the proposed model accounts for the spatial and temporal correlations of trafﬁc ﬂow inherently. The dimension of the input space is mr, whereas the dimension of the output is m, where m is the number of freeways.

In this paper, we used the proposed model to predict 15-min trafﬁc ﬂow, 30-min trafﬁc ﬂow, 45-min trafﬁc ﬂow, and 60-min trafﬁc ﬂow. We choose r from 1 to 12, the hidden layer size from 1 to 6, and the number of hidden units from {100, 200, 300, 400, 500, 600, 700, 800, 900, 1000}. After performing grid search runs, we obtained the best architecture for different prediction tasks, which is shown in Table I. For the 15-min trafﬁc ﬂow prediction, our best architecture consists of three hidden layers, and the number of hidden units in each hidden layer is [400, 400, 400], respectively. For the 30-min trafﬁc ﬂow prediction, our best architecture consists of three hidden layers, and the number of hidden units in each hidden layer is [200, 200, 200], respectively. For the 45-min trafﬁc ﬂow prediction, our best architecture consists of two hidden layers,

870

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 16, NO. 2, APRIL 2015

TABLE I STRUCTURE OF SAES FOR TRAFFIC FLOW PREDICTION
Fig. 5. Trafﬁc ﬂow prediction of roads with different trafﬁc volume. (a) Road with heavy trafﬁc ﬂow. (b) Road with medium trafﬁc ﬂow. (c) Road with low trafﬁc ﬂow.
and the number of hidden units in each hidden layer is [500, 500], respectively. For the 60-min trafﬁc ﬂow prediction, our best architecture consists of four hidden layers, and the number of hidden units in each hidden layer is [300, 300, 300, 300], respectively. From the results, we can see that the best number of hidden layers is at least two and no more than ﬁve for our experiments. Lessons learned from experience indicate that the number of hidden layers of an NN should be neither too small nor too large. Our results conﬁrmed these lessons. D. Results
Fig. 5 presents the output of the proposed model for the trafﬁc ﬂow prediction of typical roads with heavy, medium, and low trafﬁc loads. The observed trafﬁc ﬂow is also included in Fig. 5 for comparison. In Fig. 5, it is shown that the predicted trafﬁc ﬂow has similar trafﬁc patterns with the observed trafﬁc ﬂow. In addition, it matches well in heavy and medium trafﬁc ﬂow conditions. However, the proposed model does not

perform well in low trafﬁc ﬂow conditions, which is the same as existing trafﬁc ﬂow prediction methods. The reason for this phenomenon is that small differences between the observed ﬂow and the predicted ﬂow can cause a bigger relative error when the trafﬁc ﬂow rate is small. In fact, we are more focused on the trafﬁc ﬂow prediction results under heavy and medium trafﬁc ﬂow conditions; hence, the proposed method is effective and promising for trafﬁc ﬂow prediction in practice.
We compared the performance of the proposed SAE model with the BP NN, the random walk (RW) forecast method, the support vector machine (SVM) method, and the radial basis function (RBF) NN model. Among these four competing methods, the RW method is a simple baseline that predicts trafﬁc in the future as equal to the current trafﬁc ﬂow (Xt+1 = Xt), the NN methods have good performance for the trafﬁc ﬂow forecast, as aforementioned in Section II, and the SVM method is a relatively advanced model for prediction. In all cases, we used the same data set. The prediction results on the test data sets for freeways with the average 15-min trafﬁc ﬂow rate larger than 450 vehicles are given in Table II. In Table II, we can see that the average accuracy (1-MRE) of the SAE is over 93% for all the four tasks and has low MAE values. This prediction accuracy is promising, robust, and comparable with the reported results. Notice that we only use the trafﬁc volume data as the input for prediction without considering handengineering factors, such as weather conditions, accidents, and other trafﬁc ﬂow parameters (density and speed), that have a relationship with the trafﬁc volume.
In Table II, we can also ﬁnd that the SAE proved to be more accurate than the BP NN model, the RW, the SVM, and the RBF NN model for the short-term prediction of the trafﬁc volume. For the BP NN, the prediction performance is relatively stationary, which is from 88% to 90% or so. For the RW, the SVM, and the RBF, the average prediction accuracy drops much with the aggregate time interval of the trafﬁc ﬂow data increasing. For the 15-min trafﬁc ﬂow prediction, the average accuracy of the RW, the SVM, and the RBF is 7.8%, 8.0%, and 7.4%, respectively. However, for the 60-min trafﬁc ﬂow prediction, the average accuracy of the RW, the SVM, and the RBF has a large drop to 22.3%, 22.1%, and 26.4%, respectively. The maximum average prediction accuracy improvement of the SAE is up to 4.8% compared with the BP NN, over 16% compared with the RW, over 15% compared with the SVM, and over 20% compared with the RBF.
A visual display of the performance of the MRE derived with the SAE, the BP NN model, the RW, the SVM, and the RBF NN model is given in Fig. 6. It displays for each method the cumulative distribution function (cdf) of the MRE, which describes the statistical results on freeways with the average 15-min trafﬁc ﬂow larger than 450 vehicles. The method that uses SAEs leads to improved trafﬁc ﬂow prediction performance when compared with the BP NN, the RW, the SVM, and the RBF NN model. For the 15-min trafﬁc ﬂow prediction, over 86% of freeways with the average 15-min trafﬁc ﬂow larger than 450 vehicles have an accuracy of more than 90%. For the 30-min trafﬁc ﬂow prediction, over 88% of freeways with the average 15-min trafﬁc ﬂow larger than 450 vehicles have an accuracy of more than 90%. For the 45-min trafﬁc ﬂow prediction and for

LV et al.: TRAFFIC FLOW PREDICTION WITH BIG DATA: DEEP LEARNING APPROACH

871

TABLE II PERFORMANCE COMPARISON OF THE MAE, THE MRE, AND THE RMSE FOR SAES, THE BP NN, THE RW, THE SVM, AND THE RBF NN

Fig. 6. Empirical cdf of the MRE for freeways with the average 15-min trafﬁc ﬂow larger than 450 vehicles. (a) 15-min trafﬁc ﬂow prediction. (b) 30-min trafﬁc ﬂow prediction. (c) 45-min trafﬁc ﬂow prediction. (d) 60-min trafﬁc ﬂow prediction.

the 60-min trafﬁc ﬂow prediction, over 90% of freeways with the average 15-min trafﬁc ﬂow larger than 450 vehicles have an accuracy of more than 90%. Thus, the effectiveness of the SAE method for trafﬁc ﬂow prediction is promising and manifested.
V. CONCLUSION We propose a deep learning approach with a SAE model for trafﬁc ﬂow prediction. Unlike the previous methods that only consider the shallow structure of trafﬁc data, the proposed

method can successfully discover the latent trafﬁc ﬂow feature representation, such as the nonlinear spatial and temporal correlations from the trafﬁc data. We applied the greedy layerwise unsupervised learning algorithm to pretrain the deep network, and then, we did the ﬁne-tuning process to update the model’s parameters to improve the prediction performance. We evaluated the performance of the proposed method on a PeMS data set and compared it with the BP NN, the RW, the SVM, and the RBF NN model, and the results show that the proposed method is superior to the competing methods.

872

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 16, NO. 2, APRIL 2015

For future work, it would be interesting to investigate other deep learning algorithms for trafﬁc ﬂow prediction and to apply these algorithms on different public open trafﬁc data sets to examine their effectiveness. Furthermore, the prediction layer in our paper has been just a logistic regression. Extending it to more powerful predictors may make further performance improvement.
ACKNOWLEDGMENT
The authors would like to thank the anonymous referees for their invaluable insights.
REFERENCES
[1] N. Zhang, F.-Y. Wang, F. Zhu, D. Zhao, and S. Tang, “DynaCAS: Computational experiments and decision support for ITS,” IEEE Intell. Syst., vol. 23, no. 6, pp. 19–23, Nov./Dec. 2008.
[2] J. Zhang et al., “Data-driven intelligent transportation systems: A survey,” IEEE Trans. Intell. Transp. Syst., vol. 12, no. 4, pp. 1624–1639, Dec. 2011.
[3] C. L. Philip Chen and C.-Y. Zhang, “Data-intensive applications, challenges, techniques and technologies: A survey on Big Data,” Inf. Sci., vol. 275, pp. 314–347, Aug. 2014.
[4] Y. Bengio, “Learning deep architectures for AI,” Found. Trends Mach. Learn., vol. 2, no. 1, pp. 1–127, Jan. 2009.
[5] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of data with neural networks,” Science, vol. 313, no. 5786, pp. 504–507, Jul. 2006.
[6] R. Collobert and J. Weston, “A uniﬁed architecture for natural language processing: Deep neural networks with multitask learning,” in Proc. 25th ICML, 2008, pp. 160–167.
[7] I. J. Goodfellow, Y. Bulatov, J. Ibarz, S. Arnoud, and V. Shet, “Multi-digit number recognition from street view imagery using deep convolutional neural networks,” arXiv preprint arXiv:1312.6082, 2013.
[8] B. Huval, A. Coates, and A. Ng, “Deep learning for class-generic object detection,” arXiv preprint arXiv:1312.6885, 2013.
[9] H.-C. Shin, M. R. Orton, D. J. Collins, S. J. Doran, and M. O. Leach, “Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 8, pp. 1930–1943, Aug. 2013.
[10] M. S. Ahmed and A. R. Cook, “Analysis of freeway trafﬁc time-series data by using Box–Jenkins techniques,” Transp. Res. Rec., no. 722, pp. 1–9, 1979.
[11] M. Levin and Y.-D. Tsao, “On forecasting freeway occupancies and volumes,” Transp. Res. Rec., no. 773, pp. 47–49, 1980.
[12] M. Hamed, H. Al-Masaeid, and Z. Said, “Short-term prediction of trafﬁc volume in urban arterials,” J. Transp. Eng., vol. 121, no. 3, pp. 249–254, May 1995.
[13] M. vanderVoort, M. Dougherty, and S. Watson, “Combining Kohonen maps with ARIMA time series models to forecast trafﬁc ﬂow,” Transp. Res. C, Emerging Technol., vol. 4, no. 5, pp. 307–318, Oct. 1996.
[14] S. Lee and D. Fambro, “Application of subset autoregressive integrated moving average model for short-term freeway trafﬁc volume forecasting,” Transp. Res. Rec., vol. 1678, pp. 179–188, 1999.
[15] B. M. Williams, “Multivariate vehicular trafﬁc ﬂow prediction— Evaluation of ARIMAX modeling,” Transp. Res. Rec., no. 1776, pp. 194– 200, 2001.
[16] Y. Kamarianakis and P. Prastacos, “Forecasting trafﬁc ﬂow conditions in an urban network—Comparison of multivariate and univariate approaches,” Transp. Res. Rec., no. 1857, pp. 74–84, 2003, Transporation Network Modeling 2003: Planning and Administration.
[17] B. M. Williams and L. A. Hoel, “Modeling and forecasting vehicular trafﬁc ﬂow as a seasonal ARIMA process: Theoretical basis and empirical results,” J. Transp. Eng., vol. 129, no. 6, pp. 664–672, Nov./Dec. 2003.
[18] B. Ghosh, B. Basu, and M. O’Mahony, “Multivariate short-term trafﬁc ﬂow forecasting using time-series analysis,” IEEE Trans. Intell. Transp. Syst., vol. 10, no. 2, pp. 246–254, Jun. 2009.
[19] G. A. Davis and N. L. Nihan, “Nonparametric regression and short-term freeway trafﬁc forecasting,” J. Transp. Eng., vol. 117, no. 2, pp. 178–188, Mar./Apr. 1991.
[20] H. Chang, Y. Lee, B. Yoon, and S. Baek, “Dynamic near-term trafﬁc ﬂow prediction: System oriented approach based on past experiences,” IET Intell. Transport Syst., vol. 6, no. 3, pp. 292–305, Sep. 2012.

[21] N. E. El Faouzi, “Nonparametric trafﬁc ﬂow prediction using kernel estimator,” in Proc. 13th ISTTT, 1996, pp. 41–54.
[22] H. Y. Sun, H. X. Liu, H. Xiao, R. R. He, and B. Ran, “Use of local linear regression model for short-term trafﬁc forecasting,” Transp. Res. Rec., no. 1836, pp. 143–150, 2003, Initiatives in Information Technology and Geospatial Science for Transportation: Planning and Administration.
[23] S. Sun, C. Zhang, and Y. Guoqiang, “A Bayesian network approach to trafﬁc ﬂow forecasting,” IEEE Intell. Transp. Syst. Mag., vol. 7, no. 1, pp. 124–132, Mar. 2006.
[24] Y. S. Jeong, Y. J. Byon, M. M. Castro-Neto, and S. M. Easa, “Supervised weighting-online learning algorithm for short-term trafﬁc ﬂow prediction,” IEEE Trans. Intell. Transp. Syst., vol. 14, no. 4, pp. 1700–1707, Dec. 2013.
[25] E. I. Vlahogianni, M. G. Karlaftis, and J. C. Golias, “Optimized and metaoptimized neural networks for short-term trafﬁc ﬂow prediction: A genetic approach,” Transp. Res. C, Emerging Technol., vol. 13, no. 3, pp. 211– 234, Jun. 2005.
[26] K. Y. Chan, T. S. Dillon, J. Singh, and E. Chang, “Neural-network-based models for short-term trafﬁc ﬂow forecasting using a hybrid exponential smoothing and Levenberg–Marquardt algorithm,” IEEE Trans. Intell. Transp. Syst., vol. 13, no. 2, pp. 644–654, Jun. 2012.
[27] B. Park, C. J. Messer, and T. Urbanik, “Short-term freeway trafﬁc volume forecasting using radial basis function neural network,” Transp. Res. Rec., no. 1651, pp. 39–47, 1998.
[28] W. Z. Zheng, D. H. Lee, and Q. X. Shi, “Short-term freeway trafﬁc ﬂow prediction: Bayesian combined neural network approach,” J. Transp. Eng., vol. 132, no. 2, pp. 114–121, Feb. 2006.
[29] M. Zhong, S. Sharma, and P. Lingras, “Short-term trafﬁc prediction on different types of roads with genetically designed regression and time delay neural network models,” J. Comput. Civil Eng., vol. 19, no. 1, pp. 94–103, Jan. 2005.
[30] H. Dia, “An object-oriented neural network approach to short-term trafﬁc forecasting,” Eur. J. Oper. Res., vol. 131, no. 2, pp. 253–261, Jun. 2001.
[31] J. Feng and S. Sun, “Neural network multitask learning for trafﬁc ﬂow forecasting,” in Proc. IEEE IJCNN (IEEE World Congr. Comput. Intell.), Jun. 1–8, 2008, pp. 1897, 1901.
[32] H. Yin, S. C. Wong, J. Xu, and C. K. Wong, “Urban trafﬁc ﬂow prediction using a fuzzy-neural, approach,” Transp. Res. C, Emerging Technol., vol. 10, no. 2, pp. 85–98, Apr. 2002.
[33] K. Kumar, M. Parida, and V. K. Katiyar, “Short term trafﬁc ﬂow prediction for a non urban highway using artiﬁcial neural network,” Proc. Soc. Behav. Sci., vol. 104, pp. 755–764, Dec. 2013.
[34] M. Dougherty, “A review of neural networks applied to transport,” Transp. Res. C, Emerging Technol., vol. 3, no. 4, pp. 247–260, Aug. 1995.
[35] M.-C. Tan, S. C. Wong, J.-M. Xu, Z. R. Guan, and Z. Peng, “An aggregation approach to short-term trafﬁc ﬂow prediction,” IEEE Trans. Intell. Transp. Syst., vol. 10, no. 1, pp. 60–69, Mar. 2009.
[36] S. A. Zargari, S. Z. Siabil, A. H. Alavi, and A. H. Gandomi, “A computational intelligence-based approach for short-term trafﬁc ﬂow prediction,” Expert Syst., vol. 29, no. 2, pp. 124–142, May 2012.
[37] M. Cetin and G. Comert, “Short-term trafﬁc ﬂow prediction with regime switching models,” Transp. Res. Rec., vol. 1965, pp. 23–31, 2006.
[38] L. Dimitriou, T. Tsekeris, and A. Stathopoulos, “Adaptive hybrid fuzzy rule-based system approach for modeling and predicting urban trafﬁc ﬂow,” Transp. Res. C, Emerging Technol., vol. 16, no. 5, pp. 554–573, Oct. 2008.
[39] I. Okutani and Y. J. Stephanedes, “Dynamic prediction of trafﬁc volume through Kalman ﬁltering theory,” Trans. Res. B, Methodol., vol. 18, no. 1, pp. 1–11, Feb. 1984.
[40] F. Yang, Z. Yin, H. Liu, and B. Ran, “Online recursive algorithm for shortterm trafﬁc prediction,” Transp. Res. Rec., vol. 1879, pp. 1–8, 2004.
[41] R. Tahmasbi and S. M. Hashemi, “Modeling and forecasting the urban volume using stochastic differential equations,” IEEE Trans. Intell. Transp. Syst., vol. 15, no. 1, pp. 250–259, Feb. 2014.
[42] G. Comert and A. Bezuglov, “An online change-point-based model for trafﬁc parameter prediction,” IEEE Trans. Intell. Transp. Syst., vol. 14, no. 3, pp. 1360–1369, Sep. 2013.
[43] L. Li, W. H. Lin, and H. Liu, “Type-2 fuzzy logic approach for short-term trafﬁc forecasting,” Proc. Inst. Elect. Eng.—Intell. Transp. Syst., vol. 153, no. 1, pp. 33–40, Mar. 2006.
[44] S. Shiliang and X. Xin, “Variational inference for inﬁnite mixtures of Gaussian processes with applications to trafﬁc ﬂow prediction,” IEEE Trans. Intell. Transp. Syst., vol. 12, no. 2, pp. 466–475, Jun. 2011.
[45] G. Duncan and J. K. Littlejohn, “High performance microscopic simulation for trafﬁc forecasting,” in Proc. IEE Colloq. Strategic Control InterUrban Road Netw. (Dig. No 1997/055), 1997, pp. 4/1–4/3.

LV et al.: TRAFFIC FLOW PREDICTION WITH BIG DATA: DEEP LEARNING APPROACH

873

[46] M. Ben-Akiva, E. Cascetta, and H. Gunn, “An on-line dynamic trafﬁc prediction model for an inter-urban motorway network,” in Urban Trafﬁc Networks, N. Gartner and G. Improta, Eds. Berlin, Germany: SpringerVerlag, 1995, pp. 83–122.
[47] B. Ran, “Using trafﬁc prediction models for providing predictive traveller information,” Int. J. Technol. Manage., vol. 20, no. 3/4, pp. 326–339, 2000.
[48] E. Chung and N. Rosalion, “Short term trafﬁc ﬂow prediction,” presented at the 24th Australian Transportation Research Forum, Hobart, Tasmania, 2001.
[49] B. L. Smith, B. M. Williams, and R. Keith Oswald, “Comparison of parametric and nonparametric models for trafﬁc ﬂow forecasting,” Transp. Res. C, Emerging Technol., vol. 10, no. 4, pp. 303–321, Aug. 2002.
[50] A. Stathopoulos and M. G. Karlaftis, “A multivariate state space approach for urban trafﬁc ﬂow modeling and prediction,” Transp. Res. C, Emerging Technol., vol. 11, no. 2, pp. 121–135, Apr. 2003.
[51] M. Lippi, M. Bertini, and P. Frasconi, “Short-term trafﬁc ﬂow forecasting: An experimental comparison of time-series analysis and supervised learning,” IEEE Trans. Intell. Transp. Syst., vol. 14, no. 2, pp. 871–882, Jun. 2013.
[52] C. Chen, Y. Wang, L. Li, J. Hu, and Z. Zhang, “The retrieval of intra-day trend and its inﬂuence on trafﬁc prediction,” Transp. Res. C, Emerging Technol., vol. 22, pp. 103–118, Jun. 2012.
[53] B. L. Smith and M. J. Demetsky, “Trafﬁc ﬂow forecasting: Comparison of modeling approaches,” J. Transp. Eng., vol. 123, no. 4, pp. 261–266, Jul./Aug. 1997.
[54] B. M. Williams, P. K. Durvasula, and D. E. Brown, “Urban freeway trafﬁc ﬂow prediction—Application of seasonal autoregressive integrated moving average and exponential smoothing models,” Transp. Res. Rec., no. 1644, pp. 132–141, 1998.
[55] H. R. Kirby, S. M. Watson, and M. S. Dougherty, “Should we use neural networks or statistical models for short-term motorway trafﬁc forecasting?” Int. J. Forecast., vol. 13, no. 1, pp. 43–50, Mar. 1997.
[56] E. I. Vlahogianni, J. C. Golias, and M. G. Karlaftis, “Short-term trafﬁc forecasting: Overview of objectives and methods,” Transp. Rev., vol. 24, no. 5, pp. 533–557, Sep. 2004.
[57] C. P. Van Hinsbergen, J. W. Van Lint, and F. M. Sanders, “Short term trafﬁc prediction models,” presented at the ITS World Congress, Beijing, China, 2007.
[58] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for deep belief nets,” Neural Comput., vol. 18, no. 7, pp. 1527–1554, Jul. 2006.
[59] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle, “Greedy layerwise training of deep networks,” in Proc. Adv. NIPS, 2007, pp. 153–160.
[60] R. B. Palm, “Prediction as a candidate for learning deep hierarchical models of data,” Technical Univ. Denmark, Palm, Denmark, 2012.
[61] Caltrans, Performance Measurement System (PeMS), 2014. [Online]. Available: http://pems.dot.ca.gov
Yisheng Lv received the B.E. and M.E. degrees in transportation engineering from Harbin Institute of Technology, Harbin, China, in 2005 and 2007, respectively, and the Ph.D. degree in control theory and control engineering from Chinese Academy of Sciences, Beijing, China, in 2010.
He is an Assistant Professor with State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences. His research interests include trafﬁc data analysis, dynamic trafﬁc modeling, and parallel trafﬁc management and control systems.
Yanjie Duan received the B.E. degree in automation from Northwestern Polytechnical University, Xi’an, China, in 2012. She is currently working toward the Ph.D. degree in control theory and control engineering at State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China.
Her research interests include intelligent transportation systems and machine learning and its application.

Wenwen Kang received the B.E. degree in automation from Xiamen University, Xiamen, China, in 2012. He is currently working toward the M.E. degree in control theory and control engineering at State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China.
His research interests include intelligent transportation systems and machine learning and its application.
Zhengxi Li received the Ph.D. degree in control theory and control engineering from University of Science and Technology Beijing, Beijing, China, in 2004.
He is currently a Professor with North China University of Technology, Beijing, China. He is a high-level expert in Beijing and is the Director of the Beijing Intelligent Transportation Academic Innovation Team. He has been engaged in electrical transmission, control theory and control engineering, and the control and management of intelligent transportation systems. He is the author or coauthor of two academic monographs and more than 100 papers. Dr. Li is the Director of the Chinese Society for Industrial Metrology, the Director of the Metal Application Technical Committee of the Chinese Society for Metals, and a Committee Member of the Professional Committee of Artiﬁcial Intelligence of the Chinese Association of Automation. He received two National Science and Technology Progress Awards of China and four Provincial Science and Technology Progress Awards in China.
Fei-Yue Wang (S’87–M’89–SM’94–F’03) received the Ph.D. degree in computer and systems engineering from Rensselaer Polytechnic Institute, Troy, NY, USA, in 1990.
In 1990 he joined University of Arizona, Tucson, AZ, USA, where he became a Professor and the Director of the Robotics and Automation Laboratory and the Program in Advanced Research for Complex Systems. In 1999 he founded the Intelligent Control and Systems Engineering Center, Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China, under the support of the Outstanding Overseas Chinese Talents Program and, in 2002, he was appointed as the Director of the Key Laboratory for Complex Systems and Intelligence Science, Institute of Automation, CAS. From 2006 to 2010 he was the Vice President for research, education, and academic exchanges with the Institute of Automation, CAS. Since 2005 he has been the Dean of the School of Software Engineering, Xi’an Jiaotong University, Xi’an, China. In 2011 he became the State Specially Appointed Expert and the Founding Director of the State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, CAS. He is the author or coauthor of over 10 books and 300 papers published in the past three decades in his research areas, including social computing and parallel systems. Dr. Wang has served as the General or Program Chair of more than 20 IEEE, Institute for Operations Research and the Management Sciences (INFORMS), Association for Computing Machinery (ACM), and American Society of Mechanical Engineers (ASME) conferences. He was the President of the IEEE Intelligent Transportation Systems (ITS) Society from 2005 to 2007, the Chinese Association for Science and Technology (USA) in 2005, and the American Zhu Kezhen Education Foundation from 2007 to 2008. He is a member of Sigma Xi; an Outstanding Scientist of the ACM; and a fellow of the International Federation of Automatic Control, the International Council on Systems Engineering (INCOSE), the ASME, and the American Association for the Advancement of Science. Currently, he is the Vice President and Secretary General of the Chinese Association of Automation. He was the Editor-in-Chief (EiC) of IEEE INTELLIGENT SYSTEMS from 2009 to 2012. He is currently the EiC of IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS. He received the Second Class National Prize in Natural Sciences of China for his work in intelligent control and social computing in 2007, the IEEE ITS Outstanding Application and Research Award in 2009, the IEEE Intelligence and Security Informatics Outstanding Research Award in 2012, and the ASME Mechatronic and Embedded Systems and Application Achievement Award for his cumulative contribution to the ﬁeld of mechatronic/ embedded systems and applications in 2013.

View publication stats

