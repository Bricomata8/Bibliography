Infrared Indoor Positioning Using Invisible Beacon

Willy Anugrah Cahyadi
Center for Advanced Wireless Technologies (AdWiTech) Telkom University Bandung, Indonesia wac.zze@gmail.com

Yeon Ho Chung*,
Senior Member, IEEE. Department of Information and Communications Engineering Pukyong National University
Busan, Republic of Korea yhchung@pknu.ac.kr

Trio Adiono,
Member, IEEE. School of Electrical Engineering
and Informatics Institut Teknologi Bandung
Bandung, Indonesia tadiono@stei.itb.ac.id

Abstract—In this paper, we present an experimental demonstration of an infrared (IR) indoor positioning scheme (IPS). Unlike previous studies that employ light emitting diode (LED) and camera as the transmitter and the receiver, respectively, the proposed IPS is based on a widely available surveillance camera as the receiver and a single invisible IR LED beacon installed in smartphones as the transmitter in indoor environments. An intraframe algorithm is also proposed to provide accurate positioning on both static and moving beacon (smartphone) by minimizing the amount of ambient light interference. The proposed IPS is experimentally proven that it achieves centimeter accuracy with a mean positioning error of 6 cm.
Keywords—indoor positioning, infrared, beacon, invisible.
I. INTRODUCTION
Indoor positioning system (IPS) is considered an important breakthrough for the future of internet-of-things to provide connectivity and seamless information flow for mobile users. Researches on IPS are also motivated by the fact that popular global positioning system (GPS) service does not work effectively within indoor environments [1, 2].
One of the most potential schemes for IPS involves the utilization of visible light communication (VLC) since the illumination infrastructure utilizing LEDs is available within indoor environments [3, 4]. The advantages of VLC-based IPS are high positioning accuracy, license-free operation, no electromagnetic interference, and low-cost front-ends [1-4]. The VLC-based IPS in [3] and [4] employed a photodiode receiver utilizing the received signal strength based trilateration algorithm to achieve an accuracy of 2 cm and positioning error of less than 3 cm.
In VLC-based IPS studies, it is apparent that a camera receiver can also be used instead of a photodiode. Although camera based IPS schemes produce slightly poor performance in terms of positioning error [5-7], the schemes are considered more practical and viable as the camera receiver is widely available in daily used smartphones. In addition, the camera receiver employs a 2-dimensional sensor capturing more information for more flexible IPSs [5-7].
In the IPS, a prior knowledge of the environment is required to synchronize positioning references [1-7]. Therefore, either the communication channel or a prior training is required to synchronize the positioning references [1, 3, 6]. For example, for the VLC-based IPS with the camera receiver, illumination LEDs are used as the

references, while the camera receiver acts as the active positioning agent that calculates its own position relative to the references. Recently, a unique and interesting IPS scheme was proposed with the infrared (IR) camera receivers installed on the ceiling and an infrared beacon as the transmitter in an indoor environment [8].
This work employed a special IR camera on the ceiling as the active positioning agent; therefore, it can be considered advantageous as the camera is already available at the specific position, requiring no fixed reference for the IPS.
The proposed IPS is motivated by the fact that the surveillance camera is widely installed for security purposes in an indoor environment. Furthermore, this camera is sensitive to IR light at a wavelength ranging of 750 nm to 940 nm. For mobile users, the smartphones are also equipped with IR LEDs as proximity sensors that can be captured by the surveillance cameras. These IR LEDs have a potential as invisible beacons for indoor IPSs. We employ a surveillance camera as the active positioning agent (receiver) and a single IR beacon of 940 nm in wavelength as the transmitter. It should be noted that the IR beacon is invisible to human eyes. In the present work, the position of the beacon in both static and moving state is experimentally analyzed. To minimize the ambient light interference present in the indoor environment, the intraframe positioning algorithm is proposed by applying an image mask with a fixed threshold based on the measured ambient illuminance from the surroundings. It is demonstrated that the proposed scheme maintains sufficient clarity and brightness for the surveillance image by applying the red-green-blue (RGB) channel mixing. The mean positioning error is found to be 6 cm or lower with an overall accuracy of 1 cm.
II. INFRARED-BASED INDOOR POSITIONING
A. Proposed Infrared-based Indoor Positioning
As mentioned previously, both VLC-based IPSs and outdoor GPS services require references for the positioning system, i.e., the presence of the illumination LEDs and GPS satellites [1, 2]. Surveillance cameras have a night mode that can capture IR light efficiently for low light captures. Figure 1 (a) and (b) show an example of captured images from a surveillance camera using the day and night mode, respectively. In addition, the majority of smartphones available in the market have been equipped with an IR LED based optical proximity sensor on top of the screen [9]. These IR LEDs are visible when captured using an IR-

978-1-72X81X-X1-3X4-0X-X1X/1X9-/X$X31X.X00-X©/X2X0/1$X9XIE.0E0E©2018 IEEE

341

ICUFN 2019

sensitive camera as shown in Fig. 1 (c). The proposed IPS exploits these available infrastructures, i.e., the surveillance camera and the IR LED on smartphones, to provide a pragmatic indoor positioning with a single invisible IR beacon.

Fig. 3. (a) Surveillance camera, (b) The IR-LED beacon and the enclosed MCU board.
At a fixed beacon height of 100 cm, an initial measurement was carried out to define the experimental area for positioning as illustrated in Fig. 4. The whole area for positioning is defined by the ROI (green line) and covers an area of 244 cm × 223 cm, as illustrated in Fig. 2. It can be observed from the measurement that the region closest to the camera has 8 pixels in the camera capture frame for each centimeter while the farthest region has 6 pixels for each centimeter. Thus, the overall positioning accuracy can be maintained at 1 cm if the beacon can be identified within 6×6 pixels area.

Fig. 1. (a) Vision of surveillance camera in day mode, (b) Vision of surveillance camera in night mode, (c) Captured frame of IR-sensitive camera showing two smartphones blinking IR LEDs for proximity sensors.
The schematic of the proposed IPS is shown in Fig. 2, utilizing a surveillance camera to acquire the position of a beacon. The beacon is controlled by an ATmega328P-based microcontroller unit (MCU). The 940 nm IR LED acting as the beacon transmits train pulses to replicate the behavior proximity sensor used in smartphones. An IP camera receiver, HIKVISION DS-2CD2020F, is employed with a diagonal field of view (FOV) of 170°. The camera has an internal switchable IR cut filter that enables night mode when the filter is disabled. The camera is connected to a personal computer for offline video processing. An ROI is set within the video processing algorithm to confine the processing region on the capture frame based on the experimental area. Figure 3 shows both the aforementioned camera and the beacon.

Fig. 4. Measurement of positioning area (ROI).
B. Experiment Setup
Figure 5 (a) shows the process of the positioning in the IPS scheme. From the initial experiments, it is found that a fixed exposure period of 1/2000 s is required to limit the amount of interferences from both visible light and infrared light during the camera capturing. The video processing after the frame capture is carried out offline in the personal computer. The captured frame is processed in two different phases: saving of the surveillance image and the intraframe positioning. Since the exposure period is fixed to 1/2000 s, the capture image is not sufficiently bright and clear for surveillance. The RGB channel mixing is utilized to enhance the brightness of the captured image, as illustrated in Fig. 6. The RGB channel mixing is a matrix addition of intensity for the red, green, and blue channel, as denoted by MRGB in Eq. 1. The resulting MRGB matrix is an image with accumulated intensity value that is visually brighter.

Fig. 2. Schematic of the proposed scheme.
The camera is configured to the night mode on frame capture by disabling the IR cut filter, capturing only monochromatic images. The captured images are then saved into an MPEG-4 video with Advanced Video Coding (H.264) compression and sent through a local network to the personal computer.

 R11  G11  B11  R1c  G1c  B1c 



M RGB



 







 



Rr1  Gr1  Br1  Rrc  Grc  Brc 

Afterwards, the red channel is extracted from the captured frame for the intraframe positioning algorithm, which acquires the position (coordinates) of the beacon based on the current frame. Figure 5 (b) shows the intraframe positioning algorithm. The image masking passes only the

342

image area within ROI for further processing as shown in Fig. 4. The mask threshold value is obtained by the measurement depending on the light illuminance in the room prior to the experiment. The image masking process maintains only pixels which intensity value is higher than mask threshold. This masking is necessary to minimize the interference from other light sources or reflections since the camera captures both visible light and infrared light. A circular Hough transform (CHT) [10] is applied on the matrix to obtain an estimated coordinate range. The mean intensity of both columns and rows of the masked matrix are then calculated to highlight the significant intensities within the captured frame. The coordinates of the beacon (xi, yi) can then be acquired from these mean intensities that are higher than the intensity threshold, thus verifying the coordinates that lie within the limit of the estimated coordinate range from CHT. The threshold is also based on the experimental measurement in the indoor environment. These coordinates are the final data output of the intraframe positioning algorithm.

Both Eq. 2 and 3 are employed to calculate the exact physical position coordinates (xp, yp) of the beacon based on the found coordinates (xi, yi). The horizontal FOV and vertical FOV of the camera are denoted by α and β, respectively. The distance between the camera and the experiment plane is denoted by d, while S denotes a scaling constant between the actual area for the positioning and the area captured within the camera frame.

Fig. 6. RGB channel mixing for surveillance image.



1 



xp



 2d  arctan S 

2



 

 





xi 

vw 











1 



yp



 2d  arctan S 

2



 

 





yi 

vh











III. EXPERIMENT RESULTS AND ANALYSIS
Experiments were conducted to verify the proposed IPS and the experiment parameters are shown in Table 1.

Fig. 5. (a) Flow chart of the positioning, (b) Intraframe positioning algorithm.

TABLE I.

EXPERIMENT PARAMETERS

Parameters Room dimension

Values 350 cm × 390 cm × 220 cm

Flicker rate of the beacon

2 KHz

Operating voltage of the beacon

5V

Operating power of the beacon
Ambient illuminance (minimum – maximum)

150 mW 480 - 1120 lx

343

Parameters
Exposure periods of the camera
Video resolution of the camera
Capture rate of the camera FOV of the camera (diagonal, horizontal, and vertical) Fixed height of the beacon

Values 1/500 s, 1/1000 s, 1/2000 s
and 1/4000 s 1920 × 1080 pixels
30 fps
170°, 168°, and 164°
100 cm

Further experiments were conducted for the static beacon in seven different positions. The video for each position was recorded for 420 frames at an exposure period of 1/2000 s and the distribution of the found coordinates is plotted in Fig. 8. Table 2 shows a summary of the mean positioning errors on the static experiment. The beacon was held by hand for position 2, 4, and 6, while for other positions, the beacon was static on the table.

Since the camera is fixed to the night mode, the camera sensitivity is significantly increased for both visible light and IR light. Thus, the exposure period should be fixed to a considerably short period to limit the amount of light interference captured. The initial experiment was conducted in a static beacon position to determine the exposure period of the camera for the tradeoff between sufficiently bright image for surveillance and sufficiently filtered interference light.

Fig. 8. Distribution of positioning coordinates on different beacon positions.
It can be observed that the mean positioning errors for seven different positions of the beacon are 6 cm. However, both position 3 and 4 are regarded as misidentified frames, because these positions are at the edge of ROI. It is because the static beacon cannot be identified outside the ROI, thus yielding large positioning errors.

Fig. 7. Initial experiments with various exposure periods.
Figure 7 shows a different level of accuracy over different exposure periods of the camera. Note that the red circle is enlarged for readability purposes in Fig. 7. It can be observed that only the exposure periods of 1/2000 s and 1/4000 s yield accurate results identifying the actual position of the beacon. This is due to the fact that a shorter exposure period causes the camera to be less sensitive on capturing light interferences, i.e., visible light and ambient infrared light. For further experiments, an exposure period of 1/2000 s was selected, due to its sufficiently clear image for surveillance, as illustrated in Fig. 6. An exposure period of 1/4000 s keeps minimal light interference, but the visibility for surveillance image is not adequate.

TABLE II.

STATIC EXPERIMENT RESULTS

Static positions Position 1

Mean positioning errors 2 cm

Misidentified frames
0%

Position 2

4 cm

1%

Position 3

2 cm

5%

Position 4

6 cm

5%

Position 5

2 cm

2%

Position 6

3 cm

3%

Position 7

2 cm

1%

To verify the viability of the proposed positioning scheme further, the experiment continued to perform the IPS with moving beacon. By moving, we mean that the beacon was moved around by hand at a speed of approximately 50 cm/s and 100 cm/s. We recorded 120 frames and utilized the two exposure periods of 1/2000 s and 1/4000 s. Figure 9 and Table III show the experiment results of the moving beacon positioning.

344

threshold based on real-time image analysis, instead of fixed threshold to reduce the mean positioning errors. The present scheme can also be extended to employ multiple cameras to enhance the positioning accuracy and to enable tracking of the motion in an indoor environment. Nevertheless, it can be viewed that the current work represents a more practical solution to positioning schemes using widely available surveillance cameras and beacons.

Fig. 9. Positioning distribution of moving beacon experiments at different speeds and exposure periods.
It is found that several misidentified frames contribute positioning errors, due to the presence of light interference and that the exposure period of 1/4000 s can reduce the amount of error, increasing the accuracy of the positioning scheme for moving beacon.

TABLE III. MOVING EXPERIMENT RESULTS

Moving speed (approximate)
50 cm/s

Exposure period
1/2000 s

Mean positioning errors
3 cm

Misidentified frames
3%

50 cm/s

1/4000 s

2 cm

1%

100 cm/s

1/2000 s

4 cm

3%

100 cm/s

1/4000 s

3 cm

1%

IV. CONCLUSION
A unique IPS with the surveillance camera and invisible beacon (smartphone) has been proposed as a future nonintrusive indoor positioning scheme. Experiments were conducted to verify the scheme and prove that it can provide accurate centimeter scale positioning for both static and moving beacon with the mean positioning error limited to 6 cm. This positioning accuracy is achieved with the help of the proposed intraframe positioning algorithm. It is foreseen that the present IPS can further be improved using a dynamic

ACKNOWLEDGMENT
This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2018R1D1A3B07049858).
REFERENCES
[1] R. F. Brena, J. P. García-Vázquez, C. E. Galván-Tejada, D. MuñozRodriguez, C. Vargas-Rosales, and J. Fangmeyer, Jr., “Evolution of indoor positioning technologies: a survey,” Journal of Sensors, vol. 2017, 2017.
[2] G. Xu, GPS, Springer, 2003.
[3] H. Zheng, Z. Xu, C. Yu, and M. Gurusamy, “A 3-D high accuracy positioning system based on visible light communication with novel positioning algorithm,” Optics Communication, vol. 396, pp. 160168, 2017.
[4] E. Jeong, S. Yang, H. Kim and S. Han, "Tilted receiver angle error compensated indoor positioning system based on visible light communication," Electronics Letters, vol. 49, pp. 890-892, 2013.
[5] R. Zhang, W. Zhong, K. Qian and D. Wu, "Image Sensor Based Visible Light Positioning System With Improved Positioning Algorithm," in IEEE Access, vol. 5, pp. 6087-6094, 2017.
[6] B. Lin, Z. Ghasssemlooy, C. Lin, X. Tang, and S. Zhang, “An indoor visible light positioning system based on optical camera Communications,” IEEE Photonics Technology Letters, vol. 29, pp. 579-582, 2017.
[7] Y. Li, Z. Ghassemlooy, X. Tang, B. Lin and Y. Zhang, "A VLC Smartphone Camera Based Indoor Positioning System," in IEEE Photonics Technology Letters, vol. 30, pp. 1171-1174, 2018.
[8] A. Gomez, K. Shi, C. Quintana, G. Faulkner, B. C. Thomsen, and D.C. O’Brien, “A 50 Gb/s transparent indoor optical wireless communications link with an integrated localization and tracking system,” Journal of Lightwave Technology, vol. 34, pp. 2510-2517, 2016.
[9] ON Semiconductor, “TND415 - Optical Sensors in Smart Mobile Devices,” 2014. [Online]. Available: ON Semiconductor Technical Note, www.onsemi.com/pub/Collateral/tnd415-d.pdf [Accessed Oct. 10, 2018]
[10] S. J. K. Pedersen, “Circular hough transform,” Aalborg University, Vision, Graphics, and Interactive Systems, vol. 123, p. 123, 2007.

345

