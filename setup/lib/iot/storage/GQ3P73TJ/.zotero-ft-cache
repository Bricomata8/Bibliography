Experimental design and its role in data science
Tirthankar Dasgupta CS 109 / Stat 121
November 17, 2015

Using data to answer a “causal” question
• 100 people with headaches took an aspirin each, and 90 of them were cured after an hour.
• Does this suggest aspirin relieves headache within an hour?
Image: www.123rf.com

Does “Big Data” help?
• Ten million people with headaches took an aspirin each, and nine million of them were cured after an hour.
• Does this suggest aspirin relieves headache within an hour?
Image: www.123rf.com

The “missing” data
• 100 people with headaches took an aspirin each, and 90 of them were cured after an hour.
• What would have happened to these people if they did nothing (or simply drank plenty of water and/or simply relaxed for an hour)?

Adding a “control” group

Treatment
Took aspirin (Treatment) Did nothing
(Control)

Effect after one hour

Cured 90

Not cured 10

80

20

Conclusions?

Stronger evidence?

Treatment
Took aspirin (Treatment) Did nothing
(Control)

Effect after one hour

Cured 90

Not cured 10

50

50

Even stronger evidence?

Treatment
Took aspirin (Treatment) Did nothing
(Control)

Effect after one hour

Cured 90

Not cured 10

10

90

But what if …..
• 100 individuals exposed to treatment are:
• 100 individuals exposed to control are:
Images: www.vectorstock.com, www.dreamstime.com

“Designing” the study
• Define your objective (does aspirin cure headache in an hour?)
– Formulate question in “data science” language – Identify scope of inference (“whose headache?”)
• Need a treatment group and a control group.
– Assignment mechanism
• These groups should be “identical” (how to define identical and how to achieve?)
– Big data challenge: large number of covariates associated with each experimental unit.

Analyzing the outcomes
• Related to and consistent with the design. • How to calculate the “strength” of your conclusion?

Treatment
Took aspirin (Treatment) Did nothing
(Control)

Effect after one hour

Cured

Not cured

70

30

50

50

Treatment
Took aspirin (Treatment) Did nothing
(Control)

Effect after one hour

Cured

Not cured

90

10

10

90

Modern-day experiments
• Education • Marketing • Stem Cell • Nanotechnology • Law • Internet: A/B testing

How it all started
• Agricultural experiments at the Rothamstead experimental station, U.K.
• Sir R. A. Fisher hired in 1919, first edition of Design of Experiments" published in 1935.
Aerial view of Rothamstead in 2013 (www.bbsrc.ac.uk)

Potential Outcomes
A potential outcome for each unit when exposed to each treatment level

Jerzy Neyman: originated the concept (1923) and introduced the first formal notation

R. A. Fisher (1918): If we say “this boy is tall because he has been well fed”, we are suggesting that he might quite probably have been worse fed, and that in this case he would been shorter.

The fertilizer experiment (does a new fertilizer improve yield of tomatoes?)

Plot of land 1 2 3 4 5 6 7 8 9 10 11

Fertilizer A (old) Y1(c)

Fertilizer B (new) Y1(t)

Unit-level effect τ1 = Y1(t)-Y1(c)

The fertilizer experiment (does a new fertilizer improve yield of tomatoes?)

Plot of land 1 2 3 4 5 6 7 8 9 10 11

Fertilizer A (old) Y1(c) Y2(c)

Fertilizer B (new) Y1(t) Y2(t)

Unit-level effect τ1 = Y1(t)-Y1(c) τ2 = Y2(t)-Y2(c)

The fertilizer experiment (does a new fertilizer improve yield of tomatoes?)

Plot of land 1 2 3 4 5 6 7 8 9 10 11

Fertilizer A (old) Y1(c) Y2(c) Y3(c) Y4(c) Y5(c) Y6(c) Y7(c) Y8(c) Y9(c) Y10(c) Y11(c)

Fertilizer B (new) Y1(t) Y2(t) Y3(t) Y4(t) Y5(t) Y6(t) Y7(t) Y8(t) Y9(t) Y10(t) Y11(t)

Unit-level effect τ1 = Y1(t)-Y1(c) τ2 = Y2(t)-Y2(c) τ3 = Y3(t)-Y3(c) τ4 = Y4(t)-Y4(c) τ5 = Y5(t)-Y5(c) τ6 = Y6(t)-Y6(c) τ7 = Y7(t)-Y7(c) τ8 = Y8(t)-Y8(c) τ9 = Y9(t)-Y9(c)
τ10 = Y10(t)-Y10(c) τ11 = Y11(t)-Y11(c)

The fertilizer experiment (does a new fertilizer improve yield of tomatoes?)

Plot of land 1 2 3 4 5 6 7 8 9 10 11
Average

Fertilizer A (old) Y1(c) Y2(c) Y3(c) Y4(c) Y5(c) Y6(c) Y7(c) Y8(c) Y9(c) Y10(c) Y11(c) Y (c)

Fertilizer B (new) Y1(t) Y2(t) Y3(t) Y4(t) Y5(t) Y6(t) Y7(t) Y8(t) Y9(t) Y10(t) Y11(t) Y (t)

Unit-level effect τ1 = Y1(t)-Y1(c) τ2 = Y2(t)-Y2(c) τ3 = Y3(t)-Y3(c) τ4 = Y4(t)-Y4(c) τ5 = Y5(t)-Y5(c) τ6 = Y6(t)-Y6(c) τ7 = Y7(t)-Y7(c) τ8 = Y8(t)-Y8(c) τ9 = Y9(t)-Y9(c)
τ10 = Y10(t)-Y10(c) τ11 = Y11(t)-Y11(c)
τ = Y (t) − Y (c) = ∑τi 11

The “assignment mechanism” and observed outcomes

Plot of land Fertilizer A (old)

1

29.2

2

3

4

5

6

7

8

9

10

11

Average

Fertilizer B (new) ?

Assignment (W) 0

The assignment mechanism and observed outcomes (contd.)

Plot of land 1 2 3 4 5 6 7 8 9 10 11
Average

Fertilizer A (old) 29.2 11.4

Fertilizer B (new) ? ?

Assignment (W) 0 0

The assignment mechanism and observed outcomes (contd.)

Plot of land 1 2 3 4 5 6 7 8 9 10 11
Average

Fertilizer A (old) 29.2 11.4 ? ? 25.3 ? ? ? 16.5 21.1 ? 20.70

Fertilizer B (new) ? ?
26.6 23.7
? 28.5 14.2 17.9
? ? 24.3 22.53

Assignment (W) 0 0 1 1 0 1 1 1 0 0 1

Fisher’s “sharp” null hypothesis
• No effect of fertilizer on ANY plot • How to assess? • Stochastic proof by contradiction!
– Calculate observed value of test statistic – Assuming hypothesis to be true, impute missing potential
outcomes – Generate distribution of test statistic using repeated
assignments under same mechanism – Determine if observed value is “unusual”

Step-1: Calculate observed value of test statistic

Plot of land
1 2 3 4 5 6 7 8 9 10 11 Average

Fertilizer A (old)
29.2 11.4
? ? 25.3 ? ? ? 16.5 21.1 ? 20.70

Fertilizer B (new)
? ? 26.6 23.7 ? 28.5 14.2 17.9 ? ? 24.3 22.53

Assignment (W)
0 0 1 1 0 1 1 1 0 0 1

Step-2: Impute missing potential outcomes under the null hypothesis

Plot of land
1 2 3 4 5 6 7 8 9 10 11 Average

Fertilizer A (old)
29.2 11.4
26.6 23.7 25.3 28.5 14.2 17.9
16.5 21.1 24.3

Fertilizer B (new)
29.2 11.4 26.6 23.7 25.3 28.5 14.2 17.9 16.5 21.1 24.3

Assignment (W)

Step-3: Generate new assignment, new observed outcomes, new value of test statistic

Plot of land
1 2 3 4 5 6 7 8 9 10 11 Average

Fertilizer A (old)
29?.2 11.4 26?.6 23.7 25?.3 28?.5 14.2 17.9 18?.5
21.1 24?.3 17.66

Fertilizer B (new)
29.2 11?.4 26.6 23?.7 25.3 28.5 14?.2 1?7.9 16.5 21?.1
24.3 25.07

New Assignment
1 0 1 0 1 1 0 0 1 0 1 Tnew = 7.41

Step-3 (contd.): Generate new assignment, new observed outcomes, new value of test statistic

Plot of land
1 2 3 4 5 6 7 8 9 10 11 Average

Fertilizer A (old)
29.2 11.4 26.6 23.7 25.3 28?.5 14?.2 17?.9 18?.5
21?.1 24?.3 23.24

Fertilizer B (new)
29?.2 11?.4 26?.6 2?3.7 25?.3 28.5 14.2 17.9 16.5 21.1
24.3 20.42

New Assignment
0 0 0 0 0 1 1 1 1 1 1 Tnew=2.82

Step-3 (contd.): Generate new assignment, new observed outcomes, new value of test statistic

Plot of land
1 2 3 4 5 6 7 8 9 10 11 Average

Fertilizer A (old)
29?.2 11?.4 26?.6 23?.7 25?.3 28?.5 14.2 17.9 16.5
21.1 24.3 18.80

Fertilizer B (new)
29.2 11.4 26.6 23.7 25.3 28.5 14?.2 1?7.9 18?.5 21?.1 2?4.3 24.12

New Assignment
1 1 1 1 1 1 0 0 0 0 0 Tnew=5.32

How many possible assignments (and hence total values of test statistic)?
11! = 462 5!6!

Step-4: Is the observed value of the test statistic “unusual”?
Randomization distribution of test statistic tobs=1.83
pvalue=0.62

200

150

Frequency

100

50

0

0

2

4

6

8

10

test statistic

The role of randomization
Which plots receive A and which receive B?
Observed assignment leading to tobs=1.83 A A B B AB B B A A B
But you could have observed this instead: A B A B AA B B B A B
… and any of the 462 assignments with equal probability

Role of randomization: “Unbiasedness in expectation”

Assignment 1

2

3

4

5

6

7

8

9

10 11 Difference

No.

of means

1

A

A

A

A

A

B

B

B

B

B

B

-2.82

…

A

A

B

B

A

B

B

B

A

A

B

1.83

462

B

B

B

B

B

B

A

A

A

A

A

5.32

What is the expected value of the statistic over all possible randomizations? (-2.82+…+1.83+…+5.31)/462 =?
RANDOMIZATION SAFEGUARDS THE EXPERIMENT AGAINST OBSERVED AND UNOBSERVED COVARIATES IN EXPECTATION (ON AN AVERAGE)

But what if you come up with …
A A A A AB B BB B B
But I randomized the assignment as per the statistician’s suggestion

Blocking: A strategy to protect assignment from “bad” randomization:

Block 1: assign 3 A’s and 3 B’s

Block 2: assign 2 A’s and 3 B’s

FISHER: • “Block what you can, randomize what
you cannot” • “Analyze as you randomize”
How would our analysis have changed?

The Diet Experiment
• Effect of improved diet A (treatment) versus standard diet B (control).
• Twenty animals available.
• Differ with respect to age, sex and other characteristics.

Matched-pair (blocked) experiment
• Scientist forms 10 pairs of animals.
• Animals in the same pair are “identical”.
• Each animal within each pair gets either diet A or diet B; allocation decided by flip of a coin.

Potential outcomes

PAIR (BLOCK)
1 2 3 4 5 6 7 8 9 10

Potential outcome for animal 1

Diet A

Diet B

Y1,1(A)

Y1,1(B)

…

…

…

…

…

…

…

…

…

…

…

…

…

…

…

…

Y10,1(A)

Y10,1(B)

Potential outcome for animal 2

Diet A

Diet B

Y1,2(A)

Y1,2(B)

…

…

…

…

…

…

…

…

…

…

…

…

…

…

…

…

Y10,2(A)

Y10,2(B)

Observed outcomes

PAIR

Potential outcome for animal 1 Potential outcome for animal 2

Diet A

Diet B

Diet A

Diet B

1

13.2

?

?

14.0

2

?

8.8

8.2

?

3

?

11.2

10.9

?

4

14.3

?

?

14.2

5

10.7

?

?

11.8

6

6.6

?

?

6.4

7

?

9.8

9.5

?

8

10.8

?

?

11.3

9

?

9.3

8.8

?

10

?

13.6

13.3

?

Observed value of test statistic

PAIR

Potential outcome for

Potential outcome for

animal 1

animal 2

Diff (d)

Diet A

Diet B

Diet A

Diet B [Red – blue]

1

13.2

?

?

14.0

0.8

2

?

8.8

8.2

?

0.6

3

?

11.2

10.9

?

0.3

4

14.3

?

?

14.2

-0.1

5

10.7

?

?

11.8

1.1

6

6.6

?

?

6.4

-0.2

7

?

9.8

9.5

?

0.3

8

10.8

?

?

11.3

0.5

9

?

9.3

8.8

?

0.5

10

?

13.6

13.3

?

0.3

| d |= 0.41

Imputed table of potential outcomes under sharp null of no effect

PAIR

Potential outcome for animal 1 Potential outcome for animal 2

Diet A

Diet B

Diet A

Diet B

1

13.2

13.2

14.0

14.0

2

8.8

8.8

8.2

8.2

3

11.2

11.2

10.9

10.9

4

14.3

14.3

14.2

14.2

5

10.7

10.7

11.8

11.8

6

6.6

6.6

6.4

6.4

7

9.8

9.8

9.5

9.5

8

10.8

10.8

11.3

11.3

9

9.3

9.3

8.8

8.8

10

13.6

13.6

13.3

13.3

Distribution of the test statistic and the p-value
Randomization distribution of test statistic

pvalue=0.0132

tobs=0.41

Frequency 0 200 400 600 800 1000 1200

0.0

0.1

0.2

0.3

0.4

0.5

test statistic

Three fundamental principles of experimentation (Fisher 1925)
• Randomization • Replication • Blocking

How experiments are changing
• Hundreds of covariates associated with each experimental unit
– e.g., patients in clinical trials
• Multiple treatment factors
– Thirty chemical modulators in stem-cell experiments
• Complex randomization restrictions
– Non-compliance – Multi-stratum

Designs that balance several covariates over treatment groups
• The more covariates, the more likely at least one covariate will be imbalanced across treatment groups
• Covariate imbalance not limited to “unlucky” randomizations
• Blocking not intuitive • The solution: Re-randomization

Define a measure of “balance” between treatment and control groups
• Define a measure • Small values of the measure are acceptable • Large values of the measure indicate lack of
balance and are unacceptable
A A B B AB B B A A B
What can be a possible measure of balance?

Comparing treatment assignments
A A B B AB B B A A B
(3+4+6+7+8+11)/6-(1+2+5+9+10)/5=1.10
A B A B AA B B B A B (2+4+7+8+9+11)/6-(1+3+5+6+10)/5=1.83
A A A A AB B BB B B
(6+7+8+9+10+11)/6-(1+2+3+4+5)/5=5.5

Design and analysis of re-randomized
experiments
• Decide acceptable criterion (which randomizations to accept)
• Randomize until the acceptability criterion is met
• Analysis using randomization test:
– Calculate observed value of test statistic – Assuming hypothesis to be true, impute missing potential
outcomes – Generate distribution of test statistic using repeated
assignments under same mechanism (i.e., accepting randomizations that are acceptable) – Determine if observed value of “unusual”

Visualization for two continuous covariates

Visualization for two continuous covariates

Visualization for two continuous covariates

Visualization for two continuous covariates

Visualization for two continuous covariates

Criterion for re-randomization
• Mahalanobis distance M (a multivariate distance between group mean vectors)
• Acceptance criterion: M ≤ a
• Here a is a pre-determined constant
• Trade-off between throwing away randomizations and balancing groups

Reducing variance of average covariate difference between groups
Figure courtesy: Kari Lock Morgan and Donald B. Rubin

Covariate balance achieved by rerandomization - I
Figure courtesy: Kari Lock Morgan and Donald B. Rubin

Covariate balance achieved by rerandomization - II
Figure courtesy: Kari Lock Morgan and Donald B. Rubin

Multi-factor experiments
• 224 New York schools • Five new interventions labelled A-E, e.g.,
– Quality review (A) – School-wide performance bonus scheme for the
teachers (B)
• Response: A cumulative score on the annual progress report.
• A 25 factorial experiment with five factors each at two levels: 1( treatment), -1 (control).

Assignment mechanism
• Completely randomized assignment (CRA) of the 32 treatment combinations to the 224 schools (each treatment to eight schools).
• But need balance over 50 covariates • Different levels of protection (balance):
– Maximum protection to five main effects – Less protection to two-factor interactions – Zero protection to three, four, five-factor
interactions

Improving balance by rerandomization

Randomization tests

Randomization tests (contd.)

Modifying Fisher in 2015 § BLOCK WHAT YOU CAN,
RERANDOMIZE WHAT YOU CANNOT!
§ ANALYZE AS YOU RERANDOMIZE

Fixed to random potential outcomes, Finite to super-population inference
Super population of all NY schools

Fixed to random potential outcomes, Finite to super-population inference

Super population of all NY schools

⎡Yi (t) ⎤ ⎢⎣Yi (c)⎥⎦

~

N ⎜⎜⎝⎛

⎡µt

⎢ ⎣

µc

⎥⎤,σ
⎦

2

⎡1
⎢⎣ρ

ρ
1

⎤ ⎥ ⎦

⎟⎟⎠⎞

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

~

N

⎜⎛ ⎜⎝

⎢⎣⎡00⎥⎦⎤,

⎡τ 2

⎢ ⎣

0

0
τ2

⎤ ⎥ ⎦

⎟⎞ ⎟⎠

Hierarchical (Bayesian) model

Fixed to random potential outcomes, Finite to super-population inference

Y obs

⎡Yi (t) ⎤ ⎢⎣Yi (c)⎥⎦

~

N ⎜⎜⎝⎛

⎡µt

⎢ ⎣

µc

⎥⎤,σ
⎦

2

⎡1
⎢⎣ρ

ρ
1

⎤ ⎥ ⎦

⎟⎟⎠⎞

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

~

N

⎜⎛ ⎜⎝

⎢⎣⎡00⎥⎦⎤,

⎡τ 2

⎢ ⎣

0

0
τ2

⎤ ⎥ ⎦

⎟⎞ ⎟⎠

Fixed to random potential outcomes, Finite to super-population inference

Y obs

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

|

Y

obs

,

W

⎡Yi (t) ⎤ ⎢⎣Yi (c)⎥⎦

~

N ⎜⎜⎝⎛

⎡µt

⎢ ⎣

µc

⎥⎤,σ
⎦

2

⎡1
⎢⎣ρ

ρ
1

⎤ ⎥ ⎦

⎟⎟⎠⎞

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

~

N

⎜⎛ ⎜⎝

⎢⎣⎡00⎥⎦⎤,

⎡τ 2

⎢ ⎣

0

0
τ2

⎤ ⎥ ⎦

⎟⎞ ⎟⎠

Back to finite-population inference

Ymis | Yobs , W

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

|

Y

obs

,

W

⎡Yi (t) ⎤ ⎢⎣Yi (c)⎥⎦

~

N ⎜⎜⎝⎛

⎡µt

⎢ ⎣

µc

⎥⎤,σ
⎦

2

⎡1
⎢⎣ρ

ρ
1

⎤ ⎥ ⎦

⎟⎟⎠⎞

⎡µt ⎢⎣µc

⎤ ⎥ ⎦

~

N

⎜⎛ ⎜⎝

⎢⎣⎡00⎥⎦⎤,

⎡τ 2

⎢ ⎣

0

0
τ2

⎤ ⎥ ⎦

⎟⎞ ⎟⎠

Finite-population inference: Impute missing potential outcomes “stochastically”

Plot of land 1 2 3 4 5 6 7 8 9 10 11
Average

Fertilizer A (old) 29.2 11.4 ? ? 25.3 ? ? ? 16.5 21.1 ? 20.70

Fertilizer B (new) ? ?
26.6 23.7
? 28.5 14.2 17.9
? ? 24.3 22.53

Assignment (W) 0 0 1
Ymis | Yobs, W 1 0 1 1 1 0 0 1

To learn more, take Stat 140/240

