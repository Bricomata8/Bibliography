Virtual Reality Mobile Application Testing in a 5G Testbed
Soumya Kanti Datta Digiotouch OU, Estonia Email - soumya@digiotouch.com

Abstract—This paper describes an experiment for a Virtual Reality (VR) mobile application testing in a 5G testbed. The application in its current state streams high quality multimedia content from a Cloud server creating an immersive experience for the end user. While loading the 3D environment from the Cloud server, high LTE network latency and high power consumption are observed. In this context, utilizing Multi-Access Edge Computing (MEC) and 5G technologies can bring many beneﬁts to the VR application. An experiment has been designed to test the application in a 5G testbed and metrics in terms of reliability, power consumption, network resources consumption, and user experience are noted. The paper reports the experiment, testbed tools, results obtained, and upgrades performed to VR application.
Index Terms—5G; Virtual Reality; Testbed.
I. INTRODUCTION
Virtual Reality (VR), often referred to as one of the nextgeneration computing Platform, is basically an interactive computer generated experience. Generally, it takes places in a simulated environment with not only audio, video feedback but also other sensory feedback as well. The immersive VR experience is often delivered through VR headsets which consist of head mounted displays (HMD). With the anticipation of 5G deployment starting by the end of 2020, high penetration of high end smartphones, and low cost mobile data, there has been a steady growth in VR HMD shipments1 and VR applications. Market research companies estimate that the global VR market will reach a valuation more than $34 Billion by 20232. Despite such prospects, the current VR mobile applications (apps) and ecosystem continue to face several technical challenges including high network latency to load and display high quality multimedia content and interactions with 3D and VR world. Both result in inferior user experience (UX). Experts also agree that the current lack of 5G is a big barrier towards the widespread adoption of VR apps. To address these challenges the app must exploit Multi-Access Edge Computing (MEC) and 5G technologies. The Digiotouch VR app relies on state-of-the-art video technology which requires high bandwidth. With new video formats emerging and evolving, particularly 360 Degree, even higher bandwidth will be required. LTE handles 360 Degree video at 4K 30fps, but 5G is projected to improve the experience by operating at 8K 90fps. In general, VR apps will soon reach the Gbps
1https://techcrunch.com/2018/12/02/bright-spots-in-the-vr-market/ 2https://www.businesswire.com/news/home/20180508005963/en/ Global-Augmented-Reality-AR-Virtual-Reality-VR

limit of LTE as apps evolve and become more sophisticated. With 5G’s increased capacity and 10x speed, our app will provide state-of-the-art consumer experience. Also, the 5G powered VR apps will be less constrained by its physical location thanks to vastly improved service delivery capabilities at signiﬁcantly lower power consumption proﬁles. Utilization of MEC ensures that end users get a consistent performance from connectivity as VR requires a constant, stable signal.
The Digiotouch VR app has been developed to stream high quality multimedia content from the a Cloud server. The UX and delivery of the multimedia content depend heavily on the network (LTE, 3G, Wi-Fi) available. The app also registers very high power consumption for the network operations. To make the app 5G ready, it has been tested in a 5G Testbed developed by the EU H2020 Project Triangle3. It offers an end-to-end testing ecosystem for 5G for connected mobile apps [1]. The testbed framework assists app developers to experiment and evaluate their app for upcoming 5G ecosystem using current and extended FIRE testbeds. An experiment is developed to test and evaluate app in terms of reliability, power consumption, network resources consumption, and quality of user experience. A MEC component is developed to take advantage of multimedia content caching and quicker delivery than the Cloud server. There are several impacts of the experiment. It demonstrates the app performance in several real scenarios in 5G and identiﬁes the areas which can be improved to make the app ”5G ready”.
Rest of the paper is organized as follows. Section II describes the experiment objectives, setup, and 5G scenarios. Section III reports technical results and lesson learnt. Section IV concludes the paper.
II. EXPERIMENT SCENARIOS AND SETUP
The experimental setup consisted of a Cloud server, a MEC application server, Digiotouch VR app, and the Triangle testbed. The VR app normally interacts with the Cloud (i.e. Digiotouch Paradise IoT Platform) server to stream high quality multimedia content. The steps for this interaction are depicted in the Fig.1. The ﬁrst step concerns authentication of the VR app and its user. On successful authentication, the corresponding web service in the IoT Platform generates a JSON Web Token (JWT). The JWT is used in subsequent requests to identify the app user.
3triangle-project.eu

978-1-7281-1340-1/19/$31.00 ©2019 IEEE

455

ICUFN 2019

Fig. 1. Architecture before the Triangle testbed experiment.
For the experiment, a MEC application server has been introduced to the architecture depicted in Fig.1. The new MEC server is deployed as a part of the Triangle Testbed. The evolved architecture this modiﬁed interactions among its elements are shown in Fig.2. The MEC application server must authenticate itself to the Cloud server and then download the VR contents for caching. If a speciﬁc VR content (i.e. HQ video) is updated, the same is updated in the MEC server as well. The Digiotouch VR application authenticates itself to the MEC server using the same principles mentioned before. During the experimentation, the app streams video from this local MEC server.
Fig. 2. Experimental setup.
The above setup has been tested with several realistic 5G network scenarios. It is to be noted that the Triangle Project focuses more on the 5G end user perspective rather than an aggregated network related vision. This experimentation has utilized both urban and suburban 5G testing scenarios4. Both of them are further divided based on the users and trafﬁcs present in the surroundings.
4https://www.triangle-project.eu/wp-content/uploads/2016/10/ TRIANGLE Deliverable D2-1-v1.0.pdf

For urban scenario, three sub-cases are tested. • Internet cafe busy hours. This is well suited for con-
sumer applications like VR mobile apps. The scenario is a typical multi-RAT scenario with users mostly static, with some channel variations due to the street-level nature of the location (moving objects on the street, some indoor penetration). Busy hours simulate network conditions when a lot of consumers are trying to access VR contents from the MEC application server. This affects network load and the amount of network resources that each consumer can get. • Internet caf off peak. In this case, the no. of consumers in the Internet caf decreases which creates easier conditions for network access (less interference from other consumers, reduced amount of moving shield objects). • Ofﬁce. This is the typical indoor ofﬁce environment where users are static. It is characterized by the presence of indoor wireless network access points (both Wi-Fi and Small Cells). The channel and interference conditions are also dictated by the penetration of signals coming from the outdoor cells, mostly macro sites. The expected trafﬁc scenario is related to typical broadband access with a mixture of applications.
Suburban comprises of scenarios typically located in less densely populated areas. Thus, most of the access site to the network is macro, mounted on higher rise towers for coverage with a larger inter-site distance. Few sporadic Small Cell hotspots are eventually encountered within the coverage area of the macros, either for localized capacity boosting or for reinforcing the coverage. All the sub-cases of interest in these network and propagation conditions are related to the concentrated and massive presence of users.
• Festival. In this typical outdoor scenario, there are additions of few localized macro sites and Small Cells for increased capacity. The network trafﬁc is mostly consistent with dense broadband access with concerts streaming from the festival area.
• Stadium. It demonstrates the highest density of users. The stadium is covered with wireless hotspots, but its main characteristics is the balancing between no. of access points and the interference generated.
• Shopping mall busy hours. It is characterised by large indoor spaces, with a certain amount of electromagnetic reﬂecting materials. During busy hours, the shopping mall is ﬂooded with consumers. Both the business internal and customers trafﬁc is expected to overload the network.
The above are tested using three high quality videos of 1080p, 8K, and 360-degree. This experiment has utilized (i) Performance Tool, (ii) TestelDroid Mobile Monitoring App, (iii) Power Consumption Analyser, (iv) Device Action Automation Tool, and (v) App Lab live environment of the Triangle Testbed [2].
III. TECHNICAL RESULTS AND APP IMPROVEMENTS
This section described the results obtained suring the experiments, lessons learnt, and the improved made to the VR

456

app.
A. Suburban festival scenario with 1080p video streaming
In this scenario, as anticipated, the time to load and display the 3D environment for the 1080p video is considerably high (more than 6 minutes) (seen from Fig.3). This clearly has an impact on the Quality of Experience of the VR app. For such high time to load, the updated VR app informs the consumer about the network conditions and prompts to view a different video from a different provider using a different network (LTE, 3G, or Wi-Fi).

be attributed to very high number of end users present in the stadium along with the balancing between number of access points and the interference generated. Despite such high time to load, no crash or data loss were detected for the app establishing reliability KPI for the consumers. The average current consumption recorded is 11mA (achieving such low consumption is one of the key testing aspects of this experiment). A closer look at Fig.6 reveals that the ﬁrst iteration was not successful in loading the full video. The Average System GPU use of 1.9 and network downlink data of 358 KB supports this conclusion. This can be attributed to the real-life characteristics of the network scenario. The two other iterations were able to perform as expected and we see comparable results with respect to previous scenarios for device and network resources consumption aspects.

Fig. 3. Time to load and display 3D environment for 1080p video.

Fig. 5. Time to load 1080p video in suburban stadium scenario.

Fig. 4. Smartphone and network resources consumptions.

The network resource consumption indicate the uplink and downlink data usage which are about 3.7MB and 224+ MB for the three iterations. It denotes that the current VR app communicates 3.7MB data with the MEC server and is able to stream 224+ MB of 1080p video in the respective iterations.
For device resource consumption, the Average System CPU and GPU consumption are relatively low (refer to Table 1) which point to a lightweight design and implementation of the application. The average RAM utilization percentage is slightly more than 50 owing to high volume of data download and rendering 3D environment through the app. Although the time to load is more than 6 minutes, the app does not crash necessitating in auto recovery. There is no loss to any data ﬁles either. Therefore, the reliability of the app is established. The power analyser measurements report that an average of 96 mA consumption during the testing scenario with an average power consumption of 0W.
B. Suburban stadium scenario with 1080p video streaming
Here, the time to load the video varies considerably in this scenario as seen from the Fig.5. Such variation can

Fig. 6. Smartphone and network resources consumptions in suburban stadium.
C. Urban ofﬁce scenario with 1080p video streaming
For this scenario, the time to load the 3D environment and the video is a lot less than previous scenarios. Still from the consumer point of view, even 26 seconds to load the video is very high (as seen from the third iteration of Fig.7). To improve usability of the VR app, we have introduced a concept of Watch Later where the user is prompted to download the video from the MEC server. The video is then saved on the smartphone and the user can choose to play the video anytime later on. The average current consumption for this scenario is 28 mA which is beneﬁcial from the usability point. For device and network related aspects, there are no signiﬁcant deviation from previous scenarios (Fig.8).
D. Urban ofﬁce scenario with 8K video streaming
The urban ofﬁce scenario has ﬁve iterations of which four have time to load the 8K video at slightly more than 2 minutes

457

Fig. 7. Time to load 1080p video in urban ofﬁce scenario.

Fig. 10. Smartphone and network resources consumptions in urban ofﬁce scenario with 8K video.
and display the portions of the video accordingly. It is well known that use of such sensors increases the average current consumption [3] which is 438 mA in this case. In general, all scenarios with 360-degree videos have recorded very high average current consumption for this reason.

Fig. 8. Smartphone and network resources consumptions in urban ofﬁce.

(Fig.9). In just one scenario, it took 10 minutes which can be attributed to high demand and interference. This scenario is also able to achieve very low average current consumption of 21 mA. But it should be observed from Fig.9 that the second iteration (which took 10 minutes) was not able to download the entire 8K video and as a result its average system GPU consumption is just 1.61 (Fig.10). In the upgraded VR app, if such situation arises where the network is not able to download the video, a retry option is provided to the consumer. The device used in 1080p and 8K video related experiments is a Samsung S7. It should also be noted that the device does not fully support viewing the 8K video.
Fig. 9. Time to load 8K video in urban ofﬁce scenario.
E. Ideal scenario with 360-degree video streaming With 360-degree video streaming, the robotic arm of the
Triangle Testbed is utilized. The accelerometer sensor of the smartphone is used to determine the movement of the phone

Fig. 11. Device and network resource consumption for ideal scenario with 360-degree video streaming.
From Fig.11, it is also noticed that average system CPU and GPU consumptions are much less than the network scenarios with 1080p and 8K video. The reason is that, the 360degree video chosen in this experiment does not have any 3D environment to load. Consequently, the loads on CPU and GPU to render the video are much less.
F. Lessons learnt and upgraded VR app
The above experiments were extremely beneﬁcial to understand the current VR app behaviour in different 5G network conditions. All iterations were performed using cellular network. In many cases, it is noticed that the time to load the VR videos is taking up to 10 minutes. Waiting for such a long time to stream a video and then watch that does not provide a good Quality of Experience. Apart from that, it some iterations, the VR content is partially loaded which breaks the immersive experience of the consumer as well. In terms of device resource consumption, the CPU, GPU, and RAM usage denotes that the app implementation is lightweight which has a positive impact on the consumers smartphone. No app crash, data loss etc. were detected during the testing which demonstrates the good usability of the current VR app.The experimental observations and results are also analysed, and several aspects are determined to upgrade the VR app. These are presented below.
• For very high time to load, the upgraded VR app informs the consumer about the network conditions and prompts to view a different video from a different provider using a different network (LTE, 3G, or Wi-Fi).

458

• To improve usability of the VR app, we have introduced a concept of saved VR content where the user is prompted to download the video from the MEC server. The video is then saved on the smartphone and the user can choose to play the video anytime later on.
• If a video is partially loaded and then a timeout occurs, the consumer is prompted to restart the VR video download.
• The uplink communication messages from the app to the MEC server is identiﬁed and is optimized to consume even less network resources.
• 360-degree videos consume current many times more than 1080p or 8K videos. The user will be prompted about their impact on battery life when viewing or downloading them for Watch Later.
G. Conclusion
An experiment for Digiotouch VR mobile app testing in the Triangle testbed for 5G enabled end users is described in this paper. The experimental setup introduces a MEC application server for multimedia content caching and quicker delivery between the VR app and Cloud based Paradise IoT Platform. The experiment has been highly beneﬁcial to understand the behaviour of app in realistic 5G scenarios to make the app 5G ready. Triangle testbed has been used to obtain results on reliability, power consumption, network resources consumption, and user experience of the app. Based on the outcomes,

ﬁve improvements are noted and implemented in the upgraded Digiotouch VR app.
ACKNOWLEDGEMENT
The experiment and results presented in this paper are a part of Triangle project. This project has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 688712. The author would like to thank the colleagues from DEKRA and University College London for their support during this experimentation.
REFERENCES
[1] A. F. Cattoni, G. C. Madueo, M. Dieudonne, P. Merino, A. D. Zayas, A. Salmeron, F. Carlier, B. S. Germain, D. Morris, R. Figueiredo, J. Caffrey, J. Baos, C. Cardenas, N. Roche, and A. Moore, “An end-to-end testing ecosystem for 5g,” in 2016 European Conference on Networks and Communications (EuCNC), pp. 307–312, June 2016.
[2] A. D. Zayas, A. Salmern, F. J. R. Tocado, and P. Merino, “Advanced testing of mobile applications and devices,” in 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), pp. 801–804, May 2017.
[3] S. K. Datta, C. Bonnet, and N. Nikaein, “Android power management: Current and future trends,” in 2012 The First IEEE Workshop on Enabling Technologies for Smartphone and Internet of Things (ETSIoT), pp. 48–53, June 2012.

459

