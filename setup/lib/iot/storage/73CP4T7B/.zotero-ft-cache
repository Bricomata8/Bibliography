Error Mitigation in Optical Camera Communication Based Indoor Positioning System

Md. Shahjalal*, Moh Khalid Hasan, Md. Tanvir Hossan, Mostafa Zaman Chowdhury, and Yeong Min Jang• Department of Electronics Engineering, Kookmin University, Seoul, Korea
Email: *mdshahjalal26@ieee.org, •yjang@kookmin.ac.kr

Abstract- Existing indoor lighting infrastructure such as light emitting diodes (LEDs) are able to transmit digital data by changing its luminary using proper modulation technique. Camera mounted mobile robot (MR) is used to perform several indoor services using optical camera communication system which is now a challenging research issue specially in terms of communication data rate, processing time and cost. This paper proposes an image processing based solution to indoor MR positioning with increased communication distance and accuracy. Distance is measured by smart phone camera to move MR below a LED and fix its position receiving the floor coordinate of that LED. We get of positioning accuracy greater than 96% at different floor positions inside the room.
Keywords- Optical camera communication; mobile robot; indoor positioning; cloud server.
I. INTRODUCTION
Optical camera communication (OCC) becomes very promising technology in terms of localization and navigation because global positioning system (GPS) system using radio frequency (RF) based wireless network such as wireless fidelity (Wi-Fi), Bluetooth can’t provide accurate location based services. Specially in indoor environment it is much difficult to find accurate location. OCC uses unlicensed spectrum where light emitting diodes (LEDs) infrastructures are used as transmitter in both indoor and outdoor, localization is possible in cm level accuracy [1]-[3]. LED is used as transmitter because it is energy efficient, common, low cost and high accuracy localization can be possible by its changeable luminary property [4], [5].
Currently, the application of mobile robot (MR) localizing or positioning in indoor environment is increasing commercially in office, restaurant, shopping mall, and company areas. There have many applications such as location-aware services and advertisements in large museums or public libraries or buildings [6]. Nowadays in many applications or research proposals offers cloud server based Localization or navigation services using OCC, where this server is used for storing mapping data and position computing purposes [7]. Smart device is connected to this server by Wi-Fi or Bluetooth connection during location estimation. This work has some drawbacks as it is using external server and extra RF network which is costly and also time consuming process.

In visible light based communication systems flickering is a major issue to be considered. It is known human eyes can perceive luminary changes up to 200Hz [8]. As data is transmitted through changing the luminary property of LED, a flicker free modulation technique is needed.
This paper proposes an idea to get more accurate positioning information of a MR in an indoor environment which doesn’t have any requirement of additional RF spectrum. By measuring the distance between LED and camera, the relative position of detected image in the image sensor and receiving the coordinate ID from LED transmitter MR can estimate its position by processing the continuous image frames. Some horizontal movement may be needed to get actual floor coordinate of a reference LED. The rest of contents of the paper is sectionalized as follows: a brief of related works is discussed in Section II. In Section III an overview of the proposed system is given and divided in subsections which describes the mobile robot specifications, localization algorithm, distance measurement principle. Experimental scenario with some results and discussions is in Section IV.
II. RELATED WORKS
Recently, many works have been done for indoor localization using radio frequency identification (RFID), ultrawideband (UWB) where Wi-Fi access point (AP) is needed to install and which leads to cost increasing [9]. Time difference of arrival (TDOA) [10] and light detection and ranging (LiDAR) system is used for measuring distance to localize relatively. In LiDAR laser light is sent and reflected signal is received by depth sensor in some cases [11].
VLC based positioning is also becoming a hot topic in indoor application. White LED is used as transmitter and a photo diode is used to receive signal. Position is estimated by measuring received signal strength (RSS) [12] or angle of arrival (AOA) [13]. PD has some limitations as its small in size and lower field of view (FOV), also it cannot be used for multiple input multiple output (MIMO) applications.
In [14] AOA-based localization in multi-element VLC system is proposed where receiver device will take the signals from one of the LEDs in each multi-element visible access point (VAP). From each connected LED the AOA is taken for each VAP as central line of the FOV. To find the location of receiver a least square (LS) estimator is used.
Multiple light sources are also used for indoor localization. The multiple light sources are modulated with data stream and

978-1-5386-4646-5/18/$31.00 ©2018 IEEE

100

ICUFN 2018

(x1,y1)

(x1,y2)

(x1,y3)

(x2,y1)

(x2,y2)

(x2,y3)

Zw

LED transmits ID

D

through light h

Yw Xw

a
a
MR moves by a distance a

Figure 1. A scenario of proposed MRP model.

receivers receive the information. There also has a cloud based server which stores the whole mapping information of the room and that provides receiver the indoor positioning information [4].

III. SYSTEM OVERVIEW
Figure 1. shows a scenario of proposed indoor Mobile Robot Positioning (MRP) system using OCC. As LED is used in almost every indoor lighting system nowadays, it can be used as transmitter for optical camera communication. It has luminary changing property according to binary bit stream. Flickering here is an issue to be considered that human eyes can get disturbed by this continuous light on/off process. It has several bad effect like reduce visual task performance, distraction etc. So in OCC application data is modulated with high modulation frequency which is beyond that can be perceived by human eyes. 200Hz is considered safer [8]. We modulated our lights with the coordinate data bits using MFSK technique where we used frequency between 2 to 8 kHz which is much safer. After modulation done to change the data bits ‘1’ and ‘0’ to a different pattern line coding is used. LEDs are installed onto the ceiling and send coordinate number to MR. The room contains LEDs are of rectangular shape and arranged in a regular pattern. In this case of positioning system MR is used which have uniform height and the LEDs are modulated with data bits containing the (x,y) coordinate information. LEDs are continuously ON-OFF according to modulated signal and changes its luminaries. When a rolling shutter camera has frame rate less than the modulation frequency can capture an image frame which will contain continuous bright and dark stripes. Because rolling shutter camera do not capture whole image at a time. It scans the whole image row by row within a single frame duration. The captured image then processed to decode the received coordinate of that LED.
A. MR specification
Mobile robot localization and navigation is a challenging issue nowadays in case of optical camera communication. It should have self-processing capabilities. Figure 2. depicts the

Mobile Robot Processing Unit

User control

Data porcessing

Data Base

Camera

Image processing

Figure 2. Mobile robot processing unit.

Place MR into the room

Detect the LEDs within camera FoV and define as N

No

N≥ 1? Yes

Localization failed

Measure detected LED areas in camera frame of reference

Now MR is in location ( Xi,Yj )

Compare Between the areas and select nearest LED

Get the ID from that LED

Measure the distance

( Xi,Yj )

between camera and the LED

Pass that distance to reach exactly below that LED

Calculate the horizontal distance to that LED

Figure 3. Flowchart describing indoor MRP algorithm.
specifications of MR, which has a camera mounted to its top and also user can access the robot. It also has data and image processing unit (DIPU) to compare with the IDs and data base to store this previous tracking information. MR receives IDs and can localize itself. It also has the capabilities to compare within the IDs and navigate by itself if user sets its destination.
B. Principle of localization
The MRP system which is proposed can receive accurate positioning information according to an effective algorithm as shown in figure 3. Initially an intellectual mobile robot is randomly placed at any position in the room. As the entire environment in the room is unknown to MR, it needs to fix its position that means finding a co-ordinate inside the room. To do that it will first count how many LEDs are within the cameras FOV. To localize mobile robot should go at the exact floor position of a LED and get its ID. To do that it first takes the detected contour area of every LED and make a comparison between them. As all the LEDs in the room have same surface area, distance between camera and LED will be shorter if the detected area be larger. So, completing the comparison process MR can easily select the nearest LED between them. MR then measures the distance D of it from the selected LED. Horizontal distance towards the LED can be found using right angle triangular law and moving this horizontal distance MR gets the LED coordinate and have the

101

r cos(f)

Circular LED

A

Or B

f

P

f

DAB,f

DAB,0

f

Eclipse shape in the image sensor

Eclipse shape in the image sensor

Smart phone camera2 Figure 4. The shape of a circular LED changes to eclipse with the
increase of incidence angle f .

exact floor location of that LED.
C. Distance measurement Let the room contains LED lights of coordinates
(xi, y j ) here, i and j is the horizontal and vertical axis index have maximum value according to the room size and LED distribution system which is total number of LEDs in the room. We know the generalized equation for measuring distance from LED in vertical direct line of sight (LOS) as mentioned in [5].

D = F Aij

(1)

aij

Here, focal length F and actual LED size Aij are known. The
only thing to get the detected LED area aij from the IS. That
means, in this case, detected LED have original shape in its sensor. But when MR is not just below the LED then the actual shape of LED seems to be different. In Figure 4 it is explained clearly that for a circular LED how it changes to
eclipse with the increase of incidence angle f . To solve this
issue, we can modify the equation (7) as below:

DAB,f = F

p r2Cos(f) aij

(2)

In (2), actual area of reference LED changes according to the horizontal distance of the receiver from the LED. By this method of consideration, the positioning accuracy can be improved.

Direct distance between camera and LED, Dh (cm)

Figure 5. Distance measurement from camera to LED. LEDs of same size at a distance 336 cm have smaller area than that at a distance of 190 cm in the image sensor.
500
450
400
350
300
250
200
150
100
50
0 10000 20000 30000 40000 50000 60000 70000
Detected pixel area (pixels) Figure 6. Variation of direct distance with detected pixel areas in the image sensor.
IV. RESULT AND DISCUSSION
We arranged rectangular LED of size 0.25 m2 to transmit coordinate information. When there are multiple LEDs inside camera FOV it compares between the covered pixel areas of that detected LEDs. Then DIPU of MR takes only larger area to get floor position of that LED. Figure 5 depicts an application which measures the distance from different detected LEDs. This application uses Microsoft LifeCam Cinema Webcam and has frame rate of 30 fps. Generally, fps varies from 25 to 30 in general low frame rate cameras. So, it is difficult to decode signal from varying frame rate. We fixed it to 20fps and minimum processing time per frame should be t within 50 msec.
The communication distance varies with the size of LED. The larger the size of LED, the larger the communication distance. In this case we got maximum communication distance is 5 m.

102

5

4

Percentage of error

3

2

1

0

255

260

265

270

275

Direct distance Dd (cm)

Figure 7. Percentage of error with the change of direct distance between camera and LED.

Figure 6 shows the changes of distance between camera and LED at different floor positions with the detected image sensor area. When the detected pixel area in the sensor is less than 1000 pixels we get maximum communication distance.
When MR moves horizontally, sometimes it comes nearer to the vertical floor position of any LED and sometimes goes far distances. Distance measurement is required to get a position below a target LED. But positioning error increases when MR is not situated just below the target LED. We tested some values experimentally in a room having height of 2.5 m from the camera. Error increases as MR moves far distances horizontally. Figure 7 depicts how error decreases percentwise when MR comes nearer to the vertical floor position of any target LED. By adopting above discussed distance error mitigation technique percentage of error is reduced up to 4% at the boundary position.

V. CONCLUSIONS
This work represents an efficient error mitigation technique in indoor MR positioning system. The proposed MRP system need to measure distance from a target LED and in this case accuracy is improved beyond 96%. This approach examines null distance error at the vertical position from a LED. The average frame processing time to get LED coordinate is within the critical frame duration and its about 30 msec.

ACKNOWLEDGMENT
This research was supported by the MSIT (Ministry of Science and ICT), Korea, under the Global IT Talent support program (IITP-2017-0-01806) supervised by the IITP (Institute for Information and Communication Technology Promotion)
REFERENCES
[1] Y.-S. Kuo, P. Pannuto, K.-J. Hsiao, and P. Dutta, “Luxapose: indoor positioning with mobile phones and visible light,” in International Conference on Mobile Computing and Networking., 2014, pp. 447–458.
[2] Y. Nakazawa, H. Makino, K. Nishimori, D. Wakatsuki, and H. Komagata, “Indoor positioning using a high-speed, fish-eye lens-equipped camera in visible light communication,” in International Conference on Indoor Positioning and Indoor Navigation, 2013, pp. 1– 8.
[3] M. Z. Chowdhury, M. T. Hossan, A. Islam, and Y. M. Jang, “A comparative survey of optical wireless technologies: architectures and applications,” IEEE Access, vol. 6, pp. 9819–9840, Jan. 2018.
[4] M. T. Hossan, M. Z. Chowdhury, A. Islam, and Y. M. Jang, “A novel indoor mobile localization system based on optical camera communication,” Wireless Communications and Mobile Computing, vol. 2018, no. 1, pp. 1–17, Jan. 2018.
[5] M. T. Hossan et al., “A new vehicle localization scheme based on combined optical camera communication and photogrammetry,” Mobile Information Systems, vol. 2018, no. 1, pp. 1–14, Mar. 2018.
[6] X. Guo, S. Shao, Nirwan Ansari, and A. Khreishah, “Indoor localization using visible light via fusion of multiple classifiers,” IEEE Photonics Journal, vol. 9, no. 6, pp. 1–16, Dec. 2017.
[7] C. Yang and H. R. Shao, “WiFi-based indoor positioning,” IEEE Communications Magazine, vol. 53, no. 3, pp. 150– 157, Mar. 2015.
[8] S. M. Berman, D. S. Greenhouse, I. L. Bailey, R. D. Clear, and T. W. Raasch, “Human electro retinogram responses to video displays, fluorescent lighting, and other high frequency sources,” Optometry and Vision Science, vol. 68, no. 8, pp. 645–662, 1991.
[9] J. Luo, L. Fan, and H. Li “Indoor positioning systems based on visible light communication: state of the art,” IEEE Communications Surveys & Tutorials, vol. 19, no. 4, pp. 2871–2893, Aug. 2017.
[10] S. Y. Jung, S. Hann, and C. S. Park, “TDOA-based optical wireless indoor localization using LED ceiling lamps,” IEEE Transactions on Consumer Electronics, vol. 57, no. 4, pp. 1592–1597, Nov. 2011.
[11] H. Song, W. Choi, and H. Kim, “Robust vision-based relative localization approach using an RGB-depth camera and lidar sensor fusion,” IEEE Transactions on Industrial Electronics, vol. 63, no. 6, pp. 3725–3736, Jun. 2016.
[12] X. Tian, R. Shen, D. Liu, Y. Wen, and X. Wang, “Performance analysis of RSS fingerprinting based indoor localization,” IEEE Transactions on Mobile Computing, vol. 16, no. 10, pp. 2847–2861, Oct. 2017.
[13] S. H. Yang, E. M. Jeong, and S. K. Han, “Indoor positioning based on received optical power difference by angle of arrival,” Electronics Letters, vol. 50, no. 1, pp. 49–51, Jan. 2014.
[14] Y. S. Eroglu, I. Guvenc, N. Pala, and M. Yuksel, “AOA-based localization and tracking in multi-element VLC systems,” in Wireless and Microwave Technology Conference, 2015, pp. 1–5.

103

