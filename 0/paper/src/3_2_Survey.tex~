\part{Part 1}
\part{Part 2}
\chapter{Survey}
\label{ch:survey}
\minitoc
\minilof
\minilot

	\section{Introduction}
	
		%\ac{NY}
		%\ac{ny}
%		\todo{Dummy text}
	
%	\section{Motivation and Objectives}
%	\section{Contributions}
%		In this paper,
%			we propose to assist user privacy protection by providing quantitative evaluation of privacy risk.
%		Our work belongs to the second category.

%	\section{Statement of Originality}
%	\section{Publications}

		The study of privacy measurement applied to information and communication technology (ICT) is very wide and embraces many fields of knowledge
			from Sociology and Statistics to Cryptography and Artificial Intelligence.
				%Stalking Online: on User Privacy in Social Networks
		In ICT,
			users are sometimes either oblivious about their privacy,
			or concerned but underestimate the privacy risks.
			
		%Surveys
		Surveys and general discussions on social network privacy and security could be found at 
			\cite{hasan_survey_2017}\cite{ruan_survey_2016}\cite{haus_security_22}\cite{jiang_understanding_2016}\cite{wagner_technical_2018}\cite{li_survey_2012}.
		%Privacy preserving & privacy policy & privacy measurement
		Previous works on social media privacy focus on privacy preserving 
			\cite{zhang_privacypreserving_2017}\cite{hasan_survey_2017}\cite{b.s._privacy_2015} 
			and privacy policy conflicts 
				\cite{fong_relationshipbased_2011}.
		Few works 
			\cite{pensa_centralitybased_2016}\cite{wang_privacy_2013}\cite{rebollo-monedero_measurement_2013} 
			have been conducted on privacy measurement due to the challenges to quantify the privacy risk associated with online social network users.

		To better understand the privacy issues in ICT,
			we describe different types of privacy threats used by attackers to access users' private information through messaging services.
		Next,
			we present four options available to the end users to deal with ICT privacy issues.
			
%		%Mean privacy: A metric for security of computer systems
%		The challenging area of quantitative security evaluation has been received much more attention in recent years.
%		In this section,
%			we want to provide a general overview of the most important methods worked out in this important area of security analysis.

%		Due to the incomplete administrator’s knowledge of the behavior,
%			intent and skill level of attackers,
%			the prediction of their behavior would be a very difficult task.
%		Thus,
%			the use of probabilistic and stochastic models in the area of security evaluation can be an appropriate approach.
%		As shown in literature,
%			stochastic and probabilistic modeling techniques used in the context of dependability evaluation,
%			have been extended and also used to evaluate security metrics,
%			they have been introduced as useful tools for quantitative security analysis.
%		In contrast to stochastic models,
%			which are parameterized with continuous probability distributions,
%			probabilistic models are primarily parameterized with discrete probability distributions.

%		%Markov chains
%		Moayedi et al.\cite{almasizadeh_mean_2014} introduce a novel approach to extend the basic ideas of applying game theory in stochastic modeling.
%		The proposed method classifies the community of hackers based on two main criteria used widely in hacker classifications,
%			which are motivation and skill.
%		They use Markov chains to model the system and compute the transition rates between the states based on the preferences and the skill distributions of hacker classes.
%		The resulting Markov chains can be solved to obtain the desired security measures.


		%Stalking Online: on User Privacy in Social Networks
		\subsection{Privacy threats}

			Four types of privacy threats have been discovered in the literature:

			%Private information disclosure
			\subsubsection{Private information disclosure}

				When users share information with trusted social network community.
					they implicitly assume that their information shared through messages would stay within the community destination.
				However,
					this assumption is not always valid,
					an individual messages may be accessed by adversaries.
				For instance,
					messages sent to an email-based social network may be stored at a repository and consequently visible to the public,
					malicious users and applications may follow people through social networks,
					add-ons and third parties may access users’ private information,
					etc.

				\cite{krishnamurthy_leakage_2010} shows that online social networks and applications leak users’ personally identifiable information to third parties.
				The results of their study clearly show that the indirect leakage of PII via OSN identifiers to third-party aggregation servers is happening.
				OSNs in our study consistently demonstrate leakage of user identifier information to one or more third-parties via Request-URIs,
					Referer headers and cookies.
				In addition,
					two of the OSNs directly leak pieces of PII to third parties with one of the OSNs leaking zip code and email information about users that may not be even publicly available within the OSN itself.

			%Information aggregation
			\subsubsection{Information aggregation}

				When users authenticate to their favorite service messaging;
					generally,
					online social networks,
					they voluntarily release different types of personal information: name,
					screen name,
					telephone numbers,
					email addresses,
					locations,
					etc.
				Moreover,
					when users post messages in forums, blogs and webmails,
					they also disclose small pieces of private information.
				However,
					with the development of information retrieval techniques,
					private information of the same user may be collected from different sources and aggregated to reveal user privacy \cite{luo_protecting_2009}.
					
			%Inference attacks
			\subsubsection{Inference attacks}

				Aside from voluntary disclosure of explicit personal information,
					users information could be inferred from public information items.
				The privacy literature recognizes two types of private information leakage:
					identity leakage and attribute leakage,
					and identity leakage often leads to attribute leakage.
				Identity disclosure occurs when the adversary is able to determine the mapping from a record to a specific real-world entity (e.g. an individual).
				Attribute disclosure occurs when an adversary is able to determine the value of a user attribute that the user intended to stay private.

				%\cite{he_inferring_2005} study a type of indirect private information inference through social relations.
				%They notice that hidden attributes could be inferred from friends’ attributes using a Bayesian network.
				%They study the factors that impact inference accuracy,
				%	and suggest that selectively hiding social connections or friends’ attributes could help preserve privacy.
				%	
			%Privacy Threats in Published Social Network Data
			\subsubsection{Re-identification and De-anonymization attacks}

				When social network data sets are published for various legitimate reasons,
					user identity and some profile information are often removed to protect the user privacy.
				The privacy literature recognizes two types of privacy mechanisms:
					interactive and non-interactive.
				In the interactive mechanism,
					an adversary poses queries to a data-base and the database provider gives noisy answers.
				In the non-interactive setting,
					a data provider releases an anonymized version of the database to meet privacy concerns.
				Some of the well-known techniques for this purpose includes k-anonymity,
					l-diversity and t-closeness \cite{li_tcloseness_2017}.
				For instance,
					in a k-anonymized data set,
					an individual cannot be distinguished by attributes from other k-1 records.
				However,
					possibilities of \textbf{attribute re-identification attacks} on publicly available data sets have been studied in \cite{li_new_2014}.
				They show that user identities could be recovered from anonymized data sets.

				On the other hand,
					due to the nature of social network data,
					just anonymizing node attributes is not enough.
				Graph structure contains significant amount of information which could be utilized to hurt user privacy,
					i.e. \textbf{structural reidentification attacks}.
				A good survey on structural anonymization and re-identification attacks could be found at \cite{zhou_brief_2008}.
					most works show that node identities could be inferred through graph structure.

		\subsection{Privacy solutions}
			%Privacy as a Product: A Case Study in the m-Health Sector
			When an ICT user accesses a service,
				in particular,
				a messaging service,
				she has to share some information with the service provider,
				namely identity,
				type of service required,
				location,
				etc.
			Clearly,
				the shared information depends on the service but regardless of the exchanged information,
				to deal with the existing privacy issues, users have to choose between four main options:
			%	(1) trust the provider and send him all the required information,
			%	(2) individually protect the data sent to the untrusted provider,
			%	(3) collaborate with the provider to protect her data,
			%	or (4) collaborate with other users to protect their data from the provider.

			%Privacy based on trust
			\subsubsection{Privacy based on trust}
				This is probably the most common situation.
				Users tend to trust service providers because,
					they do not really have alternatives in many cases.
				Due to the fact that privacy is considered a right,
					most countries have regulations that oblige companies to guarantee the privacy of their users.
				Among this regulation,
					when users data are released to third parties they should be sanitized so as to guarantee users privacy \cite{chen_privacypreserving_2009}.
				%	statistical disclosure control techniques are generally used for sanitization.

			%Privacy based on Individual
			\subsubsection{Privacy based on Individual User Actions}\label{sssec:num2}
				Despite the legislation,
					users might prefer to keep some of their private information away from the service provider.
				In this case,
					we assume that the user cannot collaborate with the service provider.
				For example,
					in the case of sending a query to an Internet search engine such as Google or Yahoo.
				The user cannot initiate a \textbf{collaborative protocol} with the search engine,
					because the search engine is only able to receive and answer queries.

			%Privacy based on Collaboration with the Provider
			\subsubsection{Privacy based on Collaboration with the Provider}
				There are situations in which the service provider might collaborate with the user to protect her privacy by running \textbf{privacy-aware protocols.}
				TODO

			%Privacy based on Collaboration with other Users
			\subsubsection{Privacy based on Collaboration with other Users}
				This is an evolution of the proposals described in \ref{sssec:num2} in which users collaborate to protect their privacy.
				In this case,
					users do not want to trust the provider nor other third parties.
				TODO

	\section{Background}
		Quantifying and measuring privacy is very challenging,
			mainly because the definition of privacy is very subjective,
			each individual might have a different opinion about this concept.
		In our work, we present privacy challenges through three points of view: behavioral, social and technical.
	
		\subsection{Behavioral metrics}

		\subsection{Social metrics}

		\subsection{Technical metrics}

	\section{Approaches}

		\subsection{Behavioral Evaluation}
			
			%Identifying Spam Without Peeking at the Contents
			We consider two types of behavior models in this work,
				one based on typical behavior from a user perspective and one on typical behavior of a users' messages.
			Both of these models can be quantified into a probability score.

			%user perspective
			\subsubsection{User behavior}

			The user's behavior is modeled with respect to their typical service messaging usage,
				the frequency and type of messages received and sent,
				and the typical recipients with whom they exchange messages.
			Known as a behavior profile,
				this type of model is computed over some training period to learn how the user behaves within the messaging account.

			The measurements of the user's message behavior include the frequency of inbound/outbound message traffic,
				the specific times messages arrive and are sent,
				the "social cliques" of a user,
				and the user's response rates when replying to specific senders.

			%1
			Vidyalakshmi et al. \cite{vidyalakshmi_privacy_2015} proposed a privacy scoring using bezier curve.
			They present a framework for calculating a privacy score metric considering \textbf{users’ personal attitude towards privacy and communication information}.
			They focus on the rating of the user’s OSN friends based on their attitudes towards privacy,
				helping him to make an informed decision of sharing information with them.
			Bezier curve in its cubic form is used as it has to account for both privacy orientation and communication orientation of the user.

			\cite{alemany_estimation_2018}

			\cite{zhang_privacypreserving_2017}

			%2
			%\cite{li_algorithm_2016} identify the seed node set to spread the information to have a better trade-off of utility and privacy cost.

			%3
			\cite{liu_framework_2010} propose a model to compute a privacy score of a user.
			The privacy score increases based on how sensitive and visible a profile item is and can be used to adjust the privacy settings of friends.
			Their solution also focused on the privacy settings of users with respect to their profile items.
			They use Item Response Theory (IRT) to evaluate \textbf{sensitivity and visibility of attributes} when evaluating privacy scores.
			The authors definition of privacy score satisfies the following intuitive properties: the more sensitive information a user discloses,
				the higher his or her privacy risk.
			However,
				their approach do not support personalized privacy view over profile content for each individual in the social network.

			%%Game theory
			%Sallhammar et al. \cite{sallhammar_stochastic_2006} 
			%suggest the use of game theory as a method for computing the probabilities of expected attacker behavior in a quantitative stochastic model of security.
			%By viewing system states as elements in a stochastic game,
			%	they compute the probabilities of expected attacker behavior and model attacks as transitions between the system states.
			%Having solved the game,
			%	the expected attacker behavior is reflected in the transitions between the states in the system model,
			%	by weighting the transition rates according to probability distributions.
			%The proposed game model is based on a reward and cost concept and a detailed evaluation of how the reward and cost parameter influence the expected attacker behavior is included.
			%In the final step,
			%	continuous-time Markov chain (CTMC) is used to compute operational metrics of the system.

			%There are lots of applications that act as an expert system.
			%In such applications,
			%	the existing user’s preference and actions are stored,
			%	analyzed and used for giving relevant suggestions for naive users.
			%The skeptical part of using these applications are about how they handle the user’s data.
			%Many TPAs does not provide the required level of service that matches the user’s expectation,
			%	in which case the user tends to uninstall the application and choose a new application.

			%The user ends up sharing their information with many applications leaving silos of their personal information here and there,
			%	creating an opportunity for the advertising agents and data aggregators to correlate such information,
			%	and create a profile of the users.
			%Many users are not aware of the extent of information they share with the TPA \\cite{shanmughapriya\_alert\_2016} conducted a survey to record the users desirable level of data to be shared,
			%	and also captured the actual data shared by the user with TPA.


			%message perspective
			\subsubsection{Message behavior}

			The second type of behavior is specific to how spam behaves and how it appears in the message folder among normal messages.
			In general,
				spam messages can be easily detected because they appear anomalous with respect to the normal set of messages received and opened by the user.
			However, ...
			TODO
			
			\subsubsection{Discussion}

		\subsection{Social Evaluation}
			
			%Stalking Online: on User Privacy in Social Networks
			In online social networks,
				users are sometimes either oblivious about their privacy,
				or concerned but underestimate the privacy risks.
			% A Study of Online Social Network Privacy Via the TAPE Framework
			OSN service providers allow users to manage who can access which information and communication (e.g. Facebook and Google+).
			Researcher studied privacy protection from two directions:

			%first direction
			Along the first direction,
				fundamental changes to the current design of OSN were suggested to enhance users' privacy.
			Within this direction, Privacy by Design (PbD) is an important approach.
			For example,
				in \cite{baden_persona_2009}, Baden et al. proposed a new type of OSNs by using \textbf{attribute-based encryption} to hide user data,
				in which symmetric keys are used to encrypt messages and only the designated friend groups can decrypt the messages.
			In \cite{erkin_generating_2011},
				Erkin et al. proposed to use homomorphic encryption and \textbf{multi-party encryption techniques} to hide privacy-sensitive data from the service provider in a recommender system.

			%second direction
			The second direction is developing privacy protection tools based on existing OSNs.
			In our work,
				we focus on both direction to deal with current and future messaging services.

			In \cite{becker_measuring_2009},
				the authors propose to use the amount of information that can be inferred from social networks to quantify the privacy risks.
			PrivAware detect and report unintended information disclosures through quantifying privacy risk associated with friend relationship in OSNs.
			PrivAware employs inference model which is based on the fact that information about users can be inferred from their social graph.
			Privacy score is calculated as total \textbf{number of attributes visible to the third party applications} divided by total number of attributes per participant.
			The measured percentage is then mapped to a letter grade,
				where A score represents very few attributes being revealed and F score indicates that privacy risk to the threat of a malicious third party application is high.

			%Privometer
			The authors in \cite{talukder_privometer_2010} develop a tool,
				Privometer,
				to measure information leakage based on user profiles and their social graph.
			The leakage is indicated by a probability numerical value.
			Privometer is based on an augmented inference model where a potentially malicious application installed in the user’s friend profiles can access substantially more information.
			It operates in two modes.
			In online mode,
				inference is performed based on the friend’s profile where most frequently value is selected.
			In offline mode,
				it uses only immediate friends and "network-only Bayes classifier" to measure the \textbf{probability of inference}.
			The tool can suggest self sanitization actions based on the numerical value.

			%1
			\cite{wisniewski_profiling_2014} focuses on on the risk of new interactions from a privacy point of view.

			%2
			\cite{b.s._privacy_2015} proposed a privacy control framework for information dispersal on social network,
				they use the quadratic form of bezier curve to arrive at privacy scores for friends,
				they use the \textbf{communication information} for pre-sorting of friends which is lacking in \cite{vidyalakshmi_privacy_2015}.

			%3
			\textbf{Privacy Index (PIDX)} proposed in \cite{nepali_sonet_2013} is a measure of a user’s privacy exposure in a social network.
			PIDX is a numerical value between 0 and 100 with high value indicating high privacy risk in social networks.
			An \textbf{attribute’s privacy impact factor} is a ratio of its privacy impact to full privacy disclosure.
			Thus,
				an attribute’s privacy impact has a value between 0 and 1.
			They consider privacy impact factor for full privacy disclosure is 1.

			%5
			\cite{akcora_risks_2012} develop a graph-based approach and a risk model to learn \textbf{risk labels of strangers},
				the intuition of such an approach is that risky strangers are more likely to violate privacy constraints.

			%Privacy Wizard
			Fang and Le Fevre \cite{fang_privacy_2010} proposed a Privacy Wizard to help users grant privileges to their friends.
				the goal of this tool is to automatically configure a user’s privacy settings with minimal effort and interaction from the user.
			The wizard asks users to first assign privacy \textbf{labels to selected friends},
				and then uses this as input to construct a classifier which classifies friends based on their profiles and automatically assign privacy labels to the unlabeled friends.

			%Risk score
			In a similar vein,
				some studies \cite{maximilien_privacyasaservice_2009} propose a methodology for quantifying the risk posed by a user’s privacy settings.
			A risk score reveals to the user \textbf{how far his/her privacy settings are from those of other users}.
			It provides feedback regarding the state of his/her existing settings.
			However,
				it does not help the user refine his/her settings in order to achieve a more acceptable configuration.

			Trust metrics can be classified to two main categories: global and local trust metrics.
			%Local trust metrics
			\textbf{Local trust metrics},
				compute trust values that are dependent on the target user,
				Local trust metrics take into account the very personal and subjective views of the users,
				they predict different values of trust for every single user based on their own experience.
			%Global trust metrics
			\textbf{Global trust metrics (reputation)},
				on the other hand,
				predict a global reputation value for each node.

			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\subsubsection{Trust-based methods}
			
%				Yu and Singh The TRS model proposed by Yu and Singh [113] uses two information sources.
%				The first one contains the entity’s belief built as a result of its direct interaction with other entities.
%				The second one includes the testimonies of third-parties that can be beneficial in the absence of local ratings.
%				The model propose a trust network which tries to locate the most appropriate witnesses in a multi-agent system.
%				When a requesting entity wants to evaluate the trustworthiness of other entity ,
%					it sends a query to the neighbors of that entity asking for their perception regarding the target entity.
%				This model deals with malicious entities who deliberately disseminate misinformation through network.

%				REGRET REGRET [114] is a decentralized TRS designed for complex e-commerce environments 
%					where various types of entities with different social relationships play important roles.
%				It describes the social structure and relationships of the system through the ideas of cooperation,
%					competition,
%					and trade.
%				REGRET is based on a three-dimensional reputation model: 
%					Individual dimension or subjective reputation which calculates trust based on the direct impressions of an entity; social dimension,
%					which is divided into three types of reputation:
%					witness reputation,
%					neighborhood reputation,
%					and system reputation; and ontological dimension,
%					which adds the possibility of combining different aspects of reputation to calculate a complex one.
%				With the help of the ontological structure,
%					each entity is capable of determining the overall reputation of a particular entity 
%						by assigning the appropriate influence degree to each aspect related with its demand.
%				In addition to the reputation value,
%					REGRET gives a reliability measurement which reflects the confidence level of the produced reputation value.

%				2.3.10
%				Aberer and Despotovic The model proposed by Aberer and Despotovic [115] is one of the first TMS focused on P2P networks.
%				It is based on the complaints a peer receives from other peers in the network.
%				Although it improves network performance in stable environments,
%					due to the naive of its approach,
%					it is highly sensitive to malicious peers.
%				However,
%					it served as baseline to subsequent models in this area of application.

%				2.3.11
%				Esfandiary and Chandrasekharan The model proposed by Esfandiary and Chandrasekharan [116] uses to sources of information:
%					observation and interaction.
%				The processing of observed information is based on Bayesian learning.
%				The interaction is based on two main protocols:
%					an exploratory protocol and a query protocol.
%				In the exploratory protocol,
%					entities ask the other entities about known topics to evaluate their degree of trust.
%				Answers consistent with their knowledge yield to consider an entity as trusted.
%				In the query protocol,
%					entities ask for advice to previously trusted entities.
%				The authors claim that the calculation of this trust interval is equivalent to the problem of routing in a communication network and,
%					therefore,
%					known distributed algorithms used to solve that problem can be successfully applied to this situation.
%					
%				%grouping friends
%				Jones et al. (Jones and O’Neill, 2010) investigate users’ rationales for grouping friends,
%					for privacy management purposes,
%					within online social networks.
%				They identify six static criteria for grouping,
%					and evaluate the similarity of these criteria to the output of standard clustering techniques of users’ friends.
%				Their work supports our notion that standard clustering techniques can assist users in placing friends into groups analogous with privacy intentions.

%				%inference of private data from public one
%				In general,
%					semi-supervised learning has been used in social networks to infer users’ private information from the public labeled and unlabeled data 
%						using graph based semi-supervised learning,
%					e.g. (Javed and Shehab, 2012).

%				%Legitimacy scores
%				Lam et al. [32] proposed a learning approach for spam sender detection based on user interaction features (e.g.,
%					indegree/outdegree and interaction frequency) extracted from social networks constructed from email exchange logs.
%				Legitimacy scores are assigned to senders based on their likelihood of being a legitimate sender.

%				%Four security metrics
%				Lippmann et al. [23] have introduced meaningful security metrics that motivate effective improvements in network security.
%				They present a methodology for directly deriving security metrics from realistic mathematical models of adversarial behaviors.
%				Four security metrics are described that assess the risk from prevalent network threats.
%				These initial four metrics and additional ones should be added incrementally to a network to gradually improve overall security as scores drop.

%				The social trust is divided into the explicit social trust and implicit social trust[13].

				\paragraph{Explicit social trust (topographic)}
				
%					comes from the social network topology,
%						such as the graph similarity between peers,
%						the number of friends,
%						and \textbf{betweenness centrality},
%						etc.[14] For example,
%						a peer who has many friends can be estimated to have more benevolence and integrity than other peers.
%					Moreover,
%						peers trust their friends[15],
%						that is,
%						peers estimate the integrity of their friends higher than others.
%						
%					%social
%					DeBarr et al. [31] evaluated the use of social network analysis measures to improve the performance of a content filtering model.
%					They tried to detect spam by measuring the degree centrality of message relay agents and the average path length between senders and receivers.
%					They claimed that the messages from a promiscuous mail relay or messages with unusual path lengths that deviate from the average are more likely to be spam.

%					%clustering coefficient
%					Boykin et al. [3],[25] constructed a graph in which vertices represent email addresses and direct edges represent email interactions.
%					Emails are identified as spam,
%						valid,
%						or unknown based on the local clustering coefficient of the graph subcomponent.
%					This is based on the rationale that the social communication network of a normal node has a higher clustering coefficient than that of a spam node.

%					%social network analysis metrics
%					Herein,
%						we suggest that the accuracy of cluster-based systems can be improved by using social network analysis metrics.
%					Using one or more of these parameters may provide an amplified view of the AS by increasing granularity,
%						i.e. the sub-division of cluster information.

%					In [35],
%						authors introduce a new metric,
%						namely topological anonymity,
%						to quantify the level of anonymity using the topology properties of network graph. [44] introduces neighborhood attacks,
%						in which an adversary knows the neighborhood subgraph of the target,
%						and tries to reidentify the user from an anonymized network graph.
%					They propose an approach to further anonymize vertexes by modifying edges to construct isomorphic neighborhoods.

%					In [28],
%						authors define k-degree anonymity:
%						in a k-degree anonymized graph,
%						each node has the same degree with at least k other nodes.
%					They also efficiently propose k -degree anonymize graphs with minimal edge additions and deletions.

%					Moreover,
%						[15] models three types of adversary knowledge that could be used to re-identify vertexes from an anonymized social network graph.
%					They tackle the problem through graph generalization – dividing the graph into partitions and publishing summarized partition-level data.
%					K-Automorphism is introduced in [46] to defend against multiple attacks.

%					In [18],
%						authors propose a graph anonymization approach that maximally preserves original graph structure and statistical features.

%					Finally,
%						[31] considers social network as a weighted graph,
%						in which edge labels are also considered to be sensitive.
%					They propose to protect sensitive edge labels while keep certain global features of the graph.

%					Our proposed method is the first that leverages social distance and interest relationship from a social network to identify suspicious collusion 
%						and to reduce its influence on node reputation.

%					%infer private user information
%					Researchers [18, 19] demonstrated the ability to infer private user information using only friendship links,
%						group memberships and information shared by others publicly.
%						
%					%Inference problems
%					Previous studies of user privacy have focused on sensitive attribute inference problems,
%						where user private attributes are detected based on a mix of public profiles in the network,
%						friendship links and group membership information of private users [47].
%					Specifically,
%						within the friendship identification and inference attack [23],
%						a user might aim to infer private attributes of another user.

%					%Link prediction problem
%					The link prediction problem has also been applied to predict links between non-users of Facebook [20],
%						given only the link information towards non-members from the known network.
%					Additionally,
%						the network completion problem aims to infer both missing links and nodes,
%						where it has been shown that the missing part of the network can be inferred based only on the connectivity patterns of the observed part [5].

%					
%									risk labeling approach
%					In \cite{raad_privacy_2013},
%						the authors use risk labeling approach to tag users based on the community members’ feedback.
%					Active learning method is used to correctly label strangers.

				\paragraph{Implicit social trust}
					is measured by checking the communication history[16].
					Peers,
						who do not connect to each other in online social network,
						also can generate the social relationship.
					If they interact with each other through messengers or e-mail,
						then they have implicit social trust.
					The frequency and the duration of the communication affect to the implicit social trust.

					Abdul-Rahman and Hailes The trust model presented by Abdul-Rahman and Hailes \cite{abdul-rahman_supporting_2000} 
						is focused on virtual communities related to e-commerce and artificial autonomous agents.
					The model defines direct trust and recommender trust.
					Direct trust is the trust of an entity in another one based on direct experience.
					Whereas recommender trust is the trust of an entity in the ability of providing good recommendations.
					Trust can only have discrete labeled values,
						namely Very Trustworthy,
						Trustworthy,
						Untrustworthy,
						and,
						Very Untrustworthy for direct trust,
						and Very good,
						good,
						bad and,
						very bad for recommender trust.
					The difference between two ratings from different entities can be computed as semantic distance.
					This semantic distance can be used to adjust further recommendations.
					The combination of ratings is done as a weighted sum,
						where the weights depend on the recommender trust.

%%%%%%%%%%%%
				\paragraph{To-review}
				In trust networks users can ask to rate other users,
					this means that,
					a user can express her level of trust in another user she has interacted with,
					i.e. express a trust statement such as "Alice, trust Bob as 0.8 in [0,1]".
				The system can then aggregate all the trust statements in a single trust networks representing the relationships between users.
				Trust metrics are algorithms whose goal is to predict,
					based on the trust network,
					the trustworthiness of "unknown" users,
					i.e. users in which a certain user didn’t express a trust statement.
				Their aim is to reduce social complexity by suggesting how much an unknown user is trustworthy.
				%E-Mail Prioritization using Online Social Network Profile Distance
				Due to the increased use of OSNs,
					there is a growing number of studies that focus on using social network data for scoring messages in order to filter unwanted messages in messaging systems.
				The difference between each study has to do with the way the concept of trust is represented,
					computed and used.

				%Privacy and Social Capital in Online Social Networks
				The concept of trust is used to indicate the relationship between two entities.
				%Trust-involved access control in collaborative open social networks
				Trust in an entity is a commitment to an action based on a belief that the future actions of that entity will lead to a good outcome.
				There are three main properties of trust that are relevant to the development of algorithms for computing it \cite{wang_trustinvolved_2010},
					namely,
					transitivity,
					asymmetry,
					and personalization.
				%transitivity
				The primary property of trust that is used in our work is transitivity.
					if Alice highly trusts Bob,
					and Bob highly trusts Chuck,
					it does not always and exactly follow that Alice will highly trust Chuck.
				%asymmetry
				It is also important to note the asymmetry of trust,
					for two people involved in a relationship,
					trust is not necessarily identical in both directions.
				%personalization
				The third property of trust that is important in social networks is the personalization of trust,
					trust is inherently a personal opinion,
					two people often have very different opinions about the trustworthiness of the same person.

				%10
				%Protect_U & Privacy Wizard
				While much work has focused on tools for understanding and adjusting existing privacy settings,
					\textbf{Protect\_U} \cite{gandouz_protect_2012} uses machine learning techniques to recommend privacy settings based on a user’s personal data and trustworthy friends.
				Protect\_U analyzes user profile contents and ranks them according to four risk levels: Low Risk, Medium Risk, Risky and Critical.
				The system then suggests personalized recommendations to allow users to make their accounts safer.
				In order to achieve this,
					it draws upon two protection models: local and community-based.
				The first model uses the \textbf{user’s personal data} in order to suggest recommendations,
				The second model seeks the \textbf{user’s trustworthy friends} to encourage them to help improve the safety of their counter part’s account.

				%Social Market
				Despite the mole of work on social trust,
					Social Market is the first system to propose the use of \textbf{trust relationships} to build a decentralized interest-based marketplace.

				%9 TAPE
				Similarly,
					TAPE \cite{yongbozeng_study_2015} is the first attempt to combine explicit and implicit social networks into a single gossip protocol.
				Zeng et al. \cite{yongbozeng_study_2015} approaches the privacy quantification problem from a different angle.
				First,
					they consider \textbf{how likely a friend reveals others’ personal information},
					by computing the privacy trust score,
					which is a widely studied research problem \cite{gundecha_exploiting_2011}.
				Furthermore,
					the proposed work is related to \textbf{information diffusion in OSNs} such as \cite{fang_privacy_2010}.
				Finally,
				TAPE framework differs from other work,
					in considering information diffusion in the context of privacy protection,
					which requires different sets of features and considerations.

				%9
				%Zeng and Xing \cite{yongbo_zeng_study_2015}
				%	studied how individual users can expand their social networks by making trustful friends who will not leak their private IFs to unknown parties.

				%Ostra
				\textbf{Ostra} \cite{mislove_ostra_2008} utilizes trust relationship to thwart unwanted communication,
					where the number of a user’s trust relationships is used to limit the amount of unwanted communications he can produce.
				Ostra utilizes the existing trust relationship among users to charge the senders of unwanted messages and thus block spam.
				It relies on existing trust networks to connect senders and receivers via \textbf{chains of pair-wise trust relationship},
					they use a pair-wise link-based credit scheme to impose a cost on originator of unwanted communication.
				Unfortunatly,
					the scalability of this system stays uncertain as it employs a per-link credit scheme.

				%8
				Gundecha et al. \cite{gundecha_exploiting_2011} propose a feasible approach to the problem of identifying a user’s vulnerable friends on a social networking site.
				Vulnerability is somewhat contagious in this context.
				Their work differs from existing work addressing social networking privacy by introducing a \textbf{vulnerability-centered approach to a user} security on a social networking site.
				On most social networking sites,
					privacy related efforts have been concentrated on protecting individual attributes only.
				However,
					users are often vulnerable through community attributes.
				Unfriending vulnerable friends can help protect users against the security risks.

				%
				In \cite{zeng_trustaware_2014},
					Sun et al proposed a \textbf{probability trust model} that uses Beta function to address concatenation propagation and multi-path propagation of trust.

				%LENS: Leveraging Social Networking and Trust to Prevent Spam Transmission

				%SOAP
				\textbf{SOAP} \cite{li_soap_2011} presents a social network based personalized spam filter that integrates \textbf{social closeness},
					\textbf{user (dis)interest} and adaptive \textbf{trust} management into a Bayesian filter.
				SOAP proposed an email scoring mechanism based on an email network augmented with reputation ratings.
				An email is considered spam if the \textbf{reputation score of the email sender} is very low.
				Different from these social network based methods,
					SOAP focuses on personal interests in conjunction with social relationship closeness for spam detection.
				However,
					several issues with SOAP,
					including the intrinsic cost of initialization and continuous adaptation of social closeness (between sender and recipient),
					and social interests (of an individual) in the Bayesian filter,
					limit its usage.

				%6
				Relationship between \textbf{user’s trustworthiness} and privacy risk is presented in \cite{pandey_computing_2015}.

				%LENS
				Hameed \cite{hameed_lens_2011} proposed LENS,
					which extends the FoF network by adding trusted users from outside of the FoF networks to mitigate spam beyond social circles.
				Only emails to a recipient that have been \textbf{vouched by the trusted nodes} can be sent into the network.
				The authors proposed using social networks and trust and reputation systems to combat spam.
				In contrast,
					LENS can reject unwanted email traffic during the SMTP time.

				%SocialEmail
				SocialEmail \cite{tran_social_2010} considers the trust as an integral part of networking rather than working alongside of an existing communication system.
				SocialEmail leverages \textbf{social network trust paths} to rate the messages.
				The key feature of SocialEmail is that instead of directly connecting the sender and the recipient,
					messages are routed through existing friendship links.
				This gives each email recipient control over who can message him/her,
				In contrast,
					such social interaction-based methods are not sufficiently effective in dealing with legitimate emails from senders outside of the social network of the receiver.

				%Social interactions
				Social interactions (e.g.,
					\textbf{the exchange of messages between users}) have been suggested as an indicator of interpersonal tie strength \cite{xiang_modeling_2010}.
				As a consequence,
					an unsupervised model has been developed to estimate the \textbf{relationship strength} from the interaction activity and the user similarity in the OSN \cite{xiang_modeling_2010}.
				Although interaction-based methods leverage \textbf{social relationships} for extracting trust,
					the applications are not designed to be automated in the sense that the user must explicitly score other users,
					score messages,
					create whitelists or adjust the credits.
				%Furthermore,
				%	none of the aforementioned trust models are utilized to prioritize the E-mail senders.

				%access control model
				Fong \cite{fong_relationshipbased_2011} formulated this paradigm called a Relationship-Based Access Control (ReBAC) model,
					it bases authorization decisions on the \textbf{relationships between the resource owner and the resource accessor} in an OSN.
				However,
					most of these existing work could not model and analyze access control requirements with respect to collaborative authorization management of shared data in OSNs.

			%\paragraph{Trust networks and trust metrics}
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\subsubsection{Reputation-based methods}
			
%				%Trust-ware: A Methodology to Analyze, Design, and Secure Trust and Reputation Systems
%				Policy-based vs. reputation-based: there are two main approaches to evaluate trust in the literature,
%					namely: policy-based trust management and reputation-based trust management [100]–[103].

%				evaluate the peer’s trust using a system which aggregate the feedback of peers about their opponent’s integrity,benevolence and ability[9].

%				2.1) \textbf{Feedback based reputation} evaluation is the most popular method to assess the trustworthiness of peers in e-commerce services.
%				Paul et al.[10] studied the trust among peers in Ebay[11],
%					which is one of the famous e-commerce service.
%				They investigate the ability of a peer (e.g. the discount rate,
%					fast shipping) and the integrity of a peer (e.g. the quality of a product,
%					etc.) Mehmet et al.[12] studied the patterns of participation and exchange in Airbnb.
%				In detail,
%					they investigated how income,
%					race,
%					and education affect the economic activity on Airbnb and found that the education is a heavily influential factor.

%				Sporas In this model [110],
%					only the most recent rating between two entities is considered.
%				Besides,
%					entities with very high reputation values experience much smaller reputation changes after each update than entities with a low reputation.
%				Sporas incorporates a measure of the reliability of the entities’ reputation based on the standard deviation of reputation values.
%				It is robust to changes in the behavior of an entity and the reliability measure improves the usability of the reputation value.

%				Histos Histos [110] was designed as a response to the lack of personalization that Sporas reputation values have.
%				The model can deal with direct information and witness information.
%				In this case,
%					the reputation value is a subjective property assigned particularly by each individual (actually becoming a trust value).
%				The treatment of direct interaction in this reputation model is limited to the use of the most recent experience with the agent that is being evaluated.
%				The strength of the model relies on its use of witness information.
%				Ratings are represented as a directed graph.
%				The reputation of an agent at level n of the graph (with n > 0) is calculated recursively 
%					as a weighted mean of the rating values that entities in level X − 1 gave to that entity.
%				A drawback of this model is the use of the reputation value assigned to a witness also as a measure of its reliability.

%				Schillo et al.
%				This trust model [112] is oriented to scenarios where the result of an interaction between two entities is good or bad.
%				This value is a subjective property assigned particularly by each individual and it does not depend on the context.
%				It is based on Prisoner’s dilemma set of games [42] with a partner selection phase.
%				Each agent receives the results of the game it has played plus the information about the games played by a subset of all players (its neighbors).
%				The model is based on probability theory that uses the number of times that the target entity was honest.
%				Besides,
%					an entity can get information from other agents that it has met before.
%				The answer of witnesses to a query is the set of observed experiences,
%					and not a summary of them.
%				The model assumes that witnesses never lie but that can hide (positive) information in order to make other agents appear less trustworthy.

%				2.3.12
%				Afras The main characteristic of this model [117] is the use of fuzzy sets to represent reputation values.
%				Once a new fuzzy set that shows the degree of satisfaction of the latest interaction with a given entity is calculated,
%					the old reputation value and the new satisfaction value are aggregated using a weighted aggregation.
%				Besides,
%					the weights of this aggregation are calculated from a single value that they call remembrance or memory.
%				Recommendations from other entities are aggregated directly with the direct experiences.
%				If they come from a recommender with a high reputation,
%					they have the same degree of reliability as a direct experience.

%				2.3.13
%				Azzedin and Maheswaran Azzedin and Maheswaran [118] propose a TMS based on a combination 
%					of direct trust and reputation by weighting the two components differently.
%				It gives more weight to the direct trust.
%				This direct trust o trust level is calculated based on past experiences and is given for a specific context.
%				Calculation of reputation values is based on a neural network approach.

%				2.3.14
%				Carter et al.
%				Carter et al. propose a complex but novel TMS [119] based on the concept of roles.
%				They claim that the reputation of an agent is based on the degree of fulfillment of roles ascribed to it by the society.
%				Therefore,
%					if society judges that an entity has met its roles,
%					it will be rated with a positive reputation.
%				They define five main roles:
%					social information provider,
%					interactivity role,
%					content provider,
%					administrative feedback,
%					and longevity role.
%				All of them oriented to promote a informationsharing society.
%				Finally,
%					the entity’s overall reputation is calculated as a weighted aggregation of the degree of fulfillment of each role.
%				These weights are dependent on the specific society,
%					and the society has a centralized mechanism that calculate and disseminate these reputation values,
%					and monitors the society.

%				2.3.19
%				Reputation Quotient The Reputation Quotient [48],
%					[49] tries to obtain data on a company’s reputation from the point of view of the general public,
%					customers,
%					employees,
%					suppliers and investors.
%				The model measures perceptions of an organization in terms of social expectations of dimensions such as products and services,
%					vision and leadership,
%					work place environment and social responsibility.

%				2.3.20
%				FIRE In the FIRE model [124],
%					trust is evaluated based on a different number of information sources:
%					Interaction Trust (IT),
%					that is built from the self experience of an entity with the other entities; 
%						Witness Reputation (WR) that is based on the direct observation of an entity’s behavior by some third-party agent; Certified Reputation (CR),
%					one of the novelties in the FIRE model,
%					that consists of certified references disclosed by third-party agents; and Role-based Trust (RT),
%					which models the trust across predefined role-based relationships between two entities.
%				The significance of each component in the trust calculation algorithm is adjusted according to changes in the environment.
%				Each component owns a trust algorithm with relevant rating weight function to determine the quality of ratings tailored to its responsibility.
%				Thus,
%					the weight algorithm for IT in based on the age of ratings whereas WR and CR have to take the credibility of rating into account as well.
%				Credibility is based on a filtering mechanism that identifies inaccurate reports and penalizes misbehaving entities.

%				2.3.21
%				PeerTrust PeerTrust is a trust model [125] with specific characteristics for peer-to-peer e-commerce communities.
%				It uses several factors to calculate the reputation values of the entities (peers): 
%					feedback which is a judgment of other peers regarding target peer; feedback scope,
%					such as the amount of transactions the peer experienced with others; 
%						a credibility factor to evaluate the honesty of feedback sources; 
%						transaction context factor such as time and size of transactions; and community context factor.
%				This model proposes an innovative composite trust metric that incorporates the 
%					described parameters to enhance accuracy and reliability of predicted trustworthiness.

%				2.3.23
%				SPIRIT The SPIRIT model [126] can be applied to survey Corporate Reputation from the perspective of customers,
%					employees,
%					suppliers,
%					investors and community groups.
%				It measures Corporate Reputation in terms of the experience,
%					feelings and intentions of stakeholders towards a business.

%				2.3.32
%				Distributed Reputation-based Beacon Trust System 
%					This model was presented by Srinivasan and Teitelbaum [136] 
%					It is focus on keep the network performance through detecting malicious beacon nodes.
%				Each beacon node monitors and provides information about malfunction behaviors of beacons that are one hope from them.
%				Therefore,
%					nodes can choose to trust in a specific beacon based on this information.
%				They use a voting approach to calculate this trust value.
%				The voting process is based on the reputation tables of each node,
%					that are generated by processing the reputation tables of the close beacon nodes.

%				2.3.30
%				Bayesian Reputation System Bayesian Reputation System (BRS) was proposed by Jøsang et al [132].
%				It supports both binomial and multinomial rating models to allow rating supply happening in different levels.
%				Mathematically,
%					multinomial BRS is based on computing reputation scores by statistically updating the Dirichlet Probability Density Function (PDF) [133],
%					[134].
%				In this context,
%					entities are allowed to rate other entities within any level from a set of predefined ratings levels.
%				In contrast,
%					in binomial BRS which is based on Beta Distribution,
%					the agents can only provide binary ratings for the others.
%				Both systems use the same principle to compute the expected reputation scores:
%					combining previous interaction records with new ratings.
%				Besides,
%					in order to deal with dynamism in the participant’s behavior,
%					BRS provides a longevity factor which determines the expiry time of the old ratings and gives greater weight to more recent ones.

%				2.3.31
%				Reputation-based Framework for High Integrity Sensor Networks RFSN was proposed by Ganeriwal and Srivastava [135].
%				It classifies the actions as cooperative and non-cooperative.
%				It uses direct and indirect information,
%					and the behavior of the node is decided upon a global threshold.
%				If the trust value is below this threshold the node in considered a non-cooperative node,
%					and any contact from the rest of the network nodes is avoided.
%				The network propagates only positive reputation information in order to avoid some WSN specific attacks such as bad-mouthing attacks.
%				Finally,
%					an aging factor in introduced to give more weight to recent interactions.

%				2.3.26
%				TRAVOS The TRAVOS (Trust and Reputation model for Agent-based Virtual Organizations) 
%					system [128] is developed to ensure high-quality interaction between the entities of a large open system.
%				It uses two information sources to calculate the reputation of the entities:
%					Direct Interaction and Witness Observation.
%				However,
%					this model relies greatly on its direct experiences and refuses to combine others’ opinions unless they are really required.
%				For this purpose,
%					it provides a confidence metric to determine whether the direct experiences are sufficient to make an acceptable review to a particular entity or not.
%				If not,
%					it disseminates queries to obtain additional observations from other witnesses who claim to have had previous interaction with that certain entity.

%				In Trust and Reputation Systems,
%					network users try to calculate the reliability and trustworthiness of other users based on their own experiences and that of others.
%				Boykin et al. [3] proposed an automatic email ranking system based on trust and reputation algorithms.
%				MailRank [4] is a spam detection system based on trust and reputation scheme to classify email addresses

%				%previous direct interaction
%				At the same time,
%					another team of researchers suggested a model where trust is measured from the performance of previous direct interaction with a user
%						as well as the direct interaction and asking trusted users to recommend other users [Esfandiari and Chandrasekharan (2001)].

%				%direct experiences
%				In one proposed model [Yu and Singh (2001)],
%					the trustworthiness of a user is calculated based on direct experience with that user as well as the belief rating of her neighbors.

%				%peer voting
%				Both XRep [26] and X2 Rep [27] extend the work in [25] by additionally computing object reputations based on weighted peer voting.

%				%reputation values *********
%				Moreton and Twigg [28] proposed the Stamp algorithm,
%					where peers issue stamps as virtual currency for each interaction,
%					and the value of each peer’s stamps is maintained by exchange rates that act as reputation values.

%				%experience
%				The works in [13],[14],[15] let a peer evaluate others’ trustworthiness based on its experience.
%				Sorcery [16] lets clients utilize the overlapping voting histories of both their 
%					friends and the content providers to judge whether a content provider is a colluder.

%%%%%%%%%%%%%%%%%

				\paragraph{To-review}
				Trust and reputation concepts are used in order to preserve user’s privacy while increasing their social capital in OSNs.
				%Privacy and Social Capital in Online Social Networks
				Reputation concept is used to refer to a more general sense of trust towards a particular entity based on opinions of multiple entities.

				%Social network analysis for cluster-based IP spam reputation
				%Reputation-based systems.
				A reputation system collects,
					distributes and aggregates feedback about participants’ past behavior.
				Such systems help people decide whom to trust,
					encourage trustworthy behavior and deter participation by those who are unskilled or dishonest.
				%Real-time reputation-based systems.
				Various applications use real-time reputation-based systems,
					including online markets and anti-spam solutions.
				Anti-spam reputation systems generate a score,
					or rating,
					for each incoming message or IP,
					based on analysis of various parameters: message volume,
					type of traffic (e.g. sporadic vs continuous),
					rate of user complaint reports,
					feedback from spam traps,
					compliance with regulations,
					etc.
				This aggregated information,
					collected over time,
					forms the reputation of the sender.

				%SNARE
				SNARE \cite{hao_detecting_2009} infers the reputation of a message sender based on \textbf{network-level features},
					(e.g. \textbf{geodesic distance between sender and recipient, number of recipients}).
				The most influential feature in the system was the AS number of the sender.
				Using an automated reputation engine,
					SNARE classifies message senders as spammers or legitimate with about a 70\% detection rate for less than a 0.3\% false positive rate,
					without looking at the contents of a message.
				However,
					lacking authentication and non-repudiation in standard trust and reputation solution make these solutions be subject to identity spoofing,
					false accusation and collusion attacks.
				Further,
					these solutions consume extra valuable resources of messaging servers on message reception and filtering.

				%TrustMail
				In TrustMail,
					which is a prototype E-mail client,
					an approach is proposed that makes use of OSN reputation ratings to attribute different scores to E-mails \cite{golbeck_reputation_2004}.
				The actual benefit of this system is that,
					by using \textbf{social network data},
					it identifies potentially important and relevant messages even if the recipient does not know the sender \cite{golbeck_reputation_2004}.

				%Cluster-based reputation
				Qian et al. \cite{qian_networklevel_2010} addressed this issue by presenting a clustering technique that refines \textbf{AS-based and BGP prefix-based clusters}.
				The authors combined \textbf{BGP and DNS information} to identify a cluster of IP addresses within the same administrative boundary,
					and thus constructed the reputation for an entire cluster.
				This cluster-based reputation system allowed more accurate identification of the reputation of previously unknown IP addresses,
					and reduced the false negative rate by 50 percent compared to blacklists,
					without increasing the false-positive rate \cite{qian_networklevel_2010}.

				%2 multi-agent based reputation model
				Paradesi et al. \cite{paradesi_integrating_2009} adopted a multi-agent based reputation model to define \textbf{trustworthiness of services}.
				Moreover,
					they developed a trust framework to derive trust for a composite service from trust model of component services.

			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\subsubsection{Collaborative-based methods}

			%Trust-involved access control in collaborative open social networks
			%collaborative community

			The trust value assigned to a person in previous work is estimated on the basis of his/her reputation,
				which can be assessed taking into account the person behaviour.
			Indeed,
				it is a matter of fact that people assign to a person with unfair behaviour a bad reputation and,
				as a consequence,
				a low level of trust.
			A possible solution is to estimate the trust level to be assigned to a user in a collaborative community on the basis of his/her reputation,
				given by his/her behavior with regards to all the other users in the community.

			%Detecting and Resolving Privacy Conflicts for collaborative Data Sharing in Online Social Networks
			Hu et al. \cite{hu_detecting_2011} propose an approach to enable \textbf{collaborative privacy management} of shared data in OSNs.
			In particular,
				they provide a systematic mechanism to identify and resolve privacy conflicts for collaborative data sharing.
			their conflict resolution indicates a trade-off between privacy protection and data sharing by quantifying privacy risk and sharing loss

			%Interdependent Privacy: Let Me Share Your Data
			%collaborative
			Dealing with \textbf{collaborative information sharing},
				Hu et al. \cite{biczok_interdependent_2013} proposed a method to detect and resolve privacy conflicts.

			%COAT : Collaborative Outgoing Anti-Spam Technique
			%community collaboration
			The collaborative systems, called \textbf{COAT} \cite{ahmad_coat_2012}, do not rely upon semantic analysis but on the community to identify spam messages.
			Once a message is tagged as spam by one SMTP server,
				the signature of that message is transmitted to all other SMTP servers.
			This class requires the collaboration of multiple SMTP servers to implement the system.

			%SocialFilter
			\textbf{SocialFilter} \cite{yang_socialfilter_2009} proposes a collaborative spam mitigation system that uses social trust embedded in OSN to asses the trustworthiness of Spam reporter.
			The spammer reports from the SocialFilter nodes are stored at a centralized repository that computes the trust values of the reports and identifies spammers based on IP addresses.
			However,
				the SocialFilter’s effectiveness is doubtful as spammers may use dynamic IPs.

			%collective privacy management
			Squicciarini et al. \cite{hu_detecting_2011} proposed a solution for collective privacy management for photo sharing in OSNs.
			This work considered the privacy control of a content that is co-owned by multiple users in an OSN,
				such that each co-owner may separately specify her/his own privacy preference for the shared content.
			The Clarke-Tax mechanism was adopted to enable the collective enforcement for shared content.
			Game theory was applied to evaluate the scheme.
			However,
				a general drawback of this solution is the usability issue,
				as it could be very hard for ordinary OSN users to comprehend the Clarke-Tax mechanism and specify appropriate bid values for auctions.
			In addition,
				the auction process adopted in their approach indicates only the winning bids could determine who was able to access the data,
				instead of accommodating all stakeholders’ privacy preferences.
			
%%%%%%%%%%%%%

			\subsubsection{Discussion}

		\subsection{Technical-based methods (Policy)}
		
			evaluate the trust value whether the credentials of trustee match up to the policy which ruled by the trustor or not.

%			2.3.18
%			Shand et al. propose a TMS to facilitate secure collaboration in pervasive computer systems [123].
%			This is one of the first TMS that tries to overcome the performance of the policy-based trust models.
%			When applying policy-based TMS to very dynamic systems the policies are too strict to efficiently handle topology changing networks,
%				nodes entering and exiting from the system,
%				etc.
%			This model is based on the existence of some generic-policies and some local or nodespecific policies that are combined in order to calculate trust values.

%			2.3.27
%			Crosby and Pissinou Crosby and Pissinou proposed a mechanism for the election of cluster heads in WSN based on a distributed trust-base framework [129].
%			It is based on the use of direct and indirect information coming from previously trusted nodes.
%			Trust is modelled using a feature extraction and weighting mechanism of some essential parameters from the communication protocol:
%				packet drop rate,
%				data packets and control packets.
%			Each node stores a local trust table for all its neighbor nodes.
%			Cluster nodes can ask for these tables.
%			Therefore,
%				they can update their reputation values over other cluster head nodes to improve their routing path policies.

%			In [7],
%				the authors conduct a thorough study and analysis of the privacy practices and policies of various online social networking sites.
%			45 different sites are studied with 260 features to evaluate them.
%			The work in [7] does not measure the privacy scores of an individual user.
%			However,
%				it presents the concept of the privacy ranking of the websites which can allow the users to make their decisions on the basis of website privacy scores.

%			%collaborative filtering
%			Finally,
%				collaborative filtering is popular in recommender systems (Su and Khoshgoftaar, 2009),
%				and has been recently adopted for policy recommendations (Shehab and Touati, 2012).

			%collaborative access control
			In contrast,
				we propose a formal model to support the multiparty access control for OSNs,
				along with a policy specification scheme and a simple but flexible conflict resolution 
					mechanism to particularly enable collaborative data sharing in Google+.

			Nowadays, the Web converged over two main protocols,
				namely HTTP/HTTPS and SMTP/SMTPS
			Beside these,
				DNS still has a central role for reaching almost any Web server.
			In this section we focus on SMTP privacy,
				the next section relies on HTTP privacy.

			%%An Effective Defense Against Email Spam Laundering
			Many anti-spam techniques have been proposed and deployed to counter email Spam from different perspectives.
			Based on the placement of anti-Spam mechanisms,
				these techniques can be divided into two main categories: recipient-oriented and sender-oriented.

			\subsubsection{Recipient-oriented Techniques}

				This class of techniques either
					(1) block/delay email Spam from reaching the recipient’s mailbox or
					(2) remove/mark Spam in the recipient’s mailbox.
				Due to the flourish of techniques in this category,
					we further divide them into content-based and non-content-based sub-categories.

				\paragraph{Content-based Techniques}
				
									
				%Identifying Spam Without Peeking at the Contents
				Currently available solutions attempt to filter out spam based on analyzing the contents of the message and calculating a score to indicate the 'spami-ness' of the message.

				The techniques in this sub-category detect and filter spam by analyzing the content of received messages,
					including both message header and message body.
					
				%%Measurement and evaluation of a real world deployment of a challenge-response spam filter

				Most of the spam blocking techniques proposed by previous research fall into two categories:
					content-based and sender-based filtering.

%				%Content-based spam filtering techniques
%				Content-based spam filtering techniques rely on signatures and classification algorithms applied to the emails content [32, 14, 19, 15, 33].
%				Although content-based filters were initially very effective and provided an acceptable defense against spam [27],
%					with the evolution of the spam sophistication they became less effective over time.

				\textbf{Email address filters:} Email address filters are simply whitelists or blacklists.
				Whitelists consist of all acceptable email addresses and blacklists are the opposite.
				Blacklists can be easily broken when spammers forge new email addresses,
					but using whitelists alone makes the world enclosed.

				\textbf{Heuristic filters:} The features that are rare in normal messages but appear frequently in spam,
					such as nonexisting domain names and spam-related keywords,
					can be used to distinguish spam from normal email.

				\textbf{Machine learning based filters:} Since spam detection can be converted into the problem of text classification,
					many content-based filters utilize machine-learning algorithms for filtering spam.
				As these filters can adapt their classification engines with the change of message content,
					they outperform heuristic filters.

				\paragraph{Non-content-based Techniques}
				The techniques in this sub-category use non-content spam characteristics,
					such as source IP address,
					message sending rate,
					and violation of SMTP standards,
					to detect email spam.

				\textbf{DNSBLs:} DNSBLs are distributed blacklists,
					which record IP addresses of spam sources and are accessed via DNS queries.
				When an SMTP connection is being established,
					the receiving MTA (Mail Transfer Agent) can verify the sending machine’s IP address by querying the subscribed DNSBL.
				Mail server records the number and frequency of the same email sent to multiple destinations from specific IP addresses.
				If the number and frequency exceed thresholds,
					the node with the specific IP address is blocked.
				Even DNSBLs have been widely used,
					their effectiveness and responsiveness \cite{jung_empirical_2004, ramachandran_can_2006} are still under study.

				\textbf{MARID:} MARID (MTA Authorization Records In DNS) is a class of techniques to counter forged email addresses by enforcing sender authentication.
				MARID is also based on DNS and can be seen as a distributed whitelist of authorized MTAs.
				Multiple MARID drafts have been proposed,
					some of them (SPF and DKIM) are deployed in real world \cite{spf:_2018, BibEntry2014Dec}.
					PGP and S/MIME are also

				\textbf{Challenge-Response (CR):} CR is used to keep the merit of whitelist without losing important messages.
				To add a sender email address in the whitelist,
					senders are requested a challenge that needs to be solved by a human being.
				After a proper response is received,
					the sender’s address can be added into the whitelist.

				\textbf{Cryptographic:}
				Pretty Good Privacy (PGP) \cite{pgpaghiles2007} and S/MIME are both cryptographic approaches that sign the message body using public-key cryptography and append the signature in the body.
				In PGP,
					Keys are stored in end-user key rings or in public key-servers.
				Key management uses a peer-to-peer web of trust architecture.
				Whereas in S/MIME,
					management follows a hierarchical model similar to SSL and keys are signed by a certificate authority.

				\textbf{Delaying:} As a variation of rate limiting,
					delaying is triggered by an unusually high sending rate.
				Most delaying mechanisms are applied at receiving MTAs.

			\subsubsection{Sender-oriented techniques}

				To effectively deny spam at the source,
					ISPs and ESPs (Email Service Providers) have taken various measures to manage the usage of email services.
				For example,
					message submission protocol \cite{BibEntry1998Dec} has been proposed to replace SMTP,
					when a message is submitted from an MUA (Mail User Agent) to its MTA.

				%COAT
				The proposed work in \cite{ahmad_coat_2012} differs from the other techniques in a way that all of them categorize mail messages at receiver side,
					whereas COAT works at the sender side and reduces outgoing spam rather than inbox spam.
				%We have hardly found any work in literature about saving the Internet bandwidth and resource wastage by spam.

				\textbf{Cost-based approaches:} Borrowing the idea of postage from regular mail systems,
					many cost-based techniques attempt to shift the cost of thwarting spam from receiver side to sender side.

				All these techniques assume that the average email cost for a normal user is trivial and negligible,
					but the accumulative charge for a spammer will be high enough to drive them out of business.

				Cost concept may have different forms in different proposals.
				Bonded Sender \cite{BibEntry2018May} advocates associating email with real money.
				%Both centralized \cite{krishnamurthy_shred_2004} and distributed \cite{walfish_distributed_2006} cost enforcement mechanisms have also been proposed.

			\subsubsection{Technical HTTP}

				%Privacy leakage vs. Protection measures: the growing disconnect
				In this section we enumerate existing privacy protection measures available to users and one new protection proposal \cite{mayer-do-not-track-00}.

				%Blocking requests to targeted third parties
				\textbf{Blocking requests to targeted third parties:}
				This block measure includes using an advertisement blocking tool (AdBlock Plus \cite{adblockplus}) to syntactically block selected third parties via server/domain name.
				Another measure blockhidden \cite{krishnamurthy_privacy_2009} determines the true source of hidden third-parties by examining their authoritative DNS servers.

				%Refusing cookies to prevent tracking
				\textbf{Refusing cookies to prevent tracking:}
				Browsers can be set to refuse all cookies (nocook) or just third-party cookies (no3rdcook).

				%Disabling script execution
				\textbf{Disabling script execution:}
				JavaScript execution can be disabled (nojs) either permanently via the browser or selectively via a tool such as NoScript \cite{NoScript}.

				%Filtering protocol headers
				\textbf{Filtering protocol headers:}
				This is done via extensions or at an intermediary and includes the referrer measure available in some browsers to modify or remove the Referer header in an HTTP request.

				%Anonymizing the user and user action
				\textbf{Anonymizing the user and user actions:} One such anon measure is anonymizing user’s IP address via an anonymizing proxy or by using Tor.

				%Do-Not-Track HTTP header proposal
				\textbf{Do-Not-Track HTTP header proposal:}
				Researchers proposed,
					in early 2010,
					that browsers add a HTTP DoNot-Track-Header (DNT-Header) \cite{mayer-do-not-track-00} to allow users to express their interest in not being tracked by any aggregator or ad network.
				However,
					the extent to which third parties would honor such a header is unknown.
				
			\subsubsection{Discussion}

		\subsection{General Discussion}

	\section{Conclusion}
	
		%\section{Summary of Thesis Achievements}
		%Summary.
		%\section{Applications}
		%Applications.
		%\section{Future Work}
		%Future Work.
	
