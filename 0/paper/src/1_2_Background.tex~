\section{Background}
\label{sec:background}

	%Mean privacy: A metric for security of computer systems
	The challenging area of quantitative security evaluation has been received much more attention in recent years.
	In this section,
		we want to provide a general overview of the most important methods worked out in this important area of security analysis.
		
		%Stalking Online: on User Privacy in Social Networks
	When users' data and particularly users' messages are shared with other users or third parties for various legitimate reasons,
		user identity and some profile attributes are often published to increase the QoS of messaging services.
	The privacy literature recognizes two types of private information disclosure:
		attribute, identity and structural disclosure.
	Attribute disclosure occurs when an adversary is able to determine the value of a user attribute that the user intended to stay private.
	Identity disclosure occurs when the adversary is able to determine the mapping from a record to a specific real-world entity.
	Structural disclosure occurs when the adversary is able to determine the relationship between two specific real-world entity.
	
	\subsection{Privacy Threats}
		%Four types of privacy threats have been discovered in the literature:
		\subsubsection{Attribute reidentification attacks}
			
			When users authenticate to their favorite service messaging;
				generally,
				online social networks,
				they voluntarily release different types of personal information: name,
				screen name,
				telephone numbers,
				email addresses,
				locations,
				etc.
			Moreover,
				when users post messages in forums, blogs and webmails,
				they also disclose small pieces of private information:
					hobbies, religions, political and economical interests.
			In attribute reidentification attacks,
				an adversary poses queries to a data-base and the database provider gives noisy answers.
			
		\subsubsection{Identity reidentification attacks}
			In the identity reidentification setting,
				a data provider releases an anonymized version of the database to meet privacy concerns.
			Some of the well-known techniques for this purpose includes k-anonymity, l-diversity.
			For instance,
				in a k-anonymized data set,
				an individual cannot be distinguished by attributes from other k-1 records.
			However,
				possibilities of identity reidentification attacks on publicly available data sets have been studied in \cite{li_new_2014}.
			They show that user identities could be recovered from anonymized data sets.
			
			\cite{krishnamurthy_leakage_2010} shows that online social networks and applications leak users’ personally identifiable information to third parties.
			The results of their study clearly show that the indirect leakage of PII via OSN identifiers to third-party aggregation servers is happening.
			OSNs in our study consistently demonstrate leakage of user identifier information to one or more third-parties via Request-URIs,
				Referer headers and cookies.
			In addition,
				two of the OSNs directly leak pieces of PII to third parties with one of the OSNs leaking zip code and email information about users 
					that may not be even publicly available within the OSN itself.
			
		\subsubsection{Structural reidentification attacks}
			Despite from identity and attribute reidentification attacks,
				due to the nature of messaging data,
				just anonymizing node identities and attributes is not enough.
			Graph structure contains significant amount of information which could be exploited to hurt user privacy,
				i.e. structural reidentification attacks.
			A well-known techniques for this purpose is t-closeness \cite{li_tcloseness_2017}.
			A good survey on structural anonymization and reidentification attacks could be found at \cite{zhou_brief_2008}.
				most works show that node identities could be inferred through graph structure.
			
			\cite{pal_trust_2017} study a type of indirect private information inference through social relations.
			They notice that hidden attributes could be inferred from friends’ attributes using a Bayesian network.
			They study the factors that impact inference accuracy,
				and suggest that selectively hiding social connections or friends’ attributes could help preserve privacy.
			
			When users share information with trusted social network community.
				they implicitly assume that their information shared through messages would stay within the community destination.
			However,
				this assumption is not always valid.
			For instance,
				messages sent to an email-based social network may be stored at a repository and consequently visible to the public,
				malicious users and applications may follow people through social networks,
				add-ons and third parties may access users’ private information,
				etc.

	%			\begin{figure}
	%				\includegraphics[width=\columnwidth]{levels.png}
	%				\caption{Privacy levels threats \label{fig:levels}}
	%			\end{figure}

	We have seen that the current state of messaging services privacy is bad.
	Our work shows us that research is ongoing to increase the privacy of users in the future.
	This motivates further research in the area of privacy and security analysis.



