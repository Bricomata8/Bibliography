\section{Approaches}
\label{sec:approaches}
	
	\subsection{Privacy Protections}
		In any online social network, users are generating a massive amount of data.
		In this section we focus on data which is created by users with the intent of communication.
		This includes blog or micro-blog posts,
			profile information,
			instant message text,
			and so on.
		In modern service messaging,
			users can sign up for an account and become a member.
		The only requirements are a valid email address and the ability to solve a re-captcha.
%		This means the social network provider must provide the users some way to specify who they trust and who they don’t trust.
	
		As long as users are publishing content in an online social network,
			they must be careful about who has access to the content of their messages and who has access to their profile.
		Fortunately,
			practical levels of access can clearly be divided into free categories:
			third party applications,
			social network users,
			and the provider.
		These subsections outline some of the significant research in protecting user data from each of these parties.
		
		\subsubsection{Protection From Applications}
		
			Social network applications are web pages that are written by some third party that have API access to social graph data,
				this data are expected to be exclusively accessible by the messaging service provider.
			Third party applications could get access to users' sensitive information.
			In order to avoid such behavior,
				Users are asked what content an application will attempt to access.
			
			In \cite{fredrikson_repriv_2011}, Fredrikson et al. explore the idea of harvesting information about users that is stored in the browser.
			This idea is very similar to the current implementation of "my location" in many popular browsers.
			For example,
				if the provider wants to know the user’s location,
				the browser has this information and the user is prompted to allow the browser to give the site this information.
			This sort of system,
				are very convenient because it gives consideration to final users.
			However, 
				notification about what is being shared and the consequences of sharing such data are not yet known.
			
		\subsubsection{Protection From Other Users}
		
			\paragraph{Privacy policy conflicts}\hfill
			
				Many online social network providers allow the users of their social network to make privacy settings.
				This is the user’s first line of defense against malicious users.
				Privacy settings protect users information to be viewed by users that are directly or indirectly linked in the social graph.
				For example,
					in Facebook, two users that are directly linked can view more information on each other’s profiles.

				Some of these privacy setting schemes are simple and straightforward.
				For example,
					Twitter allows users to make tweets "private" which are only visible to their followers.
				This privacy setting allow users to lock undesirable audience.
				However,
					privacy settings of popular online social network providers like Facebook and LinkedIn are complex,
					users consequently don't take time to understand and configure it.
				These privacy settings must be carefully weighed and experimented in order to select the appropriate audience.
				
				We begin by analyzing the impact of choosing the most restrictive or most private settings possible.
%				In fact,
%					even if users can fully understand their privacy settings they may not be protected from other users in an online social network.
				In \cite{stutzman_friends_2010},
					Stutzman and Kramer-Duffield explore the implications of making a profile "friends only" on the Facebook online social network.
				This means that only directly connected users can view any content the user has posted.
				The researchers conclude that while such a configuration is effective against other users on the online social network,
					very few users actually utilize it.
				In another hand,
					this researcher points out that this is not a strong defense against a many other attacks from different perspectives including,
					sybil accounts,
					advertisers,
					applications,
					and the online social network provider itself.
				Additionally,
					it doesn't protect prominent features of the online social network like friend discovery.
				
				Rather than simply lock down one’s own profile,
					several papers have been written that try to make existing privacy settings easier to understand for the user.
				In \cite{lipford_understanding_2009},
					the authors attempt to help users better understand their privacy settings,
						by allowing users to view their own profile from the perspective of other users.
				This paper help users understand the privacy settings that they’ve made.
				However,
					it does not help protect them from various more subtle privacy issues such as neighborhood attacks,
						and network inference techniques.
				These techniques are out of the scope of this section and are covered in better detail next sections.
				
				In an attempt to improve upon the situation,
					\cite{fang_privacy_2010} design a privacy wizard which allow users to specify their custom privacy intentions.
				The key observation is that users categorize their relations to other users as communities.
				For example,
					users think of groups of relations such as co-workers,
					friends,
					classmates,
					etc.
				Users can create an arbitrary number of communities in order to allow proper access to the correct OSN users.
				A machine learning technique is used to classify users in the online social network.
				When a new user initiates the system they are asked to make custom privacy settings for each user as new connections are made.
				The system uses the manual classifications to make broader categories.
				In order to minimize the number of users that must be classified manually,
					it attempts to select the most informative users as models to classify other users.
				The authors leverage the fact that users’ privacy settings usually coordinate with the communities they’re associated with.
				
				%collective privacy management
				Squicciarini et al. \cite{hu_detecting_2011} proposed a solution for collective privacy management for photo sharing in OSNs.
				This work considered the privacy control of a content that is co-owned by multiple users in an OSN,
					such that each co-owner may separately specify her/his own privacy preference for the shared content.
				The Clarke-Tax mechanism was adopted to enable the collective enforcement for shared content.
				Game theory was applied to evaluate the scheme.
				However,
					a general drawback of this solution is the usability issue,
					as it could be very hard for ordinary OSN users to comprehend the Clarke-Tax mechanism and specify appropriate bid values for auctions.
				In addition,
					the auction process adopted in their approach indicates only the winning bids could determine who was able to access the data,
					instead of accommodating all stakeholders’ privacy preferences.

				%Detecting and Resolving Privacy Conflicts for collaborative Data Sharing in Online Social Networks
				Hu et al. \cite{hu_detecting_2011} propose an approach to enable \textbf{collaborative privacy management} of shared data in OSNs.
				In particular,
					they provide a systematic mechanism to identify and resolve privacy conflicts for collaborative data sharing.
				their conflict resolution indicates a trade-off between privacy protection and data sharing by quantifying privacy risk and sharing loss

				
				%Interdependent Privacy: Let Me Share Your Data
				%collaborative
				Dealing with collaborative information sharing,
					Hu et al. \cite{biczok_interdependent_2013} proposed a method to detect and resolve privacy conflicts.

				
			\paragraph{Information propagation}\hfill
				
				One of the most subtle issues in protecting user data from other users is the spread of sensitive private content.
				The key difference between this and the previous section 
					is that privacy policies try to define some set of rules for the user to define who can view their information.
				However,
					Anybody is allowed to publish this information.
				The problem with this is that users that have access to the sensitive hidden data of another user,
					can simply use their ability to publish to spread that data to users whom are not supposed to have access to it.
				Any user that is allowed to read and allowed to publish will have the ability to spread sensitive information.
				Unfortunately,
					many social networks encourage this behavior by providing a built-in mechanism for propagating messages in order to increase their popularity.
				Conversely,
					social networks that attempt to prohibit users from spreading protected content in this way are only fooling themselves.
				%
				In RT @IWantPrivacy \cite{meeder_rt_2010},
					the authors address this problem.
				In this study "protected" means that the tweet came from a user that only allows directly linked users to view their tweets.
				These protected tweets are propagated 
					because the set of followers retweet the content thus making the original content publicly available.
				This paper shows that spread is a prevalent issue in online social networking.

				\cite{gundecha_exploiting_2011} claim that certain friends increase a user’s vulnerability more than others.
				Friends should have privacy settings that protect the entire group of friends community because
					attackers can learn information about one user from another user’s content.
				This paper makes a strong assumption that users that are linked in the social network somehow effect the privacy of each other.
				In reality,
					this assumption is probably true but the actual result is subtle.

				The ML-Model \cite{magnani_mlmodel_2011} describes social networks in a grander sense.
				They rightfully recognize that many people have multiple accounts on many different social networks,
					spread information flow can happen between social networks through these users,
				This paper formalizes such a model of multiple online social networks.
				Intuitively there are pillars that represent users.
				Each user has several relationship at regular heights.
				At each height exists a social network.
				The relationships at the social network at height h are represented by the edges of a graph that exists at that height.
				In this model, information might not only flow across edges between users in the same social network 
					but also between users in different social networks.
				Any user may take content from one social network and introduce it in another social network.
		
		\subsubsection{Protection from the OSN Provider}
			
			Recently, much work has gone into protecting user content from the online social network provider.
			The online social network provider can see all data that flows through the network.
			Currently, users sign agreements with the provider which is their only line of defense.
			The social network provider itself could be a threat,
				because the social network provider has technical access to all the data on the OSN,
				users must trust that provider and trust in the provider’s privacy policy and terms of use.
				
			% A Study of Online Social Network Privacy Via the TAPE Framework
			OSN service providers allow users to manage who can access which information and communication.
			Researcher studied privacy protection from two directions:
			%first direction
			Along the first direction,
				fundamental changes to the current design of OSN were suggested to enhance users' privacy.
			Within this direction, Privacy by Design (PbD) is an important approach.
			%second direction
			The second direction is developing privacy protection tools based on existing OSNs.
			In our work,
				we focus on both direction to deal with current and future messaging services.
			
			\paragraph{Design solutions}\hfill
			
				In \cite{anderson_privacyenabling_2009},
				Anderson et al. design an online social network in the client/server architecture that does not rely on the OSN provider to be trusted.
				Instead, the server simply provides name resolution of members in the social network.
				The actual content of the social network resides on individuals’ computers spread across the Internet.
				For example,
					two users Bob and Alice want to communicate via the online social network.
				Alice’s computer needs to connect to Bob’s computer but she does not know Bob’s IP address and he does not have a domain name.
				In fact,
					it is very likely that both Bob and Alice were given dynamic IP addresses by their ISPs and that there machines are behind routers or proxies.
				In order to avoid elaborate configuration required for every member of the OSN we instead rely on the OSN servers only for name resolution.
				Alice will connect to the social network server and ask for Bob by his name.
				The social network server then gives Alice a path to Bob if Bob is online or,
					if Bob is not online,
					Alice will store the message locally and the server will notify Bob about this message the next time he is online and provide a path to Alice for Bob.
				The actual message content is not stored on or passed through the server at any point.
				This system has not been widely adopted because such system does not have the enticing revenue potential than traditional online social networks.
				In spite of this,
					it is this researcher’s opinion that a system of this design is the best solution to the problem of trusting the online social network providers.
			
			\paragraph{Encryption Solutions}\hfill
			
				One of the simplest ways to keep data private in computer science is to use encryption.
				Many papers have been written that attempt to protect privacy and security of user data on online social networks by leveraging encryption.
				This brings up many important technical and non-technical challenges.
				An encryption scheme must be chosen,
					the relationships in the social network must be defined,
					there must be a clear mechanism for storing and retrieving encrypted data,
					encryption keys must be distributed,
					and it must be clear which data is to be encrypted and which is not.
				In this section we discuss many of the works that try to solve these issues in building an online social network with encryption to protect user privacy and security.
				
				The most basic of example of this technique is the "flybynight" system described in \cite{lucas_flybynight_2008}.
				The authors here have written a Facebook application that helps users send encrypted messages to one another.
				When the user first uses the application,
					they create a public/private key pair.
				The private key is encrypted with a password and transmitted through Facebook and is stored on the application server.
				The flybynight application has a complete list of Bob’s friends that have also installed the flybynight application,
					this includes Alice.
				The application encrypts Bob’s message to Alice using client side javascript with Alice’s public key and tags this message with Alice’s ID number.
				Finally the encrypted message is transmitted via Facebook to the flybynight application servers.
				The next time Alice logs in to flybynight,
					she will be alerted of Bob’s message and she can download and un-encrypt the message using her own password-protected private key.
				
				One drawback of this approach is that it relies on clientside javascript to do the encryption which has numerous problems with encryption.
				The random number generator in javascript is not sufficient to do encryption.
				In addition,
					while the client has access to the javascript source code,
						it is laborious and tedious to check on each download that the encryption is performed faithfully.
				In the end,
					this requirement for the user to trust clientside encryption is not much different from the users trusting Facebook provider.
	%			There are several papers published recently that follow this basic idea of leveraging encryption in order to protect user data in an online social network including ?.
				These techniques are strong because they deny third parties to access users data,
				However,
					they are not streamlined.
				This is a classic trade off often seen in the security research community.
				
				In \cite{baden_persona_2009}, 
					Baden et al. proposed a new type of OSNs by using \textbf{attribute-based encryption} to hide user data.
				Symmetric keys are used to encrypt messages and only the designated friend groups can decrypt the messages.
				In \cite{erkin_generating_2011},
					Erkin et al. proposed to use homomorphic encryption and multi-party encryption techniques to hide privacy-sensitive data from the service provider in a recommender system.

				In \cite{luo_facecloak_2009},
					Luo et al. implement a very similar system called “facecloak”.
				However,
					instead of writing a Facebook app that sits inside the Facebook domain.
				They wrote a Firefox browser extension that is,
					more comfortably,
					between the user and Facebook.
				The authors describe their system as having three phases;
					setup,
					encryption,
					and decryption.
				During the setup phase,
					three keys are generated;
					a master,
					a personal index,
					and an access key.
				The access key is stored locally only for the user to use.
				The other two keys are distributed to the user’s friends (out-of-band).
				The master key is used to create a symmetric key by a user when they publish data to the social network.
				This symmetric key is used to encrypt the data being posted.
				Then receivers can decrypt the data using the publisher’s master key.
				Users tell the system to encrypt a message by proceeding it with a "@".
				This system is much easier to trust because the keys are sent out-of-band and the add-on they wrote helps to automate this process.
				However,
					this system (as well as \cite{lucas_flybynight_2008}) both relay on client-side javascript to implement encryption,
					and still suffer from the same trust problem as mentioned before.
				
				In \cite{baden_persona_2009},
				Persona is itself an online social network that leverages attributebased encryption to enforce privacy and security configurations.
				Attribute based encryption (ABE) allows users of the social network to organize their friends into groups (e.g. football fans,
					or co-workers).
				Several keys are generated in the setup phase:
					a public key,
					a master secret key,
					and a secret key for each friend.
				These secret keys are based upon the attributes of each corresponding friend.
				ABE works in such a way that a message encrypted with the structure football fan or co-worker, 
					can be decrypted by any friend that has either football fan or co-worker in their corresponding secret private key.
				Additionally,
					logical operators can be used to create structures of arbitrary length (e.g. co-worker and friend and not family).
				Unfortunately ABE encryption is very slower than standard RSA encryption and it still requires that keys be exchanged out-of-band.
				To deal with this problem,
					many ABE computations can be avoided with optimal design.
				It is clear that ABE is a much better system than any of the standard RSA encryption schemes.
				For no other reason,
					ABE obviously lends itself to the natural urge for users in an online social network to divide their friends into logical groups.
				Furthermore,
					only this technique provides the flexibility that users expect in protecting their data.
				Persona allows, for example,
					Bob to send private messages to Alice’s friends without revealing to Alice Bob’s message or to Bob Alice’s friends list.
				In this way,
					Persona and more specifically,
					ABE encryption are finer grained solutions.
			
