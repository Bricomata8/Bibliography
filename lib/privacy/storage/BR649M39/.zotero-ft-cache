Centrality Measures on Big Graphs: Exact, Approximated, and Distributed Algorithms
Francesco Bonchi1,2 Gianmarco De Francisci Morales3
Matteo Riondato4
1ISI Foundation, Turin (Italy) 2Eurecat, Technological Center of Catalonia, Barcelona (Spain)
3Qatar Computing Research Institute, Doha (Qatar) 4Two Sigma Investments LP, NYC (USA)
WWW’16 – Montréal, April 11–15, 2016
1/200

Slides available at http://matteo.rionda.to/centrtutorial/
2/200

Acknowledgements
• Paolo Boldi • Andreas Kaltenbrunner • Evgenios M. Kornaropoulos • Nicolas Kourtellis • Eli Upfal • Sebastiano Vigna
3/200

Roadmap
• Introduction • motivation, history, and deﬁnitions • closeness and betweenness centrality • axioms: what to look for in a centrality measure
• Exact algorithms • exact algorithms on static graphs • exact algorithms on dynamic graphs
• Approximation algorithms • approximation algorithms on static graphs • approximation algorithms on dynamic graphs
• Conclusions • open problems and research directions
4/200

Introduction
5/200

Social network analysis
• Social network analysis is the study of social entities and their interactions and relationships
• The interactions and relationships can be represented with a network or graph, • each vertex represents an actor • each link represents a relationship
• From the graph, we can study the properties of its structure, and the role, position, and prestige of each social entity.
• We can also ﬁnd various kinds of sub-graphs, e.g., communities formed by groups of actors.
6/200

Centrality in networks
• Important or prominent actors are those that are extensively linked or involved with other actors
• A person with extensive contacts (links) or communications with many other people in the organization is considered more important than a person with relatively fewer contacts
• A central actor is one involved in many ties • Graph centrality is a topic of uttermost importance in social
sciences • Also related to the problem of ranking in the context of Web
Search: • Each webpage is a social actor • Each hyperlink is an endorsement relationship • Centrality measures provide a query independent link-based score of importance of a web page
7/200

History of centrality (in a nutshell)
• ﬁrst attempts in the late 1940s at MIT (Bavelas 1946), in the framework of communication patterns and group collaboration;
• in the following decades, various measures of centralities were proposed and employed by social scientists in a myriad of contexts (Bavelas 1951; Katz 1953; Shaw 1954; Beauchamp 1965; Mackenzie 1966; Burgess 1969; Anthonisse 1971; Czapiel 1974...) item a new interest raised in the mid-90s with the advent of search engines: a “reincarnation” of centrality.
Freeman, 1979
“several measures are often only vaguely related to the intuitive ideas they purport to index, and many are so complex that it is diﬃcult or impossible to discover what, if anything, they are measuring.”
8/200

Types of centralities
Starting point: the central vertex of a star is the most important! Why?
1 the vertex with largest degree; 2 the vertex that is closest to the other vertexes (e.g., that has
the smallest average distance to other vertexes); 3 the vertex through which all shortest paths pass; 4 the vertex with the largest number of incoming paths of
length k, for every k; 5 the vertex that maximizes the dominant eigenvector of the
graph adjacency matrix; 6 the vertex with highest probability in the stationary
distribution of the natural random walk on the graph. These observations lead to corresponding competing views of centrality.
9/200

Types of centralities
This observation leads to the following classes of indices of centrality:
1 measures based on distances [degree, closeness, Lin’s index]; 2 measures based on paths [betweenness, Katz’s index]; 3 spectral measures [dominant eigenvector, Seeley’s index,
PageRank, HITS, SALSA].
The last two classes are largely the same (even if that wasn’t fully understood for a long time.)
10/200

Geometric centralities

• degree (folklore): cdeg(x ) = d−(x )

• closeness (Bavelas, 1950): cclos(x ) = c(x ) =

1 y d(y ,x )

• Lin (Lin, 1976): cLin(x ) =

r (x )2 y d(y ,x )

where

r (x )

is

the

number

of vertexes that are co-reachable from x

• harmonic (Boldi and Vigna, 2013) charm(x ) =

1 y =x d(y ,x )

11/200

Path-based centralities

• betweenness (Anthonisse, 1971):

cbet(x ) = b(x ) =

y ,z=x ,σyz =0

σyz (x ) σyz

where

σyz

is

the

number

of shortest paths y → z, and σyz (x ) is the number of such

paths passing through x

• Katz (Katz, 1951): cKatz(x ) = t≥0 βt pt (x ) where pt (x ) is the number of paths of length t ending in x , and β is a

parameter (β < 1/ρ)

12/200

Spectral centralities
• dominant (Wei, 1953): cdom(x ) is the dominant (right) eigenvector of G
• Seeley (Seeley, 1949): cSeeley(x ) is the dominant (left) eigenvector of Gr
• PageRank (Brin, Page et al., 1999): cPR(x ) is the dominant (left) eigenvector of αGr + (1 − α)1T 1/n (where α < 1)
• HITS (Kleinberg, 1997): cHITS(x ) is the dominant (left) eigenvector of GT G
• SALSA (Lempel, Moran, 2001): cSALSA(x ) is the dominant (left) eigenvector of GcT Gr
Where G denotes the adjacency matrix of the graph, Gr is the adjacency matrix normalized by row, and Gc is the adjacency matrix normalized by column.
13/200

Closeness and Betweenness
14/200

Closeness centrality
Motivation It measures the ability to quickly access or pass information through the graph;
Deﬁnition (Closeness Centrality)
• closeness centrality c(x ) of a vertex x
1 c(x ) = y=x∈V d (y , x ).
• d(y , x ) is the length of a shortest path between y and x . • The closeness of a vertex is deﬁned as the inverse of the sum
of the Shortest Path (SP) distances between the vertex and all other vertexes of the graph. • When multiplied by n − 1, it is eﬀectively the inverse of the average SP distance.
15/200

Betweenness centrality
Motivation It measures the frequency with which a user appears in a shortest path between two other users.

Deﬁnition (Betweennes centrality)

• betweenness centrality b(x ) of a vertex x :

b(x ) =

σst (x )

s=x=t∈V σst

s =t

• σst : number of SPs from s to t
• σst (x ): how many of them pass through x

Example retrieved from Wikipedia 16/200

Betweenness centrality
• Can be deﬁned also for edges (similarly to vertexes) • Edges with high betweenness are known as “weak ties” • They tend to act as bridges between two communities
The strength of weak ties (Granovetter 1973)
• Dissemination and coordination dynamics are inﬂuenced by links established to vertexes of diﬀerent communities.
• The importance of these links has become more and more with the rise of social networks and professional networking platforms.
17/200

Weak ties
Bakshy et al. 2012 Weak links have a greater potential to expose links to new contacts that otherwise would not have been discovered.
18/200

Weak ties
Grabowicz et al. 2012 • Personal interactions are more likely to occur in internal links within communities (strong links) • Events or new information is propagated faster by intermediate links (weak links).
19/200

Girvan-Newman algorithm for community detection (Girvan and Newman 2002)
Hierarchical divisive clustering by recursively removing the “weakest tie”:
1 Compute edge betweenness centrality of all edges; 2 Remove the edge with the highest betweenness centrality; 3 Repeat from 1.
20/200

Comparison
Which vertex is the most central? • for Degree Centrality: • for Closeness Centrality: • for Betweenness Centrality:
21/200

Comparison
Which vertex is the most central? • for Degree Centrality: user A • for Closeness Centrality: • for Betweenness Centrality:
22/200

Comparison
Which vertex is the most central? • for Degree Centrality: user A • for Closeness Centrality: users B and C • for Betweenness Centrality:
23/200

Comparison
Which vertex is the most central? • for Degree Centrality: user A • for Closeness Centrality: users B and C • for Betweenness Centrality: user D
24/200

Visual Comparison
A Degree Centrality B Closeness Centrality C Betweenness Centrality
25/200

Axioms for centrality (Boldi and Vigna 2013)
26/200

Assessing
Question Is there a robust way to convince oneself that a certain centrality measure is better than another? Answer Axiomatization. . .
• . . . hard axioms (characterize a centrality measure completely) • . . . soft axioms (like the Ti axioms for topological spaces)
27/200

Sensitivity to size
Idea: size matters! Sk,p be the union of a k-clique and a p-cycle.
• if k → ∞, every vertex of the clique becomes ultimately strictly more important than every vertex of the cycle
• if p → ∞, every vertex of the cycle becomes ultimately strictly more important than every vertex of the clique
28/200

Sensitivity to density
Idea: density matters! Dk,p be made by a k-clique and a p-cycle connected by a single bidirectional bridge:
• if k → ∞, the vertex on the clique-side of the bridge becomes more important than the vertex on the cycle-side.
29/200

Score monotonicity
Adding an edge x → y strictly increases the score of y . Doesn’t say anything about the score of other vertexes!
30/200

Rank monotonicity
Adding an edge x → y . . . • if y used to dominate z, then the same holds after adding the edge • if y had the same score as z, then the same holds after adding the edge • strict variant: if y had the same score as z, then y dominates z after adding the edge
31/200

Rank monotonicity

Centrality Harmonic Degree Katz PageRank Seeley Closeness Lin Betweenness Dominant HITS SALSA

Monotonicity

General Strongly connected

Score Rank Score Rank

yes yes* yes

yes*

yes yes* yes

yes*

yes yes* yes

yes*

yes yes* yes

yes*

no no yes

yes

no no yes

yes

no no yes

yes

no no no

no

no no ?

?

no no no

no

no no no

no

Other axioms

Size yes only k only k no no no only k only p only k only k no

Density yes yes yes yes yes no no no yes yes yes
32/200

Kendall’s τ
Hollywood collaboration network
.uk (May 2007 snapshot)
33/200

Correlation
• most geometric indices and HITS are rather correlated to one another;
• Katz, degree and SALSA are also highly correlated; • PageRank stands alone in the ﬁrst dataset, but it is correlated
to degree, Katz, and SALSA in the second dataset; • Betweenness is not correlated to anything in the ﬁrst dataset,
and could not be computed in the second dataset due to the size of the graph (106M vertices).
34/200

Exact Algorithms
35/200

Outline
1 Exact algorithms for static graphs 1 the standard algorithm for closeness 2 the standard algorithm for betweenness 3 a faster betweenness algorithm through shattering and compression 4 a GPU-Based algorithm for betweenness
2 Exact algorithms for dynamic graphs 1 a dynamic algorithm for closeness 2 four dynamic algorithms for betweenness 3 a parallel streaming algorithm for betweenness
36/200

Exact Algorithms for Static Graphs
37/200

Exact Algorithm for Closeness Centrality
(folklore)
38/200

Exact Algorithm for Closeness

Recall the deﬁnition: c(x ) =

1 y=x d (x , y )

Fastest known algorithm for closeness: All-Pairs Shortest Paths • Runtime: O(nm + n2 log n)
Too slow for web-scale graphs! • Later we’ll discuss an approximation algorithm

39/200

A Faster Algorithm for Betweenness Centrality
U. Brandes
Journal of Mathematical Sociology (2001)
40/200

Why faster?
Let’s take a step back. Recall the deﬁnition
σst (x ) s=x=t∈V σst
s =t
• σst : no. of S (SPs) from s to t • σst (x ): no. of S from s to t that go through x We could: 1 obtain all the σst and σst (x ) for all x , s, t via APSP; and then 2 perform the aggregation to obtain b(x ) for all x . The ﬁrst step takes O(nm + n2 log n), but the second step takes. . . Θ(n3) (a sum of O(n2) terms for each of the n vertices).
Brandes’ algorithm interleaves the SP computation with the aggregation, achieving runtime O(nm + n2 log n)
I.e., it is faster than the APSP approach
41/200

Dependencies

Deﬁne: Dependency of s on v :

δs (v )

=

t =s =v

σst (v ) σst

Hence:

b(v ) = δs (v )
s =v

Brandes proved that δs (v ) obeys a recursive relation:

δs (v )

=

w :v ∈Ps (w )

σsv σsw

(1

+

δs (w ))

We can leverage this relation for eﬃcient computation of betweenness

42/200

Recursive relation

Theorem (Simpler form) If there is exactly one S from s to each t, then

δs (v ) =

(1 + δs (w ))

w :v ∈Ps (w )

Proof sketch: • The Sdag from s is a tree; • Fix t. v is either on the single S from s to t or not. • v lies on all and only the SPs to vertices w for which v is a predecessor (one S for each w ) and the SPs that these lie on. Hence the thesis.
The general version must take into account that not all SPs from s to w go trough v .
43/200

Brandes’ Algorithm

1 Initialize δs (v ) to 0 for each v , s and b(w ) to 0 for each w .

2 Iterate the following loop for each vertex s:

1 Run Dijkstra’s algorithm from s, keeping track of σsv for each encountered vertex v , and inserting the vertices in a max-heap

H by distance from s; 2 While H is not empty:

1 Pop the max vertex t in H;

2

For

each

w

∈ Ps (t),

increment

δs (w )

by

σsw σst

(1

+

δs

(t ));

3 Increment b(t) by δs (t);

44/200

Shattering and Compressing Networks for Betweenness Centrality
A. E. Sarıyüce, E. Saule, K. Kaya, Ü. V. Çatalyürek
SDM ’13: SIAM Conference on Data Mining
45/200

Intuition
Observations: • There are vertices with predictable betweenness (e.g., 0, or equal to one of their neighbors). We can remove them from the graph (compression) • Partitioning the (compressed) graph into small components allows for faster SP computation (shattering)
Idea: We can iteratively compress & shatter until we can’t reduce the graph any more.
Only at this point we run (a modiﬁed) Brandes’s algorithm and then aggregate the “partial” betweenness in diﬀerent components.
46/200

Introductory deﬁnitions
• Graph G = (V , E ) • Induced graph by V ⊆ V : GV = (V , E = V × V ∩ E ) • Neighborhood of a vertex v : Γ(v ) = {u : (v , u) ∈ E } • Side vertex: a vertex v such that GΓ(v) is a clique • Identical vertices: two vertices u and v such that either
Γ(u) = Γ(v ) or Γ(u) ∪ {u} = Γ(v ) ∪ {v }
47/200

Compression
Empirical / intuitive observations • if v has degree 1, then b(v ) = 0 • if v is a side vertex, then b(v ) = 0 • if u and v are identical, then b(v ) = b(w )
Compression: • remove degree-1 vertices and side vertices; and • merge identical vertices
48/200

Shattering
• Articulation vertex: vertex v whose deletion makes the graph disconnected
• Bridge edge: an edge e = (u, v ) such that G = (V , E \ {e}) has more components than G (u and v are articulation vertexes)
Shattering: • remove bridge edges • split articulation vertices in two copies, one per resulting component
49/200

Example of shattering and compression

1, 8v 2 V

a

b

b b'

c

d

c{d}

c{d,e} f

g

e

h

1

2

3

4

5

Figure 1: (1) a is a degree-1 vertex and b is an articulation
vertex. The framework removes a and create a copy b0 to represent b in the bottom component. (2) There is no degree-1, articulation, or identical vertex, or a bridge.
0

50/200

Issues
Issues to take care of when iteratively compressing & shattering: Example of issue A vertex may have degree 1 only after we removed another vertex: we can’t just remove and forget it, as its original betweenness was not 0. Example of issue When splitting an articulation vertex into component copies, we need to know, for each copy, how many vertices in other components are reachable through that vertex. ...and more
51/200

Solution
(Sketch) • When we remove a vertex u, one of its neighbors (or an identical vertex) v is elected as the representative for u (and for all vertices that u was a representative of) • We adjust the (current) values of b(v ) and b(u) to appropriately take into account the removal of u the details are too hairy for a talk. . . • When splitting articulation vertices or removing bridges, similar adjustments take place • Brandes’ algorithm is slightly modiﬁed to take the number of vertices that a vertex represents into consideration when computing the dependencies and the betweenness values
52/200

Speedup

“org.” is Brandes’ algorithm, “best” is compress & shatter

name
Power Add32 HepTh PGPgiant ProtInt AS0706 MemPlus Luxemb. AstroPh Gnu31 CondM05

Graph |V |
4.9K 4.9K 8.3K 10.6K 9.6K 22.9K 17.7K 114.5K 16.7K 62.5K 40.4K

Epinions Gowalla bcsstk32 NotreDame RoadPA Amazon0601 Google WikiTalk

131K 196K 44.6K 325K 1,088K 403K 875K 2,394K

Time (in sec.)

|E|

org. best Sp.

6.5K

1.47 0.60 2.4

9.4K

1.50 0.19 7.6

15.7K

3.48 1.49 2.3

24.3K 10.99 1.55 7.0

37.0K 11.76 7.33 1.6

48.4K 43.72 8.78 4.9

54.1K 19.13 9.28 2.0

119.6K 771.47 444.98 1.7

121.2K 40.56 19.41 2.0

147.8K 422.09 188.14 2.2

175.6K 217.41 97.67 2.2

geometric mean 2.8

711K 2,193

839 2.6

950K 5,926 3,692 1.6

985K

687

41 16.5

1,090K 7,365

965 7.6

1,541K 116,412 71,792 1.6

2,443K 42,656 36,736 1.1

4,322K 153,274 27,581 5.5

4,659K 452,443 56,778 7.9

geometric mean 3.8

4.2 Shat each graph improveme with o, do, BFS orderi is articulat is side vert order of tec
We mea tation time the runtim Brandes’ a 7 stacked b scribed abo edges rema phase are g ures, compo 6 combinat
53/200

Composition of runtime

• Preproc is the time needed to compress & shatter, Phase 1 is SSSP, Phase 2 is aggregation
• Diﬀerent column for diﬀerent variants of the algorithm (e.g., only compression of 1-degree vertices, only shattering of edges)
• the lower the better

1.4

1

Phase 1

1.2

Phase 2

Preproc

1

Relative time

0.8

0.6

0.4

0.2

0

54/200

Betweenness Centrality on GPUs and Heterogeneous Architectures
A. E. Sarıyüce, K. Kaya, E. Saule, Ü. V. Çatalyürek
GPGPU ’13: Workshop on General Purpose Processing Using GPUs
55/200

Parallelism
• Fine grained: single concurrent BFS • Only one copy of auxiliary data structures • Synchronization needed • Better for GPUs, which have small memory • Coarse grained: many independent BFSs • Sources are independent, embarrassingly parallel • More memory needed • Better for CPUs, which have large memory
56/200

GPU
A GPU is especially well-suited to address problems that can be expressed as data-parallel computations - the same program is executed on many data elements in parallel - with high arithmetic intensity - the ratio of arithmetic operations to memory operations. Because the same program is executed for each data element, there is a lower requirement for sophisticated ﬂow control, and because it is executed on many data elements and has high arithmetic intensity, the memory access latency can be hidden with calculations instead of big data caches.1

1docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

57/200

Execution model
• One thread per data element • Thread scheduled in blocks
with barriers (wait for others at the end) • Program runs on the whole data (kernel) • Minimize synchronization • Balance load • Coalesce memory access
58/200

Intuition
• GPUs have huge number of cores • Use them to parallelize BFS • One core per vertex, or one core per edge • Vertex-based parallelism creates load imbalance for graphs
with skewed degree distribution • Edge-based parallelism requires high memory usage • Use vertex-based parallelism • Virtualize high-degree vertices to address load imbalance • Reduce memory usage by removing predecessors lists
59/200

Diﬀerence

u

v1

...

...

vk

...

Vertex-based BFS

u

v1

...

...

vk

...

Edge-based BFS

60/200

m ⌧ n2 of them. To store the same information, Jia et al.

Vertex-based used an array of size m. For an edge e 2 E, indexed as in the order of CSR adj array, they set P[e] to 1 if e is a

successor-predecessor edge and leave it 0, otherwise.

Let u be a vertex at level `, when u is being processed in

the backward-step kernel, it gathers all [v]s from its succes-

sor vertices, i.e., all v 2 V such that Pv[u] = 1. As Figure 1

• For each level, for each

shows, the vertex-based approach requires n+m+1 memory in total to store the graph. Here and in the rest of the paper,

vertex in parallel

the memory usage of each graph representation is given in terms of the number of entries it contains.

• If vertex is on level

Algorithm 2: Vertex: vertex-based parallel BC

···

• For each neighbor,

`0 .Forward phase while cont = true do

adjust P and σ

cont false .Forward-step kernel

for each u 2 V in parallel do

•

Atomic update on σ needed

1 2

if d[u] = ` then for each v 2 (u) do

3

if d[v] = 1 then

(multiple paths can be

d[v] ` + 1, cont true else if d[v] = ` 1 then Pv[u] 1

discovered concurrently)

4

if d[v] = ` + 1 then [v] atomic [v] + [u]

` `+1

• While backtracking, if u ∈ P(v ) accumulate δ(u) = δ(u) + δ(v )
• Possible load imbalance if

···

.Backward phase

while ` > 1 do

` `1

.Backward-step kernel

for each u 2 V in parallel do

if d[u] = ` then

5

for each v 2 (u) do

6

if Pv[u] = 1 then [u] [u] + [v]

.Update bc values by using Equation (5)

···

degree skewed

3.2 Edge-based parallelism
A scale-free network is a network whose degree distribution follows a power law, at least asymptotically. That is there are many vertices with a degree that is lower than av-

is in th will be value i
Alth based tions, (u, v) ation o succes curren per su based both m vertex lescing
Algo
··· ` .For whil
c . f
1
` ··· .Bac whil
` . f
2
.Upd ···
3.3
The and th 61/a2to0m0 ic

in the order of CSR adj array, they set P[e] to 1 if e is a

value in is array is either the same or one more.

Edge-based successor-predecessor edge and leave it 0, otherwise. Let u be a vertex at level `, when u is being processed in

Although the updates in the backward-phase of the vertexbased approach are handled without using atomic instruc-

the backward-step kernel, it gathers all [v]s from its successor vertices, i.e., all v 2 V such that Pv[u] = 1. As Figure 1 shows, the vertex-based approach requires n+m+1 memory in total to store the graph. Here and in the rest of the paper,

tions, in edge-based parallelism, when Pv[u] = 1 for an edge (u, v) which is currently being processed, the update operation on [u] must be atomic. Because, there can be other successor-predecessor edges (u, v0) 2 E being processed con-

the memory usage of each graph representation is given in

currently by other threads. In total, two atomic operations

For each level, for each edge • terms of the number of entries it contains.

per successor-predecessor relationship are needed in edge-

based parallelism. Hence, the edge-based approach uses

in parallel Algorithm 2: Vertex: vertex-based parallel BC

both more memory and more atomic operations than the

···

vertex-based one. But it beneﬁts from better memory coa-

If edge endpoint is on level • ` 0
.Forward phase

lescing and better load distribution.

while cont = true do
Same as above... • cont false
.Forward-step kernel

Algorithm 3: Edge: edge-based parallel BC ···

for each u 2 V in parallel do

`0

1 2

•if dW[fuo]r=hea`ictlhheevn2ba(uc) kdotracking, if

.Forward phase while cont = true do

3

if d[v] = 1 then

u ∈ P (v ) accumulate d[v] ` + 1, cont true else if d[v] = ` 1 then Pv[u] 1

cont false .Forward-step kernel
for each (u, v) 2 E in parallel do

4

δ(u) = δ(u) + δ(v ) if d[v] = ` + 1 then [v] atomic [v] + [u]

` `+1

atomically · · ·
.Backward phase

while ` > 1 do

• Multiple ` ` 1
.Backward-step kernel

edges

can

try

to

for each u 2 V in parallel do

5

if

update d[u] = ` then for each v 2

δ(u)cdoo ncurrently

6

if Pv[u] = 1 then [u] [u] + [v]

More memory (edge-based • .Update bc values by using Equation (5)
···

1

if d[u] = ` then

· · · .same as vertex-based forward step

` `+1

···

.Backward phase

while ` > 1 do

` `1

.Backward-step kernel

for each (u, v) 2 E in parallel do

if d[u] = ` then

2

if Pv[u] = 1 then [u] atomic [u] + [v]

.Update bc values by using Equation (5)

···

layout) and more atomic

3.2 Edgeo-bpaeserdaptaioranllselism
A scale-free network is a network whose degree distribution follows a power law, at least asymptotically. That is there are many vertices with a degree that is lower than average, and there are some with very high degrees, yielding a very skewed degree distribution. Social networks we have

3.3 Vertex virtualization for BC
The vertex-based parallelism su↵ers from load balancing, and the edge-based parallelism uses more memory and more atomic operations. Here, we propose a vertex virtualization technique to alleviate both of these problems at the same time. The technique replaces the high-degree vertices with

62/200

Vertex virtualization

• AKA, edge batching, hybrid between vertex- and edge-based
• Split high degree vertices into virtual ones with maximum degree mdeg
• Equivalently, pack up to mdeg edges belonging to the same vertex together
• Very small mdeg = 4
• Need additional auxiliary maps

Algorithm 4: Virtual: BC with virtual vertices

···

`0

.Forward phase

while cont = true do

cont false

.Forward-step kernel

for each virtual vertex uvir in parallel do

u vmap[uvir]

if d[u] = ` then

1

for each v 2 vir(uvir) do

2

if d[v] = 1 then

d[v] ` + 1, cont true

3

if d[v] = ` + 1 then [v] atomic [v] + [u]

` `+1

··· .Backward phase while ` > 1 do
` `1 .Backward-step kernel for each virtual vertex uvir in parallel do
u vmap[uvir]
if d[u] = ` then sum 0

4

for each v 2 (u) do

5

if d[v] = ` + 1 then sum sum + [v]

6

[u] atomic [u] + sum

.Update bc values by using Equation (5) ···

In the forward phase, each thread processes the edges of a virtual vertex uvir. The real vertex u is reached via vmap and [u] is used to update the number of shortest paths to

e a n c A
4. I o H m i
3.3.1
As w sentati improv mentio beled the sam of adjs warp a of war lesced.
The lows b ptrs a the sam the vir shows By usi 63/of20v0to

Beneﬁts
• Compared to vertex-based: • Reduce load imbalance
• Compared to edge-based: • Reduce number of atomic operations • Reduce memory footprint
• Predecessors stored implicitly in the Sdag level (reduced memory usage)
• Memory layout can be further optimized to coalesce latency via striding: • Distribute edges to virtual vertices in round-robin • When accessed in parallel, they create faster sequential memory access pattern
64/200

Speedup"wrt"CPU"1"thread"

Results

11"

10"

GPU"vertex" GPU"edge"

9"

GPU"virtual"

8"

GPU"stride"

7"

6"

5"

4"

3"

2"

1"

0"

Speedup oveFr iBgurarend4e:s’CoonmCpParUisoonn orefaGl PgrUapihmspwleitmhe3n2t-actoiorensG. PU (s = 1k, . . . , 100k)

1.8E+07%

1.4E+08%

•

Results

1c.6oEm+07p% utedCPUo%1n%thlyreaod%n

a

sam1.2pE+le08%of

GPU%
sources

and

1.4E+07%

extrapol1a.2tEe+0d7% linearly

1.0E+08%

5.3 Heter
In the last of using CPU together for B mance obtain ing only GPU presented) an same time (la later (heterog CPU to dedic
The source average paral allel CPU imp e cient. (Fig is a factor of 2 not parallelism
The GPU S mance than t (amazon0601, wiki-Talk), w performance o loc-gowalla). the parallel C tation reach t in the a6v5/e2r0a0g

Exact Algorithms for Dynamic Graphs
66/200

A Fast Algorithm for Streaming Betweenness Centrality
O. Green, R. McColl, D. A. Bader
SocialCom ’12: International Conference on Social Computing
67/200

Intuition
• Make Brandes’ algorithm incremental • Keep additional data structures to avoid recomputing partial
results • Rooted Sdag for each source s ∈ V • Depth in the tree for t = distance of t from s
• Re-run parts of modiﬁed Brandes’ algorithm on edge update • Support only edge addition (on unweighted graphs)
68/200

Data structures
• One Sdags for each source s ∈ V , which contains for each other vertex t ∈ V : • Distance dst , paths σst , dependencies δs (t), predecessors Ps (t) • Additional per-level queues for exploration
• On addition of edge (u, v ), let dd = |dsu − dsv |: • dd = 0 same level • dd = 1 adjacent level • dd > 1 non-adjacent level
69/200

Same level addition

Figure 1. Insertion of edge e = (u, v) connects two vertices that are on the same level in the BFS
s d=1

• dd = 0

d=2

• Edge creates no new
shortest paths d=i
• No change to betweenness
due to this source

e

u

v

Figure 2. Insertion of edge e = (u, v) connects two vertices that are in adjacent levels in BFS tree of root s. The new change its position in the given BFS tree.

s

70/200

Adjacent level addition

• dd = 1

Figure 2. Insertion of edge e = (u, v) connects two vertices that are in adjacent levels in BFS tree of root s. The new

Let u = u, u = v •

hcihgahnge its position lion wthe given BFS tree.

• Edge creates new shortest

paths

s

d=1

• Sdag unchanged

d=2

• Changes in σ conﬁned to

sub-dag rooted in ulow

• Changes in δ also spread d=i

above to decrease old

d=i+1

dependency and account for

uhigh

w e
ulow

new dependency

• Example: w and predecessors have now only 1/2 of dependency on sub-dag rooted in ulow
71/200

ei.o...u, splvy.,

QBF S empty queue; for level 1 to V do

Algorithm eAdhjaacveent Level InsQer[ltieovnel] empty queue;

During exploration: During backtracking: nepewnttinhoeiendss.gsseubbseetwctdte•i[oePvnn][vvw]eertiNpcreo0ests,-etvThnoat2tutcha8hreeVeadi;lng,oavrditj2hacme8nVfto;lrevinelsserotifnga dgorhilvnnnltohecseeewntshsrhB=tne)ttarnaieeecFncp=orrwetuegaSeetssetdwhsc.aih(shnniuotadghhtrnhotiguegeireetdSˆˆrneohl[onntgPtop)[[urwdvuaqqe+tablu[g]etuuloue=sheo1weeets,wsl.wuuott]aovT2ha]weeey•••sahet]fv-iuuhnto[isehsverllBtDeooibˆ]hFMEpsditww,Fenesho[esvreauinsSiwptrxsn!!ome[aioli2ulqronclortcscetwhtir;σcurctk.eoQQe8eieao]daHgneanVsvrn+[Bh.tvroaudseeide];rwnPFidri[;ciedssurno,setSioFPi.vatolag;tmhofierlfTg[weeotrue.e,htsd]rdoletot]2oiha;tfs.twfheBhtrvtaueW]hetFnen;ieriSunceinrtnmevgsthtsdeerfiberereocaeerttnertiirtericooaooeosntulnesffl.low
psohrireetniostheptmnbhsteeeeu2dd. oiTn-chtoehwdejehufsioftdfloileoﬁlerorqcQwtauhatieeinlnolugnonenteLfewvoeeirmgmahtmphlbgetaooQysprr.i;dstwehoumdoocf acvnoddbeoemfaoduendwiilnl

mma 3. Given vertex shortest paths from

tuihfleowdr,o[iwfothtt],e[=wso,n]a(l=ydre[vveNth]rote+itcv-e1Tesro)ttuihtccahehtseewnfdoilultnhhdaevinne

for all neighbor w of v do

if d[w] = (d[v] + 1) then

if t[w] = Not-Touched then

enqueue w ! QBF S;

enqueue w ! Q[d[w]];

•

t[w] Down;

d[w] d[v] + 1;
•dP [Fwi]x δdPa[nv]d; b

els•e Recurse up the whole

dP ˆ[w]

[Swˆd][wa] g+dPd[Pw[]v+];

dP

[v];

Stage 3 - modiﬁed dependency accumulation [ˆv] 0, v 2 8V ; level V ; while level>0 do
while Q[level] not empty do dequeue w Q[level]; for all v 2 P [w] do if t[v] =Not-Touched then

BFS subtree starting seerrstailnsgtarting at ulow

at ulow einnqsu’esuBeFwS !treeQ. TBhFeSB; FS can onlyenmqouveeudeowwn!s’sQB[FdS[wtr]e]e;.

enqueue v ! Q[level 1]; t[v] Up;

ﬁldnseitnoioof ntae1.

ˆs(v) is

the new

numt[bwe]r of d[w]

sDhoorwtenst; d[v] +

p1a;ths

to v.

mnvthsae.rfbe)rareoSrerntaeirttirgsyaioaoegoonuddlneffpl.P. d1T,ahwtoeefhdeAnirufelgmtdohbPreeirt[rehvmo]afirse2ntneheˆˆweel[sswwn(epvudd]pa)mPPathtbh[[sewwsrˆw,]]o[oiswflt(lhvn]ebe)+rdd.ewwPPAmdissf[[hPeatvwoei]n[rri];tvtte+Sa]rsi;ettnamdepgPdaaetihn[i1nvss,];

ˆ[v] [v];

ˆ[v]

ˆ[v]

+

ˆ[v] ˆ[w]

(1

+

ˆ[w]);

if t[v] = Up ^(v 6= uhigh _ w 6= ulow) then

ˆ[v] ˆ[v]

[v] [w]

(1

+

[w]);

if w 6= r then

CB[w] CB[w] + ˆ[w] [w];

ﬁdnvueneenrtirthdttwiiiecocieeinblnssle.2g.inˆnsi(nSwvg[)ˆthvaoii]sgfleetShtle3ae0gvn-e,eevwlm3>,2ao0ˆcds8cd(iuVvﬁom)e;udisllaeditvnieveitepliaeslunizmdeVedfno;trcoyvzeearrtcoecxfuovmr. ulatfioo[rvn]lvev2eˆlV[vd],olvev2el8V

1; ;

72/200

Non-adjacent level addition

Figure 3. IFnisgeurtrieon3.of Iendsgeertieon=o(fue,dvg)e ceon=ne(cuts, vtw) ocovnenrteicctess ttwhoat vaerreticneost tahdajtacaernetntot eaadcjhacoe vertex is moverdte(xpuisllemdouvpe)d, (vp.uFlloerdoutph)e,r vs.ceFnoarriootshearnsecnetniareriosusbatnreenmtiroevessubatsreceanmboveesseeans cinan(

s

s

d=1

d=1

d=1

• dd > 1

d=2

d=2

d=2

• Edge creates new shortest

paths

uhigh

uhigh

•

Changes

to

Sdag

d=i
(new

d=i

d=i

distances)

d=i+1 d=i+1

d=i+1

• Algorithm only sketched (most details missing) d=i+c d=i+c

ulow

ulow

(a) Before ed(ag)e Binesfeorrteioend.ge insertion.

(b) After edg(ebi)nAs addition7a3l/v2ea0rdt0idcie

Complexity
• Time: O(n2 + nm) ← same as Brandes’ • In practice, algorithm is much faster • Space: O(n2 + nm) ← higher than Brandes’ • For each source, a Sdag of complexity n + m
74/200

90
graphs.

Speedup

Results

R-MAT graph speedup
300

250

200

150

100

50

0 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 Density percentage(%)

scale 10

scale 11

scale 12

Speedup over Brandes’ on synthetic graphs (n = 4096) (b) Speedup of the streaming algorithm for R-MAT dense graphs.

75/200

Conclusions
• Up to 2 orders of magnitude speedup • Super-quadratic space bottleneck
76/200

QUBE: a Quick algorithm for Updating BEtweenness centrality
M. Lee, J. Lee, J. Park, R. Choi, C. Chung
WWW ’12: International World Wide Web Conference
77/200

Intuition
• No need to update all vertices when a new edge is added • Prune vertices whose b does not change • Large reduction in all-pairs shortest paths to be re-computed • Support both edge additions and removals
78/200

Minimum Cycle Basis
• G = (V , E ) undirected graph • Cycle C ⊆ E s.t. ∀v ∈ V , v incident to even number of edges
in C • Represented as edge incidence vector ν ∈ {0, 1}|E|, where
ν(e) = 1 ⇐⇒ e ∈ C • Cycle Basis = set of linearly independent cycles • Minimum Cycle Basis = on weighted graph with non-negative
weights we, cycle basis of minimum total weight w (C ) = i w (Ci ) where w (Ci ) = e∈Ci we
79/200

Basis is a cMyicnlime umbaCsyicsleCBasoisfExmaminpliemum total

hich minimizes w(C) =

v i=1

w(Ci),

where

w

w .e • Three cycle basis sets: {C1, C2}, {C1, C3}, {C2, C3}

• If all edges have same weight we = 1, MCB = {C1, C2}

v1

v3

c3

c1

c2

v5

v2

v4

80/200

Minimum Union Cycle
• Given a MCB C and minimum cycles Ci ∈ C • Let VCi be the set of vertices induced by Ci • Recursively union two VCi if they share at least one vertex • The ﬁnal set of vertices is a Minimum Union Cycle MUC • MUC s are disjoint sets of vertices • MUC (v ) = the MUC which contains vertex v
81/200

Connection Vertex
• Articulation Vertex = vertex v whose deletion makes the graph disconnected
• Biconnected graph = graph with no articulation vertex • Vertex v is an articulation vertex ⇐⇒ v belongs to two
biconnected components • Connection Vertex = vertex v that
• is an articulation vertex • has an edge to vertex w ∈ MUC (v )
82/200

connected component of Gj . VGj is the set of vertices

Connection Vertex Example be how to compute the between-
mentioned in Section 4, after an edge e(vi, vj ), we guarantee that s of vertices in M U C(vi) can be we ﬁnd the reduced set of vertices,

Gj . In Figure 5, G1, G2 and G3 represent disconnected su
graphs originated from the deletions of connection vertice v1, v2, and v3, respectively. G12 and G22 are connected com ponents of G2. If the dotted edge is inserted, M U CU {v1, v2, v3, v4} and connection vertices of M U CU to G1, G

, we need to eﬃciently calculate

and G3 are v1, v2, and v3, respectively.

ss centralities of the vertices in

dated vertices belong. From now

G1

MUC as M U CU .

G

•

If (v3, v4) is added,

MUC
c(v1)

(G1v3)

=0G.5’{v1,

v2,

v3,

v4}

v5

• cv(v12,) v2,1v3 ar0e.5connection cv(ve3r)tice0.s5 of 0M.5UC (v3)

|VG1|=5 G3 v3
|VG3|=6

v1

MUCU

v4 v2

•

ccsL((uvve45b))t gGra3i 0.p5bhe

t0h.5e disconnected generated by

G2

of the depenrdeemncoyvionfgthvie be-

|VG2|=4

v6

ss centralities of the vertices in a e occurs is expensive, because in involves computation of all pair ph. In the previous section, we et of vertices whose betweenness d. This set of vertices is referred

v8

v5

v7

G21 |VG21|=3

G22 |VG22|=1

Figure 5: An example of updating the betweenne

centrality (vertices in G1 and G3 are omitted.)
83/200

Finding MUCs
• Finding an MCB is well studied • Kavitha, Mehlhorn, Michail, Paluch. “A faster algorithm for
minimum cycle basis of graphs”. ICALP 2004 • Finding MUC from MCB relatively straightforward (just union
sets of vertices) • Also ﬁnd connection vertices for each MUC • All done as a preprocessing step • Need to be updated at runtime
84/200

4.3 UpdatinUgpdMatUingCMs UCs – Addition

v2

b v12

v6

v9

v1 a v4

v7

v8

v10

v3

v5

c v11

(a) Insertion
• Adding a does not aﬀect the MUC (endpoints in the same

MUC )

•

Adding b
MUC )c

crvea2tes

a new
b

MvU6C

(endpoints

dovn9ot

belong

to

a

• Adding c merges two MUC s (merge MUC s of vertices on the

S betvw1een endpoinvt4s)

v7

v8 a v10

85/200

Updatin(ag)MI nUsCesrt–ioRnemoval

c v2 b

v1

v4

v6 v7

v9 v8 a v10

v3

v5

v11

(b) Deletion
• Removing a destroys the MUC (cycle is removed → no
Fbigicuonrneect3ed: cAomnpoenexnat)mple of updating MUC
• Removing b does not aﬀect the MUC (MUC is still
biconnected)
We •noRwemopvrinegsecnstpliotsutrhetMecUhCniinqtuweo (osningmle vaeirntetxaianppineagrs ain set of MUCs, aallsSetbeotwf eceonnenndepcotiinotsn) vertices for each M U C and dis-
86/200

CENTRALITY
In this sBecettiwone,ewnne edsesscCriebnethraolwitytoDceopmepnudteentchye between-
nictnhheseas••esnrbgtcOtHreieoeeotonqdnwnwbluy.teieerroTvveeaureenslphrrind,tntdeeyeeearrxewslteeecesvfstodoasicmhirloneueonpsn,reiutdtsaoetre.isffantttlgtAehiphrteaasiewletMlhmseecsUdeoeﬁtngCnfontetsrvdtiaeohoelt(irfenthvtitereiiehedcs,eservtfsieoujnodr)pif,nudtSthawcehMeteceeedMtdgUgisorUeueaCnnaCtpdr(h4opavs,fotinii)vlantleeftctsreaetnnrticeheeabadsnet, which w•eShreorfteersttpoatahss tMo vUerCtic,ews oeutnseideedthteoMeUﬃCciently calculate and up•daStheorttehset pbatehtswteheant npaessssthcreonugthratlhietiMesUCof the vertices in the MUC to which the updated vertices belong. From now on, we simply denote such MUC as M U CU .

v1

G'’

v3

v4

v2

G v5

G G’'

c(v1) 1

0.5

c(v2) 1

0.5

c(v3) 0.5 0.5

c(v4) 3.5 0.5

c(v5) 0

Figure 4: An example of the dependency of the be- 87/200

Betweenness Centrality outside the MUC

• Let s ∈ VGj , t ∈ MUC , • Let j ∈ MUC be a connection vertex to subgraph Gj • Each vertex in Sjt is also in Sst • Therefore, betweenness centrality due to vertices outside the
MUC :

bo(v ) =

|VGj | σst
0

if v ∈ {Sjt \ t} otherwise

88/200

Betweenness Centrality trough the MUC
• Let s ∈ VGj , t ∈ VGk , • Let j ∈ MUC be a connection vertex to subgraph Gj • Let k ∈ MUC be a connection vertex to subgraph Gk • Each vertex in Sjk is also in Sst • Therefore, betweenness centrality due to paths through the
MUC :

bx (v ) =

|VGj ||VGk | σst
0

if v ∈ Sjk otherwise

More caveats apply for subgraphs that are disconnected, as every path that connects vertices in diﬀerent connected component passes through v
89/200

Updating Betweenness Centrality

b(v ) = bMUC (v ) + bo(v ) +

bx (v )

Gj ⊂G

Gj ,Gk ⊂G

90/200

Networks

QUBE algorithm
April 16–20, 2012, Lyon, France

n-

Algorithm 3: QUBE(M U CU )

U
st

input : M U CU - Minimum Union Cycle that updated vertices belong to

output : C[vi] - Updated Betweenness Centrality Array

hs

1 begin

es

2 Let SP be the set of all pair shortest paths in M U CU ;

✷

3 Let C[vi] be an empty array, vi ∈ M U CU ;

4 SP , C[vi] ← Betweenness() ;

ess

5 for each shortest path <va, . . . , vb> in SP do

6

if va is a connecting vertex then

7

Ga := Subgraph connected by a connection

ot

vertex va ;

or

8

for each vi ∈ <va, . . . , vb> - {vb} do

9

C [vi ]

:=

C [vi ]

+

|VGa | |SP (va,vb)|

;

10

if vb is also a connecting vertex then

11

Gb := Subgraph connected by a

91/200

es

2 Let SP be the set of all pair shortest paths in M U CU ;

✷

3 Let C[vi] be anQeUmpBtyEaarrlagyo, rviith∈mMUCU ;

4 SP , C[vi] ← Betweenness() ;

ess

5 for each shortest path <va, . . . , vb> in SP do

6

if va is a connecting vertex then

7

Ga := Subgraph connected by a connection

ot

vertex va ;

or

8

for each vi ∈ <va, . . . , vb> - {vb} do

9

C [vi ]

:=

C [vi ]

+

|VGa | |SP (va,vb)|

;

10

if vb is also a connecting vertex then

11

Gb := Subgraph connected by a

3) 12

connection vertex vb ; for each vi ∈ < va, . . . , vb > do

13

C [vi ]

:= C[vi]

+

|VGa |·|VGb | |SP (va,vb)|

;

es
14 15
e-

if Ga is disconnected then

C[va] := C[va] + |VGa |2 −

n l=1

(|VGla

|2

)

ts

a

h

is

4)2. Then for each shortest path between the vertices in 92/200

QUBE + Brandes
• QUBE is a pruning rule that reduces the search space for betweenness recomputation
• Can be paired with any existing betweenness algorithm to compute bMUC
• In the experiments, Brandes’ is used • Quantities computed by Brandes’ (e.g., σ) reused by QUBE
for bo and bx
93/200

Results

Time(ms)

400000 350000 300000 250000 200000 150000 100000
50000 0

QUBE+Brandes Brandes

10 20 30 40 50 60 70 80

Proportion

(c) |V|=5000 Update time as a function of the percentage of vertices of the graph in
the updated MUC for synthetic Erdös-Rényi graphs (n = 5000)
94/200

b c

hhttttpp::////swtwuﬀw..mcse.tcaoﬁrnlteelrl..Cecdoomun/c/cliounufsoriodsenusms/cps/685/2002fa/

Time (ms, log scale)

10000000

1000000

100000

10000

1000

100

10

1 Eva

QUBE+Brandes 106

Brandes

256326

Erdos02 12289 486267

Erdos972 Pgp 8640 270419 297100 3538417

Epa 34056 227158

Contact 1150801 4600805

Wikivote 361362 1082843

CAGrQc 101895 210831

Foni•grueI(rmbaeip-lcr7oodvn:aentmeTacethnetedndebespese)tnwdseehinghnleysosn csternucttruarleitoyf thuepgdraapthe time
• From 2 orders of magnitude (best) to 2 times (worst) faster up inthTanabBleran2dsehs’ows how fast the updatable version of the
95/200

Incremental Algorithm for Updating Betweenness Centrality in
Dynamically Growing Networks
M. Kas, M. Wachs, K. M. Carley, L. R. Carley
ASONAM ’13: International Conference on Advances in Social Networks analysis and Mining
96/200

Intuition
• Extend an existing dynamic all-pairs shortest path algorithm to betweenness
• G. Ramalingam and T. Reps, “On the Computational Complexity of Incremental Algorithms,” CS, Univ. of Wisconsin at Madison, Tech. Report 1991
• Relevant quantities: number of shortest paths σ, distances d, predecessors P
• Keep a copy of the old quantities while updating • Support only edge addition (on weighted graphs)
97/200

Edge update
• Compute new shortest paths from updated endpoints (u, v ) • If a new shortest path of the same length is found, updated
number of paths as
σst = σst + σsu × σvt
• If a new shorter shortest path to any vertex is found, update d, clear σ
• Betweenness decreased if new shortest path found • Edge betweenness updates backtrack via DFS over Ps (t)
b(w ) = b(w ) − σsw × σwt/σst
98/200

Edge update
• Complex bookkeeping: need to consider all aﬀected vertices which have new alternative shortest paths of equal length (not covered in the original algorithm)
• Amend P during update propagation → concurrent changes to the Sdag
• Need to track now-unreachable vertices separately • After having ﬁxed d, σ, b, increase b due to new paths • Update needed ∀s, t ∈ V aﬀected by changes (tracked from
previous phase) • Betweenness increase analogous to above decrease
99/200

relations between High-REenseurlgtsy Physics researchers) [22] P2P Communication Network (P2P file sharing) [23].

TABLE 5- PERFORMANCE OF INCREMENTAL BETWEENNESS ALGORITHM

REAL LIFE NETWORKS.

Avg

Network

D? #(N) #(E) Speedup Affect%

SocioPatterns U 113 4392 9.58 x

38.26%

FB-like

D 1896 20289 18.48 x 27.67%

HEP Coauthor U 7507 19398 357.96 x 42.08%

P2P Comm.

D 6843 7572 36732 x 0.02%

TABLE 6- NSEpTeWedOuRpKovSeTrABTrIaSnTdIeCs’SoCnOrLeaLlE-wCoTrEldDgOraNphRsEAL LIFE NETWORK

Std.

Avg.

Dev. Diam Path Clus N•etwSopreekdup depMenadxsBotnwtopAovlogg.icBatlwchaBrtawcteristeictser(e.g., Len. Coef SocidoiPaamtteetrenr,sclust.42c3o.e4ﬀ7.)7 36.752 51.139 3 1.65 0.53

FB-like

146171.2 2848.62 9753.8 8 3.19 0.08

HEP Coauthor 820318.2 13553.29 38024 15 5.74 0.46 100/200

