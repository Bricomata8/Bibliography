Graduate Theses and Dissertations

University of South Florida
Scholar Commons
Graduate School

January 2012
On the Design of Socially-Aware Distributed Systems
Nicolas Kourtellis
University of South Florida, nkourtel@mail.usf.edu

Follow this and additional works at: http://scholarcommons.usf.edu/etd Part of the American Studies Commons, and the Computer Sciences Commons
Scholar Commons Citation
Kourtellis, Nicolas, "On the Design of Socially-Aware Distributed Systems" (2012). Graduate Theses and Dissertations. http://scholarcommons.usf.edu/etd/4107
This Dissertation is brought to you for free and open access by the Graduate School at Scholar Commons. It has been accepted for inclusion in Graduate Theses and Dissertations by an authorized administrator of Scholar Commons. For more information, please contact scholarcommons@usf.edu.

On the Design of Socially-Aware Distributed Systems
by
Nicolas Kourtellis
A dissertation submitted in partial fulﬁllment of the requirements for the degree of Doctor of Philosophy
Department of Computer Science and Engineering College of Engineering
University of South Florida
Major Professor: Adriana Iamnitchi, Ph.D. Cristian Borcea, Ph.D. Miguel Labrador, Ph.D. Jay Ligatti, Ph.D.
Kingsley A. Reeves, Jr., Ph.D. John Skvoretz, Ph.D.
Date of Approval: May 3, 2012
Keywords: socially-aware system design, decentralized social data management, peer-to-peer network, projection graph, social network analysis Copyright c 2012, Nicolas Kourtellis

Dedication
To my beloved parents Panayiota and Ioannis Kourtellis for teaching me the importance of an education, and always motivating me to pursue my dreams.

Acknowledgments
I would like to thank Dr. Adriana Iamnitchi for being my major professor and academic advisor for the past six years. Her help and guidance inspired me to overcome any diﬃculties in my research, and her persistence motivated me throughout my doctoral studies. I would also like to thank Dr. Cristian Borcea, Dr. Miguel Labrador, Dr. Jay Ligatti, Dr. Kingsley A. Reeves Jr., and Dr. John Skvoretz for serving as my Ph.D. advisory committee, and Dr. Chris Ferekides for serving as the chair in my Doctoral defense.
I am obliged to my colleagues from the Distributed Systems Lab for their support. In particular, I would like to acknowledge the signiﬁcant contribution of Josh Finnis on the peer communication/gateway module of Prometheus and of Paul Anderson on the peer geo-social management module of Prometheus, and Jeremy Blackburn’s contribution in the study of the Prometheus’ resilience.
I would also like to show my gratitude to the CSE technical staﬀ, as well as the technical support from the PlanetLab testbed, for their help during the testing of the Prometheus system and the social network experiments on projection graphs.
Finally, I would not be able to ﬁnish this dissertation without the support, motivation and guidance of my parents Panayiota and Ioannis, my brothers Achilleas and Adonis, my relatives and all my friends, who were always there to help me during my Doctoral studies, here at the University of South Florida.

Table of Contents

List of Tables

iv

List of Figures

v

Abstract

x

Chapter 1 Introduction

1

1.1 Collection and Use of Social Information

3

1.2 Management of Social Information

5

1.3 System Traversal of Social Graphs

7

1.4 Thesis and Research Questions

8

1.5 Research Contributions

9

1.6 Dissertation Outline

11

Chapter 2 Decentralized Social Data Management with Prometheus

13

2.1 Prometheus Overview

13

2.1.1 Social Input: Social Sensors and Personal Aggregators

14

2.1.2 Prometheus as a Social Knowledge Service

16

2.1.3 Output to Applications and Services

17

2.1.4 Prometheus in Use: SofaSurfer Application

18

2.2 Prometheus Design Objectives

19

2.3 Prometheus Design

20

2.3.1 Building Blocks: Pastry, Past and Scribe

22

2.3.2 User Registration

24

2.3.3 Trusted Peer Group Management

25

2.3.4 Distributed Social Graph

27

2.3.5 Social Inference API

29

2.3.6 Access Control Policies

33

2.3.7 Decentralized Inference Function Execution

37

2.3.8 Retransmission Policy

41

Chapter 3 Performance Evaluation of Prometheus

44

3.1 Implementation

44

3.2 Testbeds

45

i

3.3 Experimental Setup for Performance Evaluation with Emulated Work-

loads

46

3.3.1 PlanetLab Deployment

46

3.3.2 Decentralizing the Social Graph

48

3.3.3 Emulated Workloads

50

3.3.3.1 Social Sensor Input

51

3.3.3.2 Neighborhood Inference Requests

52

3.3.3.3 Social Strength Inference Request

53

3.4 Performance Evaluation with Emulated Workloads

55

3.4.1 End-to-End Performance

55

3.4.2 Response Time vs. Completion Rate

60

3.5 Performance Evaluation with Real Mobile Application

63

3.5.1 Social Multi-Graph from Real Traces

65

3.5.2 Application Response Performance

66

Chapter 4 Resilience to Malicious Attacks in Prometheus

68

4.1 Attacks at the Social Graph Level

70

4.1.1 Creating Social Edge from Attacker to Victim

71

4.1.2 Reciprocating Social Edge from Victim to Attacker

71

4.1.2.1 Defense via Prometheus Inferences

72

4.1.2.2 Defense via SybilLimit-based Techniques

72

4.1.2.3 Manipulating Complex Inference Requests

73

4.2 Attacks at the Service Level

74

4.2.1 Peer Inﬂuence

76

4.2.2 Peer Inﬂuence on a Synthetic Graph

77

4.2.3 Peer Inﬂuence on Real Graphs

79

4.2.4 Peer Inﬂuence under Peer Collusion

83

4.3 Attacks at the Application Level

86

Chapter 5 Projection Graphs

88

5.1 Motivating Scenarios

88

5.1.1 Civilian Networking in Large-Scale Disaster

89

5.1.2 Player Networking in Online Games

90

5.2 Projection Graph Emergence

90

5.3 Projection Graph Model

91

Chapter 6 Social Network Centrality Measures in Projection Graphs

94

6.1 Degree Centrality

95

6.2 Node Betweenness Centrality

96

6.3 Edge Betweenness Centrality

98

Chapter 7 Experimental Study of Projection Graphs

100

7.1 Projection Graphs From Real Networks

100

7.1.1 Network Description

101

7.1.2 Mapping Users onto Peers

102

ii

7.1.3 Community Size and Degree Variability

105

7.2 Centrality Measures in Social vs. Projection Graph

107

7.2.1 Estimation of Centrality Measures

108

7.2.2 Applicability of Results

113

7.3 Estimating Top Centrality Scoring Peers

115

Chapter 8 Leveraging the Projection Graph in Application and System Design

119

8.1 Application Workloads and Experimental Setup

119

8.1.1 Application Workloads

120

8.1.2 Experimental Setup

120

8.2 Leveraging the Projection Graph at the Application Level

121

8.2.1 Social Search Techniques

122

8.2.2 Experimental Results

123

8.3 Leveraging the Projection Graph at the P2P Overlay Level

126

8.3.1 P G-Based Unstructured P2P Overlays

126

8.3.2 Experimental Results

128

8.4 Applicability of Results

131

Chapter 9 Related Work

134

9.1 Socially-Aware Applications and Services

134

9.2 Social Data Management

136

9.2.1 Mobile Systems for Social Data Management

136

9.2.2 Peer-to-Peer Systems for Social Data Management

137

9.3 Privacy and Security in Decentralized OSNs

140

9.4 Application Programmable Interfaces for Social Information

142

9.5 Projection Graphs in Existing Peer-to-Peer Systems

143

9.6 Peer Centrality

144

Chapter 10 Lessons on Designing Socially-Aware Distributed Systems

146

10.1 Socially-Aware Decentralization of the Social Graph

146

10.2 Peer Organization and Centrality Estimation

147

10.3 Leveraging Peer Centrality in the Application Design

149

10.4 Leveraging Peer Centrality in the System Design

150

Chapter 11 Conclusions and Future Work

153

List of References

156

Appendices

172

Appendix A: List of Acronyms

173

Appendix B: Pseudocode for Generation of Synthetic Networks

174

Appendix C: Reuse of Material from Copyrighted Sources

175

About the Author

End Page

iii

List of Tables

Table 2.1 Access control policy deﬁnitions for a user in Prometheus.

33

Table 3.1 Metrics used to select stable and resourceful PlanetLab peers for the

Prometheus deployment and testing.

47

Table 3.2 Graph properties of the synthetic social graph used for the high-stress

experiments.

49

Table 3.3 Probability distribution function for social inputs, based on a Face-

book study.

51

Table 3.4 Probability distribution function for the neighborhood requests, based

on a Twitter study.

53

Table 3.5 Probability distribution function for the social strength requests, based

on a BitTorrent study.

54

Table 3.6 Graph properties of the multi-graph produced using real collocation

and Facebook data from NJIT.

65

Table 4.1 Summary information of the real networks used in the experimental

study for the inﬂuence in Prometheus requests.

79

Table 7.1 Summary information of the real networks used in the projection

graph experimental study.

102

Table 7.2 Summary statistics for communities identiﬁed with the Louvain (L)

and Recursive-Louvain (RL) methods on the real networks used.

104

iv

List of Figures

Figure 1.1 Users share a wealth of social information over a variety of social

applications and services.

1

Figure 1.2 Decentralization of users’ social information in diﬀerent system archi-

tectures.

5

Figure 2.1 Prometheus in the social hourglass infrastructure.

14

Figure 2.2 Prometheus input, social graph maintained, and output to applica-

tions.

17

Figure 2.3 Overview of the Prometheus architecture.

20

Figure 2.4 An example of a social graph for eight users (A-H ) distributed on

seven peers.

28

Figure 2.5 A calculation example of the social strength inference function.

32

Figure 2.6 Example set of default access control policies of user Bob.

35

Figure 2.7 Example set of access control policies of user Bob in Prometheus.

36

Figure 2.8 Possible scenarios of inference execution along with associated delays

in the distributed infrastructure.

39

Figure 2.9 Probability distribution function of the time delay to send 2, 4 or 6

messages between peers, when the retransmission policy is used.

41

Figure 2.10 CDF of the time delay for a request with the following scenarios: (a)

no timeouts, (b) 1 timeout and 2T R (r = 2, k = 1) , (c) 1 timeout

and 4T R (r = 3, k = 2) and (d) 2 timeouts and 2T R (r = 3, k = 1),

when the retransmission policy is used.

42

v

Figure 3.1 Geographical distribution of PlanetLab sites used in the Prometheus’

experiments.

47

Figure 3.2 CDF of the average end-to-end response time of the neighborhood

inference for the random and social mappings, diﬀerent social hops

for 10 users per peer, with T = 15 seconds.

56

Figure 3.3 CDF of the average end-to-end response time of the neighborhood

inference for the random and social mappings, diﬀerent social hops

for 30 users per peer, with T = 15 seconds.

56

Figure 3.4 CDF of the average end-to-end response time of the neighborhood

inference for the random and social mappings, diﬀerent social hops

for 50 users per peer, with T = 15 seconds.

57

Figure 3.5 CDF of the time needed for a peer to create a trusted peer list of a

user in PlanetLab.

59

Figure 3.6 CDF of the round trip time (RTT) between same-country peers in

PlanetLab.

61

Figure 3.7 CDF of the average end-to-end response time of the 2-hop neighbor-

hood inference for the social mapping, with 30 users per peer and

varying timeout values.

61

Figure 3.8 CDF of the average end-to-end response time of the 3-hop neighbor-

hood inference for the social mapping, with 30 users per peer and

varying timeout values.

62

Figure 3.9 CDF of the average completion percentage of 3–hop neighborhood

requests for varying timeout values.

63

Figure 3.10 Real multi-graph with Facebook edges (black dashed lines) and collo-

cation edges (red continuous lines).

66

Figure 3.11 CDF of average end-to-end response time for CallCensor, under three

social inference function requests: 1 and 2 hops neighborhood requests

and social strength (SocS) requests.

67

Figure 4.1 Attacks can target a social data management service at diﬀerent sys-

tem levels.

68

Figure 4.2 User attack on the social graph: Alice creates a fake edge to Cary

with high weight to bias inferences from Bob to Cary.

73

vi

Figure 4.3 Example of peer inﬂuence.

75

Figure 4.4 CDF of average peer inﬂuence for random and social mappings of the

synthetic graph, for combinations of users per peer and number of

hops per request.

78

Figure 4.5 Average peer inﬂuence for random and social mappings for real graphs,

for combinations of users per peer and number of hops per request.

80

Figure 4.6 Average diﬀerence of peer inﬂuence between random and social map-

pings for real graphs.

81

Figure 4.7 CDF of average peer inﬂuence for random and social mappings for

real graphs, for combinations of users per peer and number of hops

per request.

82

Figure 4.8 Average peer inﬂuence for random (RM ) and social mapping (SM )

of the slashdot network, for 10 users per peer and diﬀerent number of

hops per request.

84

Figure 4.9 Average peer inﬂuence for random (RM ) and social mapping (SM )

of the slashdot network, for 10 users per peer and diﬀerent number of

hops per request.

84

Figure 4.10 Average peer inﬂuence for random and social mapping of the slashdot

network, for 10 users per peer and diﬀerent number of hops per re-

quest.

84

Figure 5.1 An example of a social graph distributed on a set of peers which are

organized in a P2P overlay.

91

Figure 6.1 The degree centrality of user A is higher than other users in this ex-

ample social graph.

94

Figure 6.2 The node betweenness centrality of user A is higher than other users

in this example social graph.

95

Figure 6.3 The edge betweenness centrality of the social edge connecting users A

and B is higher than other edges in this example social graph.

95

Figure 6.4 The four categories of shortest paths between two users s and t through

u, when users are mapped on peers.

97

Figure 6.5 The ﬁve categories of shortest paths between two users s and t through

e, when users are mapped on peers.

99

vii

Figure 7.1 Distribution of the community size rank vs frequency observed in the

diﬀerent average size of communities and diﬀerent real networks.

106

Figure 7.2 Distribution of the peer degree rank vs frequency observed in the

diﬀerent average size of communities and diﬀerent real networks.

107

Figure 7.3 Correlation of cumulative normalized centrality scores of users vs

normalized centrality scores of peers for Degree, Node Betweenness

and Edge Betweenness Centrality.

108

Figure 7.4 Comparison of cumulative normalized scores of users (point lines)

vs average normalized scores of peers (smoothed lines) for Degree

Centrality.

110

Figure 7.5 Comparison of cumulative normalized scores of users (point lines)

vs average normalized scores of peers (smoothed lines) for Node Be-

tweenness Centrality.

111

Figure 7.6 Comparison of cumulative normalized scores of user edges (point lines)

vs average normalized scores of peer edges (smoothed lines) for Edge

Betweenness Centrality.

112

Figure 7.7 Average number of social edges found within a peer (thick lines) or

between two peers (thin lines).

113

Figure 7.8 Percent overlap of peers for top N % degree centrality in the networks

used.

117

Figure 7.9 Percent overlap of peers for top N % node betweenness centrality in

the networks used.

118

Figure 8.1 CDF of the number of social graph hops for successful queries in so-

cial graph traversals.

123

Figure 8.2 CDF of the percentage of peers accessed in the system in social graph

traversals.

125

Figure 8.3 CDF of the number of projection graph hops for successful queries in

projection graph traversals.

129

Figure 8.4 CDF of the percentage of peers accessed in the system in projection

graph traversals.

130

Figure C.1 Permission for reusing material from 11th ACM/IFIP/USENIX Inter-

national Conference on Middleware, November-December 2010.

175

viii

Figure C.2 Approval for reusing material from IEEE Internet Computing Maga-

zine, May-June 2012.

176

Figure C.3 Approval for reusing material from 11th IEEE International Confer-

ence on Peer-to-Peer Computing, August-September 2011.

177

ix

Abstract
Social media services and applications enable billions of users to share an unprecedented amount of social information, which is further augmented by location and collocation information from mobile phones, and can be aggregated to provide an accurate digital representation of the social world. This dissertation argues that extracted social knowledge from this wealth of information can be embedded in the design of novel distributed, socially-aware applications and services, consequently improving system response time, availability and resilience to attacks, and reducing system overhead. To support this thesis, two research avenues are explored.
First, this dissertation presents Prometheus, a socially-aware peer-to-peer service that collects social information from multiple sources, maintains it in a decentralized fashion on user-contributed nodes, and exposes it to applications through an interface that implements non-trivial social inferences. The system’s socially-aware design leads to multiple system improvements: 1) it increases service availability by allowing users to manage their social information via socially-trusted peers, 2) it improves social inference performance and reduces message overhead by exploiting naturally-formed social groups, and 3) it reduces the opportunity of attackers to inﬂuence application requests. These performance improvements are assessed via simulations and a prototype deployment on a local cluster and on a worldwide testbed (PlanetLab) under emulated application workloads.
Second, this dissertation deﬁnes the projection graph, the result of decentralizing a social graph onto a peer-to-peer system such as Prometheus, and studies the system’s network
x

properties and how they can be used to design more eﬃcient socially-aware distributed applications and services. In particular: 1) it analytically formulates the relation between centrality metrics such as degree centrality, node betweenness centrality, and edge betweenness centrality in the social graph and in the emerging projection graph, 2) it experimentally demonstrates on real networks that for small groups of users mapped on peers, there is high association of social and projection graph properties, 3) it shows how these properties of the (dynamic) projection graph can be accurately inferred from the properties of the (slower changing) social graph, and 4) it demonstrates with two search application scenarios the usability of the projection graph in designing social search applications and unstructured P2P overlays. These research results lead to the formulation of lessons applicable to the design of sociallyaware applications and distributed systems for improved application performance such as social search, data dissemination, data placement and caching, as well as for reduced system communication overhead and increased system resilience to attacks.
xi

Chapter 1: Introduction
The dramatic increase in the number of computing devices used by billions of people from around the world allows individuals to share with each other their location, collocation with others, daily schedules, personal preferences such as in dining, movies, and music, hobbies and other social activities such as sports, games, etc., through numerous social applications and services (Figure 1.1).
Figure 1.1: Users share a wealth of social information over a variety of social applications and services. Social information collected by such applications and services include declared relationships (e.g., friendships on Facebook or membership in LinkedIn groups), as well as inferred social relationships (e.g., users “like” the same video on YouTube or play online games together) and location of their users. Typically, users are represented as nodes in a social graph and are connected with each other by a social edge. Socially-aware applications and services, by deﬁnition, exploit user relationships to provide enhanced functionality and better performance. For example, such services have
1

leveraged out-of-band social relationships for ﬁltering restaurant recommendations based on reviews by friends (e.g., Yelp [Yel12]), recommending email recipients or ﬁltering spam based on previous email activity [KRS+06], exploiting social incentives for computer resource sharing [TCL08, LD06], improving security in social networks [YKGF06, YGKX08], inferring trust in peer-to-peer storage systems [MRG+05], and building peer-to-peer overlays [PCT04] for private communication.
In addition, social relationships inferred from online social information have been used to rank Internet search results relative to the interests of a user’s neighborhood in the social network [GMD06], to favor socially connected users in a BitTorrent swarm [PGW+08], and to reduce unwanted communication between users [MPDG08]. Social information has also been leveraged in conjunction with location and collocation data to provide novel mobile applications such as Loopt [Loo12], Foursquare [Fou12] and Latitude [Goo12a].
The common approach for building such social applications is the vertical integration, where one source of information is used to construct a social graph of users-nodes connected over application speciﬁc edges and used within the application bounds. Instead, combining declared and interaction-based social information from multiple sources can provide more accurate and personalized support for novel social applications covering a wide spectrum of domains. This can be achieved through an infrastructure that absorbs social information from an unrestricted set of domains, and can export it to an everevolving collection of socially-aware applications and services [IBK12].
At the heart of this infrastructure must be a persistent social knowledge management service, scalable with the number of users represented and the number of social sources providing input. Such a service should support a variety of requests from social applications through a basic API. Furthermore, depending on where users store their social information, the search workload imposed by applications can lead to socially-informed routing of requests within the computing system supporting the service.
2

This dissertation makes two main contributions. First, it presents the design and evaluation of such a social knowledge service, Prometheus. Second, it proposes the projection graph model to study the network properties that the service’s computing nodes acquire during the mining of social information from applications.
The next two sections (Section 1.1 and 1.2) present the types of social information collected by Prometheus and the system architecture used to support and manage these social data. Section 1.3 expands on the network properties that system peers acquire during application traversals of the user social graph. Section 1.4 presents the thesis and extracts relevant research questions addressed through this dissertation. Section 1.5 summarizes the research contributions and Section 1.6 outlines the chapter structure of this dissertation.
1.1 Collection and Use of Social Information
Social information can be collected and managed within the context of an application, as in the examples presented earlier, or can be exposed from platforms such as online social networks (OSNs) (e.g., Facebook, Google+, etc.), which are speciﬁcally designed to collect and manage social information on user’s behalf, and make it available to 3rd party online applications and services. In such networks, however, hidden incentives for users to have many “friends” can lead to declarations of contacts with little connection in terms of trust, interactions, common interests, shared objectives, or other such manifestations of real social relationships [GWH07]. For example, 90% of Facebook users perform 70% of their interactions with only 20% of their friends [WBS+09].
Alternatively, interaction-based social information provides an unprecedented level of detail compared to the binary declared relationships typical of OSNs. First, it provides the opportunity to quantify the strength of the social relationship based on domain-speciﬁc
3

metrics, such as quantity (e.g., phone call duration or number of characters in instant messaging exchanges) and frequency. Second, it conveys more accurate information than declared relationships, which are generously created and rarely removed. However, there are declared relationships that could not be removed, even if rarely supported by interactions, such as family relations or long lasting ties with close friends. Thus, a social application must wade through a lot of noise embedded in the collection of such social information in OSNs to provide targeted functionalities.
In this work, we argue that the combination of social information from diverse application domains can enable novel socially-aware applications. For example, a context-aware phone-call ﬁltering application (e.g., CallCensor [KFA+10a]) may ﬁlter calls when caller Bob tries to reach callee Alice, based on 1) the declared professional relationship between them in LinkedIn, 2) the personal relationship between them in Facebook, 3) the phone call interactions between them, and 4) the current collocation of Alice with other individuals. A social knowledge service could store all these types of social information about Bob and Alice and allow the mobile application to query for a particular type of social edge connecting Bob and Alice within the social graph. Using this combined information, personal calls can be automatically silenced during professional meetings, but co-workers’ or other professional-related calls are let through.
Therefore, such a social knowledge service should manage and expose to applications a combination of declared and interaction-based information from diverse social sources, as well as location and collocation information. This wealth of information can 1) lead to a more accurate inference of trust and incentives for resource sharing [KFA+10a, IBK12], 2) help identify social contexts, e.g., for geo-socially-aware data sharing when in a personal vs. professional context [KFIB09], and 3) enable novel classes of social applications [AKFI10, KFA+10a, IBK12].
4

1.2 Management of Social Information
The graph constructed from the social knowledge service could be stored and managed by a wide range of system architectures, as illustrated in Figure 1.2.
Figure 1.2: Decentralization of users’ social information in diﬀerent system architectures. A mobile device can typically hold only the user-owner’s social circle. Centralized company servers have access to all users’ social data. A P2P network node holds information about a small subset of users. On one side of the spectrum, the social graph could be stored in a centralized way on company servers, and exposed to services and applications via APIs. However, the business model of a centrally administrated architecture (e.g., Facebook, Google, etc.) is typically based on selling users’ data to 3rd party companies for advertising [NM09, Con12, Gun11]. Therefore, there are no incentives or appropriate business models to store social data for free and, at the same time, respect user privacy and allow users full control over their data. Additionally, users must trust their provider for complying with privacy and availability policies and not practicing “Big Brother” monitoring, which is especially important when it comes to aggregated collection of social information [Nis04, BDMN06]. Furthermore, some OSNs institute particularly draconian policies concerning the ownership of user-contributed information and content. For example, users cannot easily delete their OSN proﬁles (e.g., from Facebook servers); they cannot export their social data to a service of their choice in a transparent and easy way (e.g., from Facebook to
5

Google+); and the use of social information is restricted by the functionalities oﬀered within the OSN that manages it. In summary, current OSN users depend on information collected and exposed by centralized OSNs and have to trade privacy and ownership of their data, as well as transparency in usage of their data by 3rd-party companies, for service availability and functionality.
On the other side of the spectrum, as shown in Figure 1.2, the users’ social data could be managed by the users’ mobile devices in a fully decentralized fashion [MMC09, POL+09, SRA10, TPI11]. Much of the social information is nowadays generated by mobile devices. However, they are inherently unsuitable for running a complex social service that combines social information from multiple sources, performs multi-hop inferences on multiple users’ social data (not just the device’s owner) and exposes these inferences to applications and services of many users. This is due to resource constraints: the mobile devices may not be always online or synchronized to support up-to-date inferences; and computational resources, and more importantly energy, are likely to be scarce.
In between these two extremes, there is a wide range of distributed solutions where groups of users have their social information stored on the same machine. Of the various distributed architectures, the peer-to-peer (P2P) architectural approach [BSVD09, SVCC09, CMS09, AR12, GGS+11, KFA+10a] has signiﬁcant beneﬁts over centralized systems and mobile devices. In the P2P approach, the social graph is divided into subgraphs and stored and maintained by the P2P system in a decentralized fashion across the user-contributed peers. Therefore, a social knowledge service that uses a P2P architecture can: 1) eliminate single points of failure and provide better user control over privacy of social data compared to centralized systems (e.g., Facebook) and, 2) provide better service availability and functionality for social applications mining the social graph than mobile devices.
6

1.3 System Traversal of Social Graphs
Regardless of the type of system architecture, the computing nodes (company servers, peers or phones) are “connected” with each other because of the social ties connecting the users-owners of the social data stored on each node. When an application submits requests in the system to traverse the social graph, the requests will be forwarded between computing nodes in a manner informed by the way the graph is divided and stored in these nodes. In particular, the routing of requests between nodes can follow the social edges connecting users over multiple social hops. To study the properties of this socially-informed routing we use projection graphs. In these graphs, computing nodes are connected if users storing their data on diﬀerent nodes are directly connected in the social graph. Furthermore, during request routing, system nodes acquire particular network centrality properties because of the users’ position in the social graph, and could be forced to serve a high (or low) load of requests. These load imbalances could be signiﬁcant for centralized systems, but especially for decentralized systems such as P2P networks, where peers are typically less resourceful than company servers, are interconnected over high delay network connections and exhibit higher churn. Consequently, studying the projection graph and the centrality properties of the P2P system that supports a social knowledge service such as Prometheus can reveal opportunities to inform the service’s design for better data caching, data replication, or system load balancing. Furthermore, these properties can be used to inform the design of applications using the social graph, thus improving overall application and system performance.
7

1.4 Thesis and Research Questions
In general, a social knowledge service should: 1) be able to store and manage social information from multiple sources in the form of declared and interaction-based social edges, 2) distribute this aggregated information on a P2P system instead of a mobile-based or centralized system, for better user-controlled privacy, service availability and functionality, and 3) expose this aggregated information via an inference API, thus enabling novel socially-aware applications and services. Furthermore, the decentralization of the service’s social graph on multiple peers can inﬂuence the routing of queries in the system. Hence, studying the network centrality properties acquired by particular peers can reveal opportunities to inform the design and improve the performance of the social knowledge service and other socially-aware distributed applications and services. These observations on the collection and management of social information via a social knowledge service, and the use of social information from applications and services lead to this dissertation’s thesis: Embedding social information in the design of a distributed social data management system leads to improved service availability and query response time, reduced system overhead and increased resilience to attacks. This thesis raises a number of research questions which motivate the work presented in this dissertation:
• How can the system store and manage users’ social data, collected from multiple sources, in a decentralized fashion?
8

• How can the system process social graph information on behalf of social application and service requests, while oﬀering users privacy and access control to their data?
• How can the system take advantage of social knowledge from the user graph to enhance service scalability, availability and inference functionality?
• How does the topology of the decentralized social graph aﬀect the routing of application queries in a social knowledge service?
• How does the degree of social data decentralization aﬀect the network properties of nodes in such a service?
• How can a system or application designer use these node network properties to inform the design, and thus improve the performance, of distributed applications and systems?
1.5 Research Contributions
The research approach we followed to support this thesis can be grouped into two main parts. First, we designed, implemented and evaluated Prometheus, a large-scale distributed system for social data management. Our work on Prometheus resulted in the abstraction of several network properties that are applicable to many similar systems. This abstraction led to the projection graph, a generalized model of these distributed systems. Within this second part, we deﬁned a model for the projection graph, an evaluation of its network properties and how they can be used to design more socially-aware applications and P2P overlay systems. The research contributions of this dissertation are described in more detail in the next paragraphs.
9

First, we design Prometheus [KFA+10a], a socially-aware P2P service, that manages user social information and exposes it to applications and services through an interface that implements non-trivial social inferences. This service collects social information from actual interactions between users within multiple environments (e.g., OSNs, email, mobile phones), and stores it on user-selected peers. Thus, it maintains richer and more nuanced social information than current OSNs, which can lead to more accurate inferences of trust, interests, and context. Prometheus represents social information as a directed, weighted and labeled social multi-graph distributed on a P2P network comprised of usercontributed peers. Access to social data by applications is controlled by user-deﬁned policies.
Second, we demonstrate that Prometheus’ socially-aware design increases service availability, improves social inference execution performance and enhances resilience to attacks. This is shown experimentally via simulations on real social graphs and via worldwide large-scale experiments on hundreds of machines on the PlanetLab testbed [Pla12].
Third, we deﬁne the projection graph (P G) [KI11] emerging from the decentralization of a social graph on a P2P system such as Prometheus, and study its network properties. We discover that within a range of social data decentralization on the P2P network, the projection graph inherits the network structure of the social graph it projects. We identify experimentally this range through the study of three classical network centrality measures: i) degree centrality, ii) node betweenness centrality, and iii) edge betweenness centrality, We investigate how these metrics in the projection graph correlate with the metrics of the social graph, while varying the degree of social data decentralization in the system (as seen in Figure 1.2).
Fourth, we empirically demonstrate how the projection graph centrality properties can be used to enhance application performance. We focus on social data search and experimentally show signiﬁcant improvements on search success rate, as well as reduction of the
10

expected system overhead during the traversal of the social graph distributed on multiple peers. Fifth, we empirically demonstrate how the projection graph centrality properties can be used to reduce overlay overhead in a P2P system that stores a social graph. We focus on unstructured P2P overlays and experimentally show how we can leverage the projection graph properties to construct an overlay that improves overall success rate in social search as well as reduces system overhead imposed by the application search queries.
1.6 Dissertation Outline
The outline of this dissertation is described in the following paragraphs. Chapter 2 presents the details of the Prometheus’ design. Chapter 3 examines experimentally Prometheus’ performance under high-stress workloads from emulated applications on a local 10-node cluster and on a hundred machines on PlanetLab. Furthermore, it demonstrates the system’s usability with CallCensor, a mobile social application which imposes real-life constraints. Chapter 4 discusses the resilience of a socially-aware system such as Prometheus to attacks from malicious users and peers. Chapter 5 introduces the projection graph and presents a formal model for the emerging projection graphs in P2P systems such as Prometheus. Chapter 6 presents the analytical relations of the three social network metrics between projection and social graphs. Chapter 7 examines experimentally on real networks the association between projection and social graphs and estimation methods for the centrality metrics. Chapter 8 demonstrates the use of projection graph properties in the traversal of distributed social graphs at the application level, as well as for the overlay organization of unstructured P2P networks.
11

Chapter 9 presents a literature review in the main research areas covered by this dissertation. Chapter 10 discusses a set of lessons applicable to previous social-based P2P systems and provides guidelines for the design of future socially-aware distributed systems. Finally, Chapter 11 concludes this dissertation with a summary of the main ﬁndings and a discussion on future research directions.
12

Chapter 2: Decentralized Social Data Management with Prometheus 1
Prometheus is a socially-aware P2P service that manages the social information of registered users in a decentralized fashion on user-contributed peers. Social information populates the Prometheus-managed social graph via social sensors. Access to social data is controlled by user-deﬁned policies. This social information can be exposed to a wide range of applications and services through an API that implements non-trivial social inferences. In order to better understand the functionality of the Prometheus service and how it supports novel socially-aware applications, we ﬁrst identify in Section 2.1 its role in the social hourglass infrastructure proposed in [IBK12] In Section 2.2 we present the design objectives of this service and in Section 2.3 we present in detail the design characteristics that enable these functionalities.
2.1 Prometheus Overview
The social hourglass infrastructure (illustrated in Figure 2.1) consists of ﬁve main components: social signals, social sensors, personal aggregators, social knowledge service and social applications. Social signals are unprocessed user social information such as interaction logs (e.g., phone call history, emails, etc) or location and collocation information.
1Portions of this work have been previously published in [KFA+10a, IBK12] and are utilized with permission of the publisher.
13

User social sensors parse the users’ social signals, analyze them and send processed social information to the personal aggregator of the user.
A user’s personal aggregator combines social information from the user’s sensors and produces a personalized output based on user preferences. This is the social input of a social knowledge service (SKS). Based on this input, the SKS builds an augmented social graph which is decentralized on user-contributed machines. The social graph can be mined by applications and services through an API that implements social inferences. Prometheus fulﬁlls the role of the SKS in the social hourglass infrastructure.
SOCIALLY-AWARE APPLICATIONS

Roommate Finder

Sofa Surfer

CallCensor

Novel applications use social data to provide socially-aware functionalities
Stored data can be accessed by applications through a Prometheus API

Prometheus stores social data into a distributed social graph

A1

A2

A3

Personal aggregators collect, fuse, and personalize sensor output

S11

S21

S22

S32 S33 S43

NETFLIX
Linked in facebook
citeulike

Valve

You Tube Bluetooth
reddit Google

SOCIAL SIGNALS

Social sensors analyze social signals and quantify social relations
Social signals encode social data

Figure 2.1: Prometheus in the social hourglass infrastructure. [IBK12]. c 2012 IEEE.

2.1.1 Social Input: Social Sensors and Personal Aggregators
Current socially-aware applications and services depend on what we refer to as social signals: information that exposes social relationships between people. A vast diversity of so-
14

cial signals already exist as byproducts of Internet- or phone-mediated interactions, such as email logs, comments on blogs, instant messaging, ratings on user-generated content, phone call history, or via face-to-face interactions determined from (GPS or Bluetoothreported) collocation data. For example, a social signal could reﬂect the interactions of two users A and B over a soccer video posted on YouTube by user A. These interactions could reﬂect comments, “likes”, other video sharing, friendship creation, etc.
Social sensors analyze social signals of users. Sensors are applications running on behalf of users on various platforms such as their mobile phone, pc, web browser, or trusted 3rd party services, and transforming the domain-speciﬁc interactions for a social activity into a weighted and labeled social edge.
Two types of social ties can typically be inferred from user interactions. The ﬁrst type, object-centric ties, are identiﬁed through the use of similar resources or participation in common activities. Examples include tagging the same items in collaborative tagging communities such as Delicious or CiteULike, repeatedly being part of the same BitTorrent swarms, as well as ties inferred from recorded collocation traces [MLF+08] or personal conversations [LBBP+11]. The second type, person-centric ties, are determined from declared social relationships (e.g., in online social networks), or declared membership to groups (e.g., networks and groups in Facebook or LinkedIn).
Many such sensors already exist, although they may not output social ties as they have been implemented in diﬀerent contexts and for diﬀerent purposes. For example, these sensors record and quantify user activity in online social networks [LKG+08], co-appearance on web pages [MMH+06], or co-presence recorded as collocation via Bluetooth [EP06].
All sensors deployed on behalf of a user report social edges speciﬁc to each sensor’s domain to the personal aggregator of each user, with the following format: ego : <alter , label , weight> e.g. ,
15

A: <B, s o c c e r ,0.1 > A: <B, f o o t b a l l ,0.2 >

( from s e n s o r r e a d i n g YouTube s i g n a l ) ( from s e n s o r r e a d i n g NFL w e b s i t e s i g n a l )

The personal aggregator, a trusted application typically running on a user-owned device (laptop, desktop, mobile phone, etc), fuses multiple same activity social edges and personalizes information to user preference. The aggregator could perform sophisticated analysis on these edges, such as diﬀerentiating between routine encounters with familiar strangers and interactions between friends [EP06]. Weights can be assigned on each edge as a function of the number and frequency of interactions which allows for a more accurate representation of the relationship strength [XNR10]. Therefore, the aggregator incorporates all sensors’ input for the same domain, and outputs social data corresponding to labeled and weighted directed edges for its owner and sent as input to Prometheus in the following format:
<ego , a l t e r , l a b e l , a g g r e g a t e d weight> e.g. , <A, B, s p o r t s ,0.15 >

If the labels given by the social sensors are very domain-speciﬁc, the aggregator may apply more general labels to enhance data usability by the user’s social applications. Also the weight can be personalized further by the user, who can prioritize sensor input based on importance for his social applications.

2.1.2 Prometheus as a Social Knowledge Service

The SKS provides a mechanism for storing and managing user social data and exposing them to applications and services. Prometheus, which ﬁlls-in the role of SKS in the social hourglass infrastructure, distributes the social information on multiple peers contributed by users and performs replication for better service availability and data durability. Furthermore, access to social information is subject to user-deﬁned access control policies.
16

SOCIAL SENSORS AND PERSONAL AGGREGATORS

SOCIALLY-AWARE APPLICATIONS
Is the incoming call Who should I invite personal or work related? to the pop concert?

<A, B, work, 0.1> <C, D, music, 0.2> Top 2 relations of B? {A and C}

PROMETHEUS GRAPH

music,0.3 work,0.1

B
work,0.2

school,0.1 music,0.3

A

music,0.15

C

school,0.3

movies, 0.3

music,0.25

E

movies,0.2

games,0.3

D

movies,0.3

work,0.3

F

Figure 2.2: Prometheus input, social graph maintained, and output to applications. Social input from aggregators is stored as a directed, labeled and weighted multi-graph. Applications mine the graph via Prometheus API social inferences.

Figure 2.2 presents an overview of the Prometheus architecture. The information reported by the users’ aggregators is processed by the service to create a weighted, directed, labeled, and multi-edged social graph, where vertices correspond to users and edges correspond to interactions between users as reported by their aggregators. The interactions are described with a label (e.g.,“work”, “hiking”) and a weight that speciﬁes the intensity of the interaction.

2.1.3 Output to Applications and Services

Prometheus exposes an interface to a rich set of social inference requests computed over the distributed social graph. For example, an application can request on its user’s behalf to receive her top relations over a particular label. Similarly, it can request the social strength between its user and another user not directly connected in the social graph. Prometheus provides the mechanism by which inference requests can access not only a single user’s social graph (i.e., directly connected users), but also the social information of users located several hops away in the global social graph.

17

All inferences are subject to user-deﬁned access control policies enforced by the trusted peers of the user-owner of the data. These policies allow users to have ﬁne-grained control over the access of all or parts of their graph by other users. For example, these policies can specify access control as a function of social labels.
2.1.4 Prometheus in Use: SofaSurfer Application
A typical user application scenario is presented below for explaining how Prometheus is used in the context of the social hourglass infrastructure. Let us assume that user Bob installs a new application, SofaSurfer, that allows him to tap his social relations and identify who in his social circle to ask for hosting while on a low-budget road trip. At installation, the application checks with the Bob’s aggregator which of the required and optional social sensors he is registered with. Assume that Bob has accounts on Facebook, Skype, Google (and uses the chat utilities on all these platforms), LinkedIn, and is active on a Team Fortress 2 (TF2) game server, and all the corresponding social signals are observed by previously deployed social sensors running on Bob’s behalf.
These sensors consequently report Bob’s activity to Prometheus, subject to a personalized ﬁlter stored and applied by his aggregator. For example, the instant messaging activity is aggregated into a value recorded on Prometheus that gives more weight to Google Chat than to Skype chat activity, the latter being mainly used for work interactions. This personalization ﬁlter can be updated rarely—due to signiﬁcant changes in activity patterns or to new social sensors deployed—or can be left to a default setting that weighs equally all signals.
SofaSurfer will query Prometheus for a list of Bob’s social contacts that are geographically close. Consequently, Prometheus will 1) retrieve Bob’s 1-hop social neighborhood, 2) use Bob’s location to ﬁlter-out those not within his geographical proximity, and 3)
18

order the remainder of contacts based on a social strength with Bob. Among contacts can also be “friends of friends” (i.e., 2-hop social neighborhood), subject to user-speciﬁed application-related preferences. For example, the application might allow Bob to specify that friends of friends connected via Facebook friendships are trusted enough if also linked over direct TF2 interactions with Bob (i.e., they played together on TF2). If not all necessary social signals are available for Bob, they will be identiﬁed when the application is ﬁrst installed. An out-of-band service lists the various implementations of sensors and their social signals. Bob will be prompted to agree with the deployment of missing sensors. His aggregator, as his personal assistant, provides the credentials for these sensors (e.g., the Facebook password to access wall posts). Sensors are deployed on where each social signal is (e.g., as a Facebook application) or on user-controlled platforms (e.g., a TF2 sensor running on user’s desktop). The cognitive load on the user is determined by the level of sophistication desired for social inferences, from default, onesize-ﬁts-all settings to fully personalized.
2.2 Prometheus Design Objectives
Prometheus was designed to fulﬁll the following system objectives:
• Extensibility: the service should be independent of the diﬀerent types of social information stored.
• Accessibility: the social information should be exposed to applications and services through an API that implements basic social inferences.
• Privacy and Access Control: users should be able to control where the social information is stored and what is accessed by applications and services.
19

• Availability: the service should be able to cope with peer churn and allow users to control the degree of availability of their data.
• Durability: the social information should not be lost due to peer failures, even if not always available for use.
• Scalability: the service should be scalable to thousands or even millions of users and peers.

2.3 Prometheus Design

PROMETHEUS PEER ARCHITECTURE

Social Graph Management

Privacy Management

Trusted Peer Group Management

Scribe

Past

Pastry/DHT

Figure 2.3: Overview of the Prometheus architecture. Prometheus peers organized using Pastry, a DHT-based overlay, Scribe, a DHT multicast infrastructure, and Past, a DHT storage system. Same color machines comprise a user’s trusted peer group allowed to decrypt and mine the user’s social subgraph. Continuous (red ) arrows show communication for social graph and group maintenance. Prometheus inferences are executed between peers in a decentralized fashion (dashed arrows).

The Prometheus P2P network is organized using Pastry [RD01a], a distributed hash table (DHT)-based overlay (Figure 2.3). Prometheus uses Past [RD01b] for replicated storage of the social data, which can be stored encrypted at any peer. A registered user creates a group of trusted peers by selecting speciﬁc peers to manage her social data inserted by the user’s aggregator. Only such a trusted peer selected by the owner of the social data can decrypt the social data stored on Past. This group of trusted peers allows improved

20

service availability of data decryption and processing for social inferences. The maintenance of the trusted peer group is done by leveraging Scribe [CDKR02], an applicationlevel DHT multicast infrastructure.
Prometheus uses a public-key infrastructure (PKI) to ensure both message conﬁdentiality and user authentication. All users have public/private keys for both themselves and their trusted peers accessing their social data. For access control purposes, users are identiﬁed by their personal public keys. These keys are used by the aggregators to encrypt and sign all data submitted to the service. Also, applications and services use them for secure communication with Prometheus when requesting and receiving social information. In the future we plan to enhance the security of communication between the various entities involved in Prometheus using the Transport Layer Security protocol [TD08]. To accomplish the various Prometheus functionalities, each peer currently runs three components: 1) for social graph management, 2) for privacy management, and 3) for trusted group management. Applications submit requests to mine the social graph via a distributed interface. Answers to these requests are subject to user-speciﬁed access policies.
Prometheus’ design leverages user social relations to increase service availability and improve social inference performance. In particular, social awareness is embedded in the design of the service in two ways. First, Prometheus allows users to select trusted peers to maintain their social subgraph based on out-of-band relationships. Socially-incentivized users keep their computers online, thus reducing churn [TCL08, LD06] and consequently increasing service availability for their friends’ social inference requests.
Second, socially-related users are likely to select the same trusted peers to store their social subgraphs (i.e., friends have common friends who contribute peers in the system and thus select the same trusted peers). This enables collocation of neighboring users’ data on the same peer(s), leading to scalability and reduced replication cost [PES+10]. Therefore, complex social inferences over several social graph hops can be fulﬁlled locally,
21

thus reducing application response time. At the same time, user data collocation reduces the dependability on many peers and thus reduces the opportunity of malicious peers to inﬂuence service requests, as discussed in Chapter 4. In the next subsections we present the design details of Prometheus.
2.3.1 Building Blocks: Pastry, Past and Scribe
Prometheus leverages Pastry-based systems as building blocks for several of its P2P functionalities. Pastry [RD01a] is a scalable substrate for peer-to-peer applications, which facilitates request routing between peers and deterministic placement and retrieval of objects in the system. Peers participating in a Pastry-based overlay form a decentralized, self-organizing and fault-tolerant network. Pastry is used in Prometheus to organize the network of peers into a highly scalable DHT overlay. When joining such an overlay, peers acquire a unique, uniform random ID from a circular 128-bit ID space (typically the cryptographic SHA-1 hash of its IP address or public key). Application-speciﬁc messages sent between peers are represented by their own unique ID, depending on the application speciﬁc functionality. When presented with such a message, a Pastry peer eﬃciently routes it to the peer currently live and with peer ID numerically closest to the message ID. The expected number of steps the message is forwarded in the overlay is less than log2bN under normal operation, for a network size of N live peers (b is a conﬁguration parameter with typical value 4). Also, eventual delivery of the message is guaranteed, unless l/2 peers with adjacent IDs fail simultaneously (l is a conﬁguration parameter with a typical value of 32). To achieve these guarantees, each peer maintains a routing table with log2bN × (2b − 1) + l entries (i.e. peer IDs pointing to particular peer IPs). For example,
22

with b = 4, l = 32 and N = 108 peers, a routing table of a peer would contain on average 137 entries and the expected number of routing hops would be 7.
In order to minimize the network distance travelled by a message while being forwarded to the closest peer ID, Pastry utilizes network proximity of peers (e.g., ping delays) to choose the network-wise closest peer for each forwarding step. During the routing of the message from peer to peer, the application instance of each peer which is responsible for that type of message is notiﬁed and can perform application-speciﬁc computations or take application-speciﬁc actions, relevant to the message received.
Past [RD01b] is a P2P scalable storage system that stores and retrieves ﬁles in a network of peers using the Pastry DHT overlay. Prometheus uses Past to store ﬁles containing the encrypted social data of users. In Past, a peer computes the quasi-unique ﬁle ID with a 160-bit hash of the ﬁle’s name, owner’s name or public key and a random salt, and uses the 128 most signiﬁcant bits of this ID as a Pastry message ID for the ﬁle to be stored or retrieved. Replication within Past guarantees that the data will be available unless all replicas are lost (or the corresponding peers fail simultaneously and unexpectedly). Storage balancing performed in Past allows high utilization of the storage resources of peers. In addition, caching allows faster access to popular ﬁles and load balancing on peers.
Scribe [CDKR02], an application-level DHT multicast infrastructure is leveraged for the maintenance of the trusted peer group of each user. Scribe allows peers to join highly dynamic publish/subscribe groups and is implemented on top of Pastry. As mentioned earlier, peers trusted from a user to manage her social data join her trusted peer group and respond to inference requests from applications. In Scribe, a peer computes the message ID (i.e., the group-topic ID), using the hash of the topic’s name. It then publishes the message using this ID to the rest of the peers subscribed to the particular group,
23

by sending it through the group multicast peer tree implemented on top of the Pastry routing protocol.
2.3.2 User Registration
A user registers with Prometheus from a trusted device (e.g., their pc) by creating a uniform random U ID from the circular 128-bit ID space of the DHT (typically the hash of her public key). At registration time, she speciﬁes the peer(s) she owns (controls) and willing to contribute to the network (if any). Through her trusted device, she creates a mapping between U ID and the list of these peers’ IP addresses and signs it with her private key for veriﬁcation. By contacting any peer in the network to momentarily join the DHT ring, the user stores this mapping in the network as the key-value pair U ID = {IP1, ..., IPn}. When one of these peers returns from an oﬄine state, it updates the mapping with its current IP address.
A user selects, deploys, and conﬁgures the social sensors she wants to use via her social aggregator (as described in [IBK12]). She may declare particular social relationships, such as family relations, that are diﬃcult or impossible to infer by social sensors. She compiles a list of other Prometheus users with whom she shares strong out-of-band trust relations and searches the DHT storage for their machine mappings (using their U IDs). From the returned list of peers owned by these users, she selects an initial set of peers to comprise her trusted peer group.
Selecting a large set of trusted peers increases the service availability of the particular user. At the same time it may decrease the consistency of social data maintained across all trusted peers of that user, and furthermore may decrease the overall system performance due to unnecessary redundancy. As social information about a new user will be incorporated in the social graph, a user may be prompted with diﬀerent choices for trusted
24

peers (e.g., peers belonging to users with stronger ties than owners of her current trusted peers).
2.3.3 Trusted Peer Group Management
Each user has a dedicated group of trusted peers that she can expand or contract based on application need for availability of her data, and trust in the peers’ owners. Therefore, three issues concerning the trusted peer group management of a user are important: (a) group membership, (b) search for trusted peers, and (c) group churn.
A user can add peers in her trusted peer group by initiating a secure three-step handshake procedure to establish a two-way trust relationship between her and the peer owner. During this handshake process, the following steps take place: 1) the owner of the social data sends an invitation to the owner of the peer, 2) if the peer-owner trusts the dataowner not to be malicious, it replies with an acceptance message, 3) upon acceptance of the invitation, the data-owner sends to the peer owner the group keys to enable the peer to join her trusted peer group.
The group keys are transferred to the peer using an Encrypt/Sign/Encrypt process: 1) encrypting the group keys with the public key of the peer’s owner, 2) adding a plaintext on the ciphertext referring to the peer owner and signing the whole message with the group owner’s private key, and 3) re-encrypting all the above with the public key of the peer’s owner. Upon receiving of the group keys, the new peer subscribes to the Scribe trusted group of the user. The Scribe group’s handle is the concatenation of the predeﬁned string “Trusted Peer Group” and the user’s UID and can be used to publish signed messages to the group using the Scribe multicast protocol.
A user may decide to remove a peer X from her trusted group, if she no longer trusts the peer’s owner or she wants to add more stable peers in her group. To this end, the user
25

creates new group keys and distributes them via unicasts to the rest of the peers that are still trusted using the previously described Encrypt/Sign/Encrypt process. She also reencrypts her social data and replaces the copy in the DHT storage for future use. This removal of the peer is multicasted to all group peers and peer X is unsubscribed from the group. The distribution of new keys and re-encryption of the social data disallows the newly removed peer from decrypting updated versions of the user’s social data in the future.
A peer owner may also decide to remove her peer from a trusted group of another user (e.g, due to overload on the peer or malicious activity from the data owner). This request is multicasted to all the other group peers, who alert the data owner and execute the same procedure as above. If a peer becomes untrusted while oﬄine, a trusted peer from the group alerts the returning peer of the change and unsubscribes it from the Scribe group.
Service requests for a user (UID) can be sent to any peer, but only the user’s trusted peers can provide data about her. Therefore, a random peer can ﬁnd a user’s trusted peers by submitting a multicast request with handle Trusted Peer Group UID. With the multicast, all online group trusted peers are required to respond with their IP and signed membership, which is veriﬁed for authenticity with the user’s group public key. The random peer creates a trusted peer list (TPL) of IPs based on peer responses.
The multicast (instead of using anycast for just one peer) allows the random peer to have peer alternatives in case of churn or erroneous communication with the ﬁrst responding peer. Since the search for trusted peers follows the DHT routing, the responds are typically sorted in the TPL by network proximity (latency). The peer, upon creating the TPL for a user’s group, can communicate directly with the individual trusted peers, preferably the network-closest one (i.e., with shortest latency). Prometheus caches the TPL after the ﬁrst access and updates it when the trusted peers are unresponsive, changed
26

their IP, or became untrusted. Users could also apply their own policies for refreshing the local TPLs based on their usage patterns (e.g., daily).
The social graph for a user is unavailable if all her trusted peers leave the network; no service requests involving this user can be answered until a trusted peer rejoins the network. However, we ensure that generated data (i.e., input from social aggregators) are not lost while a user’s group is down via storage and replication in the DHT by Past.
2.3.4 Distributed Social Graph
Prometheus represents the social graph as introduced in [AKFI10, And10]: a directed, labeled, and weighted multi-edged graph, maintained and used in a decentralized fashion, as presented in Figure 2.4.
Multiple edges can connect two users, and each edge is labeled with a type of social interaction and assigned a weight (a real number in the range of [0, 1]) that represents the intensity of that interaction. The labels for interactions and their associated weights are assigned by the personal aggregator of each user. From an application point of view, distinguishing between diﬀerent types of interactions allows for better functionality. The latest known location of a user and an associated timestamp are also maintained as an attribute of the user’s vertex in the graph. We chose to represent the graph as directed and weighted because of the well-accepted result in sociology that ties are usually asymmetrically reciprocal [Wel88]. Representing edges as directed also limits the potential eﬀects of illegitimate graph manipulation such as spamming. We elaborate in more detail on this issue in Chapter 4.
The social data for each user U ID are stored in Past after the Encrypt/Sign/Encrypt process is applied, i.e., encrypt with the public key of the user’s trusted group, add plaintext referring to the group and sign with the user’s private key and re-encrypt with group’s
27

Figure 2.4: An example of a social graph for eight users (A-H ) distributed on seven peers. The top ﬁgure shows the mapping between users, peer owners, and trusted peers (upper left corner) and how users are connected with each other over social edges, each marked with its label and weight. The bottom ﬁgures illustrate the subgraphs maintained by peers 1 and 5. Users in dark color (e.g., A, B, C on peer 1 ) trust the peer to manage their social data. Users in light-shaded color (e.g., E, D on peer 1 ) do not trust the peer but are socially connected with users who do.
public key. The data are stored in the append-only ﬁle Social Data U ID as encrypted records. Only the user’s aggregator can append records in her ﬁle and only trusted peers can decrypt and use these records. Since the ﬁle is append-only, readers (trusted peers) can access it at any time: in the worst case, they will miss the latest update. We designed Prometheus to be oblivious to the number and diﬀerent types of social activity reported by the social sensors/aggregator, thus allowing extensibility.
Personal aggregators can send updates to create new edges, remove old edges, or modify an edge weight. Each record contains a sequence number and encrypted data with the label and its associated weight. Trusted peers periodically check the ﬁle for new records
28

and retrieve all such records: this is easily done based on sequence number comparison starting from the end of the ﬁle. The peer decrypts the new records and veriﬁes the digital signature to make sure the updates are authentic. Then, it updates the local subgraph of the user with the newly retrieved records. For short periods of time, the trusted peers may have inconsistent data, but this is not a major problem as social graphs do not change often [Gol07]. Edges may “decay” over time if few (or no) updates for those edges are received due to reduced number and frequency of social interactions associated with those labels [RD10]. This aging process should be activity speciﬁc, but it should also reﬂect the user’s social habits and interests: users who are less socially active and users with a great number of friends should have their relationships age slower. Currently, the system applies a simple aging function to reduce an edge’s weight by 10% for every week the two users do not interact over the particular label (thus, the connection never completely disappears and the aging happens slowly). A user’s aggregator may specify a diﬀerent decrement value of the weight and the time period for aging (these values are also stored in the Social Data U ID ﬁle for each user).
2.3.5 Social Inference API
Prometheus exposes to applications an API of basic social inference functions that are executed in a decentralized fashion; more complex inferences can be built on top of this set. The boolean function Relation Test(ego, alter, α, x) checks whether ego is directly connected to alter by an edge with label α and with a minimum weight of x. A mobile phone application can use this function, for example, to determine whether an incoming call
29

is from a coworker with a strong social tie, and therefore, should be let through even on weekends.
The function Top Relations(ego, α, n) returns the top n users in the social subgraph of ego (ordered by decreasing weights) who are directly connected to ego by an edge with label α. An application can use this function, for example, to invite users highly connected with ego to share content related to activity α.
Preliminary experiments (shown in [KFA+10a]) revealed volatility of the peer-to-peer communication and long response delays during multi-hop inference execution on a worldwide testbed. Thus, the following API functions were designed to oﬀer better quality of service to applications by allowing them to deﬁne, not only inference-speciﬁc parameters (such as label and weight), but also a timeout parameter T , which declares the application waiting time per hop.
The function Neighborhood(ego, α, x, radius, T) returns the set of users in ego’s social neighborhood who are connected through social ties of a label α and minimum weight of x within a number of social hops equal to radius. The radius parameter allows for a multiple hop search in the social graph (e.g., setting radius to 2 will ﬁnd ego’s friends of friends). Our CallCensor mobile phone application which silences ego’s cell phone during meetings at work (Section 3.5) uses this function to determine if a caller is in ego’s work neighborhood in the social graph even if not directly connected.
The function Proximity(ego, α, x, radius, distance, timestamp, T) is an extension of the neighborhood function which ﬁlters the results of the neighborhood inference based on physical distance to ego. After the location information is collected for ego and the function neighborhood returns a set of users, proximity returns the set of users who are within distance from ego and their location information is at most as old as timestamp (assuming synchronized clocks with online time servers). Users who do not share their location or have location information older than the timestamp are not returned. A mobile phone
30

application might use this function to infer the list of collocated coworkers within a certain distance of ego.

The function Social Strength(ego, alter, T) returns a real number in the range of [0, 1] that quantiﬁes the social strength between ego and alter from ego’s perspective. The two users can be multiple hops apart in the social graph. However, we limit the indirect path length connecting the two users to two hops, using a well-accepted result in sociology known as the “horizon of observability” [Fri83], where two individuals are unlikely to have any meaningful social relationship or being aware of each other’s work if connected over more than two social hops. The return value is normalized, as shown below, to ego’s social ties, to ensure that the social strength is less sensitive to the social activity of the users. Next, we elaborate in more detail on how this function is calculated on the social multi-graph.

Assume that Λi,j is the set of labels of edges connecting users i and j and w(i, j, λ) is the

weight of an edge between users i and j over a label λ. Ji is the set of directly connected

neighbors to i. Then N W (i, j) is the overall normalized weight between two directly con-

nected users i and j:

w(i, j, λ)

N W (i, j) =

∀λ∈Λi,j

max

w(i, j, λ)

∀j∈Ji ∀λ∈Λi,j

(2.1)

Also, assume that Pi,m is the set of diﬀerent paths p ∈ Pi,m joining two indirectly connected users i and m. Using the results from [Fri83], we limit the indirect paths to 2 social hops and also take into account the number of indirect paths connecting users i and m. Then S(i, m) is the return value for social strength between users i and m, over a multi-level 2 hop path:

31

<GAMES, 0.5>

D

<MOVIES, 0.1>

A

<GAMES, 0.5>

NW(A,B) = 0.3 / 0.5 = 0.6 NW(B,C) = 0.5 / 0.5 = 1.0 NW(A,E) = 0.2 / 0.5 = 0.4 NW(E,C) = 0.1 / 0.2 = 0.5

<WORK,0.1>
<WORK,0.1> <SCHOOL,0.2> <SCHOOL,0.3> <S<CSHCOHOOLO,0L.2,0>.2>

<SPORTS,0.4>

B

<SPORTS,0.5>

C

<SCHOOL,0.1> E

Figure 2.5: A calculation example of the social strength inference function.

S(i, m) = 1 −
∀p∈Pi,m ∀j∈Ji∩Jm

min{N W (i, j), N W (j, m)} 1−
2

(2.2)

In Figure 2.5 we demonstrate on a weighted, directed multi-graph the calculation of the social strength between users A and C, over 2-hop paths. Using the normalized weights N W between all involved users (shown below the graph), we can calculate the social strength between A and C:

S(A, C) = 1 − S(A, C) = 0.44

1

−

min{N W (A,B),N W (B,C)} 2

1

−

min{N W (A,E),N W (E,C)} 2

Such a function could be used, for example, to estimate social incentives for resource sharing. Supported by the results and discussion in [Fri83], we expect the expression 2.2 of the social strength request to be an accurate quantiﬁcation of the tie strength between two indirectly connected users. However, more qualitative studies are needed to establish the user-perceived quality of the function’s outcome.

32

2.3.6 Access Control Policies

Users can specify access control policies (ACPs) upon registration and update them any time thereafter. These policies, stored on each of the user’s trusted peers, are applied each time an inference request is submitted to one of these peers to access social information for the particular user. For availability, the policies are encrypted with the group public key, signed with the data owner’s private key, re-encrypted with the group public key and stored in the DHT, allowing a rejoining trusted peer to recover updated policies. The same mechanism used for updating the social graph is used to update policies. As future work, we plan to investigate the provision of strong consistency and conﬂict resolution for policies.
Currently, we consider ACPs that are comprised of two parts: (1) the social data object(s) to be accessed and (2) the speciﬁcation(s) to be met before access is granted for the particular data object(s). They are deﬁned as entries of the ACP U ID ﬁle in the following format:
<S o c i a l Data Object ( s )> : : <ACP S p e c i f i c a t i o n ( s )>

In Table 2.1 we present a list of access control policy deﬁnitions comprised of these two parts.

Table 2.1: Access control policy deﬁnitions for a user in Prometheus.

Social Data Object(s) ACP Speciﬁcation(s)

Social edge label α Social distance ρ

Social edge weight χ Social edge label γ

User location Λ

Social edge weight y

Originator user B

Originator peer P

Intermediate user C

Intermediate peer M

Application S

Originator’s location λ

33

Following is a list of social data objects for which a user U ID1 (owner of the information) can allow access to an inference request originating from user U ID2:
• Social edge label α: A policy to control access to social edges of user U ID1 with other users, over label α, regardless of the weight.
• Social edge weight χ: A policy to control access to social edges of user U ID1 with other users, that have minimum weight χ, regardless of the label type.
• User location (Λ1, Λ2, Λ3): A policy to control access to user U ID1’s last stored location with latitude Λ1, longitude Λ2 and altitude Λ3.
By design, ACPs are whitelists. To specify who is allowed to access these categories of social information, user U ID1 can set the following access policy speciﬁcations:
• Social distance ρ: User U ID2 must be within a maximum distance of r hops in the social graph from user U ID1.
• Social edge label γ: User U ID2 must be connected with user U ID1 over a social edge of label γ (directly or indirectly).
• Social edge weight y: User U ID2 must be connected with user U ID1 over a social edge of weight y, regardless of the label type.
• Originator user B: The inference request must originate from user B (=U ID2).
34

• Originator peer P : The inference request must originate from peer P .
• Intermediate user C: The Inference request must be forwarded from user C (as part of a multi-hop inference request).
• Intermediate peer M : The inference request must be forwarded from peer M (as part of a multi-hop inference request).
• Application S: The inference request must come from application S.
• User location (λ1, λ2, λ3): The inference request must originate from a user U ID2 with current location latitude λ1, longitude λ2 and altitude λ3.
Each of these access policy speciﬁcations can be placed to fulﬁll the requirements to access any of the data objects stated earlier. These speciﬁcations are meant to establish the minimum rights needed from a request to access a particular piece of social information of the user-owner of the social data. Each of the data objects, as well as each of the speciﬁcations, can be combined with logical operators such as AND, OR, NOT, etc, to create more complex access policies. A default set of access policies for user Bob is shown in Figure 2.6.
< α1 >::< B = Bob AND P = Bob s peer > < α2 >::< B = Bob AND P = Bob s peer > ... < αm >::< B = Bob AND P = Bob s peer > < x = 0 >::< B = Bob AND P = Bob s peer > < Λ1, Λ2, Λ3 >::< B = Bob AND P = Bob s peer >
Figure 2.6: Example set of default access control policies of user Bob.
35

To verify the access rights, Prometheus may call its inference functions, when applicable. For example, to detect whether the originator of the request is within N -hops, the originator is checked against the result of a N -hop neighborhood inference. ACPs also allow for blacklisted users (and their peers) for convenience. These users and peers are blocked either because the owner of the social data doesn’t want to share any social information with them, or the system has ﬂagged them as malicious.
Figure 2.7 shows an example of the set of access control policies for user Bob. By deﬁning the policy for label work with the speciﬁc requirements, Bob allows work -related social information to be given to requests coming from users within 2 social hops (i.e., friends and friends-of-friends), that are also connected with him over work label, or when these requests come in from the CallCensor application. Also, he allows his parents and his brother to access his exact location at any time. However, everybody else must be in the same approximate area with him (within a diﬀerence δ) to retrieve Bob’s location. If a neighborhood inference request on the tango label is submitted to Bob’s trusted peer, Prometheus checks his ACP in the order Blacklist→labels→weights. User Alice is excluded from all types of inferences and cannot receive any information about Bob.
< α = hike >::< ρ = 2 AND γ = hike AND y = 0.2 > < α = tango >::< γ = tango OR γ = salsa > < α = work >::< (ρ = 2 AND γ = work) OR S = CallCensor > < α = school AND χ = 0.2 >::< (ρ = 1 AND γ = school) OR y = 0.25 OR S = CallCensor > < χ = 0.3 >::< ρ = 1 AND S = Sof aSurf er AND (C = Charles OR C = Dane OR C = Eve) > < Λ1, Λ2 >::< λ1 = Λ1 ± δ, λ2 = Λ2 ± δ > < Λ1, Λ2, Λ3 >::< B = mom OR B = dad OR B = brother > −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− < blacklist >::< B = Alice OR B = Gary OR C = Alice >
Figure 2.7: Example set of access control policies of user Bob in Prometheus.
36

2.3.7 Decentralized Inference Function Execution
We assume that applications interacting with Prometheus cache a number of peer IP addresses to bootstrap the interaction. A social inference request for user D submitted from B (e.g., Neighborhood(D, football, 0.2, 1 hop, 5 sec) in the social graph of Figure 2.4) can be sent to any Prometheus peer (e.g., peer 1). The request is encrypted with D’s trusted group public key, signed with B’s private key and re-encrypted with D’s group public key.
The receiving random peer creates D’s trusted peer list (i.e., peers 2, 3, 4, 5 and 6, as explained in 2.3.3) and forwards the request to the D’s network-closest (shortest latency) trusted peer (e.g., peer 5), which decrypts the request, veriﬁes the submitter’s identity via his public key and enforces D’s access control policies for B. If the request is allowed, the peer fulﬁlls the request by traversing the local social subgraph for the information requested by the application and then returns the result (i.e., users C, E and F ) to the application using an Encrypt/Sign/Encrypt process.
For functions that can traverse the graph for multiple hops h (e.g., Neighborhood(D, football, 0.2, 2 hops, 5 sec), the peer (peer 5) submits secondary requests for information about other users to their trusted peers, as follows. A secondary request includes the U ID of the original submitter (B) along with the U ID of the intermediary user (D) producing the secondary request, in order for the receiving peer to verify each user’s access rights. A time period of T ∗ (h − 1) seconds is given to the secondary peers (e.g., peer 2 for user C and peer 4 for user E, and locally at peer 5 for user F ) to respond with their results (peers at each hop use independent clocks for T seconds). The peer submitting the secondary requests uses the Encrypt/Sing/Encrypt process.
Each receiving secondary peer authenticates the request and checks the access control policies for the requesting user B as well as the intermediary user D. If the request is granted, the result is returned to the requesting peer. If the request still needs more in-
37

formation, that peer (e.g., at hop k) repeats the same process and submits a secondary request with an adjusted T ∗ (h − k − 1) timeout. Finally, the original requesting peer recursively collects all the replies and submits the ﬁnal result to the application.
Even though Prometheus contacts peers in parallel in each network hop, there can still be variations on the communication time between peers of the same hop, leading to extended delays. In the future, we plan to tackle this problem with the following greedy optimization. Using the trusted peer lists of users, a peer preparing to send secondary requests for the next hop could calculate the minimum set of secondary peers needed to cover all users for the next hop. For the example used earlier, if peer 5 sent the secondary request to peer 3, all users could be traversed within the same peer. This optimization can decrease request delays by reducing the number of peers to be contacted at each hop and thus the variability of request execution. Furthermore, the submitting peer can select not only the minimum set of needed peers, but also the network-wise closest set of peers. Potential conﬂicts between peer entries can be resolved using utility functions to model the gains from each level of optimization.
The possible scenarios of inference execution for a request of h hops (h ∈ H = {1, 2, . . . }) are illustrated in Figure 2.8. T A deﬁnes the time for an application to send or receive a request to a local or remote peer. T R deﬁnes the time for a request or reply to be sent between remote peers over 1 network hop. If the application is not running on the local peer, then we can assume that T A T R. If it does, then we can assume that T A 0. T D deﬁnes the time for a peer to parse a request submission or reply and act accordingly (i.e., create secondary requests or back-forward the results). We assume that T A, T R and T D are constant and independent of the number of hops a request will traverse the system. The overall delay given a number of network hops r (r ∈ R = {1, 2, . . . }) involved in the execution scenario is deﬁned as d(r), with r ≤ h. Assuming a request that traverses the social graph for h number of social hops, F (r, h) deﬁnes the fraction of social paths of this request that will force peers to traverse the system for r number of network hops.
38

INFERENCE EXECUTION SCENARIOS TA

DELAYS 1 HOPS 2 HOPS 3 HOPS

Application

TA

TD

Remote/Local

Peer 1

TA

TR

d(0)= 2TA 1TD

F(0,1)

F(0,2) F(0,3)

Application

TA

TD

TR

Remote/Local

Peer 1

TA

TR

TD Remote Peer 2
TR

d(1)= 2TA 2TR 3TD

F(1,1) F(1,2) F(1,3)

Application

TA

TD

TR

Remote/Local

Peer 1

TA

TR

TD

TR

Remote

Peer 2

TR

TD Remote Peer 3
TR

d(2)=

2TA

0

F(2,2) F(2,3)

4TR

5TD

d(3)=

2TA

0

6TR

TA

TD

TR

TD

TR

TD

TR

TD

7TD

Application

Remote/Local

Remote

Remote

Remote

Peer 1

Peer 2

Peer 3

Peer 4

0 F(3,3)

Figure 2.8: Possible scenarios of inference execution along with associated delays in the distributed infrastructure. T A deﬁnes the time for an application to send a request or receive a reply. T R deﬁnes the time for a request/reply to be sent between remote peers. T D deﬁnes the time for a peer to parse a request/reply. F (r, h) deﬁnes the fraction of social paths of a request of h social hops that force peers to traverse Prometheus for r number of network hops. d(r) deﬁnes the overall delay for a request that needs r number of network hops.

It would be tempting to model each inference execution scenario as a discrete-state Markov process with each network hop being a diﬀerent state in the execution process. However, we cannot assume exponential distribution of 1) the arrival time of requests, 2) the arrival time of secondary requests, 3) the departure time of replies (service time). This is because the future state of the execution of an inference request highly depends on the

39

past states and what portion of the social graph traversal was fulﬁlled in each of these states. Therefore, the probability of transition from the ith state (i.e. ith network hop) to the next state (i + 1)th, i.e., (i + 1)th network hop, or to the previous state (i − 1)th is not constant and not exponentially distributed.
Using the notation of Figure 2.8, and given that the various secondary requests produced are executed in parallel, we can deﬁne the overall execution delay, D(h), of a request of h social hops as follows:

D(h) = F (r, h)d(r) = F (r, h)(2T A + (2r + 1)T D + 2rT R)

r∈R

r∈R

(2.3)

As mentioned earlier, an application request can enforce a timeout T for every social hop requested. Depending on how the social graph is decentralized on peers, this timeout may be enforced up to h − 1 times, if h = r. For example, we notice that in the third scenario of Figure 2.8, peer 3 can lead peer 2 to a T timeout, and in the fourth scenario, peer 4 can lead peer 3 to a T timeout and peer 3 and/or peer 4 can lead peer 2 to T or 2T timeouts. Thus, the peer that will timeout can be at hop k, with k < r. We can assume that Q(r, k) is the probability of a request of r number of total network hops to timeout at a particular peer at the network hop k. From the above, Q(r, k) = 0 for k ≥ r. Using this probability, we can incorporate the timeout T in the equation 2.3 above, by adjusting appropriately the term 2rT R as follows:

D(h) = F (r, h) 2T A + (2r + 1)T D + B , where
r

B=
r

Q(r, k)((r − k)T + 2kT R) + 2rT R 1 − Q(r, k)

k

k

(2.4)

40

2.3.8 Retransmission Policy

From our experience with Prometheus when deployed on a highly dynamic system such as PlanetLab [KFA+10a], we noticed that 10%–25% of the requests were dropped by remote peers, due to overloaded network interfaces, reduced computing resources, etc. To tackle this problem, we introduced in the decentralized inference execution a retransmission policy for sending messages (requests or replies) between peers. Under this policy, a peer can try to send a message to another peer up to three times, with each trial timing out at 1 second. Therefore, it can take from a little over 0 and up to 3 seconds for a message to be transmitted between two peers or permanently dropped. This policy helped reduce the drop rate (less than 5% drops were observed in our new experiments on PlanetLab), but also introduced an extra delay in the inference execution process. This delay forced the request end-to-end time to vary signiﬁcantly but more predictably, depending on the number of message resends during the decentralized execution process.

0.30 2TR

4TR

0.25

6TR

0.20

PDF

0.15

0.10

0.05

0.00 0 2 4 6 8 10 12 14 16 18 Time (s)
Figure 2.9: Probability distribution function of the time delay to send 2, 4 or 6 messages between peers, when the retransmission policy is used.

41

CDF

Expected delays with no timeouts (a)

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2
0.1
0 0

2TR 4TR 6TR

5

10 15 20 25 30

Time (s)

Expected delays with 1T+4TR (3 hops) (c)

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

5

10 15 20 25 30

Time (s)

CDF

CDF

Expected delays with 1T+2TR (2 and 3 hops) (b)

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3
0.2
0.1
0 0

T=2.5s T=5.0s T=7.5s T=10.0s

5

10 15 20 25 30

Time (s)

Expected delays with 2T+2TR (3 hops) (d)

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

5

10 15 20 25 30

Time (s)

CDF

Figure 2.10: CDF of the time delay for a request with the following scenarios: (a) no timeouts, (b) 1 timeout and 2T R (r = 2, k = 1) , (c) 1 timeout and 4T R (r = 3, k = 2) and (d) 2 timeouts and 2T R (r = 3, k = 1), when the retransmission policy is used.

Figure 2.9 demonstrates how this delay varies probabilistically for the scenarios where a request involves 2, 4 or 6 messages between remote peers (i.e., 2T R, 4T R or 6T R delays from equation 2.3), under all possible combinations of these messages and the times required to be transmitted. These are the simplest cases expected in inference requests of up to 3 social hops not including timeouts, assuming that the delays for computation and communication with the application are negligible in comparison to the network delays, i.e. T D << T R and T A << T R (as shown earlier in Figure 2.8 and in equation 2.3). We notice that an increase in the number of messages involved from 2 to 4 or 6, leads to an overall time delay normally distributed with an increasing mean from 3 to 6 or 9 seconds.

42

Figure 2.10 demonstrates the execution delay when we take into account the possible cases of timeout that could occur in the inference execution for 2 and 3 hop requests (as described in equation 2.4 and assuming T D << T R and T A << T R) for timeout values T = 2.5, 5.0, 7.5 and 10 seconds. We observe that the expected delay for each scenario highly depends on the network hop that the timeout will occur (i.e., value of k in equation 2.4) and the number of network hops of the request (i.e., value of r in equation 2.4). Overall, the expected delay of a request will be a mixture of the delays shown in Figure 2.10, since an inference request could have diﬀerent portions fulﬁlled in diﬀerent peers, over multiple network hops (this was declared with the fraction F (r, h)), and with diﬀerent probabilities for timeouts at each network hop (this was declared with the probability Q(r, k)).
43

Chapter 3: Performance Evaluation of Prometheus 1
In this chapter, we present the experimental evaluation of the Prometheus performance in three diﬀerent experimental setups. In the ﬁrst two experiments, we deployed our prototype implementation of Prometheus on PlanetLab to test the system’s performance in a real distributed environment under the same high-stress workloads, while varying inference request parameters such as number of social hops to be traversed, and timeout set by the application (Section 3.4). In the third experiment, we built a weighted multigraph from real collocation and Facebook traces and assessed the system’s time responsiveness to social inference requests from a mobile application with real-time constraints (Section 3.5).
3.1 Implementation
Prometheus was implemented on top of FreePastry [Fre12b], a Java implementation of Pastry DHT [RD01a], which also provides API support for the functionalities of the components Scribe [CDKR02] and Past [RD01b]. The Keyczar library [Key12] was used for public/private key management and enforcement, as well as signing and authenticating messages when sent between peers or between application instances and peers. Furthermore, NetworkX library [Net12] was used for the social graph management.
1Portions of this work have been previously published in [KFA+10a] and are utilized with permission of the publisher.
44

We performed various optimizations and ﬁne tuning from our earlier work [KFA+10a] to better handle the communication volatility and peer churn typically observed in a distributed infrastructure, as explained in Section 2.3. We also redesigned the API as it previously required applications and peers to exchange string-formatted messages with no extensibility on the number of request ﬁelds. The new API allows applications to submit a serializable class-based request using JSON [JSO12], by deﬁning within the class object not only inference-speciﬁc parameters (such as weight and label) but also the new timeout parameter T , which declares the application waiting time per hop when requesting multi-hop inferences. Furthermore, applications and peers can deﬁne parameters such as request id and timestamp, error ﬂags, etc. Overall, the new API design enhances extensibility for future inference parameters, portability across diﬀerent computing platforms, and improves the peer-to-peer and peer-to-application communication during inference execution.
3.2 Testbeds
The Prometheus prototype was ﬁrst deployed and extensively tested on the local cluster of the Distributed Systems Group (USF), which at the time was comprised of 10 servers with quad-core CPUs Intel(R) Xeon(R) x3220, 2.40GHz, and 4GB RAM and interconnected via a Gbit Ethernet switch. Later, the Prometheus prototyped was deployed and evaluated on the PlanetLab (PL) testbed [Pla12].
PlanetLab is a network of more than a thousand machines with a wide range of computing capabilities, contributed by more than 500 research sites around the globe, and used for research on distributed systems and networking at a planetary-scale. Each machine runs PLC, a Linux-based operating system that supports distributed virtualization. Diﬀerent projects are allocated “slices” on the hardware and software of each machine, enabling them to deploy and test distributed services at the same time.
45

3.3 Experimental Setup for Performance Evaluation with Emulated Workloads
For the end-to-end performance and completion rate experiments under high-stress loads, we decentralized a social graph on selected PL machines and used emulated application workloads produced from studies on real social networks. The three metrics used in this evaluation were: (1) end-to-end response time to quantify the performance as perceived from an application point of view, (2) percentage of completion to quantify the tradeoﬀ between request response time and level of request completion, and (3) number of network messages to quantify the service overhead.
3.3.1 PlanetLab Deployment
As mentioned earlier, the PL machines are shared among multiple research projects with variable workloads and daily patterns. Therefore, their highly heterogeneous network, computation and memory resources were scarce at times throughout our experiments. To increase the number of stable and resourceful PL machines included in the experiments, we used the CoMon tool [PP12] provided by the PL organization and polled the status of the machines before each run of our experiments using the metrics shown in Table 3.1. These strict status metrics reduced the potential set of peers to about 150. However, from previous experience [KFA+10a] with Prometheus on PL, we concluded that such peers are more appropriate for long-term experiments as they are typically more stable and well-provisioned. From this set of peers, we handpicked 100 PL peers placed in multiple countries around the globe for a good geographical coverage (Figure 3.1). Our previous experience also showed that applications need to wait 10–20secs/hop for a high response completion when many peers are involved in a multi-hop inference re-
46

Table 3.1: Metrics used to select stable and resourceful PlanetLab peers for the Prometheus deployment and testing.

Resource

Availability

Total RAM

≥ 2GB

Free RAM Free Disk Space

≥ 90% ≥ 20GB

Cores per CPU % of free CPU Live Slices (allocated projects) SSH & DNS Status

≥2 ≥ 90%
≤3 responsive in last 2h

Figure 3.1: Geographical distribution of PlanetLab sites used in the Prometheus’ experiments.
quest. Therefore, for the end-to-end performance experiments, we set the application timeout to 15 seconds for every social hop in the graph traversed by Prometheus to fulﬁll an inference request at a high completion rate. This time is needed to tackle peer-topeer communication delays due to long round-trip-times (RTT) (200–300ms on average), busy peer network interfaces (the PL peers were used by other researchers at the same time), peer churn (for maintenance or network disconnections) and retransmissions of requests to alternative peers. Prometheus uses this parameter by aggregating intermediate results until the per hop timeout T is reached, and then sends these results back to the
47

requesting peer. For the completion rate experiments we varied this timeout T to assess the trade-oﬀ between end-to-end response time and completion rate of a request.
3.3.2 Decentralizing the Social Graph
We used a bidirectional graph of 1, 000 users with initial edge weight of 0.1. The graph was created using a synthetic social graph generator described in [SCW+10] (a pseudocode of the algorithm used is presented in Appendix B), which consistently produces graphs with properties such as degree distribution and clustering coeﬃcient similar to real social graphs. The properties of this graph are shown in Table 3.2. As reported in [MMG+07] and [WBS+09], social networks such as Facebook, Youtube, orkut and LiveJournal exhibit power-law degree distributions with exponents in the range of 1.5 and 1.75. Furthermore, the average clustering coeﬃcient of such networks is in the range of 0.16 and 0.33. The synthetic graph exhibits an average clustering coeﬃcient and a power-law exponent close to the values found for these real social graphs.
Typical social graphs exhibit small-world properties [WS98], thus have small average shortest path legths, similar to random graphs of equal size, but have a signiﬁcantly larger average clustering coeﬃcient. If we compare the average shortest path length and average clustering coeﬃcient of the synthetic graph with a random graph of equal size, we observe that the synthetic graph has a much larger clustering coeﬃcient than the random graph (as expected [WS98]), but a slightly smaller average path length than the random graph. This can be attributed to the graph generator’s focus on preferential attachment which increases connections between highly connected nodes [SCW+10], which leads to the overall reduction of the path lengths.
The graph size allowed for a realistic distribution of the 1, 000 users’ data on the 100 PL peers. We distributed the social graph on peers in two ways. In the ﬁrst way, users’
48

Table 3.2: Graph properties of the synthetic social graph used for the high-stress experiments.
Nodes 1,000 Edges 5,846 Radius 5 Diameter 8 Average Degree 11.692 Average Eccentricity 6.061 Average Clustering Coeﬃcient 0.328 Average Shortest Path Length 3.545 Power-law Distribution Exponent 1.39 Average Clustering Coeﬃcient of a random graph 0.0117 Average Shortest Path Length of a random graph 3.912
social data are stored on randomly selected peers. Consequently, groups of random users are mapped on the same peer. We will refer to this as the random mapping of users on peers. In the second way, we assume that groups of socially-connected users share the resources provided by a peer possibly contributed by a member of the group. Therefore, social groups of users are mapped on peers, reﬂecting a more realistic scenario of social data decentralization. We will refer to this as the social mapping of users on peers.
In our experiments, we created such a social mapping by using a modiﬁed version of the community detection algorithm introduced in [GN02] that allowed us to control the number of communities and their average size. The algorithm takes as input a social graph, the number of communities to be identiﬁed (which in our case is the number of peers in the system) and the minimum acceptable community size. The algorithm iteratively removes the social edge with the highest edge betweenness centrality [GN02] if by removing it a new community of the desired size is created. Removal of edges continues until the speciﬁed number of communities is met. Users from a given community are then mapped on the same peer.
However, even in the social mapping, neighboring communities in the social graph were mapped on random peers worldwide. This setup implies that geographically-close commu-
49

nities could store their information on random peers across the globe, which allowed us to examine a worst case performance of the platform with respect to network delays. Moreover, we assumed users deﬁned ACPs that allowed access to all their data from all users. Therefore, any user could submit requests to access data of any other user and proceed over multiple hops, consequently stressing the system even further with the maximum graph traversal load.
The placement (mapping) of user data on peers introduces bias on the delays of requests between peers. Furthermore, although we did not apply any peer churn, and despite our eﬀorts to pick stable nodes, random PL peers exhibited an average churn of up to 5% of the peers used during the experimental runs, which lasted 8 hours each. Therefore, splitting the application workload among initial peers (i.e., each peer submits requests only for a particular set of users) would have ampliﬁed this bias on the request performance. To minimize this bias, each peer probabilistically submitted the same application workload on behalf of the social graph’s users and we report averaged results across all peers.
The average number of users mapped per peer, N , was set to 10, 30 and 50. The number of PL peers was kept constant to 100, forcing the user groups to overlap with each other for N >10 users/peer. This resembles the realistic scenario of overlapping social circles of users with some users participating in more than one circle (peer), and thus having multiple trusted peers. In eﬀect, user’s data were replicated on K=N /10 peers on average, hence K=1, 3 and 5 trusted peers/user.
3.3.3 Emulated Workloads
We emulated the workload of one social sensor and two social applications based on previous system characterizations [WBS+09, KGA08, GCX+05]. The emulated social sen-
50

sor tested the ability of the platform to manage and incorporate new social input with the existing data of users while under high-stress load. The emulated social applications tested the end-to-end performance of the neighborhood and social strength requests.
3.3.3.1 Social Sensor Input

We emulated a Facebook social input based on a Facebook trace analysis [WBS+09]. The workload was characterized by the probability distribution function (PDF) for users to post comments on their friends’ Facebook walls and photos.
Users were ranked into groups based on their social degree and each group was mapped onto a probability class using the cumulative distribution function (CDF) from Figure 8 in [WBS+09], as shown in Table 3.3.

Table 3.3: Probability distribution function for social inputs, based on a Facebook study. [WBS+09].

Social Degree

% Total

Group assigned Probability to

Rank (Top%) Interaction (CDF)

to user

choose user (PDF)

5

40.0

1

0.400

10

60.0

2

0.200

20

80.0

3

0.200

30

90.0

4

0.100

40

95.0

5

0.050

50

97.5

6

0.025

>50

100.0

7

0.025

To emulate a social interaction from user ego to user alter, a group was selected based on its associated probability, and a user ego from the group (who was not selected yet) was picked as the source of input. User alter was randomly selected from ego’s direct social connections, to maintain the small-world properties of the graph. The weight of each input was kept constant to 0.01 for all users. Due to the fact that users were picked

51

based on their social degree, users with higher social degree probabilistically produced more input, leading to higher weights on their corresponding edges in the social graph.
3.3.3.2 Neighborhood Inference Requests
In order to create a workload for the neighborhood inference requests, we used an analysis of Twitter traces [KGA08]. Twitter [Twi12a] is a micro-blogging website that allows its users to share information at real-time. The sharing happens via small bursts of information called tweets, which can be at most 140 characters long. Each user can follow other users’ stream of tweets that she ﬁnds interesting. Thus, she can be characterized by the number of followers she has over the number of users she follows, or the ratio R of Followers/Following and the number of tweets she produces.
According to the study [KGA08], we can classify the users into three main categories: 1) the broadcasters are heavily followed but they follow very few other users and publish a lot of tweets (e.g., news station, artists, etc), 2) the acquaintances are typical OSN users who tend to reciprocate the follow action of others (similar to “friendship” in Facebook) and they broadcast a moderate number of tweets, 3) the spammers are heavily spamming other users with following requests and do not tweet that often.
Depending on the content of a tweet, users may choose to repost it on their account status and this action can continue for multiple hops in the social graph, leading to a rapid spread of a tweet. Therefore, we can intuitively associate a tweet such as “Go Bulls! Let’s meet for a drink after the football game”, with a Prometheus neighborhood request (centered at the leader of the tweet) which traverses the social graph for a number of social hops h, over a label football and some minimum weight w.
We used the Twitter analysis to extract the probability distribution function of submitted neighborhood requests. We assumed that the users in our social graph were of the second
52

category (i.e. acquaintances) and thus had a ratio R close to one (which could also be reﬂected by the ratio in/out degree). From [KGA08] we observed that users with R 1 but with increased absolute number of followers and following (i.e. higher social degree) tend to tweet more. Therefore, using Figure 4 in [KGA08], each user was assigned to a group with a particular twitter count based on their degree.

Each user group was mapped onto a particular probability to be selected and submit a neighborhood request, as shown in Table 3.4. We assumed that users from the last group produced about half the tweets of users from the previous group, since numbers were not provided in the study. Once the group was selected, a user (who was not selected yet) was picked to be the source of the request. The number of hops for the request was randomly picked from 1, 2 or 3 hops and the weight was randomly picked from the set of values 0.01, 0.02, . . . , 0.10. Applying a weight threshold ≤0.1 on the inference requests produced a high-stress load since all edges had an initial weight of 0.1.

Table 3.4: Probability distribution function for the neighborhood requests, based on a

Twitter study. [KGA08].

Degree Number Group assigned Probability to

of tweets

to user

choose user (PDF)

100-1000 1727

1

0.544

10-100

964

2

0.304

0-10

482

3

0.152

3.3.3.3 Social Strength Inference Request

In order to create a workload for the social strength inference requests, we used an analysis of BitTorrent traces [GCX+05]. BitTorrent [Coh03] is currently the most popular P2P ﬁle-sharing protocol and responsible for about a third of the internet’s traﬃc around the world [SM09]. It allows users to distribute ﬁles to other users in a decentralized way, therefore eliminating the need of a centralized server with bandwidth and computation
53

limitations. Via a cooperation mechanism in the protocol, each ﬁle is split into chunks, and peers (i.e., users) participating in the sharing of the ﬁle are organized into a swarm. Peers or leechers in a swarm may download chunks of the ﬁle from the other swarm peers (seeds), but also upload chunks they currently have, thus contributing back to the swarm.
A battery-aware BitTorrent application [KBI09] could run on mobile devices and users could rely on social incentives to be allowed to temporarily “free ride” the system (i.e., do not upload any chunks to other users) when low on battery. Members of the same swarm (i.e., they have interest in the same ﬁle) could check their social strength with the needy leecher to see if they want to contribute by uploading on her behalf. This translates into a series of social strength requests submitted to Prometheus by random users participating in BitTorrent swarms.
Therefore, for the social strength workload we assumed that users participated at random in BitTorrent swarms. Two users were randomly selected as the source and destination of the social strength inference request. The source user was associated with a total number of requests she would submit throughout the experiment. This number was extracted by the torrent request distribution from the analysis of BitTorrent traces (Figure 9b in [GCX+05]), as shown in Table 3.5.

Table 3.5: Probability distribution function for the social strength requests, based on a BitTorrent study. [GCX+05].

Number of torrent requests Probability to choose

(i.e., social strength requests)

user (PDF)

to submit during experiment

1

0.450

2

0.144

4

0.178

8

0.104

15

0.079

25

0.026

35

0.015

45

0.004

54

3.4 Performance Evaluation with Emulated Workloads
In the ﬁrst two experiments, we deployed Prometheus on PlanetLab to test the performance of the system’s functionalities in a real distributed environment. During these experiments, we used high-stress workloads from the two emulated social applications and the social input as described earlier, while varying inference request parameters such as users involved in the request and number of social hops to be traversed. The ﬁrst set of experiments was performed under a constant, but relatively long, timeout per hop T = 15 seconds to allow high completion rate of inference requests. The second set of experiments was performed with a variable timeout per hop, as it would be selected by each application, to assess variability in the quality of results returned (completion rate) vs. end-to-end performance.
3.4.1 End-to-End Performance
The ﬁrst set of experiments had two goals: (1) to measure Prometheus’ performance over a widely distributed network such as PL, and (2) to assess the eﬀect of socially-aware trusted peer selection on the system’s overall performance. For every experimental run, more than 1 million social strength and neighborhood requests and more than 100 thousand social inputs were submitted from the emulated applications and social aggregator. Figures 3.2– 3.4 show the cumulative distribution function of the end-to-end average response time for the neighborhood inference for diﬀerent social hops and number of users per peer. We do not include the results for the social strength inference as its performance is almost identical to the one for neighborhood for 2 hops. The reason is that this function has to verify all the possible paths between two users within at most 2 social hops of each other. We formulate the following lessons from this set of experiments.
55

CDF

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

random 1-hop social 1-hop
random 2-hop social 2-hop
random 3 hop social 3 hop
5 10 15 20 25 30 35
Time (s)

Figure 3.2: CDF of the average end-to-end response time of the neighborhood inference for the random and social mappings, diﬀerent social hops for 10 users per peer, with T = 15 seconds. The distributions of the social mapping were found statistically diﬀerent from the random mapping using the Kolmogorov-Smirnov test, with p < 0.0001 and test statistics k = 0.0132, k = 0.2276 and k = 0.1641 for 1, 2 and 3 social hop requests, respectively.

CDF

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

random 1-hop social 1-hop
random 2-hop social 2-hop
random 3-hop social 3-hop
5 10 15 20 25 30 35
Time (s)

Figure 3.3: CDF of the average end-to-end response time of the neighborhood inference for the random and social mappings, diﬀerent social hops for 30 users per peer, with T = 15 seconds. The distributions of the social mapping were found statistically diﬀerent from the random mapping using the Kolmogorov-Smirnov test, with p < 0.0001 and test statistics k = 0.0180, k = 0.2771 and k = 0.2918 for 1, 2 and 3 social hop requests, respectively.

56

CDF

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

random 1-hop social 1-hop
random 2-hop social 2-hop
random 3-hop social 3-hop
5 10 15 20 25 30 35
Time (s)

Figure 3.4: CDF of the average end-to-end response time of the neighborhood inference for the random and social mappings, diﬀerent social hops for 50 users per peer, with T = 15 seconds. The distributions of the social mapping were found statistically diﬀerent from the random mapping using the Kolmogorov-Smirnov test, with p < 0.0001 and test statistics k = 0.0480, k = 0.2642 and k = 0.1710 for 1, 2 and 3 social hop requests, respectively.

Lesson 1: The social-based mapping of users onto peers leads to signiﬁcant improvements in end-to-end response time and reduction in message overhead. In all cases of users/peer, the social mapping leads to faster responses of requests than the random mapping. For the case of 30 users/peer, gains of up to 20–25% in response time over the random mapping are observed. The diﬀerence is more visible for 2 and 3 hops, as the 1 hop function is computed either locally at the submitting peer or the ﬁrst available trusted peer of the source user. For the case of 50 users/peer, the system continues to perform better with the social than the random mapping, but the improvements are smaller than between 10 and 30 users/peer. This is because under this case, the average number of peers that must be contacted for information is reduced for both mappings. However, the reduction is more prominent in the random mapping, and thus we notice more improvement on the random than the social mapping.
In all cases, the social mapping outperforms the random mapping since it needs significantly less number of messages to fulﬁll the same requests. For 10 users per peer, the

57

system with social mapping has 38.4% reduction in message overhead over the random mapping. The average message overhead is increased in the case of 30 users per peer under the social mapping. This is because the increase in number of users per peer (N ) from 10 to 30 also increases the number of peers per user (K) from 1 to 3, which adds alternative peers in the system for the users that their requests failed in the N = 10 case. However, the social mapping still outperforms the random mapping with 16.3% less message overhead. Increasing further the number of users per peer reduces the overall number of messages needed as the number of peers to be contacted is also reduced in both mappings. Still, the social mapping leads to 37.3% less message overhead than the random mapping.
Lesson 2: Increasing the service availability through data replication and number of users per peer improves end-to-end response time and reduces message overhead. Our experimental design has the following speciﬁcs: by increasing the average number of users who are mapped on a peer (N ), we also increase the average number of trusted peers per user (K), and therefore, service availability for that user. In general, since inference requests for a user can be fulﬁlled by any of her trusted peers, we observe that increasing the availability of users’ data by a factor of 3 to 5 times, and correspondingly increasing the number of users mapped per peer, improves the end-to-end performance by up to 25% (when K=3) and reduces the message overhead in the system by ∼30%, on average. This overall performance gain is due to the following two reasons. First, having more user data on each peer allows for a higher portion of each request to complete locally on the peer, and therefore fewer peers need to be contacted, i.e., fewer network peer hops. Second, given high peer churn and vulnerable P2P communication, more service availability per user means more alternative trusted peers to contact for an inference request to be fulﬁlled faster.
Lesson 3: Creating the T P L can be an expensive operation. A request for a user X can arrive at any random peer. This peer has to ﬁrst create X’s T P L, and then forward the
58

request to X’s network-wise closest trusted peer (as explained in 2.3.3). This operation

involves several time-consuming lookups in the DHT, which result in multiple peer traver-

sals. The distribution of the overhead associated with the cold start of creating a user’s T P L over the P L infrastructure had a 50th, 90th, and 99th percentile of 1.05, 2.15 and

8.78 seconds, respectively (as shown in Figure 3.5). Thus, for the majority of the users

this process can be fast, but for some unfortunate users it can take as much as 8–10 sec-

onds. Similar delays (6–10 seconds) were reported in [SVCC09] for the group activities

of the Vis-a-Vis system running over PL nodes. To mitigate this problem, Prometheus

caches the T P L as explained in 2.3.3. The graphs in Figures 3.2– 3.4 show the perfor-

mance using this caching mechanism, since we are interested in testing Prometheus’ per-

formance in inference execution and not in DHT lookups.

CDF

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0.01

TPL creation time

0.1

1

10

100

Time (seconds)

1000

Figure 3.5: CDF of the time needed for a peer to create a trusted peer list of a user in PlanetLab.

Lesson 4: The response time is relatively high due to the overloaded testbed, especially for 2 and 3 hops. In our worldwide PL testbed, the average RT T was 200-300 ms. In addition, the testbed was generally loaded with other projects running along with ours, thus leading to about 1–2 seconds just to establish a reliable T CP connection to submit a request to a peer or receive an inference result from a peer. The response time greatly depends on the number of hops to be traveled by the request and the number of peers to

59

be contacted at each hop. Even though the aggregation of a request result is executed in parallel per social hop, multiple peers must be contacted per hop, with potentially long response delays to complete a request at the highest rate possible. For example, for 10 users/peer in the social (random) mapping, an average of 37 (48) peers have to be contacted to collect neighborhood results from users located 3 social hops away from the source user (the number of users returned is 350 on average). Such a request took about 30–35 seconds to reach ∼100% completion rate, given the 15-second timeout per hop.
Lesson 5: Caching optimizations and geographic social graph decentralization allows better scalability. By placing socially-close communities on random peers, we examined a rather pessimistic experimental scenario of longer than expected delays for request execution. However, in reality, we expect neighboring communities in the social graph being placed in geographically close peers (e.g., same country peers) instead of random, which could eﬀectively reduce delays by one order of magnitude, since the average (median) RT T between PL peers of the same country was 25.5 (15.7) msec in our experiments for over 35 countries, as seen in Figure 3.6. To further reduce execution delays, we plan to implement caching of recently computed results as well as pre-computing results in the background. These methods are expected to work well as the social graph rarely changes [Gol07] and will allow the inference execution to scale easier to thousands of peers.
3.4.2 Response Time vs. Completion Rate
In general, the longer an application is willing to wait, the more complete the information returned by the social inference is. In the previous experiments we assumed that a long timeout of T =15 seconds per hop oﬀers a very high completion rate for requests fulﬁlled in the PL infrastructure. We designed a second set of experiments to measure the tradeoﬀ between end-to-end response time and response completion rate, when applications use
60

CDF CDF

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

RTT between same-country peers 0

0.01

0.1

1

10

100

Time (msecs)

1000

Figure 3.6: CDF of the round trip time (RTT) between same-country peers in PlanetLab.

variable timeout T =2.5, 5.0, 7.5, 10.0 seconds, using a social mapping of 30 users/peer for the 1000-user social graph.

1

0.9

0.8

0.7

0.6

0.5

0.4

2.5s 2-hop

0.3

5.0s 2-hop

0.2

7.5s 2-hop 10.0s 2-hop

0.1

0 0 2 4 6 8 10 12 14

Time (s)

Figure 3.7: CDF of the average end-to-end response time of the 2-hop neighborhood inference for the social mapping, with 30 users per peer and varying timeout values.

Figure 3.7 and 3.8 show the CDF of the end-to-end response times for neighborhood requests of 2 and 3 social hops, respectively (a request of 1 social hop cannot timeout). For both request types, we can clearly see the eﬀect of the timeout in the end-to-end response time performance. Furthermore, in the 3-hop requests, we notice a more promi-

61

CDF

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

2.5s 3-hop 5.0s 3-hop 7.5s 3-hop 10.0s 3-hop

5

10

15

20

25

Time (s)

Figure 3.8: CDF of the average end-to-end response time of the 3-hop neighborhood inference for the social mapping, with 30 users per peer and varying timeout values.

nent use of the retransmission policy (also seen in Figures 3.2– 3.4 but in a lesser degree) and especially in the cases of 7.5 and 10 seconds. Using the theoretical results shown in Figure 2.10, we notice that case (c) with one timeout and 4 remote messages (4T R) is the most prominent for the 3-hop requests with one timeout and the case (d) with two timeouts and 2 remote messages (2T R) the next more prominent.
In a system such as PlanetLab, the time delays T A and T D are not truly negligible and the minimum time delay of one remote message (T R) cannot be zero, as assumed in the analysis of Section 2.3.8. Therefore, the requests exhibit an even longer delay to be fulﬁlled, and this delay presents a multi-step variability, depending on what portion of the requests was executed in 1, 2 or 3 network hops and at what network hop there were timeouts involved.
Figure 3.9 shows the cumulative distribution function of the average completion percentage of the 3-hop neighborhood requests under diﬀerent application-set timeout values. The results for 1 and 2 hops showed practically 100% completion for all requests and timeout values and are omitted for brevity. Overall, we observe a clear trade-oﬀ between request completion rate and application waiting time for response. For example, when

62

1 2.5s 3-hop

5.0s 3-hop

0.8

7.5s 3-hop

10.0s 3-hop

0.6

CDF

0.4

0.2

0

0

0.2 0.4 0.6 0.8

1

Completion Percentage (%)

Figure 3.9: CDF of the average completion percentage of 3–hop neighborhood requests for varying timeout values.

T =7.5(10)seconds, about 50%(80%) of the requests have > 90% completion. A real-time social application—e.g., “using the proximity inference, invite my 2-hop football contacts for celebration of the team’s victory”—could set a low timeout for quick, yet incomplete, results.

3.5 Performance Evaluation with Real Mobile Application

We validate the usability of Prometheus as a social data management service by developing a mobile social application, CallCensor, that utilizes the Prometheus inference functions through the exposed API, under real-time constraints. Past work (ContextPhone from University of Helsinki [ROPT05]) introduced an application called ContextContact which oﬀers cues to the caller about the callee’s social context such as location, collocation with other people, phone ringer status, etc. Our application builds on these lessons and allows the callee’s phone to adjust the phone ring based on the owner’s social context and the social relationship with the caller. We measured its end-to-end performance using a real multi-graph of 100 users.
63

The CallCensor application leverages social information received from Prometheus to decide whether or not to allow incoming calls to go through. In addition to the social information from Prometheus, this application also uses the phone location and collocation via BT with other phones, to infer whether the user is at work and in a meeting (e.g., in the boss’s oﬃce). For each incoming call, the application queries Prometheus with a social strength or neighborhood inference request to assess the type of social connection between the caller and the phone owner. Based on the owner settings (e.g., don’t allow personal calls while at work), the application decides if the phone should ring, vibrate or silence upon receiving the call. The application was written in Java for devices running Google Android OS and was tested on a Nexus One mobile phone from HTC (1GHz CPU, 512MB RAM). There are multiple scenarios a caller can be connected to the phone’s owner; we tested three: directly connected within 1 social hop, indirectly connect by 2 social hops, and connected with a high social strength. We tested each of these scenarios 50 times. For each of them, the ego and alter were randomly chosen, and the inference request was sent to a random peer. We assumed users deﬁned ACPs allowing access to all their data, thus enabling requests to proceed over multiple hops, and consequently stressing the system at maximum possible load. We measured the end-to-end response time of an inference request submitted to Prometheus. This experiment introduced additional overhead due to the communication between the mobile application and Prometheus, and the processing time by the mobile application.
64

3.5.1 Social Multi-Graph from Real Traces
The social graph used in the CallCensor application experiments was based on data collected at NJIT [PBB11]. The graph has two types of edges, representing Facebook friends and Bluetooth collocation. Mobile phones were distributed to students and collocation data (determined via Bluetooth addresses discovered periodically by each mobile device) were sent to a server. The same set of subjects installed a Facebook application to provide their friend lists and participate in a survey.
The user set was small (100 users) compared to the size of the student body (9, 000), therefore resulting in a somewhat sparse graph. About half of the subjects reported less than 24 hours of data over the span of a month. The collocation data have two thresholds of 45 and 90 minutes for users to have spent together. Thus, the 90 minute collocations comprise a subgraph of the 45 minute collocations. A summary of the graph properties (when ﬂattened) is shown in Table 3.6.
Table 3.6: Graph properties of the multi-graph produced using real collocation and Facebook data from NJIT. [PBB11].
Nodes 100 Edges 469 Average Degree 9.38 Average Eccentricity 4.47 Average Clustering Coeﬃcient 0.37 Average Shortest Path Length 2.50 Power-law Distribution Exponent 1.37
While the graph edges were not initially weighted, we applied synthetic weights of 0.1 for “Facebook” edges, 0.1 for “collocation” of 45 minutes and 0.2 for “collocation” of 90 minutes. For the mobile application experiments, we consider the “collocation” edges to represent a work relationship, while the “Facebook” edges represent a personal relationship. The user (ego) was assumed to be in a work environment when another user (alter ) called.
65

Figure 3.10 illustrates this graph and demonstrates one of Prometheus’ features: using multi-edge graphs provides for better connectivity between users. Neither the “Facebook” nor the “collocation” graph is connected, but the graph containing both types of edges is. We equally distributed the N JIT graph with a social mapping on three PL nodes in the US. Splitting this 100 user-graph on 3 PL peers implies a similar ratio of users/peer as before (about 30 users/peer), while testing 1 and 2 hop inference execution on a real multi-graph.
Figure 3.10: Real multi-graph with Facebook edges (black dashed lines) and collocation edges (red continuous lines). Line thickness demonstrates edge weight (for collocation edges).
3.5.2 Application Response Performance
Figure 3.11 presents the performance for the requests sent by CallCensor, for each of the three scenarios examined. The results show the time spent by the requests only in Prometheus and the overall time needed by the CallCensor to request and handle a response. We ﬁrst observe that the results meet the time constraints of the application: the
66

��

����

����

����

����

���

����

����

���� ���� ����
�� ��

����������������� �����������������
��������������� ����������������� �����������������
���������������

��

��

��

��

��������

Figure 3.11: CDF of average end-to-end response time for CallCensor, under three social inference function requests: 1 and 2 hops neighborhood requests and social strength (SocS) requests.

response must arrive and the ring must be adjusted before the call is forwarded to the voicemail of the callee (we used the default voicemail time setting).
Second, we notice that the application itself introduced a signiﬁcant overhead: for example, as much as 100% in the 1–hop neighborhood and 50% in the 2–hop neighborhood and social strength, due to both communication overhead and execution time on the mobile phone. Third, we conﬁrm the similarity of the social strength results with the neighborhood for 2 social hops, as found in the ﬁrst set of experiments. Fourth, the 2-hop request results using this small social graph are similar in performance with the larger 1000-user graph used before (social mapping, 30 users/peer). In particular, more than 70% of requests ﬁnished within 2.5 seconds in both setups, which leads us to believe that similar performance of the mobile application could be expected in a larger social graph distributed over hundreds of peers.

67

Chapter 4: Resilience to Malicious Attacks in Prometheus

A social data management service can be the target of attacks at diﬀerent levels of the system (Figure 4.1): 1) at the infrastructure level, 2) at the social graph level, 3) at the service level, and 4) at the application level. Depending on the architecture of the system (centralized or decentralized), defenses can be more eﬀective and easier to implement. In this Chapter we discuss how the design characteristics of Prometheus enable the system to resist such attacks, or mitigate their eﬀects on users.

Application Level

Misuse social data by applications

CallCensor SofaSurfer

Service Level

Manipulate social inferences Drop requests, modify results

Social Graph Level
Manipulate graph structure Create/modify edges
Infrastructure Level

DDoS, attacks on DHT, routing, storage, network

`

``

` ``

Figure 4.1: Attacks can target a social data management service at diﬀerent system levels.

First, attacks at the infrastructure level such as denial of service attacks can target both the servers of a centralized system and the peers participating in a decentralized system.
68

A decentralized system such as a P2P network, however, can be the target of additional attacks on the infrastructure, with a goal to disrupt the communications (routing of messages between peers) or storage of content in the system. The main classes of attacks on DHT-based P2P systems are: 1) the Sybil attack, 2) the Eclipse attack, and 3) attacks on the routing and storage functionalities of the system. Solutions to such attacks are reviewed in [UPvS11]. Attacks at the infrastructure level are out of the scope of this work.
Second, attacks on the social graph aim to manipulate the graph structure by creating or modifying social edges between users. Centralized systems have complete knowledge of the social graph and monitor its changes due to user activity. Thus, it can be easier to detect when malicious users, independently or in collaboration, create artiﬁcial edges with honest users to gain access to their social data (e.g., Facebook Immune System [SCM11]). However, not all such defenses are successful [BMBR11] and more research is needed to address such attacks. Decentralized systems can also employ techniques (e.g., [YKGF06, YGKX08]) to defend against such attacks, but they are typically more expensive and less eﬀective due to the distributed nature of the social graph. In Section 4.1 we discuss how the characteristics of the social graph maintained by Prometheus, i.e., a directional, labeled and weighted social graph, protect users against many variants of these attacks.
Third, attacks at the service level attempt to manipulate inferences on the social graph (drop requests, modify results, etc). A centralized system such as Facebook can claim trust in the social inferences on the social graph, since it controls the access and use of its servers. Such attacks are more eﬀective on decentralized systems due to the diﬀerent level of guarantees that distributed, user-contributed peers can provide. In Section 4.2 we discuss how the socially-aware design of Prometheus increases the system resilience to these attacks.
Finally, we consider attacks at the application level. Centralized systems expose the social data of users to 3rd party applications and services through APIs. However, users
69

typically have limited or no control on the exposure and use of their data from such 3rd party services, as seen by the numerous attacks on users with email spam and phishing campaigns [Sym11, BCF09], as well as collection of private information from online social aggregators such as Spokeo [Spo12]. Prometheus enables applications to mine the rich social graph stored in the system via social inference functions, but allows users to control access to their social data via ﬁne-grained access control policies. In Section 4.3 we discuss how Prometheus can defend against attacks at the application level.
4.1 Attacks at the Social Graph Level
It has been shown that attackers are able to create social edges with honest users in social networks (e.g., Koobface [BCF09, Dan09, Vam08]), or bias them to reciprocate social edges [CM08]. Moreover, these attacks can be automated using socialbots [BMBR11] and current defense systems are not capable of detecting and stopping the majority of such attacks (e.g., Facebook [SCM11]). The reciprocation of a social edge (e.g., Facebook, Twitter, etc) usually means partial or complete access to honest users’ social data. These data could include online proﬁles and personal information and can be used for email spam and phishing campaigns [Sym11, BCF09], or sold to the black market for identity thefts. A more subtle attack could include eﬀorts to manipulate public opinion on sensitive issues, for example with respect to public health [Mor09] or political elections [RCM+11, Mis11]. Because Prometheus maintains a directed social graph, manipulating it eﬀectively is more challenging. While it is relatively easy to create an edge from the attacker to the victim, creating the reciprocal edge from the victim to the attacker is not in the attacker’s control. Next, we examine these two scenarios in more detail.
70

4.1.1 Creating Social Edge from Attacker to Victim
Attackers could bias their social sensors to create directed edges towards victims to manipulate the social graph and access their social data. For example, Alice could repeatedly email a large number of users to create a social edge with them. These edges could be of diﬀerent labels and weights, in an eﬀort to cover a wide range of social activities that honest users interact with each other. However, no matter how many edges she creates with various labels and weights, the directionality of these edges will always be from her to victims, thus restricting their eﬀectiveness when it comes to aﬀecting or even accessing honest users’ social data. Therefore, even though she can include in her 1-hop neighborhood the entire social graph, she will not be part of any honest user’s 1-hop (or n-hop) social neighborhood.
4.1.2 Reciprocating Social Edge from Victim to Attacker
An attacker Alice can try via social engineering [Gal11] or other means (for example, socialbots [BMBR11]) to convince an honest user Bob to reciprocate an edge to her. Bob can defend against such attackers using Prometheus inferences or SybilLimit-based techniques [YGKX08]. However, if this attack is successful, Alice (and her malicious 1-hop neighborhood) may be able to access part of his social data, depending on Bob’s access control policies. This could also lead to a more subtle attack on complex social inferences such as the social strength. In the next paragraphs we examine in more detail the two defense mechanisms that Bob can use to reduce the reciprocation of social edges to attackers, as well as the attack on the complex social inference requests.
71

4.1.2.1 Defense via Prometheus Inferences
Bob could consult his direct social neighborhood about Alice before establishing an edge with her. Individuals typically share a signiﬁcant number of social contacts (i.e., people have common friends with each other) and this overlap of friends is an indication of the strength of their social relationship [OSH+07]. Therefore, Bob could query Prometheus for his 2-hop social neighborhood (i.e., the direct contacts of his contacts), to establish if Alice appears in his friends’ 1-hop neighborhood, and if she does, under what edge label and corresponding weight. Note that a similar mechanism has been used by Facebook [Fac12b] to allow users to recover their account password through 3 of their friends. However, the particular Facebook mechanism has also been shown to be vulnerable to Sybil attacks via social engineering [Gal11]. Instead, our proposed mechanism takes into account edge labels and weights, and allows for a more collective decision to take place between friends regarding a stranger, emphasizing Prometheus’ socially-aware design.
4.1.2.2 Defense via SybilLimit-based Techniques
Bob could apply a SybilLimit-based technique [YGKX08] to traverse his social graph and investigate if this social edge is legitimate or not. This technique assumes that attackers such as Alice, with potentially multiple or Sybil identities in the system, are concentrated within a Sybil region and attack the honest users H via a speciﬁc set of social edges SG, or attack edges. Such a defense mechanism provides guarantees that each honest user could reciprocate at most O(logH) social edges to attackers in the social graph, per attack edge in the set SG, even when |SG| = o(H/logH). Given the technique’s decision, Bob can accept an edge or not. As an extension to this technique, if the social edge is not
72

accepted, it can be placed under “quarantine”, until Bob has enough interaction history with Alice to reconsider his decision on the edge formation.
4.1.2.3 Manipulating Complex Inference Requests

Alice could partially inﬂuence complex requests such as social strength, that traverse the social graph over diﬀerent types of edges and weights to reach users that are directly or indirectly connected.

Ed <Ga<<mGReaesma,0de.s_5,B>0l.o5g>,0.1>

Bo<Hbiking<<,H0Si.k1cinh>g<o,oS0l.c,10h>.o2o>Dl,0<a.3Wv>eork,0.01>

<Sc<hSocohl,0o.o1l>,0.1>

Alice

<Fake,1.0>

Cary

Figure 4.2: User attack on the social graph: Alice creates a fake edge to Cary with high weight to bias inferences from Bob to Cary.

Assume that Alice has a reciprocal edge with Bob and creates a fake edge with high weight to another attacker Cary who also managed to create a reciprocal edge from Bob to her, as in Figure 4.2. Given that Bob submitted a social strength request between him and Cary, the request will search the social graph to identify the path (direct or indirect) with the highest strength (as explained in Section 2.3). The fake edge between Alice and Cary can cause the reported social strength between Bob and Cary to be 0.1 whereas without the fake edge it would be 0.01. Thus, Alice can mislead such a request originating from Bob to utilize the indirect social path of Bob to Cary through her, instead of the direct path between the two users.

73

In general, an attacker Alice could cause any social strength request from a user directly connected to her to be artiﬁcially increased. In theory, this implies that Alice could enforce a minimum social strength to any other user within her 1–hop neighborhood, given that she is in their 1–hop neighborhood as well. In practice however, even though Alice can easily create outbound edges, she has little control over the creation of inbound edges, their label and weight, as well as if she will be granted access from Bob through his ACPs. The above example demonstrates the need for further investigation of attacks when considering the implementation of complex inferences such as the social strength.
4.2 Attacks at the Service Level
Prometheus allows users to store their social data on particular peers based on out-ofband trust with the peer owners. Therefore, users can assume that these peers will not act maliciously while hosting their data and during the execution of an inference request. If such a peer acts maliciously, the peer and its owner can be ﬂagged accordingly (blacklisted) in the ACPs of all honest users so that future requests initiated from the particular peer and user are dropped and requests are not sent to the speciﬁc peer for service.
As explained earlier in the inference function execution (Section 2.3.7), if a peer does not have the social data necessary to fulﬁll a request locally, a diﬀerent peer must provide them. In fact, in a decentralized system such as Prometheus, many peers can participate in the execution of a single inference request. This depends on how the social graph is decentralized in the system and the type of request and the n-hop distance it will travel on the social graph, which can translate to multiple network hops in the P2P system.
Prometheus’ design enables users to decentralize their social graph in a socially-aware manner, since socially connected users can store their data on the same peer, therefore reducing the number of peers needed to be queried during inference execution. However,
74

A `

B

`

C

`

D `

H `
E `

`
F `

J
G `

Figure 4.3: Example of peer inﬂuence. The red peer (D) can aﬀect the requests submitted from the blue peers (A, B or C) that pass through peer D to reach peers E–J or results returned from these peers.
even with this design, multiple peers may need to be queried and in a system that protects user privacy, a requestor cannot distinguish how and from which peer any given item entered the result set.
Therefore, the intermediate peers serving a multi-hop inference request cannot be identiﬁed from the requester. Consequently, for Alice to mount a successful attack at the service level, she would have to control such intermediate peers in the system. These peers could have the opportunity to drop incoming requests, modify intermediate results sent to other peers, or change the parameters of secondary requests sent to new peers (Figure 4.3).
For example, if a malicious peer serves the ith hop of a n-hop request, it can “override” the results of the ith+1 to the nth hop of its leg of the request and remain undetected. Moreover, if malicious peers collude with each other (either because they are owned or have been compromised by the same attacker) they can increase the magnitude of the attack at the service level.
In this section we experimentally investigate how the socially-aware design of Prometheus increases the system resilience to such attacks at the service level, under diﬀerent experimental setups.

75

4.2.1 Peer Inﬂuence
We studied system resilience to attacks on inference request execution by measuring peers’ opportunity to inﬂuence results when serving a neighborhood inference request. We deﬁne a peer’s inﬂuence on requests as the fraction of requests that the peer serviced over the total number of requests issued in the system, during a period of time t:
number of requests the peer serviced during period t peer inﬂuence =
total number of requests issued during period t
This fraction represents the overall opportunity of a peer to serve, and thus potentially manipulate the results of any given request issued.
A peer’s inﬂuence on a request increases with the number of social hops the request traverses the graph, since, probabilistically, there are more chances the peer will participate in the request’s graph traversal. We do not consider the ﬁrst hop (i.e., the source peer) of a request as malicious, since if it is, no results can be considered legitimate. We consider the worst case scenario in which we do not restrict the weight of the social relationships used, all edges are reciprocal and users deﬁne ACPs allowing access to all their data, thus enabling requests to proceed over multiple peer hops.
Next, we extend our preliminary work [BKI11] and experimentally evaluate the inﬂuence malicious peers have over social inference execution on a distributed social graph. We performed three sets of experiments and extracted lessons regarding the system’s resilience with respect to inference execution. During the experiments, an n-hop neighborhood request was performed for each ego (user) in the social graph. This request was submitted to the peer the user was mapped to, i.e. peer P0, which could fulﬁll requests regarding information only about users mapped to P0. For users in subsequent social hops from ego that P0 did not have social data, P0 randomly chose one of the peers stor-
76

ing the particular users’ data and submitted secondary requests to be fulﬁlled by those peers. Each time a peer served a secondary request, we increased the peer’s inﬂuence.
4.2.2 Peer Inﬂuence on a Synthetic Graph
The ﬁrst set of experiments was performed on the 1000-user synthetic graph (same graph used in Section 3.4) distributed on 100 peers. In this set of experiments we studied the peer inﬂuence by identifying and mapping communities onto peers using the algorithm from Section 3.3.2. This algorithm allowed us to control the size and number of communities as well as the average replication factor of users’ social data (K). Therefore, multiple copies of a user’s data were allowed and thus multiple trusted peers for each user. To eliminate any bias introduced by the random peer selection, we performed 100 iterations of each experimental conﬁguration and report the average inﬂuence. Since we reach nearly 100% of the users in the 1000-user social graph within 4 hops, we only measured inﬂuence for 2, 3, and 4 hop requests. To produce random mappings while preserving the community size distribution, we used the community sizes produced by the social mappings and shuﬄed the users randomly between communities. Figure 4.4 plots the cumulative distribution function of the average inﬂuence of peers in neighborhood requests for the synthetic graph, for diﬀerent combinations of users per peer and number of hops per request and for social and random mappings of users onto peers. From these results we formulate the following lesson. Lesson 1: The socially-aware mapping of users onto peers reduces the average opportunity of peers to inﬂuence requests. From the results in Figure 4.4 we observe that the random mapping leads to an overall steady inﬂuence rate on peers, depending on the number of hops. On the other hand, the social mapping leads more than 85% of peers to have less
77

CDF

10 users per peer 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Average Influence
40 users per peer 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Average Influence

CDF

CDF

20 users per peer

1

0.9

social 2 h

0.8

random 2 h

0.7 0.6

social 3 h random 3 h
social 4 h

0.5

random 4 h

0.4

0.3

0.2

0.1

0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Average Influence

50 users per peer
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Average Influence

CDF

Figure 4.4: CDF of average peer inﬂuence for random and social mappings of the synthetic graph, for combinations of users per peer and number of hops per request.

average inﬂuence than peers in the random mapping, even though this inﬂuence increases and is also depended on the number of hops.
We can explain this result if we consider that in a social mapping, socially-close users are mapped to the same peers, increasing the likelihood that more hops are served locally when compared to randomly mapped users on peers. This also implies that a social mapping results in fewer secondary requests sent in the system (regardless of the way communities were identiﬁed and mapped on peers), and therefore supports our performance results (Chapter 3) which showed inferences on a socially-mapped graph to execute faster than on a randomly-mapped graph.

78

4.2.3 Peer Inﬂuence on Real Graphs

In our second set of experiments we studied the peer inﬂuence on ﬁve larger graphs based on real traces from diverse application domains, such as ﬁle sharing using peer-to-peer protocols (Gnutella, [RIF02]), email communications between company employees (Enron, [Les12]), trust on consumer reviews (Epinions, [Les12]) and friendships in a news website (Slashdot, [Les12]). We considered all networks undirected and unweighted and used only the largest connected component from each graph to ensure reachability between all pairs of users.

The time complexity of the community detection algorithm used in Section 3.3.2 is very high and unsuitable for networks larger than a few thousand nodes. Thus, to produce social mappings of users to peers for the real graphs, we identiﬁed social communities with the modiﬁed algorithm used in [KI11] (recursive-based Louvain method, Section 7.1.2), for average community sizes of N =10, 50 and 100, while maintaining the replication factor to one (K=1). Table 4.1 presents a summary of these networks and the communities found. We describe in more detail these networks and the community detection algorithm in Section 7.1.

Table 4.1: Summary information of the real networks used in the experimental study for

the inﬂuence in Prometheus requests.

Network

Users

Edges

Communities (avg size N) N=10 N=50 N=100

Source

Gnutella04 10,876 39,994 1,088 218

109 [RIF02]

Email-Enron 33,696 180,811 6,256 1,246

619 [Les12]

Gnutella31 62,561 147,878 3,370 674

337 [RIF02]

Epinions

75,877 405,739 7,564 1,485

727 [Les12]

Slashdot

82,168 504,230 8,207 1,607

794 [Les12]

Figure 4.5 plots the average inﬂuence of peers on the real graphs used. Figure 4.6 shows the diﬀerence of the average inﬂuence between random and social mapping for the real

79

10-1

gnutella04 SM gnutella031 SM
enron SM epinions SM slashdot SM

gnutella04 RM gnutella031 RM
enron RM epinions RM 100 slashdot RM

Average Influence Average Influence

10-2

10-1

10-3

10-2

10-4 0

20 40 60 80 100 Users per peer (2 hops)

10-3 0

20 40 60 80 100 Users per peer (3 hops)

Figure 4.5: Average peer inﬂuence for random and social mappings for real graphs, for combinations of users per peer and number of hops per request. (Note: y-axis in log scale).

graphs, for clarity. Figure 4.7 plots the CDFs of the average inﬂuence of peers. From these results we formulate several lessons.
Lesson 2: Increased number of users per peer and decreased social graph size directly increase peer inﬂuence on requests. The results on real graphs (Figures 4.5, 4.6 and 4.7) verify the intuition that more users mapped on a peer increase the peer’s inﬂuence on requests, regardless of the type of mapping (random or social). However, the diﬀerence between the two mappings (as seen in Figure 4.6) also increases with larger communities mapped on peers, as well as increased number of hops traversed. This means that socially-aware mappings increase the peer inﬂuence in a smaller rate than random mappings, further supporting Lesson 1. Moreover, malicious peers are more eﬀective in small networks, since they can serve and thus inﬂuence a larger portion of requests. For example, Gnutella04 exhibits a higher average inﬂuence than Gnutella31, which even though has the same topological characteristics (as also seen by the peer inﬂuence proﬁle in Figure 4.7), it’s 6 times larger in size and thus peers have less opportunity to serve (portions of) requests.

80

Average Influence Difference (Rand-Soc)

100 10-1 10-2

gnutella04 gnutella031
enron epinions slashdot

10-3

10-4 10-2

50-2

100-2

10-3

50-3

Users per peer - Social Hops

100-3

Figure 4.6: Average diﬀerence of peer inﬂuence between random and social mappings for real graphs. I.e., diﬀerence between random and social mapping lines in Figure 4.5), for combinations of users per peer and number of hops per request. (Note: y-axis in log scale).

Lesson 3: The topology of the social graph aﬀects the peer inﬂuence. The size of the decentralized graph is not always an accurate predictor of the opportunity of peers to inﬂuence requests. It also depends on the particular application domain and topology of the network. For example, Gnutella31 exhibits similar peer inﬂuence proﬁle with Gnutella04, even though it has overall lower absolute values due to its larger size (as explain in Lesson 2). On the contrary, Gnutella31 is smaller in size than Slashdot and Epinions, and yet exhibits overall lower peer inﬂuence as seen in the diﬀerent peer inﬂuence proﬁle in Figure 4.7.
Lesson 4: The socially-aware distribution of a social graph onto peers allows the formation of “hot-spot” peers. The maximum inﬂuence of each mapping is higher than its corresponding average for all networks (synthetic or real), and all average community sizes N and all n-hop requests. This reveals highly inﬂuential peers that control more requests ﬂowing through the P2P topology than the average peer. We especially notice these peers for the social mapping of the small 1000-user graph. This is because users of high social degree centrality are closely connected with each other and more likely to be mapped together on the same peer [SBAG08] in the social than in the random mapping.

81

CDF

CDF

CDF

Gnutella04 10 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Gnutella31 10 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Enron 10 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Epinions 10 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Slashdot 10 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

CDF

CDF

CDF

CDF

CDF

Gnutella04 50 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Gnutella31 50 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Enron 50 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Epinions 50 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence
Slashdot 50 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

CDF

CDF

CDF

CDF

CDF

Gnutella04 100 u/p

100

10-1

10-2

Random 2 h Social 2 h

10-3 10-410-5

Random 3 Social 3
10-4 10-3

h h
10-2

10-1

100

Average influence

Gnutella31 100 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

Enron 100 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

Epinions 100 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

Slashdot 100 u/p 100 10-1 10-2 10-3 10-410-5 10-4 10-3 10-2 10-1 100
Average influence

Figure 4.7: CDF of average peer inﬂuence for random and social mappings for real graphs, for combinations of users per peer and number of hops per request. (Note: axes in log scale).

CDF

CDF

82

Further, due to the small size of the graph, peers participate in more requests and the variability of peer inﬂuence is higher (especially for 3 hop requests). These peers can be identiﬁed based on the users mapped on them [KI11] and targeted for quarantine in the early stages of a malware outburst or used to disseminate faster and more eﬃciently security software patches to handle a malicious attack.
4.2.4 Peer Inﬂuence under Peer Collusion
In the third set of experiments we investigated the peer inﬂuence when peers collude with each other, i.e., they are controlled by the same attacker. We used the largest network slashdot and the social mappings created in the second experimental setup for average community size of N =10 users per peer. The two collusion types examined where the following: 1) a social-based collusion of neighboring peers (i.e., their mapped users are connected with each other over social edges), 2) a random-based collusion of random peers. We seeded the collusion by selecting a random set of peers amounting to 1% of the total peers in the system. Then, we iterated over these peers expanding their collusion set depending on the type of collusion (social or random), until the overall malicious peers across all collusion sets amounted to a speciﬁc portion of the total network. We varied the overall fraction of peers colluding C in the range of 10% to 50% of the total peers. Figures 4.8 and 4.9 plot the average inﬂuence of peers when colluding in a social or random way, respectively, to cover a portion C of the total number of peers in the system. Figure 4.10 plots both types of collusion on the same graph for easier comparison (note that peer inﬂuence is on the x-axis). We also compare average inﬂuence of the peers when colluding or not colluding, when the social graph is distributed with a random or social
83

Average Influence

2 social hops
0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01 0.00
0 10 20 30 40 50 60
Percentage of Malicious Peers

3 social hops 0.70

0.60

0.50

NC-SM

0.40

NC-RM SC-SM

0.30

SC-RM

0.20

0.10 0 10 20 30 40 50 60
Percentage of Malicious Peers

4 social hops 1.00 0.95 0.90 0.85 0.80 0.75 0.70
0 10 20 30 40 50 60 Percentage of Malicious Peers

Figure 4.8: Average peer inﬂuence for random (RM ) and social mapping (SM ) of the slashdot network, for 10 users per peer and diﬀerent number of hops per request. We vary the percentage of social collusion (SC) and compare with the no-collusion (N C) scenario. Error bars show 95% conﬁdence intervals on reported average peer inﬂuence.

Average Influence

2 social hops 0.06 0.05 0.04 0.03 0.02 0.01 0.00
0 10 20 30 40 50 60 Percentage of Malicious Peers

3 social hops 0.60

0.50

0.40

NC-SM

0.30

NC-RM RC-SM

0.20

RC-RM

0.10

0.00 0 10 20 30 40 50 60
Percentage of Malicious Peers

4 social hops 0.95 0.90 0.85 0.80 0.75 0.70 0.65
0 10 20 30 40 50 60 Percentage of Malicious Peers

Figure 4.9: Average peer inﬂuence for random (RM ) and social mapping (SM ) of the slashdot network, for 10 users per peer and diﬀerent number of hops per request. We vary the percentage of random collusion (RC) and compare with the no-collusion (N C) scenario. Error bars show 95% conﬁdence intervals on reported average peer inﬂuence.

Portion C (%)

50 40 30 20 10
10-3

NC(RC)-SM NC(RC)-RM NC(SC)-SM NC(SC)-RM

2 hops
RC-SM RC-RM SC-SM SC-RM

10-2

10-1

Average Influence

3 hops

4 hops

100

Figure 4.10: Average peer inﬂuence for random and social mapping of the slashdot network, for 10 users per peer and diﬀerent number of hops per request. We vary the percentage of social and random collusion and compare with the no-collusion scenario.

84

mapping and for neighborhood requests of diﬀerent number of hops. From these results we formulate several lessons.
Lesson 5: Peer collusion attacks are less eﬀective on socially-aware mappings. Collusion of peers into groups increases their individual eﬀectiveness when attacking the system. As seen from Figures 4.8, 4.9 and Figure 4.10, the average inﬂuence measured on collusion groups (SC or RC) is always higher than the average inﬂuence of their individual peer members when not colluding with each other (N C). However, a random distribution of the social graph onto peers (RM ) forces requests to access data from more peers than in a social distribution (SM ), and thus allows peers to control and inﬂuence a higher portion of inference requests, either if they are colluding (SC and RC) or not colluding (N C).
Lesson 6: Random peer collusions are less eﬀective on socially-aware mappings. Generally, the average peer inﬂuence increases dramatically with the number of social hops of the neighborhood request: from less than 0.1 for 2 hops to more than 0.9 for 4 hops (as also shown in the previous two sets of experiments on the synthetic graph and real graphs). In the social collusion SC, the attack targets neighboring peers (i.e., their users are directly connected in the social graph). In this case, the attacker can achieve higher peer inﬂuence on requests than if the attack targeted random peers (random collusion RC). However, the diﬀerence between social and random collusion is limited to about 0.02 in 2 hop requests, increases to about 0.1 in 3 hop requests and decreases to about 0.05 in 4 hop requests.
Lesson 7: Network hops aﬀect more the peer inﬂuence than collusion size. In either of the two collusion types and graph mappings, increasing the number of colluding peers increases the average peer inﬂuence of an attacker. However, the peer inﬂuence rate (change of peer inﬂuence) depends more on the number of social hops the request will traverse
85

