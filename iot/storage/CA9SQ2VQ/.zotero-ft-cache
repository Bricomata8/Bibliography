Deep Learning-based Application Speciﬁc RAN Slicing for Mobile Networks

Ping Du The University of Tokyo
Tokyo, Japan Email: duping@iii.u-tokyo.ac.jp

Akihiro Nakao The University of Tokyo
Tokyo, Japan Email: nakao@nakao-lab.org

Abstract—Eﬀectively identifying application is desirable for network operators to improve spectrum eﬃciency and user experience in future mobile networks that are expected to support multiple kinds of applications with diﬀerent quality of service (QoS) requirements. In this paper, we present a Radio Access Network (RAN) slicing architecture utilizing in-network deep learning to apply application speciﬁc radio spectrum scheduling. We use a small number of customized supervising phones to generate training data in real-time and apply deep learning at the packet gateway (P-GW), where we tag the downlink packets with the identiﬁed application name and transmit them to eNB for application speciﬁc spectrum scheduling. The preliminary experimental results show the feasibility and the eﬃciency of the proposed application speciﬁc RAN slicing.
Keywords—Software-deﬁned Networking (SDN); Application Speciﬁc Optimization; Mobile Network
I. Introduction
Although 5G Mobile networks will provide much more mobile bandwidth than current LTE networks, the area of radio resource allocation optimization will continue receiving signiﬁcant interest as the operators face an increasing demand for mobile data traﬃc with various quality of service (QoS) requirements. Network slicing has been considered as one of the most signiﬁcant technologies for 5G mobile networks [1], where mobile network operators can apply diﬀerent spectrum allocation policies to diﬀerent Radio Spectrum Network (RAN) slices to improve spectrum eﬃciency and user experience.
However, how to eﬀectively identify and classify applications in real-time is still an open issue especially in the RAN research area due to the two main challenges. First, as long as data has been transmitted from user equipments (UEs) into a mobile network, the contextual information of the data (e.g., which application the data belongs to) is hidden from network alliances. Second, data packets will be compressed, concatenated and modulated in a RAN area, which makes application identiﬁcation in a RAN much more diﬃcult than that in a core network (CN).
To address this issue, we present an application speciﬁc RAN slicing architecture utilizing in-network deep learning. In our design, we apply in-network deep learning at Packet Gateway (P-GW) to identify mobile applications and attach the
978-1-5386-6831-3/18/$31.00 ⃝c 2018 IEEE

identiﬁcation results to the downlink packets and transmit them to eNodeB (eNB). The eNB can apply application speciﬁc spectrum allocation policy based on the attached application information.
The main advantage of the proposed architecture is that we propose to apply deep learning-based application identiﬁcation at packet gateway (P-GW). P-GW is the best point to perform application identiﬁcation since all traﬃc needs to go through P-GWs. As a comparison, there could be only a very limited number of UEs connected to a single eNB so that we may not be able to collect enough training data at a single eNB.
Second, with applying application identiﬁcation only once, we can apply the identiﬁcation results in both RAN and CN. Where, we deploy application speciﬁc spectrum allocation at eNB using the identiﬁcation results piggyback on the packets from P-GW to RAN. Meanwhile, we classify the uplink packets to diﬀerent virtual network functions for application speciﬁc in-network processing [2].
Finally, we show the feasibility of our proposal with a prototype on our existing platform [1]. As far as we know, there is very few real implementation of application speciﬁc spectrum scheduling although there are many simulation-based works [3], [4] on how to schedule spectrum resources with diﬀerent QoS requirements (e.g., real-time and delay-tolerant).
II. System Design

Internet

Supervising smartphone

App-specific scheduling
App tagged packet (TCP SYN)
eNB1

App tagged packet (TCP SYN/ACK)

Feature2 extraction
Classifier2 updating

regular packet
Regular smartphones

App-specific scheduling
eNB2

Traffic classification(UL) and tagging (DL)
P-GW

Feature data

Deep Learning
App1-specific Processing
App2-specific Processing
Appn-specific Processing
MEC

Fig. 1. Architecture of Deep Learning-based Application Speciﬁc RAN Slicing

As shown in Figure 1, we propose an architecture for application speciﬁc design of spectrum scheduling in RAN and packet processing in Mobile Edge Computing (MEC) in real-time utilizing deep learning on reliable training data

generated by supervising smartphones. We use a small number of customized smartphones as supervising smartphones to generate training data where packets are tagged with the information of the application transmitting them. Then we apply deep learning on given ﬂow and extract the useful features in a train of packets contained in the ﬂow, without looking into the payload of packets. After identify application at the Packet Gateway (P-GW), we can (1) classify the uplink packets from UE to diﬀerent virtual network functions in MEC for application speciﬁc in-network processing and (2) tag the downlink packets from MEC with the identiﬁed application name and transmit them to eNB. Then the eNB can apply application speciﬁc spectrum scheduling based on the attached application information. Since we have already shown the eﬃciency of application speciﬁc in-network processing in our previous work [2], we will focus on application speciﬁc spectrum scheduling in RAN in this paper.
A. Application Identiﬁcation at P-GW

Dst_IP Dst_Port
Protocol TTL
Packet_size

input hidden layer layer

hidden output layer layer

YouTube

Yahoo

Chrome

GMail

FireFox

Twi;er

Facebook

Packet Features

DNN

Applications

Fig. 2. Application Identiﬁcation with Deep Neural Networks with Extracted Features

Conventionally, there are several ways to achieve application identiﬁcation and classiﬁcation, e.g., packet header marking [5], and deep packet inspection (DPI) [6] to identify application from packet payload. But packet header marking fails to identify a broad scope of applications while DPI is becoming harder and harder due to that application speciﬁc information conveyed in payload is mostly likely encrypted.
As shown in Fig. 2, our training model is deﬁned based on deep neutral networks (DNN) with an input layer, multiple fully connected hidden layers and an output layer. Each layer is a feed-forward neural network.
To protect users’ privacy, we use <dst ip, dst port, protocol, ttl, packet size> as ﬂow features without looking into the payload of packets. The detail of our DNN module could be found in our previous work [7].

B. Application Speciﬁc Spectrum allocation in RAN
The radio resource of LTE link can be divided in both time and frequency dimensions. The frequency dimension is divided into subcarriers. The time dimension is ﬁrst divided into 10ms radio frames and each frame is further subdivided into ten 1ms subframes consisted of two 0.5ms slots. Transmission bandwidth depends on the number of active Resource Blocks (RBs) in a transmission. Each resource block can be allocated to only one user at a time slot.
Mobile operators are interested in improving their RB allocation algorithm to improve spectrum eﬃciency and user experience. For example, real time applications such as VoIP

and video streaming have strict latency and throughput requirements while the traﬃc of some other applications (e.g., Email) can adjust to wide range of changes in delay and throughput and still meet the user expectations. In [3], [4], the rate allocation algorithm gives priority to real-time applications over delay-tolerant applications when allocating resources as the utility proportional fairness rate allocation policy is used.
Some others work on RAN slicing to provide diﬀerent levels of radio resource isolation. FlexRAN [8] enables RAN slicing by decoupling the control from the data plane of base stations using a custom-tailored southbound API, where the radio resources need to be allocated among the connected UEs based on the requirements of the slice they belong to. The Orion [9] approach groups PRBs into vRB through a set of abstractions, and provides only relevant resource information to the corresponding slice.
None of the above works have addressed how to identify application and classify traﬃc to RAN slice. In most of existing work, mobile users are categorized based on applications running on their devices. In the proposed architecture shown in Fig. 1, we can reuse the application identiﬁcation results at P-GW and piggyback the application information on the very ﬁrst packets (e.g., TCP SYN/ACK) of each ﬂow. There are two beneﬁts of our design: (1) we don’t need to apply deep learning based application identiﬁcation on eNB so that the processing load of eNB could be reduced; (2) the traﬃc of all UEs must pass through the P-GWs while there is only a very limited number of UEs connected a single eNB so that we may not be able to get enough training data if we apply deep learning on the traﬃc collected at a single eNB.
C. Prototype of Application Speciﬁc RAN
We prototype the proposed application speciﬁc RAN slicing based on our previous work [1] with FLARE nodes [10] and OpenAirInterface (OAI) [11].
For the purpose of downlink spectrum scheduling, each UE probes the channel quality and reports the Channel Quality Indicator (CQI) to its associated eNB. The MAC layer of eNB then decides on the modulation scheme that can be scheduled to the UE and then check the physical resource grid for availability of the RBs. From this step the MAC can decide upon the modulation and coding scheme index (IMCS ) and then decide upon the number of resource blocks (RBs), which can be allocated to the UE. After this step, the maximum amount of data that can ﬁt into a RB, named transport block size (TBS) is derived from the look up table as speciﬁed in the LTE phy speciﬁcation [12].
The architecture of the OAI scheduling algorithm at MAC scheduler is as following: (1) calculates the average number of RBs for each active UE; (2) assigns the minimum RBs between requested RBs and average RB to each UE; (3) sorts active UEs according to some criteria such as the channel quality; (4) allocates the remaining RBs to high priority UEs according to the sorted list until no more RBs are available.
We ﬁrst retrieve an IP packet encapsulated in GTP-U at the S1-U interface of an eNB. Then we check whether its

trailer is tagged with application name. In our prototype, only TCP SYN/ACK packets with zero-payload are tagged with application information. The application information of the following packets from the existing ﬂows can be get from the <FlowID, App> table. The MAC layer will lookup the <App, Policy> table to schedule RBs according to the Policy. For a packet cannot be found in the <FlowID, App> table, the MAC layer will apply default RB scheduling policy.
One challenge is that the eNB schedules subframes at granularity of UE while we classify data into application at granularity of ﬂow, where data from multiple ﬂows of the same UE are assembled into one subframe at MAC layer. According to our previous research in [2], about 55% of UE devices launch only one TCP connection, and 70% of UE devices launch less than 2 concurrent TCP connections. So here we can safely assume that there is only main application running on each UE in a LTE network. In future 5G network, when a UE is running multiple applications with diﬀerent QoS requirement, we need to assemble ﬂows from diﬀerent applications into diﬀerent subframes even they are from the same UE.

Throughput (Mbps)
40 iperf-UE1 iperf-UE2

30

Test1

Test 2

20

Throughput (Mbps)
40 SpeedTest-UE1 iperf-UE2

30

Test3

Test4

20

10

10

0

Fair Fair

Greedy Fair

(a)

0

Fair Fair

Greedy Fair

(b)

Fig. 3. Comparison of Greedy and Fairly-Sharing Scheduling Policies.

observe that the two UEs can share bandwidth fairly under default fairly-sharing policy (Test3). As a comparison, if we apply SpeedTest the greedy policy, the SpeedTest-UE1 can get more bandwidth than iperf-UE2 in Test4.
IV. Conclusion and Future Work
In this paper, we present an application speciﬁc mobile network architecture utilizing in-network deep learning to apply application speciﬁc radio spectrum scheduling in RAN. We show the eﬃciency of the proposal with prototype. Our future work will focus on user-deﬁned RB scheduling policies.

III. System Evaluation
A. Application Identiﬁcation at P-GW
We use two-week MVNO data as training data, where each day of traﬃc consists of about 40000 ﬂows. Besides training and test, we use one-day of traﬃc as validation in training.
By using a tuple of <dst ip, dst port, protocol, ttl, packet size> as the features of application traﬃc captured at an MVNO, we can successfully identify 200 mobile applications with about 93.5% accuracy over 39-day traﬃc using an 8-layer Deep Neural Network with TensorFlow [13], where each hidden layer consists of 40000 (200x200) neurons. The detail of the evaluation is shown in [7].
B. Application Speciﬁc Spectrum Scheduling in RAN
As we introduced in Sect. II, a naive OAI RB scheduling is done in two rounds. At the ﬁrst round, we assign a maximum number of average number of RBs to each UE. The remaining RBs are allocated to high priority UEs. In our preliminary evaluation, besides the default two-round fairly scheduling policy, we also deﬁne a new greedy scheduling policy, where a UE running a high priority application can be assigned with requested RBs at the ﬁrst round.
In our evaluation, we ﬁrst check whether two UEs with default fairly-sharing policy can get bandwidth fairly. We run iperf receiver on both UEs and send UDP traﬃc to them from eNB. Fig. 3(a) shows that two UEs can get almost the same bandwidth when both applied the fairly-sharing policies (Test1). As a comparison, UE1 can get more bandwidth if we apply greedy policy to it in Test2.
Fig. 3(b) shows the experimental throughput results under diﬀerent scheduling policies with two TCP applications: iperf and SpeedTest. The iperf traﬃc is scheduled with the default fairly-sharing policy while SpeedTest is scheduled with fairly-sharing and greedy policy in diﬀerent tests. We

Acknowledgments
This work has been partly supported by the EU-Japan
coordinated R&D project 5G!Pagoda, and JSPS KAKENHI
Grant number JP18K11255 in Japan.
References
[1] Akihiro Nakao and Ping Du et. al, “End-to-end network slicing for 5g mobile networks,” IPSJ Journal of Information Processing, 2017.
[2] Ping Du and Akihiro Nakao, “Application speciﬁc mobile edge computing through network softwarization,” in Cloud Networking (Cloudnet), 2016 5th IEEE International Conference on. IEEE, 2016, pp. 130–135.
[3] Tugba Erpek, Ahmed Abdelhadi, and T Charles Clancy, “An optimal application-aware resource block scheduling in lte,” in Computing, Networking and Communications (ICNC), 2015 International Conference on. IEEE, 2015, pp. 275–279.
[4] Jun He and Wei Song, “Appran: Application-oriented radio access network sharing in mobile networks,” in Communications (ICC), 2015 IEEE International Conference on. IEEE, 2015, pp. 3788–3794.
[5] Arthur Callado, Carlos Kamienski, Ge´za Szabo´, Bala´zs Pe´ter Gero, Judith Kelner, Steˆnio Fernandes, and Djamel Sadok, “A survey on internet traﬃc identiﬁcation,” IEEE communications surveys & tutorials, vol. 11, no. 3, 2009.
[6] Michelle Cotton, Lars Eggert, Joe Touch, Magnus Westerlund, and Stuart Cheshire, “Internet assigned numbers authority (iana) procedures for the management of the service name and transport protocol port number registry,” Tech. Rep., 2011.
[7] Akihiro NAKAO and Ping DU, “Toward in-network deep machine learning for identifying mobile applications and enabling application speciﬁc network slicing,” IEICE Transactions on Communications E101B, vol. 14, pp. 153–163, 2018.
[8] Xenofon Foukas, Navid Nikaein, Mohamed M Kassem, Mahesh K Marina, and Kimon Kontovasilis, “Flexran: A ﬂexible and programmable platform for software-deﬁned radio access networks,” in Proceedings of the 12th International on Conference on emerging Networking EXperiments and Technologies. ACM, 2016, pp. 427–441.
[9] Xenofon Foukas, Mahesh K Marina, and Kimon Kontovasilis, “Orion: Ran slicing for a ﬂexible and cost-eﬀective multi-service mobile network architecture,” in Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking. ACM, 2017, pp. 127–140.
[10] “Flare: Open deeply programmable network node architecture,” http: //netseminar.stanford.edu/seminars/10 18 12.pdf.
[11] Navid Nikaein, Mahesh K Marina, Saravana Manickam, Alex Dawson, Raymond Knopp, and Christian Bonnet, “Openairinterface: A ﬂexible platform for 5g research,” ACM SIGCOMM Computer Communication Review, vol. 44, no. 5, pp. 33–38, 2014.
[12] ETSI Lte, “Evolved universal terrestrial radio access (e-utra); base station (bs) radio transmission and reception (3gpp ts 36.104 version 8.6. 0 release 8), july 2009,” ETSI TS, vol. 136, no. 104, pp. V8, 2009.
[13] “Tensorﬂow,” https://www.tensorﬂow.org/.

