\subsection{Background}

\subsubsection{Bandit Algorithm}
\begin{frame}{Multi-Armed-Bandit Algorithm}{Related work}


\begin{itemize}
	\item Arms: K = {1, ... , K}
	\item Decision: T = {1, ... , T}
	\item Reward: $X^{k}_{t}$ with $\mu^{k}_{t}$ = E $[X^{k}_{t}]$
	\begin{itemize}
		\item Best reward: $X^{*}_{t}$ with $\mu^{*}_{t}$ = max $\mu^{k}_{t}$,  k\in  K
	\end{itemize}
\end{itemize}

\end{frame}

\subsubsection{Genetic Algorithm}

\begin{frame}{Genetic Algorithm}{Related work \cite{alkhawlani_access_2008a}}

\begin{itemize}
	\item Heterogeneous wireless network: (RAT 1 ,RAT 2 ,...,RAT n)
	\item Criteria up to i (c 1 ,c 2 ,...,c i ) the operators, the applications, and the network conditions.
	\item 
	\item The different sets of scores (d 1 , d 2 ,...,d i ) are sent to the MCDM in the second component.
	\item GA component assigns a suitable weight (w 1 ,w 2 ,...,w i )
\end{itemize}

\end{frame}

\begin{frame}{Genetic Algorithm}{Related work}

\Itemize{
	\item 
	\item S = {SF12, BW125, 4/8, 17 dBm}
	\item Input: 
	\Itemize{
		\item Problem: f(x) = {max($x^{2}$), x \in [0,32]}
		\Itemize{
			\item $x_{1}: 01101_{b}$ 
			\item $x_{2}: 11000_{b}$
			\item $x_{3}: 01000_{b}$
			\item $x_{4}: 10011_{b}$
		}
	}

	\item Method: Genetic algorithm
	\Itemize{
		\item Generate a set of random possible solution
		\item Test each solution and see how good it is (ranking)
		\Itemize{
			\item Remove some bad solutions
			\item Duplicate some good solutions
			\item Make small changes to some of them (Crossover, Mutation)
		}
	}

	\item Output:
	\Itemize{
			\item $x_{1}$: 01101  (169)  (14.4)
			\item $x_{2}$: 11000  (576)  (49.2)
			\item $x_{3}$: 01000  (64 )  (5.5)
			\item $x_{4}$: 10011  (361)  (30.9)
	}
}
\end{frame}



\subsubsection{Marcov chain}

\begin{frame}{Marcov chain}{Related work}

\begin{equation}
V(s, \pi)=\mathbb{E}_{s}^{\pi}\left(\sum_{k=0}^{\mathrm{inf}} \gamma^{k} \cdot r\left(s_{k}, a_{k}\right)\right), s \in \mathbb{S}
\end{equation}

\begin{equation}
r\left(s_{k}, a_{k}\right)=G_{k} \cdot P R R\left(a_{k}\right)
\end{equation}

\begin{equation}
\pi^{*}=\arg \max _{\pi} V(s, \pi)
\end{equation}


% \stamp{HGHGJ}
% \begin{tikzpicture}[remember picture, overlay]
% 	\node[draw, rotate=30] at (25em, 7ex) {\color{red!90}\huge\bfseries APPROVED};
% \end{tikzpicture}

\begin{equation}
PRR=(1-BER)^{L}
\end{equation}

\begin{equation}
BER=10^{\alpha e^{\beta SNR}}
\end{equation}

\end{frame}

\begin{frame}{Marcov chain}{Related work}
\Figure{h}{1}{markov}{}
\end{frame}


\subsubsection{Game theory}
\begin{frame}{Game theory}{Related work}
\Itemize{
	\item Players: $K = \{1, ... , K\}$
	\item Strategies: $S =S_{1} \times \ldots \times S_{K}$
	\Itemize{
		\item $S_{k}$ is the strategy set of the $k^{th}$ player.
	}
	\item Rewards: $u_{k} : S \longrightarrow R_{+}$ and is denoted by $r_{k} (s_{k} , s_{-k})$
	\Itemize{
		\item $s_{-k}=\left(s_{1}, \dots, s_{k-1}, s_{k+1}, \ldots, s_{K}\right) \in S_{1} \times \ldots \times S_{k-1} \times S_{k+1} \times \ldots \times S_{K}$
	}
}
 \end{frame}


