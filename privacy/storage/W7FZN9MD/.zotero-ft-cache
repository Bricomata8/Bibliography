UNIVERSIDAD POLITE´ CNICA DE MADRID
ESCUELA TE´ CNICA SUPERIOR DE INGENIEROS DE TELECOMUNICACIO´ N
TESIS DOCTORAL Trust-ware: A Methodology to Analyze, Design, and
Secure Trust and Reputation Systems
Autor: David Fraga Aydillo
Ingeniero de Telecomunicacio´ n
Directores: Jose´ Manuel Moya Ferna´ndez
Doctor Ingeniero de Telecomunicacio´ n
Zorana Bankovic´
Doctor Ingeniero de Telecomunicacio´ n
2015

David Fraga Aydillo E-mail: dfraga@die.upm.es
©2015 David Fraga Aydillo
Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later versio´n published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled GNU Free Documentation License.

Ph.D. Thesis

T´ıtulo: Autor: Tutor: Departamento:

Trust-ware: A Methodology to Analyze, Design, And Secure Trust and Reputation Systems
DAVID FRAGA AYDILLO
JOSE´ MANUEL MOYA FERNA´ NDEZ ZORANA BANKOVIC´
DEPARTAMENTO DE INGENIER´IA ELECTRO´ NICA

Miembros del tribunal:
Presidente: Secretario: Vocal: Vocal: Vocal:
Suplente: Suplente:
Los miembros del tribunal arriba nombrados acuerdan otorgar la caliﬁcacio´ n de:

Madrid, de

de 2015

“Trust is the glue of life. It’s the most essential ingredient in effective communication. It’s the foundational principle that holds all relationships.”
— Stephen Covey

Acknowledgments
“If I have seen a little further it is by standing on the shoulders of Giants.”
— Isaac Newton
El camino que ha sido necesario recorrer para llegar hasta aqu´ı no ha sido corto. De hecho, ha sido muy largo. Quiza´s no tanto en duracio´ n, pero s´ı en intensidad. Durante mucho tiempo llegue´ a pensar que nunca me ver´ıa en la situacio´ n de escribir estas l´ıneas. Me alegro de haberme equivocado.
Gran parte de la culpa de que al ﬁnal este trabajo haya podido llegar a su ﬁn recae en toda esa gente que conﬁo´ en mi incondicionalmente y siempre me apoyo´ a que siguiera adelante. Para todos ellos son estos agradecimientos.
En primer lugar quiero dar las gracias a josem. Si ya fue´ mi maestro, y aute´ntico referente, en el desarrollo de mi vida como ingeniero, ahora lo ha vuelto a conseguir en mi vida como investigador. Pragmatismo, optimismo, paciencia y dispersio´ n a partes iguales. Aunque casi, no hay dos como e´l.
A continuacio´ n, mencio´ n especial para mis dos compan˜ eros de venturas y desventuras en la l´ınea de TRS: Zorana y Juan Carlos. No puedo tener mejor recuerdo de los meses que pudimos trabajar juntos. Una ma´quina perfectamente engrasada en la conseguimos que el equipo fuera incluso mejor que la suma de sus partes (que se dice pronto).
Por otro lado me gustar´ıa agradecer todo su apoyo a esas otras dos familias investigadoras de las que he podio formar parte: la gente de GreenLSI, que me acogio´ en los momentos ma´s duros para que pudiera continuar con mi investigacio´ n, y la gente del GTH del 039. Gracias por hacerme sentir tan a gusto entre vosotros (aunque fuera una anomal´ıa).
Ahora es el turno de mis otras dos familias, las de verdad. Gracias a Jose´ Antonio y a Amalia, por su conﬁanza y apoyo incondicionales y por ser los mejores padres que alguien podr´ıa tener, y gracias a Susana, por ser la sonrisa que siempre alegra nuestros d´ıas. Y por supuesto, gracias a Patricia, por estar siempre ah´ı. Tengo un millo´ n de cosas que agradecerte, pero tambie´n toda una vida para hacerlo.
Ya por u´ ltimo, por no perder la costumbre, quer´ıa dar las gracias a Los Hijos del Trueno y a Dani Filth por hacer del mundo un lugar tan especial.
I

Abstract
“I suppose the most obvious question is: how can I trust you?”
— Neo talking to The Oracle, The Matrix Reloaded
By collective intelligence we understand a form of intelligence that emerges from the collaboration and competition of many individuals, or strictly speaking, many entities. Based on this simple deﬁnition, we can see how this concept is the ﬁeld of study of a wide range of disciplines, such as sociology, information science or biology, each of them focused in different kinds of entities: human beings, computational resources, or animals.
As a common factor, we can point that collective intelligence has always had the goal of being able of promoting a group intelligence that overcomes the individual intelligence of the basic entities that constitute it. This can be accomplished through different mechanisms such as coordination, cooperation, competence, integration, differentiation, etc.
Collective intelligence has historically been developed in a parallel and independent way among the different disciplines that deal with it. However, this is not enough anymore due to the advances in information technologies. Nowadays, human beings and machines coexist in environments where collective intelligence has taken a new dimension: we yet have to achieve a better collective behavior than the individual one, but now we also have to deal with completely different kinds of individual intelligences. Therefore, we have a double goal: being able to deal with this heterogeneity and being able to get even more intelligent behaviors thanks to the synergies that the different kinds of intelligence can generate.
Within the areas of collective intelligence there are several open topics where they always try to get better performances from groups than from the individuals. For example: collective consciousness, collective memory, or collective wisdom. Among all these topics we will focus on collective decision making, that has inﬂuence in most of the collective intelligent behaviors.
The ﬁeld of study of decision making is really wide, and its evolution has been completely parallel to the aforementioned collective intelligence. Firstly, it was focused on the individual as the main decision-making entity, but later it became involved in studying social and institutional groups as basic decision-making entities.
The ﬁrst studies within the decision-making discipline were based on simple paradigms, such as pros and cons analysis, criteria prioritization, fulﬁllment, following orders, or even chance. However, in the same way that studying the community instead of the individual meant a paradigm shift within collective intelligence, collective decision-making means a new challenge for all the related disciplines. Besides, two new main topics come up when dealing with collective decision-making: centralized and decentralized decision-making systems. In this thesis project we focus in the second one, because it is the most interesting based on the opportunities to generate new knowledge and deal with open issues in this area, as well as these results can be put into practice in a wider set of real-life environments.
Finally, within the decentralized collective decision-making systems discipline, there are several basic mechanisms that lead to different approaches to the speciﬁc problems of this ﬁeld, for example: leadership, imitation, prescription, or fear. We will focus on trust and reputation. They are one of the most multidisciplinary concepts and with more potential for applying them in every kind of environments. Besides, they have historically shown that they can generate better performance than other decentralized decision-making mechanisms.
III

Shortly, we say trust is the belief of one entity that the outcome of other entities’ actions is going to be in a speciﬁc way. It is a subjective concept because the trust of two different entities in another one does not have to be the same.
Reputation is the collective idea (or social evaluation) that a group of entities within a system have about another entity based on a speciﬁc criterion. Thus, it is a collective concept in its origin.
It is important to say that the behavior of most of the collective systems are based on these two simple deﬁnitions. In fact, a lot of articles and essays describe how any organization would not be viable if the ideas of trust and reputation did not exist. From now on, we call Trust an Reputation System (TRS) to any kind of system that uses these concepts.
Even though TRSs are one of the most common everyday aspects in our lives, the existing knowledge about them could not be more dispersed. There are thousands of scientiﬁc works in every ﬁeld of study related to trust and reputation: philosophy, psychology, sociology, economics, politics, information sciences, etc. But the main issue is that a comprehensive vision of trust and reputation for all these disciplines does not exist.
Every discipline focuses its studies on a speciﬁc set of topics but none of them tries to take advantage of the knowledge generated in the other disciplines to improve its behavior or performance. Detailed topics in some ﬁelds are completely obviated in others, and even though the study of some topics within several disciplines produces complementary results, these results are not used outside the discipline where they were generated.
This leads us to a very high knowledge dispersion and to a lack in the reuse of methodologies, policies and techniques among disciplines.
Due to its great importance, this high dispersion of trust and reputation knowledge is one of the main problems this thesis contributes to solve.
When we work with TRSs, all the aspects related to security are a constant since it is a vital aspect within the decision-making systems. Besides, TRS are often used to perform some responsibilities related to security. Finally, we cannot forget that the act of trusting is invariably attached to the act of delegating a speciﬁc responsibility and, when we deal with these concepts, the idea of risk is always present. This refers to the risk of generated expectations not being accomplished or being accomplished in a different way we anticipated.
Thus, we can see that any system using trust to improve or enable its behavior, because of its own nature, is especially vulnerable if the premises it is based on are attacked.
Related to this topic, we can see that the approaches of the different disciplines that study attacks of trust and reputation are very diverse. Some attempts of using approaches of other disciplines have been made within the information science area of knowledge, but these approaches are usually incomplete, not systematic and oriented to achieve speciﬁc requirements of speciﬁc applications. They never try to consolidate a common base of knowledge that could be reusable in other context.
Based on all these ideas, this work makes the following direct contributions to the ﬁeld of TRS:
• The compilation of the most relevant existing knowledge related to trust and reputation management systems focusing on their advantages and disadvantages.
• We deﬁne a generic architecture for TRS, identifying the main entities and processes involved.
• We deﬁne a generic security framework for TRS. We identify the main security assets and propose a complete taxonomy of attacks for TRS.
• We propose and validate a methodology to analyze, design, secure and deploy TRS in real-life environments. Additionally we identify the principal kind of applications we can implement with TRS and how TRS can provide a speciﬁc functionality.
• We develop a software component to validate and optimize the behavior of a TRS in order to achieve a speciﬁc functionality or performance.
IV

In addition to the contributions made directly to the ﬁeld of the TRS, we have made original contributions to different areas of knowledge thanks to the application of the analysis, design and security methodologies previously presented:
• Detection of thermal anomalies in Data Centers. Thanks to the application of the TRS analysis and design methodologies, we successfully implemented a thermal anomaly detection system based on a TRS. We compare the detection performance of Self-OrganizedMaps and Growing Neural Gas algorithms. We show how SOM provides better results for Computer Room Air Conditioning anomaly detection, yielding detection rates of 100%, in training data with malfunctioning sensors. We also show that GNG yields better detection and isolation rates for workload anomaly detection, reducing the false positive rate when compared to SOM.
• Improving the performance of a harvesting system based on swarm computing and social odometry. Through the implementation of a TRS, we achieved to improve the ability of coordinating a distributed network of autonomous robots. The main contribution lies in the analysis and validation of the incremental improvements that can be achieved with proper use information that exist in the system and that are relevant for the TRS, and the implementation of the appropriated trust algorithms based on such information.
• Improving Wireless Mesh Networks security against attacks against the integrity, conﬁdentiality or availability of data and communications supported by these networks. Thanks to the implementation of a TRS we improved the detection time rate against these kind of attacks and we limited their potential impact over the system.
• We improved the security of Wireless Sensor Networks against advanced attacks, such as insider attacks, unknown attacks, etc. Thanks to the TRS analysis and design methodologies previously described, we implemented countermeasures against such attacks in a complex environment. In our experiments we have demonstrated that our system is capable of detecting and conﬁning various attacks that affect the core network protocols. We have also demonstrated that our approach is capable of rapid attack detection. Also, it has been proven that the inclusion of the proposed detection mechanisms signiﬁcantly increases the effort the attacker has to introduce in order to compromise the network.
Finally we can conclude that, to all intents and purposes, this thesis offers a useful and applicable knowledge in real-life environments that allows us to maximize the performance of any system based on a TRS.
Thus, we deal with the main deﬁciency of this discipline: the lack of a common and complete base of knowledge and the lack of a methodology for the development of TRS that allow us to analyze, design, secure and deploy TRS in a systematic way.
V

Resumen
Entendemos por inteligencia colectiva una forma de inteligencia que surge de la colaboracio´ n y la participacio´ n de varios individuos o, siendo ma´s estrictos, varias entidades. En base a esta sencilla deﬁnicio´ n podemos observar que este concepto es campo de estudio de las ma´s diversas disciplinas como pueden ser la sociolog´ıa, las tecnolog´ıas de la informacio´ n o la biolog´ıa, atendiendo cada una de ellas a un tipo de entidades diferentes: seres humanos, elementos de computacio´ n o animales.
Como elemento comu´ n podr´ıamos indicar que la inteligencia colectiva ha tenido como objetivo el ser capaz de fomentar una inteligencia de grupo que supere a la inteligencia individual de las entidades que lo forman a trave´s de mecanismos de coordinacio´ n, cooperacio´ n, competencia, integracio´ n, diferenciacio´ n, etc.
Sin embargo, aunque histo´ ricamente la inteligencia colectiva se ha podido desarrollar de forma paralela e independiente en las distintas disciplinas que la tratan, en la actualidad, los avances en las tecnolog´ıas de la informacio´ n han provocado que esto ya no sea suﬁciente. Hoy en d´ıa seres humanos y ma´quinas a trave´s de todo tipo de redes de comunicacio´ n e interfaces, conviven en un entorno en el que la inteligencia colectiva ha cobrado una nueva dimensio´ n: ya no so´ lo puede intentar obtener un comportamiento superior al de sus entidades constituyentes sino que ahora, adema´s, estas inteligencias individuales son completamente diferentes unas de otras y aparece por lo tanto el doble reto de ser capaces de gestionar esta gran heterogeneidad y al mismo tiempo ser capaces de obtener comportamientos au´ n ma´s inteligentes gracias a las sinergias que los distintos tipos de inteligencias pueden generar.
Dentro de las a´reas de trabajo de la inteligencia colectiva existen varios campos abiertos en los que siempre se intenta obtener unas prestaciones superiores a las de los individuos. Por ejemplo: consciencia colectiva, memoria colectiva o sabidur´ıa colectiva. Entre todos estos campos nosotros nos centraremos en uno que tiene presencia en la pra´ctica totalidad de posibles comportamientos inteligentes: la toma de decisiones.
El campo de estudio de la toma de decisiones es realmente amplio y dentro del mismo la evolucio´ n ha sido completamente paralela a la que cita´bamos anteriormente en referencia a la inteligencia colectiva. En primer lugar se centro´ en el individuo como entidad decisoria para posteriormente desarrollarse desde un punto de vista social, institucional, etc.
La primera fase dentro del estudio de la toma de decisiones se baso´ en la utilizacio´ n de paradigmas muy sencillos: ana´lisis de ventajas e inconvenientes, priorizacio´ n basada en la maximizacio´ n de algu´ n para´metro del resultado, capacidad para satisfacer los requisitos de forma m´ınima por parte de las alternativas, consultas a expertos o entidades autorizadas o incluso el azar. Sin embargo, al igual que el paso del estudio del individuo al grupo supone una nueva dimensio´ n dentro la inteligencia colectiva la toma de decisiones colectiva supone un nuevo reto en todas las disciplinas relacionadas. Adema´s, dentro de la decisio´ n colectiva aparecen dos nuevos frentes: los sistemas de decisio´ n centralizados y descentralizados. En el presente proyecto de tesis nos centraremos en este segundo, que es el que supone una mayor atractivo tanto por las posibilidades de generar nuevo conocimiento y trabajar con problemas abiertos actualmente as´ı como en lo que respecta a la aplicabilidad de los resultados que puedan obtenerse.
Ya por u´ ltimo, dentro del campo de los sistemas de decisio´ n descentralizados existen varios mecanismos fundamentales que dan lugar a distintas aproximaciones a la problema´tica propia de este campo. Por ejemplo el liderazgo, la imitacio´ n, la prescripcio´ n o el miedo. Nosotros nos
VII

centraremos en uno de los ma´s multidisciplinares y con mayor capacidad de aplicacio´ n en todo tipo de disciplinas y que, histo´ ricamente, ha demostrado que puede dar lugar a prestaciones muy superiores a otros tipos de mecanismos de decisio´ n descentralizados: la conﬁanza y la reputacio´ n.
Resumidamente podr´ıamos indicar que conﬁanza es la creencia por parte de una entidad que otra va a realizar una determinada actividad de una forma concreta. En principio es algo subjetivo, ya que la conﬁanza de dos entidades diferentes sobre una tercera no tiene porque´ ser la misma.
Por otro lado, la reputacio´ n es la idea colectiva (o evaluacio´ n social) que distintas entidades de un sistema tiene sobre otra entidad del mismo en lo que respecta a un determinado criterio. Es por tanto una informacio´ n de cara´cter colectivo pero u´ nica dentro de un sistema, no asociada a cada una de las entidades del sistema sino por igual a todas ellas.
En estas dos sencillas deﬁniciones se basan la inmensa mayor´ıa de sistemas colectivos. De hecho muchas disertaciones indican que ningu´ n tipo de organizacio´ n podr´ıa ser viable de no ser por la existencia y la utilizacio´ n de los conceptos de conﬁanza y reputacio´ n. A partir de ahora, a todo sistema que utilice de una u otra forma estos conceptos lo denominaremos como sistema de conﬁanza y reputacio´ n (o TRS, Trust and Reputation System).
Sin embargo, aunque los TRS son uno de los aspectos de nuestras vidas ma´s cotidianos y con un mayor campo de aplicacio´ n, el conocimiento que existe actualmente sobre ellos no podr´ıa ser ma´s disperso.
Existen un gran nu´ mero de trabajos cient´ıﬁcos en todo tipo de a´reas de conocimiento: ﬁlosof´ıa, psicolog´ıa, sociolog´ıa, econom´ıa, pol´ıtica, tecnolog´ıas de la informacio´ n, etc. Pero el principal problema es que no existe una visio´ n completa de la conﬁanza y reputacio´ n en su sentido ma´s amplio.
Cada disciplina focaliza sus estudios en unos aspectos u otros dentro de los TRS, pero ninguna de ellas trata de explotar el conocimiento generado en el resto para mejorar sus prestaciones en su campo de aplicacio´ n concreto. Aspectos muy detallados en algunas a´reas de conocimiento son completamente obviados por otras, o incluso aspectos tratados por distintas disciplinas, al ser estudiados desde distintos puntos de vista arrojan resultados complementarios que, sin embargo, no son aprovechados fuera de dichas a´reas de conocimiento.
Esto nos lleva a una dispersio´ n de conocimiento muy elevada y a una falta de reutilizacio´ n de metodolog´ıas, pol´ıticas de actuacio´ n y te´cnicas de una disciplina a otra.
Debido su vital importancia, esta alta dispersio´ n de conocimiento se trata de uno de los principales problemas que se pretenden resolver con el presente trabajo de tesis.
Por otro lado, cuando se trabaja con TRS, todos los aspectos relacionados con la seguridad esta´n muy presentes ya que muy este es un tema vital dentro del campo de la toma de decisiones. Adema´s tambie´n es habitual que los TRS se utilicen para desempen˜ ar responsabilidades que aportan algu´ n tipo de funcionalidad relacionada con el mundo de la seguridad. Por u´ ltimo no podemos olvidar que el acto de conﬁar esta´ indefectiblemente unido al de delegar una determinada responsabilidad, y que al tratar estos conceptos siempre aparece la idea de riesgo, riesgo de que las expectativas generadas por el acto de la delegacio´ n no se cumplan o se cumplan de forma diferente.
Podemos ver por lo tanto que cualquier sistema que utiliza la conﬁanza para mejorar o posibilitar su funcionamiento, por su propia naturaleza, es especialmente vulnerable si las premisas en las que se basa son atacadas.
En este sentido podemos comprobar (tal y como analizaremos en ma´s detalle a lo largo del presente documento) que las aproximaciones que realizan las distintas disciplinas que tratan la violacio´ n de los sistemas de conﬁanza es de lo ma´s variado. u´ nicamente dentro del a´rea de las tecnolog´ıas de la informacio´ n se ha intentado utilizar alguno de los enfoques de otras disciplinas de cara a afrontar problemas relacionados con la seguridad de TRS. Sin embargo se trata de una aproximacio´ n incompleta y, normalmente, realizada para cumplir requisitos de aplicaciones concretas y no con la idea de aﬁanzar una base de conocimiento ma´s general y reutilizable en otros entornos.
Con todo esto en cuenta, podemos resumir contribuciones del presente trabajo de tesis en las siguientes.
VIII

• La realizacio´ n de un completo ana´lisis del estado del arte dentro del mundo de la conﬁanza y la reputacio´ n que nos permite comparar las ventajas e inconvenientes de las diferentes aproximacio´ n que se realizan a estos conceptos en distintas a´reas de conocimiento.
• La deﬁnicio´ n de una arquitectura de referencia para TRS que contempla todas las entidades y procesos que intervienen en este tipo de sistemas.
• La deﬁnicio´ n de un marco de referencia para analizar la seguridad de TRS. Esto implica tanto identiﬁcar los principales activos de un TRS en lo que respecta a la seguridad, as´ı como el crear una tipolog´ıa de posibles ataques y contramedidas en base a dichos activos.
• La propuesta de una metodolog´ıa para el ana´lisis, el disen˜ o, el aseguramiento y el despliegue de un TRS en entornos reales. Adicionalmente se exponen los principales tipos de aplicaciones que pueden obtenerse de los TRS y los medios para maximizar sus prestaciones en cada una de ellas.
• La generacio´ n de un software que permite simular cualquier tipo de TRS en base a la arquitectura propuesta previamente. Esto permite evaluar las prestaciones de un TRS bajo una determinada conﬁguracio´ n en un entorno controlado previamente a su despliegue en un entorno real. Igualmente es de gran utilidad para evaluar la resistencia a distintos tipos de ataques o mal-funcionamientos del sistema.
Adema´s de las contribuciones realizadas directamente en el campo de los TRS, hemos realizado aportaciones originales a distintas a´reas de conocimiento gracias a la aplicacio´ n de las metodolog´ıas de ana´lisis y disen˜ o citadas con anterioridad.
• Deteccio´ n de anomal´ıas te´rmicas en Data Centers. Hemos implementado con e´xito un sistema de detecio´ n de anomal´ıas te´rmicas basado en un TRS. Comparamos la deteccio´ n de prestaciones de algoritmos de tipo Self-Organized Maps (SOM) y Growing Neural Gas (GNG). Mostramos como SOM ofrece mejores resultados para anomal´ıas en los sistemas de refrigeracio´ n de la sala mientras que GNG es una opcio´ n ma´s adecuada debido a sus tasas de deteccio´ n y aislamiento para casos de anomal´ıas provocadas por una carga de trabajo excesiva.
• Mejora de las prestaciones de recoleccio´ n de un sistema basado en swarm computing y odometr´ıa social. Gracias a la implementacio´ n de un TRS conseguimos mejorar las capacidades de coordinacio´ n de una red de robots auto´ nomos distribuidos. La principal contribucio´ n reside en el ana´lisis y la validacio´ n de las mejoras incrementales que pueden conseguirse con la utilizacio´ n apropiada de la informacio´ n existente en el sistema y que puede ser relevante desde el punto de vista de un TRS, y con la implementacio´ n de algoritmos de ca´lculo de conﬁanza basados en dicha informacio´ n.
• Mejora de la seguridad de Wireless Mesh Networks contra ataques contra la integridad, la conﬁdencialidad o la disponibilidad de los datos y/o comunicaciones soportadas por dichas redes.
• Mejora de la seguridad de Wireless Sensor Networks contra ataques avanzamos, como insider attacks, ataques desconocidos, etc. Gracias a las metodolog´ıas presentadas implementamos contramedidas contra este tipo de ataques en entornos complejos. En base a los experimentos realizados, hemos demostrado que nuestra aproximacio´ n es capaz de detectar y conﬁnar varios tipos de ataques que afectan a los protocoles esenciales de la red. La propuesta ofrece unas velocidades de deteccio´ n muy altas as´ı como demuestra que la inclusio´ n de estos mecanismos de actuacio´ n temprana incrementa signiﬁcativamente el esfuerzo que un atacante tiene que introducir para comprometer la red.
Finalmente podr´ıamos concluir que el presente trabajo de tesis supone la generacio´ n de un conocimiento u´ til y aplicable a entornos reales, que nos permite la maximizacio´ n de las prestaciones resultantes de la utilizacio´ n de TRS en cualquier tipo de campo de aplicacio´ n.
IX

De esta forma cubrimos la principal carencia existente actualmente en este campo, que es la falta de una base de conocimiento comu´ n y agregada y la inexistencia de una metodolog´ıa para el desarrollo de TRS que nos permita analizar, disen˜ ar, asegurar y desplegar TRS de una forma sistema´tica y no artesanal y ad-hoc como se hace en la actualidad.
X

Contents

Acknowledgments

I

Abstract

III

Resumen

VII

1 Introduction

1

1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2.1 Collective Intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.2.2 Decentralized Decision-making Techniques . . . . . . . . . . . . . . . . . 2

1.2.3 T&R in different ﬁelds of knowledge . . . . . . . . . . . . . . . . . . . . . 4

1.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

1.4 Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

1.5 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

1.5.1 Journal papers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

1.5.2 Conference papers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

1.5.3 Other publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

1.6 Research Projects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

2 Related work

17

2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.2 Trust Management Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.3 State of the Art . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2.3.1 Marsh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2.3.2 Fortune’s Most Admired Companies List . . . . . . . . . . . . . . . . . . 18

2.3.3 Castelfranchi and Falcone . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2.3.4 Sporas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.3.5 Histos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.3.6 Abdul-Rahman and Hailes . . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.3.7 Schillo et al. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.3.8 Yu and Singh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.3.9 REGRET . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2.3.10 Aberer and Despotovic . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2.3.11 Esfandiary and Chandrasekharan . . . . . . . . . . . . . . . . . . . . . . 20

2.3.12 Afras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2.3.13 Azzedin and Maheswaran . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.3.14 Carter et al. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.3.15 SECURE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.3.16 Wang and Vassileva . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.3.17 XenoTrust . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.3.18 Shand et al. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

2.3.19 Reputation Quotient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

2.3.20 FIRE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

XI

CONTENTS
2.3.21 PeerTrust . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.3.22 Corporate Personality Scale . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.3.23 SPIRIT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.24 TIBFIT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.25 UniTEC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.26 TRAVOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.27 Crosby and Pissinou . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.28 BambooTrust . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.3.29 TidalTrust . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.3.30 Bayesian Reputation System . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.3.31 Reputation-based Framework for High Integrity Sensor Networks . . . 24 2.3.32 Distributed Reputation-based Beacon Trust System . . . . . . . . . . . . 24 2.3.33 Subjective Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

I Models and Methodologies

27

3 Architecture and Methodology to Analyze TRS

29

3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

3.2 Proposed TRS Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

3.2.1 Architectural Components . . . . . . . . . . . . . . . . . . . . . . . . . . 30

3.2.2 Processes Involved . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

3.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

3.3.1 Observers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

3.3.2 Trust Information Acquisition . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.3.3 Trust Calculation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 34

3.3.4 Disseminators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

3.3.5 Dissemination Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

3.3.6 Reputation Servers, Information Sources, and Calculation Algorithms . 37

3.3.7 Underlying system requirements . . . . . . . . . . . . . . . . . . . . . . . 38

3.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

4 TRS Design Methodology

41

4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

4.2 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

4.3 Characterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.3.1 Basic Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.3.2 Extended Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

4.3.3 Typology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

4.3.4 Underlying System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

4.4 TRS Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

4.4.1 Trust and Reputation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.4.2 Architectural components . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.4.3 Sources of Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.4.4 Architectural processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.5 Related Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.5.1 Implementation and Deployment . . . . . . . . . . . . . . . . . . . . . . 47

4.5.2 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

XII

CONTENTS

5 TRS Attack Taxonomy

49

5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

5.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

5.3 Proposed Security Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

5.4 Trust and Reputation System Attack Taxonomy . . . . . . . . . . . . . . . . . . . 53

5.4.1 Attacks against gathering T&R information . . . . . . . . . . . . . . . . . 54

5.4.2 Attacks against T&R calculation . . . . . . . . . . . . . . . . . . . . . . . 55

5.4.3 Attacks against T&R dissemination . . . . . . . . . . . . . . . . . . . . . 56

5.4.4 Taxonomy-based Analysis Conclusions . . . . . . . . . . . . . . . . . . . 57

5.5 Case of study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.5.1 Journal Citation Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.5.2 Gathering T&R information . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.5.3 T&R calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

5.5.4 Gathering T&R dissemination . . . . . . . . . . . . . . . . . . . . . . . . 58

5.5.5 JCR Analysis Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

II Cases of study

61

6 Detection and isolation: Anomalies in Data Centers

63

6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

6.2 Detecting Anomalies in Data Centers . . . . . . . . . . . . . . . . . . . . . . . . . 64

6.3 TRS and Anomaly Detection in Data Centers . . . . . . . . . . . . . . . . . . . . 64

6.3.1 Underlying System Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 65

6.3.2 Requirement and Goals: Taxonomy of Anomalies . . . . . . . . . . . . . 65

6.3.3 Trust and Reputation System Analysis . . . . . . . . . . . . . . . . . . . . 66

6.3.4 Trust and Reputation Algorithms . . . . . . . . . . . . . . . . . . . . . . . 66

6.3.5 TRS mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68

6.4 Experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

6.4.1 Anomalies in the data room cooling . . . . . . . . . . . . . . . . . . . . . 70

6.4.2 Anomalies in the workload execution . . . . . . . . . . . . . . . . . . . . 71

6.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72

7 Throughput Maximization: Social Odometry

73

7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

7.2 Social Odometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

7.2.1 The odometry problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

7.2.2 Learning from others . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

7.2.3 Social Odometry equations . . . . . . . . . . . . . . . . . . . . . . . . . . 75

7.3 TRS in a Social Odometry context . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

7.3.1 Underlying System Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 76

7.3.2 Trust and Reputation System Analysis . . . . . . . . . . . . . . . . . . . . 76

7.3.3 The Trust Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77

7.3.4 TRS mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

7.4 Experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

7.4.1 Simulation Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

7.4.2 Simulation experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81

7.4.3 Computation and communication complexity . . . . . . . . . . . . . . . 82

7.5 Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

7.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

XIII

CONTENTS

8 Improving Overall Security: Wireless Mesh Networks

87

8.1 Introduction to WMNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87

8.2 Attacks and countermeasures in WMNs . . . . . . . . . . . . . . . . . . . . . . . 88

8.2.1 Authentication/Identity attacks . . . . . . . . . . . . . . . . . . . . . . . 88

8.2.2 Availability attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89

8.2.3 Utility attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89

8.2.4 WMN countermeasures: Secure routing protocols . . . . . . . . . . . . . 90

8.2.5 WMN Security Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . 91

8.3 Improving WMN security with TRS . . . . . . . . . . . . . . . . . . . . . . . . . 91

8.3.1 Trust and Reputation System Analysis . . . . . . . . . . . . . . . . . . . . 91

8.3.2 The Trust Information Sources . . . . . . . . . . . . . . . . . . . . . . . . 92

8.3.3 The Trust Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

8.3.4 TRS mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94

8.4 Experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96

8.4.1 The Redundancy problem . . . . . . . . . . . . . . . . . . . . . . . . . . . 96

8.4.2 Routing-behavior attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . 98

8.4.3 Resources availability attacks . . . . . . . . . . . . . . . . . . . . . . . . . 98

8.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

9 Advanced Topics: Insider Attacks in Wireless Sensor Networks

103

9.1 Introduction to Insider Attacks in Wireless Sensor Networks . . . . . . . . . . . 103

9.1.1 Overview of the Proposed Scenario . . . . . . . . . . . . . . . . . . . . . 104

9.2 Detecting and Conﬁning Insider Attacks in WSN . . . . . . . . . . . . . . . . . . 104

9.3 Improving WSN security with TRS . . . . . . . . . . . . . . . . . . . . . . . . . . 105

9.3.1 Underlying System Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 106

9.3.2 Trust and Reputation System Analysis . . . . . . . . . . . . . . . . . . . . 107

9.4 Trust and Reputation algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

9.4.1 Feature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108

9.4.2 Deployed Distance Function . . . . . . . . . . . . . . . . . . . . . . . . . 108

9.4.3 Scope of Attacks Covered With the Approach . . . . . . . . . . . . . . . 108

9.4.4 Trust Calculation and Recovery from Attacks . . . . . . . . . . . . . . . . 110

9.4.5 Distributed Organization of Observers . . . . . . . . . . . . . . . . . . . 112

9.4.6 Deployment issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

9.4.7 TRS mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113

9.5 Experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

9.5.1 Simulation Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

9.5.2 Insider Attack Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116

9.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

9.6.1 Network Survivability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

9.6.2 Resource Consumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

9.6.3 Characterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120

9.6.4 Optimal threshold value . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

9.6.5 Starting Point Of Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

9.6.6 Reducing false positives . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

9.6.7 Detection time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

9.7 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

10 Conclusions and Future Work

123

10.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

10.2 Future Research Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125

XIV

CONTENTS

Appendix A TRS-sim: Trust and Reputation System Simulator

127

A.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127

A.2 TRS-Sim Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127

A.3 Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128

A.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128

Bibliography

142

XV

CONTENTS XVI

List of Tables
1.1 Main trust and reputation topics of study by ﬁeld of knowledge . . . . . . . . . 9 2.1 Main contributions of TMS in the literature - I . . . . . . . . . . . . . . . . . . . . 25 2.2 Main contributions of TMS in the literature - II . . . . . . . . . . . . . . . . . . . 26 5.1 TRS Attack Taxonomy. Gathering T&R Information . . . . . . . . . . . . . . . . 54 5.2 TRS Attack Taxonomy. T&R Calculation . . . . . . . . . . . . . . . . . . . . . . . 55 5.3 TRS Attack Taxonomy. T&R Dissemination . . . . . . . . . . . . . . . . . . . . . 56 6.1 TRS and Anomaly Detection in Data Centers: system speciﬁcation. . . . . . . . 69 7.1 TRS and Social Odometry: system speciﬁcation. . . . . . . . . . . . . . . . . . . 80 7.2 Information transmitted between the robots when encounter occurs. . . . . . . 83 8.1 TRS and security in WMN: system speciﬁcation. . . . . . . . . . . . . . . . . . . 96 9.1 TRS and security in WSN: system speciﬁcation. . . . . . . . . . . . . . . . . . . . 115
XVII

LIST OF TABLES XVIII

List of Figures
1.1 Overview of the Ph.D. Thesis structure and chapter organization . . . . . . . . 12 3.1 Generic TRS architecture components . . . . . . . . . . . . . . . . . . . . . . . . 30 3.2 Generic TRS architecture processes . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.1 Design process. Iterative loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 5.1 Security Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 6.1 Simulated environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 6.2 Server inlet temperature with time under CRAC failure. . . . . . . . . . . . . . . 71 6.3 CRAC fan failure detection and isolation with individual anomalies in sensors. 71 6.4 Power proﬁle in two different architectures and workload misconﬁguration de-
tection with individual anomalies in sensors. . . . . . . . . . . . . . . . . . . . . 72 7.1 Robots sharing information about the estimated location of area Y. . . . . . . . 75 7.2 Simulation results for 3x3m2 arena . . . . . . . . . . . . . . . . . . . . . . . . . . 84 7.3 Simulation results for 5x5m2 arena . . . . . . . . . . . . . . . . . . . . . . . . . . 85 8.1 Function for updating trust values . . . . . . . . . . . . . . . . . . . . . . . . . . 97 8.2 Evolution of the impact of the attack and the based on the node redundancy. . 97 8.3 Trust evolution for a wormhole attack . . . . . . . . . . . . . . . . . . . . . . . . 99 8.4 Trust evolution for a DoS attack. . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 8.5 Trust evolution for a severe DoS attack. . . . . . . . . . . . . . . . . . . . . . . . 100 8.6 Trust evolution for a DDoS attack. . . . . . . . . . . . . . . . . . . . . . . . . . . 101 8.7 Trust evolution for severe a DDoS attack. . . . . . . . . . . . . . . . . . . . . . . 101 9.1 Envisioned WSN model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 9.2 The Sybil attack - start at 650 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 9.3 The Sybil attack - start at 30 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 9.4 The Pulse-delay attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 9.5 Wormhole attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 9.6 Max. % of compromised nodes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 9.7 Memory consumption vs. number of nodes . . . . . . . . . . . . . . . . . . . . . 120
XIX

1. Introduction
“You must trust and believe in people or life becomes impossible.”
— Anton Chekhov
This introductory Chapter presents the motivation, problem context and a brief state of the art on the work presented in this Ph.D. Thesis. Besides, the main contributions of this work are highlighted and an overview of the structure of this Ph.D. Thesis is also provided.
1.1 Motivation
The study of Trust and Reputation Systems (TRS) is a discipline that belongs to the ﬁeld of decentralized decision-making techniques. They have a wide range of uses, and they are increasing their importance as heterogeneous and distributed systems are more and more present in any facet of our lives.
However, there is not a systematic way to analyze, design, secure and deploy TRS into reallife scenarios. Therefore, working with TRS becomes more a craft-work than an engineering process.
Even though TRSs are one of the most common everyday aspects in our lives, the existing knowledge about them cannot be more dispersed. There are thousands of works in every ﬁeld of study related to trust and reputation: philosophy, psychology, sociology, economics, politics, information sciences, etc. But the main issue is that a comprehensive vision of trust and reputation for all these disciplines does not exist.
Every discipline focuses its studies on a speciﬁc set of topics but none of them tries to take advantage of the knowledge generated in the other disciplines to improve its behavior or performance. Detailed topics in some ﬁelds are completely obviated in others, and even though the study of some topics within several disciplines produce complementary results, these results are not used outside the discipline where they were generated. This lead us to a very high knowledge dispersion and to a lack in the reuse of methodologies, policies and techniques among disciplines.
This Ph.D. Thesis addresses the deﬁnition of a set of conceptual models and methodologies in order to allow a more precise, systematic, complete, and secure analysis and design of this kind of systems.
1.2 Context
In order to explain the context where this thesis has been developed, more details on the stateof-the art of the main topics related to this work are given in the next sections. Section 1.2.1
1

1. Introduction
gives an overview of the main topics regarding Collective Intelligence. Then, Section 1.2.2 describes some classical approaches to decentralized decision-making techniques. Finally, Section 1.2.3 details how different ﬁelds of knowledge study trust and reputation.
1.2.1 Collective Intelligence
By collective intelligence [1]–[3] we understand a form of intelligence that emerges from the collaboration and competition [4] of many individuals, or strictly speaking, many entities. Based on this simple deﬁnition, we can see how this concept is the ﬁeld of study of a very wide range of disciplines, such as sociology, information science or biology. Each of them focused in different kinds of entities: human beings, computational resources, or animals.
As a common factor we point that collective intelligence has always had the goal of being able of promoting a group intelligence that overcomes the individual intelligence of the basic entities that constitute it. This can be accomplished through different mechanisms such as coordination, cooperation, competence, integration, differentiation, etc. It can also be understood as an emergent property from synergies among information, knowledge, software, hardware, and living entities that continuosly learns from feedback to produce knowledge for better decisions than these elements acting alone.
The idea emerged from the writings of Douglas Hofstadter [5], Pierre Levi [6], Howard Bloom [7], Francis Heylighen [7], Douglas Phillip Brown [1] and other theorists and writers.
In order to understand the proposed thesis, we need to identify some of the constitutive elements of collective intelligence. Speciﬁcally we are going to focus our analysis on who are the entities involved in any collective intelligence behavior, and how they try to achieve their goals [8].
Dealing with collective intelligence organization, we can ﬁnd two basic structures: hierarchy and crowd [2], [9].
In traditional hierarchical organizations [10], someone in authority assigns a particular person or group of people to perform a task. In this way, the collective behavior is driven by an individual intelligence.
In crowd collectives [11], activities can be assumed by anyone in a large group who chooses to do so, without being assigned by someone in a position of authority. In this way, crowd becomes a central feature of any collective intelligence system.
Based on this feature, we will analyze the behavior of different decentralized decisionmaking techniques, where TRSs are included.
1.2.2 Decentralized Decision-making Techniques
Introduction
There are two possible alternatives related to decentralized decision-making techniques when talking about decisions that are made by crowd collectives, namely Individual Decisions and Group Decisions.
The Individual Decision occurs when members of a crowd make decisions that, though informed by a crowd input, do not need to be identical for all of them. On the other hand, Group Decision [12], [13] occurs when inputs from members of the crowd are assembled to generate a decision that holds for the group as a whole.
Based on these two vectors we can identify some paradigmatic approaches.
Social Networks
Social Networks are one of the most important techniques from the point of view of our analysis.
In Social Networks, members of a crowd form a network of relationships that might be translated into levels of trust, similarity of taste and viewpoints, or other common characteristics that might cause individuals to feel an afﬁnity for one another.
2

1.2. Context
Then, crowd entities assign different weights to individual inputs on the basis of their relationship with the entities who provided them and then make individual decisions. Among many other applications, social network relationships and this preference-making behavior, are extremely useful to implement collaborative ﬁltering/decision-making techniques [14].
Markets
In Markets, there is some kind of formal exchange (usually money) involved in the decisions. Each entity of the crowd makes an individual decision about what products to buy or sell. All purchasing decisions made by buyers in the crowd together, determine the collective demand. This demand affects the availability of products and, therefore, their prices. On the other hand, the quantities and prices of the goods that are sold in the system inﬂuence the purchasing decisions, and so on.
SWARM Intelligence
Swarm Intelligence systems [15] are one of the most studied and applied collective intelligence behaviors. Besides, they are specially interesting from the point of view of our analysis because they are a link between individual decision and group decision techniques. Each entity or individual makes decisions based on its knowledge of the system, but it is the collection of all these individual decisions what makes possible to solve the global objective.
Swarm Intelligence systems are typically made up of a population of simple agents interacting locally with one another and with their environment. The group of individuals acting in such a manner is referred to as a swarm. Individuals within the group interact by exchanging locally available information such that the global objective is solved more efﬁciently than if it is done by a single individual. Therefore, decision-making or problem-solving behavior that emerges from such interactions is called swarm intelligence. Thus, structures and solutions appear at the global level of a system from interactions among its lower-level components.
The basic components of this kind of self-organizing mechanisms are:
• Positive feedback: examples are recruitment and reinforcement
• Negative feedback: counterbalances positive feedback. Examples are saturation, exhaustion or competition.
• Ampliﬁcation and randomness: it enables to discover new non-trivial solutions.
• Multiple interactions: a minimal density and amount of individuals are required to create an effective swarm intelligence.
Averaging
Averaging belongs to the category of group decisions [16]. It is very common in cases where decisions involve picking a number. The most common behavior is to average the numbers contributed by the members of the crowd.
Averaging is commonly used in systems that rely on a point scale for quality rating. For example, most of web-based collective systems, such as Amazon [17], IMDB [18], hotel booking systems, etc. are based on this kind of techniques.
Consensus
Consensus means that all group members agree on the ﬁnal decision. It seems like a complex technique in order to achieve a stable decision, but it is very common in some on-line systems, such as Wikipedia [11], [19]–[21], where articles that remain unchanged are those for which everyone who cares is satisﬁed with the current version.
Another example is reCAPTCHA [22]. reCAPTCHA is a Web security, where two words are displayed on the screen. Users are asked to type both to gain access to a Web page. One
3

1. Introduction
of the words is a security key and the other a word previously scanned as part of a project to digitize old books. The words that the recognition software ﬁnds difﬁcult to read are served to several users as one half of each reCAPTCHA. When transcriptions provided by multiple users reach a level of consensus, that word is considered to have been correctly transcribed.
Voting systems
New technologies make the voting techniques [23] feasible in many situations where it would not otherwise have been practical. The technique is quite simple: the most voted option becomes the chosen one. It is used in a wide range of applications: from news websites [24] to collective chess matches [25].
Two important sub-variations are implicit voting and weighted voting. In implicit voting, some actions (different to the act of voting) are counted as votes, because they show some level of preference related to the entities or items involved in the action (e.g.,the number of times a photography has been downloaded can be used to choose the rank of most popular photographs). In weighted voting, the weight of the votes depends on their source (e.g.,the Google’s Page-Rank algorithm [26] gives more weight to links from sites that are, themselves, more popular).
Prediction Markets
A useful way of letting crowds estimate the probability of future events is with prediction markets. In prediction markets [27], [28], people buy and sell shares or options of predictions about future events. If their predictions are correct, they are monetarily rewarded, either with real money or with some kind of bonus or points that can be redeemed for prizes or cash.
They are extremely useful when crowd is considered to have enough knowledge to solve a problem, but it is needed to bring this decentralized knowledge to the attention of these people who can act on in.
Trust and Reputation Systems
TRS stands as one of the most wide spectrum and most common collective decision-making techniques It is based on the well-known concepts of trust and reputation.
Shortly, we say trust is the belief of one entity that the outcome of other entities’ actions are going to be in a speciﬁc way. It is a subjective concept because the trust of two different entities in another one does not have to be the same. In this sense, trust-based system are a paradigmatic example of individual decision systems.
On the other hand, reputation is the collective idea that a group of entities within a system have about another entity based on a speciﬁc criterion. Thus, it is a collective concept in its origin but it is not different for every single entity. It rather has the same value for all the entities throughout the system. Therefore, reputation-based systems are a clear example of group decision systems.
The behavior of TRSs can be described as follows [29]. The TRS assigns a lower reputation to the entities where it detects anomalous activities, or a bad throughput, or any other ratio that can be interesting in order to evaluate the performance of the whole system. Besides, every entity is being examined by at least another entity, that generates a subjective value of trust. Furthermore, entities advocate avoiding any contact with the entities that have low trust or reputation. In this way, the anomalous entities remain isolated from the system and has no role in its further operation [30].
1.2.3 T&R in different ﬁelds of knowledge
After giving an overview of the main topics regarding Collective Intelligence, describing some classical approaches to decentralized decision-making techniques, and deﬁning the basic concepts related to TRSs, this section details how different ﬁelds of knowledge study trust and reputation.
4

1.2. Context
Introduction
Even though TRSs are one of the most common everyday aspects in our life’s, the existing knowledge about them cannot be more dispersed. There are thousands of scientiﬁc works in every ﬁeld of study related to trust and reputation: philosophy, psychology, sociology, economics, politics, information sciences, etc. But the main issue is that a comprehensive vision of trust and reputation for all these disciplines does not exist.
Every discipline focuses its studies on a speciﬁc set of topics but none of them try to take advantage of the knowledge generated in the others disciplines to improve its behavior or performance. Detailed topics in some ﬁelds are completely obviated in others, and even though the study of some topics within several disciplines produce complementary results, these results are not used outside the discipline where they were generated.
This lead us to a very high knowledge dispersion and to a lack in the reuse of methodologies, policies and techniques among disciplines.
Due to its great importance, this high dispersion of trust and reputation knowledge is one of the main problems this thesis will try to solve.
T&R in Philosophy
According to the Stanford Encyclopedia of Philosophy, “trust is important but dangerous”. Since trust allows us to form relationships with others and to rely on others for advice, help, etc., trust is regarded as a very important factor in our life that compels others to give us such things in an altruistic way, with no outside force such as the law [31].
On the other hand, since trust requires taking a risk that the trustee may not behave as the trustor expects, trust is dangerous implying the possible betrayal of trust.
In Lagerspetz’s book titled Trust: The Tacit Demand [32], it is described the author’s view on trust as a moral relationship in human society. Langerspetz believes that investigations of trust reveal that human individuals, their beliefs, desires and actions are only intelligible against the background of existing social practices and social ties.
Thus, trustful or betrayal actions can occur between a trustor and a trustee based on nature of their relationships, in this case, their personal relationships.
In this way, we can see that trust, loyalty, moral boundaries and betrayal are the most studied topics of TRS from the point of view of Philosophy.
T&R in Psychology
From the point of view of Psychology, trust starts from the moment of birth of the child. As the child grows older, trust also grows stronger. However, the root of trust derives from the relationship between the mother of the child, since the strength of the family relies on trust. If the child is raised in a family which is very accepting and loving, the child also returns those feelings to others by trusting them. But if trust is lost, it is hard to recover it again.
In this sense, trust in psychology emphasizes the cognitive process that human beings learn trust from their experiences.
Deutsch [33] deﬁnes trust as the conﬁdence that one will ﬁnd what is desired from another rather than what is feared. In addition, Hardin [34] and Rotter [35] observed in their experiments that past experiences may affect later capacity for trust. For example, bad experience with people will lower the trust level, leading to fewer relationships with people [36].
Besides, high trustors are less likely to lie or cheat or steal. Also they are less likely to be unhappy, conﬂicted, or unstable. Even though high trustors are deceived more often in novel or unknown situations, low trustors are also losing effectiveness in their relationships by distrusting trustworthy people, thereby losing the advantages that high trustors may have [35].
In this way, we can see that trust as a learning process, memory and the effects of trust/distrust are some of the most studied topics of TRSs from the point of view of Psychology.
5

1. Introduction
T&R in Sociology
The Italian social scientist Diego Gambetta is one of the most inﬂuential researchers in this ﬁeld. Gambetta’s notion of trust [37] is popularly called sociological trust and is deﬁned as an assessor’s a priori subjective probability that a person (or agent, or group) will perform speciﬁc actions that affect the assessor.
Thus, Gambetta [37] describes the nature of trust as subjectivity, an indicator for future actions, and dynamism based on continuous interactions between two entities.
Adams et al. [38] rephrased Gambetta’s trust concept quantifying trust based on the acceptance of risk. Thus, he stressed that risking betrayal is an important aspect in building trust.
Luhmann [39] also emphasized the importance of trust in society as a mechanism for building cooperation among people to extend human interactions for future collaboration.
The last main concept we can draw from sociology is based on the importance of prejudices or preconceptions. Tajfel, H. and Turner J.C. [40] describe these concepts as a way for social groups to build and reinforce relationships among their members (in-group favoritism), even though, at the same time, they are a way to exclude and degrade relationships with those not belonging to the group (out-group derogation).
In this way, we can identify that subjectivity, prejudices/preconceptions acceptance of risk, and trust as a mechanism to build cooperation and predict actions are some of the most studied topics of TRSs from the point of view of Sociology.
T&R in Economy
Economy is one of the ﬁrst ﬁelds that distinguishes between the personal or informal trust (that comes from your relationships), and the impersonal or institutionalized trust (that comes from your ﬁnancial status). In fact, this institutionalized trust is closer to the concept of reputation than to the concept of trust.
In economics, trust is represented as an expectation that applies to situations in which trustors take risky actions under uncertainty or information incompleteness [41].
Besides, trust in economics is based on the assumption that humans are rational and maximizers of their own interest or incentives [42]. Thus, although the assumption of selﬁsh entities is reasonable, altruistic behaviors can emerge from mechanisms that may be initially purely selﬁsh [43] if the incentives for collaboration are high enough based on their interest.
The study of redemption mechanisms in another important topic that Economy deals with. In this way, we can identify that maximization, risk and redemption are some of the most studied topics of TRSs from the point of view of Economy.
T&R in Organizational Management
In this ﬁeld, the concept of trust is deﬁned at different levels. First, it can be applied to the relationship between employers and employees, or between
team managers and workers. In this context trust is deﬁned as the extent to which one party is willing to count on someone or something with a feeling of relative security in spite of possible negative consequences, emphasizing the possibility of facing risk [44].
Moreover, Organizational Management add a new facet to the meaning of trust. They identify efﬁciency and proﬁciency as two of the main components of trust [45]. Derived from this idea, they also explain that trust is not necessarily mutual and is not reciprocal.
Finally, trust in Organizational Management can give us insights on how to measure trust by investigating methods to measure ability, integrity, and benevolence of member of the organization or work team.
Thus, we can say that proﬁciency, efﬁciency and measurability are some of the most studied topics of TRSs from the point of view of Organizational Management.
6

1.2. Context
T&R in Corporations
Nowadays, improving public reputation has become one of the highest priority challenges for corporations all around the world.
In this context, corporate reputation usually derives from terms such as innovation, ﬁnancial soundness, the use of corporate assets and social responsibility [46], [47].
Obtaining the reputation based on the point of view of the general public, customers, employees, suppliers and investors is other common technique in this ﬁeld [48], [49]. These models measure perceptions of an organization in terms of social expectations of dimensions such as products and services, vision and leadership, work place environment and social responsibility. Related to the responsibility topic, international standardization organizations have published standards such as ISO26000 [50].
Finally, other common approaches [51] try to identify the corporate personality through surveys to customers and employees in terms of their perceptions of organization’s personality, focusing on dimensions such as agreeableness, competence and enterprise.
In this way, we can say that dealing with disperse and diverse sources of information and the process of abstract information are some of the most studied topics of TRSs in this ﬁeld.
T&R in Personal Branding
Personal Branding derives from the concept of corporate reputation. Tom Peters wrote the ﬁrst article [52] where personal branding was cited, The Brand Called You. He explored the evolution of career development, and exposed that instead of relying on a company for career guidance, it is up to the individuals to take ownership of their own brand [53].
The basic idea that underlies Personal Branding is understanding the unique attributes of the individuals (strengths, skills, values, and passions) and using them to separate them from their competitors. Thus, Personal Branding is becoming increasingly essential to entrepreneurs, consultants, or even corporate employees.
The basic process to develop a personal brand are: discover, create, communicate and maintain. These two last steps are the focus of all the trust and reputation analysis in this ﬁeld, and they are based on common sense: depending on your target audience, it is needed to adapt your message to properly communicate your brand, it is useful to communicate past actions to create a more compelling and appealing future brand, etc.
Thus, we can say that creating and maintaining reputation is the most studied topic of TRSs from the point of view of Personal Branding.
T&R in Communications and Networking
The concept of trust has been always very common to communication and network protocol designers. Trust not only enables secure communications, but trust relationships among participating nodes are critical in building cooperative and collaborative environments to optimize system objectives, such as scalability, reconﬁgurability, reliability or fault tolerance, etc.
Classical trust frameworks in this ﬁeld (policy-based trust) are based in cryptographic algorithms that support Public Key Infrastructures [54], [55], enable nodes to share secret keys or, in a more wide range, provide mechanisms to ensure the identiﬁcation or authentication processes and the conﬁdentiality and integrity of the communications.
Therefore, we can say that promoting collaboration and improving performance through the use of trust and reputation is the most studied topic of TRSs from the point of view of communications and networking. Policy-based trust scheme are also common in this ﬁeld.
T&R in Ad-hoc Networks
The main feature of ad-hoc networks [56] is that they dynamically change their structure really quickly [57]. This means different entities join and leave the system very often.
Entities are continuously confronted with other unknown entities, which can be of a great help to them if they can collaborate with each other. But collaboration between unknown
7

1. Introduction
entities is not fully utilized, due to the fear of not being trusted and the potential risk of such collaboration [58].
Trust relationships in this kind of networks are established, evolved, propagated and expired on the ﬂy. So, they are very susceptible to attacks. Nevertheless, fast trust-generation mechanisms [59]–[61] are one of the main contributions of the ad-hoc networks to the global ﬁeld of TRS.
T&R in Wireless Sensor Networks
Due to its importance, we are going to analyze the works related to trust and reputation from the point of view of Wireless Sensor Networks (WSN), even though, based on the context, they can be categorized in some cases into Ad-Hoc networks.
TRSs in WSN networks add a great value in constructing the network and making easier the addition and deletion of sensor nodes. They also improve the mechanisms to replace failing or unreliable nodes in a transparent way [62].
Due to the intrinsic features of WSN (dynamism, low computational and communication resources, etc.) [63], the creation, operation and management of this kind of networks are dependent upon the cooperative and trusting nature of its nodes. Thus, the trust establishment between nodes is a desirable requirement.
However, using the traditional tools such as cryptographic processes to generate public key infrastructure and establish trust based on them are not possible in a WSN, due to the resource limitations of sensor nodes [57]. Therefore, TRS are a perfect approach to offer the needed mechanisms and to cope with these resource limitations [64].
The main researches in this ﬁeld are focused on: the development and evaluation of algorithms to calculate trust and reputation, the identiﬁcation and characterization of sources of information (direct and indirect information) to calculate both parameters, and the study of methods to secure the basic network protocols (aggregation of sensed values, time synchronization, and routing) [65].
T&R in Online Services
The provision of online services [66] is one of the most proliﬁc ﬁelds related to the study and deployment of TRS.
eBay [67], Amazon [17], Booking [68] or AirBnB [69] are good examples of online marketplaces that use reputation mechanisms.
All these models consider reputation as a global property, and use a single value that is not dependent on the context nor on the entity. Thus, we say that they are pure-reputation-based systems, since there is no trust (subjective values) at all.
The information source used to build the reputation value is the information that comes from other entities that previously interacted with the target entity.
They do not often provide explicit mechanisms to deal with users that provide false information. In this context, only redundancy, a great number of opinions about the same subject, is the only way to increase the reliability of the global reputation value.
The main researches in this ﬁeld are focused on: the development of reputation calculation algorithms in order to enable an maximize transactions between the entities belonging to the system, and the dissemination of trust and reputation information throughout global scope systems.
T&R in P2P
TRSs in the context of peer-to-peer (P2P) networks are distributed [70], [71]; there is no centralized entity to analyze the behavior of entities in a network, so individual nodes keep track of their peers’ behavior and exchange this information directly with others. In this way, these systems are mainly based on the idea of trust and, in some cases in the management of local reputation values [72].
8

1.2. Context

Discipline Philosophy Psychology Sociology Economy Organizational Management Corporations Personal branding Communication&Networking Ad-hoc Networks WSN Online Services P2P networks Social Networks

Main topics loyalty, delegation, risk, betrayal, moral boundaries learning process, memory, punishment, trust/distrust subjectivity, prejudices, mechanism to build cooperation personal vs. institutionalized trust, maximization, risk, redemption proﬁciency, efﬁciency, measurability disperse sources of information, processing of abstract information sources of information, creating and maintaining reputation promoting collaboration, improving performance fast trust-generation mechanisms calculation algorithms, sources of information, securing protocols calculation, revocation, enabler of interactions, dissemination cooperation over risk, massively distributed trust systems reputation sources, dissemination, virtual vs. real-life

Table 1.1: Main trust and reputation topics of study by ﬁeld of knowledge

Besides, these systems try to counter selﬁsh behavior of nodes by enforcing nodes to cooperate with each other in order to rise their own trust and obtain more beneﬁts from the system.

T&R in Social Networks
Research works are focused on two main topics: the increasing importance of virtual reputation in virtual worlds, and the increasing inﬂuence of virtual relationships in real-life reputation.
Related to the ﬁrst topic, researches have analyzed the sources of virtual trust and reputation in different kinds of social networks, creating user-centered models [73], [74] based on message forwarding, like actions, etc.
Related to the inﬂuence of virtual activity in the real-life reputation, Golbeck [75]–[77] proposes a trust concept derived from a sociological point of view where virtual relationships expand their inﬂuence and they have to be taken into account outside those virtual environments in the same way than other real-life relationships (family, friends, work colleges, etc.) are considered.
Thus, we can say that identifying reputation sources and analyzing reputation dissemination are the most studied topics of TRSs from the point of view of Social Networks.

Conclusions
Derived from the previous analysis, we can see how every discipline focuses its studies on a speciﬁc set of topics, but none of them tries to take advantage of knowledge generated in other disciplines to improve its behavior or performance. Detailed topics in some ﬁelds are completely obviated in others, and even though the study of some topics within several disciplines produces complementary results, these results are not usually used outside the discipline where they were generated. Main topics for each ﬁeld are compiled in Table 1.1
This lead us to a high dispersion of knowledge and to a lack in the reuse of methodologies, policies and techniques among different ﬁelds.
Due to its great importance, this high dispersion of trust and reputation knowledge is one of the main problems this thesis will try to solve.
9

1. Introduction
1.3 Contributions
This Ph.D. Thesis addressed the improvement of the models and methodologies related to TRS in order to allow a more precise, systematic, complete and secure analysis and design of this kind of systems.
Regarding the proposition of novel models and methodologies to improve the general understanding and the deﬁnition of TRS, the main contributions of this PhD thesis are:
• The compilation of an extensive literature and knowledge about the goals, utilization, and the characteristics of TRS in different ﬁelds of knowledge: philosophy, psychology, sociology, economics, business management, communications and networking, online services, etc.
• The deﬁnition of a generic architecture for TRS, identifying the entities and processes involved in this kind of systems regardless of the ﬁeld of knowledge or the speciﬁc case of use where we apply them.
• The deﬁnition of a analysis methodology for TRS that systematically allows to identify all the assets and process involved in this kind of systems. This methodology allows systematizing the process of understanding and predicting the behavior of any TRS independently of the ﬁeld of knowledge or the speciﬁc case of use where we apply them.
• The deﬁnition of a design methodology for TRS. This methodology describes the steps to systematically select all the components and processes involved in the development and deployment of a TRS in a real-life environment. As a further result of this design methodology a taxonomy of types of TRS according to their functional objectives is proposed.
Regarding the proposition of novel frameworks and methodologies to improve the security of TRS, the main contributions of this PhD thesis are:
• The deﬁnition of a generic framework for analyzing security of any kind of system. Based on this framework all assets and processes prone of being attacked can be identiﬁed in a systematic way.
• The deﬁnition of a taxonomy of attacks against TRS. This taxonomy will allow us to learn and study attacks that had not yet been identiﬁed in the literature.
• The deﬁnition of a methodology to systematically analyze vulnerabilities and possible countermeasures of any TRS in real environments. Therefore, we will be able to make design decisions that minimize the probability of an attack being successfully completed, as well as we can make design decisions to minimize the impact of an attack in those cases where it cannot be completely avoided.
• The development of TRS simulator that allows to analyze the performance of applying a TRS with a speciﬁc set of features to any type of environment.
Finally, we have made original contributions to different areas of knowledge thanks to the application of the models and methodologies previously presented. The ﬁelds of knowledge addressed and their corresponding contributions are:
• The detection of thermal anomalies in Data Centers. Thanks to the application of the TRS analysis and design methodologies, we successfully implemented a Thermal Anomalies Detection System based on a TRS. Its main contribution is the autonomous management of the diverse trust and reputation information available in the data center.
10

1.4. Structure
• The improvement of the performance of a harvesting system based on swarm computing and social odometry. Through the implementation of a TRS we achieved to improve the ability of coordinating a distributed network of autonomous robots. The main contribution lies in the analysis and validation of the incremental improvements that can be achieved with proper use information that exist in the system and that can be relevant for the TRS, and the implementation of the appropriated trust algorithms based on such information.
• The improvement of Wireless Mesh Networks security against attacks against the integrity, conﬁdentiality or availability of data and communications supported by these networks. Thanks to the implementation of a TRS we improved the detection time rate against these kind of attacks and we limited their potential impact over the system.
• The improvement of Wireless Sensor Networks behavior against advanced attacks, such as insider attacks, unknown attacks, etc. Through the deployment of a TRS we can implement countermeasures against such attacks in a complex environment.
1.4 Structure
This Ph.D. thesis is organized as follows:
• Chapter 2 presents the basic concepts and the state of the art on Trust Management Systems. It will help us to understand the difﬁculties derived from these diversity of models and technologies in order to create a knowledge base about TRS.
The rest of the document is divided into two main sections. The ﬁrst part focuses on presenting the theoretical contributions of this work and it is organized as follows:
• Chapter 3 describes an architecture that copes with the previously described complexity and allows us to identify the main entities and processes related to any kind of TRS, no matter the ﬁeld of knowledge where it is applied. Besides, a methodology to analyze TRS is presented.
• Chapter 4 presents a methodology to design a TRS in order to attain a speciﬁc set of goals. A taxonomy of TRS application patterns is proposed based on the functional areas where TRS are highly effective.
• Chapter 5 presents a generic security framework to analyze attacks against any kind of system. Subsequently, this framework is applied to TRS analyzing the entities and processes identiﬁed in Chapter 3. This yield a complete and novel taxonomy of TRS attacks.
The second part focuses on presenting the practical application of the previous models and methodologies to solve problems or improve the performance of real-life scenarios. It is organized as follows:
• In Chapter 6 we apply the models and methodologies to the ﬁeld of energy consumption in data center. In this scenario, a TRS is designed to detect and isolate thermal anomalies in data centers. This scenario serves as an example of how a TRS can detect and isolate anomalous behaviors.
• In Chapter 7 different designs and implementations of a TRS are applied to improve the performance of a swarm of autonomous robots. This scenario serves as an example of how a TRS can be use to minimize the degradation of a system or maximize its performance.
11

1. Introduction
Figure 1.1: Overview of the Ph.D. Thesis structure and chapter organization • Chapter 8 describes the improvement of the security of a WMN through the use of a
TRS specially designed to achieve this goal. This scenario serves as an example of how a TRS can be use to minimize the likelihood and the impact of attacks against a distributed and complex system. • Chapter 9 analyzes in detail some advanced topics derived from the use of TRS. In the context of the security of a WSN, we describe the consequences of make some design decisions, and analyze the performance of a TRS under different environment hypothesis and attacks of different strength. Finally, Chapter 10 summarizes the conclusions derived from the research that is presented in this Ph.D. thesis, as well as the contributions to the state-of-the-art on analyzing, designing, and securing TRSs. The Chapter also includes a summary on future research directions. Figure 1.1 provides the reader with an overview of the structure of this Ph.D. thesis and how the Chapters are organized.
1.5 Publications
The results of this PhD Thesis, together with other related research have been published in international conferences and journals. In this section we brieﬂy present these publications and highlight the chapter in which the speciﬁc contributions can be found.
1.5.1 Journal papers
In terms of scientiﬁc publications, this Ph.D. thesis has generated the following articles in international journals:
• D. Fraga, A´ . Gutie´rrez, J. C. Vallejo, et al., “Improving social odometry robot networks with distributed reputation systems for collaborative purposes”, Sensors, pp. 11 372– 11 389, 2011 [JCR Q1 IF=1.870] (Chapter 4 and Chapter 7 of this Ph.D. Thesis) 12

1.5. Publications
• Z. Bankovic, D. Fraga, J. M. Moya, et al., “Improving security in wmns with reputation systems and self-organizing maps”, Journal of Network and Computer Applications, vol. 34, no. 2, pp. 455 –463, 2011, Efﬁcient and Robust Security and Services of Wireless Mesh Networks, ISSN: 1084-8045 [JCR Q2 IF=0.660] (Chapter 4 and Chapter 8 of this Ph.D. Thesis)
• Z. Bankovic´, J. M. Moya, D. Fraga, et al., “Distributed intrusion detection system for wireless sensor networks based on a reputation system coupled with kernel self-organizing maps”, Integr. Comput.-Aided Eng., vol. 17, pp. 87–102, 2 2010, ISSN: 1069-2509 [JCR Q2 IF=2.042] (Chapter 9 of this Ph.D. Thesis)
• M. Zapater, D. Fraga, P. Malago´ n, et al., “Self-organizing maps versus growing neural gas in detecting anomalies in data centres”, Logic Journal of the IGPL, vol. 23, no. 3, pp. 495– 505, 2015 [JCR Q3 IF=0.458]
• Z. Bankovic´, D. Fraga, J. M. Moya, et al., “Bio-inspired enhancement of reputation systems for intelligent environments”, Inf. Sci., vol. 222, pp. 99–112, Feb. 2013, ISSN: 00200255 [JCR Q4 IF=0.205]
• Z. Bankovic´, J. C. Vallejo, D. Fraga, et al., “Detecting false testimonies in reputation systems using self-organizing maps”, Logic Journal of the IGPL, vol. 21, no. 4, pp. 549–559, 2013 [JCR Q3 IF=0.458]
• Z. Bankovic, D. F. Aydillo, J. M. M. Ferna´ndez, et al., “Detecting unknown attacks in wireless sensor networks that contain mobile nodes”, Sensors, vol. 12, no. 8, pp. 10 834– 10 850, 2012 [JCR Q1 IF=1.870]
• J. Moya, A´ . Araujo, Z. Bankovic´, et al., “Improving security for scada sensor networks with reputation systems and self-organizing maps”, Sensors, vol. 9, no. 11, p. 9380, 2009 [JCR Q1 IF=1.870]
• J. M. Moya, J. C. Vallejo, D. Fraga, et al., “Using reputation systems and non-deterministic routing to secure wireless sensor networks”, Sensors, vol. 9, no. 5, p. 3958, 2009, ISSN: 1424-8220 [JCR Q1 IF=1.870]
1.5.2 Conference papers
Also, this Ph.D. thesis has generated the following articles in international peer-reviewed conferences:
• D. Fraga, Z. Bankovic, and J. M. Moya, “A taxonomy of trust and reputation system attacks”, in 11th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2012, Liverpool, United Kingdom, June 25-27, 2012, 2012, pp. 41–50 [Core A conference] (Chapter 5 of this Ph.D. Thesis)
• Z. Bankovic, J. Moya, D. Fraga, et al., “Holistic solution for conﬁning insider attacks in wireless sensor networks using reputation systems coupled with clustering techniques”, in Trust, Security and Privacy in Computing and Communications (TrustCom), 2011 IEEE 10th International Conference on, 2011, pp. 61–72 [Core A conference] (Chapter 9 of this Ph.D. Thesis)
• Z. Bankovic, D. Fraga, J. C. Vallejo, et al., “Improving reputation systems for wireless sensor networks using genetic algorithms”, in Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation, ser. GECCO ’11, Dublin, Ireland: ACM, 2011, pp. 1643–1650, ISBN: 978-1-4503-0557-0 [Core A conference]
• Z. Bankovic, D. Fraga, J. C. Vallejo, et al., “Self-organizing maps versus growing neural gas in detecting data outliers for security applications”, in Hybrid Artiﬁcial Intelligent Systems - 7th International Conference, HAIS 2012, Salamanca, Spain, March 28-30th, 2012. Proceedings, Part II, 2012, pp. 89–96
13

1. Introduction
• Z. Bankovic, J. C. Vallejo, D. Fraga, et al., “Detecting bad-mouthing attacks on reputation systems using self-organizing maps”, in Computational Intelligence in Security for Information Systems - 4th International Conference, CISIS 2011, Held at IWANN 2011, TorremolinosMa´laga, Spain, June 8-10, 2011. Proceedings, A´ . Herrero and E. Corchado, Eds., ser. Lecture Notes in Computer Science, vol. 6694, Springer, 2011, pp. 9–16, ISBN: 978-3-642-21322-9
• Z. Bankovic´, J. M. Moya, D. Fraga, et al., “Detecting unknown attacks in wireless sensor networks using clustering techniques”, in Proceedings of the 6th International Conference on Hybrid Artiﬁcial Intelligent Systems - Volume Part I, ser. HAIS’11, Wroclaw, Poland: Springer-Verlag, 2011, pp. 214–221, ISBN: 978-3-642-21218-5
• Z. Bankovic, D. Fraga, J. M. Moya, et al., “Detecting and conﬁning sybil attack in wireless sensor networks based on reputation systems coupled with self-organizing maps”, in Artiﬁcial Intelligence Applications and Innovations - 6th IFIP WG 12.5 International Conference, AIAI 2010, Larnaca, Cyprus, October 6-7, 2010. Proceedings, 2010, pp. 311–318 on Reputation Systems Coupled with Self-organizing Maps
1.5.3 Other publications
Finally, the author has also contributed in the following articles in international peer-reviewed conferences and journals, not speciﬁcally related to the contents of this Ph.D. Thesis:
• Z. Bankovic, J. M. Moya, E. Romero, et al., “Using clustering techniques for intelligent camera-based user interfaces”, Logic Journal of the IGPL, vol. 20, no. 3, pp. 589–597, 2012 [JCR Q3 IF=0.458]
• P. Arroba, D. Fraga, J. C. Vallejo, et al., “A methodology for developing accessible mobile platforms over leading devices for visually impaired people”, in Ambient Assisted Living - Third International Workshop, IWAAL 2011, Held at IWANN 2011, Torremolinos-Ma´laga, Spain, June 8-10, 2011. Proceedings, 2011, pp. 209–215
• Z. Bankovic´, E. Romero, J. Blesa, et al., “Using self-organizing maps for intelligent camerabased user interfaces”, in Hybrid Artiﬁcial Intelligence Systems, 5th International Conference, HAIS 2010, San Sebastia´n, Spain, June 23-25, 2010. Proceedings, Part II, 2010, pp. 486–492
• E. Romero, A´ . Araujo, J. M. Moya, et al., “Image processing based services for ambient assistant scenarios”, in Distributed Computing, Artiﬁcial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living, 10th International Work-Conference on Artiﬁcial Neural Networks, IWANN 2009 Workshops, Salamanca, Spain, June 10-12, 2009. Proceedings, Part II, 2009, pp. 800–807 [JCR Q4 IF=0.402]
• A´ . Araujo, D. Fraga, J. M. Fernandez, et al., “Domotic platform based on multipurpose wireless technology with distributed processing capabilities”, in Proceedings of the IEEE 15th International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC 2004, 5-8 September 2004, Barcelona, Spain, 2004, pp. 3003–3007
1.6 Research Projects
During the development of the Ph.D. Thesis the author has participated in the following R&D projects and industrial contracts:
• LPCloud project: This project focuses on the optimum management of low-power modes for cloud computing. Funded by the National Program for Public-Private Cooperation, INNPACTO (MINECO) of the Spanish Ministry of Economy and Competitiveness. [September 2013]
This work was partially supported by:
14

1.6. Research Projects • DGUI de la Comunidad Auto´ noma de Madrid and Universidad Polite´cnica de Madrid
under Research Grant CCG07-UPM/TIC-1742 • Campus of International Excellence (CEI) of Moncloa, under Research Grant of the Pro-
gram for Attracting Talent (PICATA). • P8/08 within the National Plan for Scientiﬁc Research, Development and Technological
Innovation 2008-2011 • The Spanish Ministry of Industry, Tourism and Trade, under Research Grant TSI-020301-
2009-18 (eCID). • The Spanish Ministry of Science and Innovation, under Research Grant AMILCAR TEC2009-
14595-C02-01, and the CENIT Project Segur@. • The N4C.Networking for Challenged Communications Citizens: Innovative Alliances
and Test beds project, funded by the Seventh Framework Program (FP7-ICT-223994N4C) of the European Commission.
15

2. Related work
2.1 Introduction
In this chapter we will present the concept of Trust Management System (TMS). Basically, a TMS is speciﬁc approach for dealing with the ideas of trust of reputation. They deﬁne the topics and elements that are essential for their proposed models, the involved processes to manage trust and reputation, etc. Each TMS can specify different architectural components and processes based on its priorities or its ﬁeld of application. Therefore, we can ﬁnd a number of different TMS for a speciﬁc ﬁeld. As we have already described in Chapter 1, trust and reputation have been studied in a wide range of ﬁelds of knowledge. Therefore, this multiplicative factor (i.e.,many TMS for ﬁelds of knowledge multiplied by many ﬁeld of knowledge working with trust and reputation) yields to the existence of a a huge number of TMS described in the literature.
The knowledge derived from this compilation of TMS analysis, will lead us to propose a meta-model or generic architecture for TRS in Chapter 3. This architecture will allow us to express in its terms all the TMS in the literature. Furthermore, it will allow us to describe and analyze any kind of system dealing with trust and reputation, even if it is not based on a previously known TMS.
In the Section 2.2 we present the main concepts regarding Trust Management Systems. Section 2.3 provides a comprehensive analysis of TMSs found in the literature. Finally, in Section 2.4 we draw some conclusions about the diversity and complexity of the existing TMS.
2.2 Trust Management Systems
Any framework to deﬁne trust and reputation dynamics are known as Trust Management Systems in the literature. Historically, Trust Management appears as a special case of Risk Management [98], an area of knowledge deeply studied specially in Business and Organization Management. Traditionally, a Trust Management System includes the deﬁnition of processes such as: trust establishment, trust update, and trust revocation [56], [99].
They can be classiﬁed based on three main dimensions or features:
• Policy-based vs. reputation-based: there are two main approaches to evaluate trust in the literature, namely: policy-based trust management and reputation-based trust management [100]–[103]. Policy-based trust management is based on strong and objective security schemes such as cryptographic processes, logical rules, signed credentials, etc. This policy-based trust management approach usually makes a binary decision according to which the requester is trusted or not. They are usually oriented to grant access to requested resources. On the other hand, reputation-based trust management uses numerical and computational mechanisms to evaluate trust. Typically, trust is calculated by collecting, aggregating, processing, and disseminating trust and reputation throughout the system.
• Evidence-based vs. monitoring-based: based on Li and Singhal [104] there are two main approaches to calculate trust regarding the sources of information they use. Evidence-
17

2. Related work
based trust management is based on knowledge that can unambiguously prove trust among nodes: public keys, identity, challenge processes.
Monitoring-based trust management is based or rating the trust level of each entity based on behavioral information. This information can be obtained by direct observation or communicated by other entities within the system.
This classiﬁcation can be called as Certiﬁcate-based vs. behavior-based in the literature [105].
• Positive, negative, and mixed TMS: Adams [106] proposes these three types of TMS. Positive reputation systems only consider observations of the positive behaviors of an entity, and negative reputation only take into account observations of the negative behaviors of and entity. This classiﬁcation is more useful when there is a default state of trust (trusted/untrusted) and the current trust values are calculated in a negative way (based on the observed behaviors in opposition to this default state).
As we described in Section 1.2, without loss of generality, we will focus our analysis in reputation-based, monitoring-based, and mixed Trust Management Systems. Therefore, in the next sections some TMS belonging to these classiﬁcation are described in detail.
2.3 State of the Art
2.3.1 Marsh
The work of Marsh [107] is said to be the ﬁrst work on trust in computer science. Marsh concentrates on modeling trust between only two agents. Thus, the trust management does not treat the collection of recommendations provided by other entities.
This model identiﬁes knowledge, utility, importance, risk, and perceived competence as important aspects related to trust.
The model deﬁnes three types of trust: dispositional trust, the trust of an entity independent from the possible cooperation partner and the situation; general trust, the trust of an entity in another one, independently of the speciﬁc situation; and situational trust, which describes the trust of an entity in another one in a speciﬁc situation or context.
2.3.2 Fortune’s Most Admired Companies List
The Fortune’s Most Admired Companies List (MAC List) [108] surveys CEOs and ﬁnancial analysts about their view of listed companies in terms of issues such as ﬁnancial soundness, innovation, use of corporate assets and social responsibility.
The list is developed by the Fortune’s editorial panel in discussion with business leaders and ﬁnancial analysts and try to identify features that executives and ﬁnancial experts admire in companies.
2.3.3 Castelfranchi and Falcone
The model proposed by Castelfranchi and Falcone [109] was a forefather of cognitive trust models, and it is the base of later models in literature.
They claim that trust is the mental background of delegation. Thus, trust becomes a mental state that yields one entity to delegate a task to other. This concept of trust is based on a number of basic beliefs: competence belief (the other entity can actually do the task), dependence belief (the other entity is necessary or a better choice to perform the task), willingness belief (the other entity is supposed to be willing to do the task), and persistence belief (the other entity is stable on its intentions of performing the task).
18

2.3. State of the Art
2.3.4 Sporas
In this model [110], only the most recent rating between two entities is considered. Besides, entities with very high reputation values experience much smaller reputation changes after each update than entities with a low reputation.
Sporas incorporates a measure of the reliability of the entities’ reputation based on the standard deviation of reputation values. It is robust to changes in the behavior of an entity and the reliability measure improves the usability of the reputation value.
2.3.5 Histos
Histos [110] was designed as a response to the lack of personalization that Sporas reputation values have. The model can deal with direct information and witness information. In this case, the reputation value is a subjective property assigned particularly by each individual (actually becoming a trust value).
The treatment of direct interaction in this reputation model is limited to the use of the most recent experience with the agent that is being evaluated.
The strength of the model relies on its use of witness information. Ratings are represented as a directed graph. The reputation of an agent at level n of the graph (with n > 0) is calculated recursively as a weighted mean of the rating values that entities in level X − 1 gave to that entity.
A drawback of this model is the use of the reputation value assigned to a witness also as a measure of its reliability.
2.3.6 Abdul-Rahman and Hailes
The trust model presented by Abdul-Rahman and Hailes [111] is focused on virtual communities related to e-commerce and artiﬁcial autonomous agents.
The model deﬁnes direct trust and recommender trust. Direct trust is the trust of an entity in another one based on direct experience, whereas recommender trust is the trust of an entity in the ability of providing good recommendations.
Trust can only have discrete labeled values, namely Very Trustworthy, Trustworthy, Untrustworthy, and, Very Untrustworthy for direct trust, and Very good, good, bad and, very bad for recommender trust.
The difference between two ratings from different entities can be computed as semantic distance. This semantic distance can be used to adjust further recommendations. The combination of ratings is done as a weighted sum, where the weights depend on the recommender trust.
2.3.7 Schillo et al.
This trust model [112] is oriented to scenarios where the result of an interaction between two entities is good or bad. This value is a subjective property assigned particularly by each individual and it does not depend on the context.
It is based on Prisoner’s dilemma set of games [42] with a partner selection phase. Each agent receives the results of the game it has played plus the information about the games played by a subset of all players (its neighbors). The model is based on probability theory that uses the number of times that the target entity was honest. Besides, an entity can get information from other agents that it has met before. The answer of witnesses to a query is the set of observed experiences, and not a summary of them. The model assumes that witnesses never lie but that can hide (positive) information in order to make other agents appear less trustworthy.
2.3.8 Yu and Singh
The TRS model proposed by Yu and Singh [113] uses two information sources.
19

2. Related work
The ﬁrst one contains the entity’s belief built as a result of its direct interaction with other entities. The second one includes the testimonies of third-parties that can be beneﬁcial in the absence of local ratings.
The model propose a trust network which tries to locate the most appropriate witnesses in a multi-agent system. When a requesting entity wants to evaluate the trustworthiness of other entity , it sends a query to the neighbors of that entity asking for their perception regarding the target entity.
This model deals with malicious entities who deliberately disseminate misinformation through network.
2.3.9 REGRET
REGRET [114] is a decentralized TRS designed for complex e-commerce environments where various types of entities with different social relationships play important roles. It describes the social structure and relationships of the system through the ideas of cooperation, competition, and trade.
REGRET is based on a three-dimensional reputation model: Individual dimension or subjective reputation which calculates trust based on the direct impressions of an entity; social dimension, which is divided into three types of reputation: witness reputation, neighborhood reputation, and system reputation; and ontological dimension, which adds the possibility of combining different aspects of reputation to calculate a complex one. With the help of the ontological structure, each entity is capable of determining the overall reputation of a particular entity by assigning the appropriate inﬂuence degree to each aspect related with its demand.
In addition to the reputation value, REGRET gives a reliability measurement which reﬂects the conﬁdence level of the produced reputation value.
2.3.10 Aberer and Despotovic
The model proposed by Aberer and Despotovic [115] is one of the ﬁrst TMS focused on P2P networks.
It is based on the complaints a peer receives from other peers in the network. Although it improves network performance in stable environments, due to the naive of its approach, it is highly sensitive to malicious peers. However, it served as baseline to subsequent models in this area of application.
2.3.11 Esfandiary and Chandrasekharan
The model proposed by Esfandiary and Chandrasekharan [116] uses to sources of information: observation and interaction. The processing of observed information is based on Bayesian learning. The interaction is based on two main protocols: an exploratory protocol and a query protocol.
In the exploratory protocol, entities ask the other entities about known topics to evaluate their degree of trust. Answers consistent with their knowledge yield to consider an entity as trusted. In the query protocol, entities ask for advice to previously trusted entities.
The authors claim that the calculation of this trust interval is equivalent to the problem of routing in a communication network and, therefore, known distributed algorithms used to solve that problem can be successfully applied to this situation.
2.3.12 Afras
The main characteristic of this model [117] is the use of fuzzy sets to represent reputation values. Once a new fuzzy set that shows the degree of satisfaction of the latest interaction with a given entity is calculated, the old reputation value and the new satisfaction value are aggregated using a weighted aggregation. Besides, the weights of this aggregation are calculated from a single value that they call remembrance or memory.
20

2.3. State of the Art
Recommendations from other entities are aggregated directly with the direct experiences. If they come from a recommender with a high reputation, they have the same degree of reliability as a direct experience.
2.3.13 Azzedin and Maheswaran
Azzedin and Maheswaran [118] propose a TMS based on a combination of direct trust and reputation by weighting the two components differently.
It gives more weight to the direct trust. This direct trust o trust level is calculated based on past experiences and is given for a speciﬁc context.
Calculation of reputation values is based on a neural network approach.
2.3.14 Carter et al.
Carter et al. propose a complex but novel TMS [119] based on the concept of roles. They claim that the reputation of an agent is based on the degree of fulﬁllment of roles ascribed to it by the society. Therefore, if society judges that an entity has met its roles, it will be rated with a positive reputation.
They deﬁne ﬁve main roles: social information provider, interactivity role, content provider, administrative feedback, and longevity role. All of them oriented to promote a informationsharing society.
Finally, the entity’s overall reputation is calculated as a weighted aggregation of the degree of fulﬁllment of each role. These weights are dependent on the speciﬁc society, and the society has a centralized mechanism that calculate and disseminate these reputation values, and monitors the society.
2.3.15 SECURE
The trust model and trust management in the SECURE project [120] aims to transfer a human notion of trust to ubiquitous computing.
The main aspect of the trust model is the distinction between unknown and untrustworthy. An entity b is unknown to an entity a, if a cannot collect any information about b. Whereas b is untrusted if a has information, based on direct interaction or recommendations, stating that b is an untrustworthy entity.
The trust propagation is based on policies. These policies allow entities to explicitly express whose recommendations are considered in a trust decision. And ﬁnally, the decision making is threshold based.
2.3.16 Wang and Vassileva
Wang and Vassileva [121] proposed a trust model using Bayesian networks based on the quality of services provided by entities.
The entities manage two different values of trust in another entities: competence in providing services, and reliability in providing recommendations about other entities.
The model uses binary events to qualify transactions (successful or unsuccessful transactions) between entities. Trust is modelled based on this transactions and it used to weight the direct and indirect information: the entity will discard the recommendations from the untrustworthy sources but will combine the recommendations from the trustworthy and unknown sources.
2.3.17 XenoTrust
XenoTrust is a TMS proposed by Dragovic [122]. It describes a novel approach to TMS because it is an event-based distributed trust management system. This event-based paradigm allows to reduce communication overheads and can simplify, and even enable, the use of TMS in systems with tight communication limitations. XenoTrust uses some performance criteria
21

2. Related work
(i.e.,reliability, honesty and throughput) to calculate the trust values assigned to other entities in the system.
2.3.18 Shand et al.
Shand et al. propose a TMS to facilitate secure collaboration in pervasive computer systems [123]. This is one of the ﬁrst TMS that tries to overcome the performance of the policy-based trust models.
When applying policy-based TMS to very dynamic systems the policies are too strict to efﬁciently handle topology changing networks, nodes entering and exiting from the system, etc.
This model is based on the existence of some generic-policies and some local or nodespeciﬁc policies that are combined in order to calculate trust values.
2.3.19 Reputation Quotient
The Reputation Quotient [48], [49] tries to obtain data on a company’s reputation from the point of view of the general public, customers, employees, suppliers and investors. The model measures perceptions of an organization in terms of social expectations of dimensions such as products and services, vision and leadership, work place environment and social responsibility.
2.3.20 FIRE
In the FIRE model [124], trust is evaluated based on a different number of information sources: Interaction Trust (IT), that is built from the self experience of an entity with the other entities; Witness Reputation (WR) that is based on the direct observation of an entity’s behavior by some third-party agent; Certiﬁed Reputation (CR), one of the novelties in the FIRE model, that consists of certiﬁed references disclosed by third-party agents; and Role-based Trust (RT), which models the trust across predeﬁned role-based relationships between two entities.
The signiﬁcance of each component in the trust calculation algorithm is adjusted according to changes in the environment.
Each component owns a trust algorithm with relevant rating weight function to determine the quality of ratings tailored to its responsibility. Thus, the weight algorithm for IT in based on the age of ratings whereas WR and CR have to take the credibility of rating into account as well. Credibility is based on a ﬁltering mechanism that identiﬁes inaccurate reports and penalizes misbehaving entities.
2.3.21 PeerTrust
PeerTrust is a trust model [125] with speciﬁc characteristics for peer-to-peer e-commerce communities.
It uses several factors to calculate the reputation values of the entities (peers): feedback which is a judgment of other peers regarding target peer; feedback scope, such as the amount of transactions the peer experienced with others; a credibility factor to evaluate the honesty of feedback sources; transaction context factor such as time and size of transactions; and community context factor.
This model proposes an innovative composite trust metric that incorporates the described parameters to enhance accuracy and reliability of predicted trustworthiness.
2.3.22 Corporate Personality Scale
The Corporate Personality Scale [51] surveys customers and employees in terms of their perceptions of organization’s personality, focusing on dimensions such as agreeableness, competence and enterprise.
22

2.3. State of the Art
2.3.23 SPIRIT
The SPIRIT model [126] can be applied to survey Corporate Reputation from the perspective of customers, employees, suppliers, investors and community groups. It measures Corporate Reputation in terms of the experience, feelings and intentions of stakeholders towards a business.
2.3.24 TIBFIT
The model was proposed by Krasniewski and Varadharajan [127]. TIBFIT is a trust scheme implemented in the form of a communication protocol. It is designed to detect node failures in event-driven WSN. This detection is based on the analysis of binary reports from nodes close to any event in the system. If TIBFIT detects a node failure, it masks any communication related to this node. Additionally it can communicate this failure. Therefore, the system as a whole can try to take actions to deal with this situation.
2.3.25 UniTEC
UniTEC is the TMS proposed by Kinateder at al. [103]. This model is focused on experience as base of trust values. It uses direct and indirect information and performs direct and indirect trust values updates separately.
UniTEC gives more weight to the recent experience than to the old one, and previously calculated trust values are expressed as a binary metric (good or bad experiences). Thus, as a side-effect, the storage of old experience requires less resources than the new ones.
2.3.26 TRAVOS
The TRAVOS (Trust and Reputation model for Agent-based Virtual Organizations) system [128] is developed to ensure high-quality interaction between the entities of a large open system.
It uses two information sources to calculate the reputation of the entities: Direct Interaction and Witness Observation. However, this model relies greatly on its direct experiences and refuses to combine others’ opinions unless they are really required.
For this purpose, it provides a conﬁdence metric to determine whether the direct experiences are sufﬁcient to make an acceptable review to a particular entity or not. If not, it disseminates queries to obtain additional observations from other witnesses who claim to have had previous interaction with that certain entity.
2.3.27 Crosby and Pissinou
Crosby and Pissinou proposed a mechanism for the election of cluster heads in WSN based on a distributed trust-base framework [129].
It is based on the use of direct and indirect information coming from previously trusted nodes. Trust is modelled using a feature extraction and weighting mechanism of some essential parameters from the communication protocol: packet drop rate, data packets and control packets. Each node stores a local trust table for all its neighbor nodes. Cluster nodes can ask for these tables. Therefore, they can update their reputation values over other cluster head nodes to improve their routing path policies.
2.3.28 BambooTrust
Proposed by Kotsovinos [130], BabooTrust is based on XenoTrust. It is focused on global public computing platforms such as grid computing systems and it is built as a P2P system.
It is a model with a high-performance regarding the distribution of trust information throughout the system.
23

2. Related work
It implements as Bamboo hash table in order to facilitate the performance, scalability, efﬁciency, and load-balancing of the whole system.
2.3.29 TidalTrust
This trust model proposed by Golbeck [131] is based on ten discrete trust values in the interval [1, 10].
This model is based on the idea that humans are better in rating on a discrete scale than on a continuous one and the 10 discrete trust values should be enough to approximate continuous trust values. Besides, recursive trust or rating propagation allows to infer the rating of subjects by the ratings provided by other entities. Since each entity aggregates its collected ratings and passes only a single value to its ancestor in the recursion, the source cannot evaluate which nodes provided their rating.
2.3.30 Bayesian Reputation System
Bayesian Reputation System (BRS) was proposed by Jøsang et al [132]. It supports both binomial and multinomial rating models to allow rating supply happening in different levels. Mathematically, multinomial BRS is based on computing reputation scores by statistically updating the Dirichlet Probability Density Function (PDF) [133], [134].
In this context, entities are allowed to rate other entities within any level from a set of predeﬁned ratings levels. In contrast, in binomial BRS which is based on Beta Distribution, the agents can only provide binary ratings for the others.
Both systems use the same principle to compute the expected reputation scores: combining previous interaction records with new ratings. Besides, in order to deal with dynamism in the participant’s behavior, BRS provides a longevity factor which determines the expiry time of the old ratings and gives greater weight to more recent ones.
2.3.31 Reputation-based Framework for High Integrity Sensor Networks
RFSN was proposed by Ganeriwal and Srivastava [135]. It classiﬁes the actions as cooperative and non-cooperative. It uses direct and indirect information, and the behavior of the node is decided upon a global threshold. If the trust value is below this threshold the node in considered a non-cooperative node, and any contact from the rest of the network nodes is avoided.
The network propagates only positive reputation information in order to avoid some WSN speciﬁc attacks such as bad-mouthing attacks. Finally, an aging factor in introduced to give more weight to recent interactions.
2.3.32 Distributed Reputation-based Beacon Trust System
This model was presented by Srinivasan and Teitelbaum [136] It is focus on keep the network performance through detecting malicious beacon nodes.
Each beacon node monitors and provides information about malfunction behaviors of beacons that are one hope from them. Therefore, nodes can choose to trust in a speciﬁc beacon based on this information. They use a voting approach to calculate this trust value. The voting process is based on the reputation tables of each node, that are generated by processing the reputation tables of the close beacon nodes.
2.3.33 Subjective Logic
This trust model presented by Jøsang [137] combines elements of Bayesian probability theory with belief theory.
Besides, related to belief theory, trust is represented by opinions which can be used to express the subjective probability that an entity will behave as expected in the next interaction.
24

2.4. Conclusions

Trust Management System Marsh
MAC List Castelfranchi and Falcone Sporas Histos Abdul-Rahman and Hailes
Schillo et al. Model by Yu and Singh REGRET Aberer and Despotovic Esfandiary and Chandrasekharan Afras
Azzedin and Maheswaran Carter et al. SECURE Wang and Vassileva XenoTrust Shand et al.

Main contributions Trust based on knowledge, utility, importance, risk, and perceived competence Types of trust: dispositional, general, situational Output performance as source of reputation Global dissemination process Cognitive trust calculation process. Trust based on beliefs Short-term trust Hysteresis Trust Direct and witness information Direct trust and recommender trust Trust as discrete value Aggregated trust values Bipolar trust Trustworthiness based. Independent on the context Direct and on-demand witness information. Countermeasures against misinformation attacks Complex trust sources: direct, witness, reasoning Introduction of mixed trust and reputation systems Trust in P2P networks. Negative trust model Direct and indirect information. Q&A challenges Trust calculation based on distributed routing algorithms Trust formulation: fuzzy values Direct observation plus communicated trust Quantiﬁcation of memory Reputation as source of trust information. Context based Categorization: role-based reputation. Roles are society dependent. Calculation based on society principles. Concept of unknown’ ’ and untrustwhortiness Calculation and dissemination based on ﬁlters, and thresholds Explicit difference between conﬁdence for actions and reliability for communication capabilities Performance (reliability, honesty and throughput) as source of trust Event-based model Improved policy-based system

Table 2.1: Main contributions of TMS in the literature - I

In belief theory as introduced in an opinion can be expressed as a triple (b, d, u), where b represents the belief, d the disbelief, and u the uncertainty about a certain statement.
Finally, it deﬁnes operators for combining and recommending opinions.

2.4 Conclusions
In this chapter we have detailed the main concepts regarding trust and reputation as they are described in the literature. Besides, the Trust Management Systems have been presented as one of the common approaches when dealing with the ideas of trust of reputation.
There are a high diversity of TMS proposal in the literature. We can ﬁnd the main contributions of each model to the ﬁeld of TMS in Table 2.1 and Table 2.2.
However, each one is focused on speciﬁc problems or speciﬁc architectures. Therefore, this diversity and speciﬁcity prevents them from being used in different environments to those they were designed to.
Even though the lack of generality of each model, the compilation of such information
25

2. Related work

Trust Management System Reputation Quotient FIRE
PeerTrust Corporate Personality Scale SPIRIT TIBFIT
UniTEC TRAVOS
Crosby and Pissinou
BambooTrust Tidal Trust Bayesian Reputation System
RFSN
DRBTS Subjective Logic

Main contributions Ratings from internal members of an organization as sources of reputation Direct, witness, certiﬁed reputation, role-based trust. Introduction of categorization Trust algorithm as weight function Feedback based: information, scope, credibility, transaction, and community Combination of internal and external opinions as source of reputation Experiences and feelings as source of organizational reputation Trust integrated in a communication protocol Auto-ﬁltering of malfunctioning nodes Focused on experience. Simpliﬁcation of memories Focused on subjective trust. Witness as ﬁne tuning Minimum amount of information required to calculate valid trust values Introduction of local trust-tables Feature extraction from low level features of the underlying system Highly efﬁcient and scalable trust dissemination process Trust as discrete values. Trust transitivity based on weighting Dirichlet Probability Density and Beta Distribution Longevity factor. Direct and indirect information. Global threshold Only positive information is propagated Local reputation based on voting over second-hand information Combination of belief theory and Bayesian Reputation systems

Table 2.2: Main contributions of TMS in the literature - II

about the state-of-the-art in TMS gives us a wide perspective of the common elements of these models, their special features, their advantages and disadvantages, the processes involved in the different dynamics, etc. This knowledge will enable us to deﬁne a generic architecture for TRS.

26

Part I
Models and Methodologies
27

3. Architecture and Methodology to Analyze TRS
3.1 Introduction
After identifying the ﬁelds of application of TRS, the state of the art in the literature, and the main challenges this discipline faces, we are now in a position to start to present the set of methodologies developed in this Ph.D. Thesis.
As in many other areas of knowledge, the development of a speciﬁc ﬁeld can be described based on the tools it has to cope with the description, the prediction, and the control‘ of all the elements and dynamics related to it. Therefore, a ﬁeld of knowledge with tools that enable users to control its dynamics is much more evolved than a ﬁeld of knowledge that only counts with tools to describe its dynamics.
If we apply this simple reasoning to the trust and reputation discipline, we can see that we don’t even have tools to describe this kind of systems in a complete and systematic way.
The main goal of this chapter is to provide this basic but fundamental tool (a methodology) to identify and describe the architecture and the dynamics (components and processes) related to any kind of TRS, and to predict its behavior.
Despite its concision, this chapter is essential for understanding the contributions and implications of this Ph.D. Thesis.
In the Section 3.2 we present the proposed TRS architecture, describing both its origin and its main components and processes. Section 3.3 describes the methodology to analyze TRS based on the architecture. Finally, in Section 3.4 we draw some conclusions about the application spectrum and the limitations of the proposed methodology.
3.2 Proposed TRS Architecture
In the Chapter 2 we have presented a number of Trust Management Systems which cover a wide range of ﬁelds of application, technologies, and even architectures. However, this diversity and speciﬁcity prevents them from being used in different environments to those they were designed to.
A model with such features cannot be used as a framework to describe and analyze a generic TRS (independently of its ﬁeld of knowledge, technologies used, etc.). However, the compilation of such information about TMS has given us a wide perspective of the common elements of these models, their special features, the processes involved in the different dynamics, etc. This global knowledge enables us to deﬁne a generic architecture, or meta-model, for TRS.
This generic TRS architecture will allow us to identify and analyze any kind of TRS and stands as one of the main contribution of this Ph.D. Thesis.
Our main goal when deﬁning the architecture was to keep it as simpler as possible without loss of generality. As the result of this process we will present an architecture with only four components and ﬁve processes. However, all the previously presented TMS can be expressed in terms of this architecture.
29

Reputation system

3. Architecture and Methodology to Analyze TRS

Reputation server Disseminators Observers Entities

Underlying system

Figure 3.1: Generic TRS architecture components
Figure 3.2: Generic TRS architecture processes
3.2.1 Architectural Components
• Underlying System. Trust and Reputation Systems exist to improve the performance of another system in a speciﬁc way. This system is called underlying system, and its basic components are called entities.
• Observers. They are the basic agents of the TRS. They create and manage values of trust for the entities.
• Disseminators. The trust values calculated by the observers can be used by other observers or can be used to calculate reputation values. In order to allow this transmission of information some agents in the TRS can have the capacity of relaying both trust and reputation information messages.
• Reputation Servers. Some agents in the TRS can use the trust information generated and distributed by the observers and disseminators to generate values of reputation for all the entities. As we said before, reputation is a global and objective concept in opposition to trust, that is a subjective and local concept.
3.2.2 Processes Involved
• Trust Information Acquisition. In order to create a useful value of trust for entities, observers can use any of these sources of information: they can use their perception to obtain information by direct observation of the real world; they can use their memory, so 30

3.3. Methodology
they are able to evaluate the historical behavior of the entities; they can use information provided by other observers (disseminated trust information); they can use categorization as trust source information when the group the entities belong to is associated to a speciﬁc trust environment; and ﬁnally they can use the global reputation value of the entities (this is common in early interactions or when the global perception of an entity is more important than the local perception).
• Trust Calculation Algorithm. In order to create a useful value of trust, observers process all or some of the aforementioned sources of information with an internal algorithm. This is a key element in the whole reputation system so it has to be analyzed and designed very carefully, as we will see in the next section. As we have mentioned before, it is important to remark that trust should be a concept associated to an entity performing a speciﬁc service. It is not associated to an entity as a whole.
• Dissemination Protocol. The transmission of trust and reputation information carried out by the disseminators is based on the existence of a speciﬁc communication protocol that is commonly called dissemination protocol.
• Reputation Information Acquisition. In order to create a useful value of reputation for entities, reputation servers can use any of these sources: trust, previously calculated reputation values, and external reputation values, among others.
• Reputation Calculation Algorithm. In order to calculate valid reputation values, reputation servers use an internal algorithm similar to the Trust Calculation Algorithm but utilizing different sources of information, and with the goal of generating an global and objective concept (in opposition to trust, that is local and subjective).
3.3 Methodology
As we described before, the main goal of this chapter is to provide a methodology to identify and describe the architecture and the dynamics (components and processes) related to any kind of TRS, and predict its behavior.
The methodology is actually simple and straightforward. It is based on:
• Checking the presence of every component and process of the proposed architecture in the analyzed system.
• Identifying the main features of those components and processes based on the list of features provided in the next sections.
• Analyzing the consequences of all features in the behavior of the individual components and processes, and in the system as a whole.
Therefore, the methodology is essentially a checklist of items and implications that covers possible alternatives for the elements and dynamics belonging to the TRS. However, in order to facilitate understanding and use of this methodology we will not take into account the implications or consequences in the security of the TRS. Due to the complexity and speciﬁcity of these topics, they will be discussed in a dedicated chapter (Chapter 5).
3.3.1 Observers
They are the basic agents of the TRS. They create and manage the trust used by the whole system. To do that they are responsible for acquiring trust information and calculating trust values.
In the well-known scheme of “source that claim a quality over a target” proposed by Josang [101] they assume the role of source, because they are responsible for generating trust values for the entities of the underlying system.
The main features we identify and analyze in a TRS regarding observers are:
31

3. Architecture and Methodology to Analyze TRS
• Number of observed entities: the observer can be responsible for calculating trust values for a single entity or for several of them. A single entity observer is usually simpler than multiple entity observer due to fact that it needs less memory resources to store the trust information and less computational resources to calculate trust values. However, in many scenarios this difference do not have any signiﬁcant impact if the required resources for every additional observed entity are insigniﬁcant compared to the available resources. Anyway, we should estimate the required resources needed to observe an entity. Thus, we can count with a basic unit of cost per observable entity.
• Observation time: the time needed to acquire trust information and calculate trust values could be of signiﬁcant importance. Based on the maximum number of observable entities by an observer, we should estimate the required time to perform these processes. In order to calculate this ratio some matters such as the need of dedicated resources, or the capability of multiplexing data acquisition or trust calculation for several entities simultaneously has to be taken into account. Besides, it is important to identify if both processes are parallelizable.
• Range of observation: in a multiple entity observer scenario it is important to identify the range of observation of the observer. We understand by range of observation the area (physical or logical) that can be observed and has to be observed by the observer. Based on this data and depending on the topology and density of the observable entities of the underlying system, we can estimate some important features such as required storage and computation resources, variability of the number and density of the observable entities, etc. Observation time takes even more importance in this scenarios.
• Area of inﬂuence or traceability of the entities: this is a feature of the entities of the underlying system. However, regarding to the previous point, it is important to identify the area of inﬂuence of those entities: the maximum distance to an observer that makes the entity observable. This concept might be mixed up with the previous one. Thus, we will explain this feature with an hypothetical example: we can envision a scenario where a policeman is an observer and a thief is an entity that will be potentially observed (caught) by the policeman. The range of observation of the policeman can be a whole city. But the area of inﬂuence of the thief it is only a few meters (the distance where the policeman can actually catch the thief). If the act of observation by the policeman were “to see” instead of “to catch”, the area of inﬂuence of the thief would be higher. And if the act of observation were “to ﬁnd a clue”, the area of inﬂuence of the thief would be even higher.
• Internal or external observers: most TRS are based on this architectural element, but in cases we can ﬁnd scenarios where trust information acquisition and trust calculation are performed by external or uncontrollable agents. Examples of this kind of system can be pure-reputation systems, or some ranking or recommendation services. For example a website that ranks movies based on its visitors valuations could be considered as an external-observer-TRS, because the TRS is not involved in the process of visitors acquiring the information about the movie, nor in the process of visitors generating their opinions about the movie.
3.3.2 Trust Information Acquisition
As we described before, in order to create a useful value of trust for the entities, observers can use a number of sources of information.
After analyzing most of the TMS in the literature (Chapter 2) we can conclude that the main sources of trust information for any kind of TRS are:
• Perception, direct observation, or ﬁrst hand information: an observer can obtain information by direct observation of the real world. Generally, this is a high quality source of information, because it takes into account fresh data, and it is not ﬁltered by third parties. Actually, we should always try to incorporate this kind of information to our TRS.
32

3.3. Methodology
• Communicated information, witness information, indirect observation, or second-hand information: an observer can obtain trust information provided by other entities in the system (usually other observers). Generally, the quality or reliability of this information is worse than the previous one. This information could have been processed and not exactly reﬂect the observable qualities of the observed entities. However, it has some advantages over direct observation. It allows to gather information beyond the direct acquisition capabilities of the observer (for example, an observer with a sensor temperature could send its data to another observer with a humidity temperature to improve its trust calculation process). Besides, it allow to expand the range of observation (by relying information, a group of observers can act as a bigger one).
• Memory: an observer can use previously acquired information in order to improve the performance of the trust calculation process. Memory utilization do not have many signiﬁcant drawbacks, but the need of more storage resources in the observer. Memory is highly beneﬁcial (almost indispensable) when the entities has to be evaluated for a long period of time or when their acts can inﬂuence trust and reputation values long time after those acts has happened. The main drawback of using this kind of information is that it confers a level of inertia to all the processes of the TRS. The more memory information is used the slower the variation of values of trust is. Based on the features of the analyzed system and the goals of the underlying system this inertia can become a critical issue.
• Categorization: an observer can use a pre-deﬁned information about an entity based on a distinctive feature. In a social environment categorization is usually known as prejudices, but in this context it does not have any kind of negative connotation. This is specially useful when an entity is new in the system or the observer has not previously interacted with it. Categorization can be used as an accelerator of the initial trust calculation process because it allows to the observer to assign a default trust value to the entity or, at least, the observer has a previous knowledge about some signiﬁcant feature of the entity. In both cases, it should allow to generate accurate initial trust values. They main drawback of this source of information resides in the fact that categorization can lead to an excessive generalization that do not reﬂect the actual features of speciﬁc entities. Besides, an erroneous categorization could lead to miscalculated trust values.
• Reputation: an observer can use the value of reputation assigned for the reputation server(s) to calculate the trust value for the observed entity. This can be useful in early interactions in the same way that categorization was. In a general case, it can be a good source of information when the global perception of an entity is more important than the local perception of its features. However, we cannot forget that reputation is a global and objective concept, but trust is local and subjective. Thus, the utilization of reputation to calculate trust can lead to biased trust values or values that do not reﬂect the real interactions (observations) of the observer over the entity. If this happens for a long period of time, the beneﬁts of using the theoretically local and subjective concept of trust, can be lost.
• Reasoning: an observer can generate trust information about an entity by processing all or some of the sources of information previously described. Due to its importance, this process of reasoning stands as one of the main processes of any TRS. It is also known as Trust Calculation Algorithm, and it will be described in detail in the next section.
• Trustworthiness: this is one of the most common topics of the Trust and Reputation literature. Therefore, although this concept is not a new source of trust information but a sort of combination of some of the previous ones, we will give more details about its meaning. Based on Becerra [138], Trustworthiness is a characteristic of the trustee, while trust is the trustor’s willingness to engage in risky behavior that stem from the trustor’s vulnerability to the trustee’s behavior.. This deﬁnition allow us to express trustworthiness as validated and consolidated trust values assigned to an entity. i.e: a calculated
33

3. Architecture and Methodology to Analyze TRS
(reasoned) trust value based only previously calculated trust values memory. Therefore, in its simplest version, we could express trustworthiness as sort of local reputation from the point of view of the speciﬁc observer that calculated it.
Other main features we could identify and analyze in a TRS regarding Trust Information Acquisition are:
• Nature of the information: information can be quantitative or qualitative. Quantitative information usually leads to more accurate trust values, but qualitative information can be extremely useful when observing abstract or complex features of the entities.
• Certainty/reliability: when dealing with information we always have to know the reliability of every trust information source. Ideally, information under a speciﬁc threshold of reliability should be discarded or, at least, the system has to be aware of it, and weight it in some way.
• Redundancy: it is important to know if a speciﬁc quality of an entity is observed through several features of that entity, or if several observers can observe that same quality. Redundancy of information is the main mechanism to deal with low reliability sources of information. The more redundancy, the less reliability we should be willing to accept. Some drawbacks derived from the use of redundant information are: a higher processing complexity of the information, and a new uncertainty factor derived from dealing with different sources of information with different levels of reliability but reﬂecting the same feature of the entity.
• Scope: one of the most simple but important concepts about trust is the fact that trust is a concept associated to a entity performing a speciﬁc service. It should not be associated to a entity as a whole. Therefore, it’s important to identify if the sources of information are actually related to a speciﬁc service or not.
3.3.3 Trust Calculation Algorithm
In order to create a useful value of trust, observers process all or some of the aforementioned sources of information with an internal algorithm. This is a key process for the whole TRS.
The main features we could identify and analyze in a TRS regarding the Trust Calculation Algorithm are:
• Calculation time: regarding the previous topic, time needed to calculate trust values has implications on most of the other processes involved in a TRS. A short calculation time yields to more ﬂexible TRS and they usually require less time to adapt themselves to environmental changes. However, they could yield to a more unstable behaviors. The opposite advantages and disadvantages can be found when dealing with a long calculation time.
• Required Computational resources: the complexity of the algorithm is not the only factor determining the calculation time. Obviously, the resources available to execute the Trust Calculation Algorithm in the observer are a key factor too. However, the resources needed to execute the algorithm are not only a limiting element of the calculation time. A minimum amount of computational resources or memory storage can be a hard requirement depending on the algorithm selected. Therefore, the availability of such resources under diverse scenarios should be analyzed. In addition, a description of the degradation of the quality of calculated values should be provided for the TRS under study.
• Number of observed entities: the observer can be responsible for calculating trust values for a single entity or for several of them. A single entity observer is usually simpler than multiple entity observer due to fact that it needs less memory resources to store the trust information and less computational resources to calculate trust values. However, in many scenarios this difference do not have any signiﬁcant impact if the required resources for
34

3.3. Methodology
every additional observed entity are insigniﬁcant compared to the available resources. Anyway, we should estimate the required resources needed to observe an entity. Thus, we can count with a basic unit of cost per observable entity.
• Nature of the information: information can be quantitative or qualitative. Quantitative trust information usually performs better when: the concept of trust in the TRS is associated to a quantiﬁable feature of the entities; it is easy to deﬁne absolute minimum and maximum values of trust; or when a scale can deﬁne the trustworthiness of the entity. Qualitative trust information can be extremely useful when the concept of trust in the TRS is: associated to an abstract or complex feature of the entities in the underlying system; or when the deﬁnition of a ﬁnite number of statuses can explain the trustworthiness of the entity.
• Required information: it is important to identify the required information for the algorithm to be executed. We can ﬁnd algorithms that can keep working in the absence of information but they provide low quality results when this happens. As they acquire more information, they calculate more precise values. In this scenarios, early stages can be prone of highly misestimate trust values. However, they can count with some of the advantages of the short calculation time algorithms previously described. Other algorithms do not calculate any trust value until the have all the required information. This scenarios have to be analyzed in detail because the absence of only one source of information could stop the whole trust calculation process. Anyway, this feature will always introduce a latency to all the process involved in the TRS.
• Information consumption: we have to identify if the algorithm consumes the processed information (i.e: the information can be used only once). This feature can impact in the observer requirements. Consuming-information algorithms might require shorter observation times for the observers to keep the same trust calculation rates than others with no-consuming-information algorithms.
In addition to the algorithmic features previously described, the essential properties of the trust information, as deﬁned in the literature [139], have to be known. Some of them have been cited in previous chapters. Anyway, we will detail all of them for completeness.
The Trust Calculation Algorithm should provide trust values taking into account these properties:
• Scope: as we described in the previous section, one of the most simple but important concepts about trust is that it is context speciﬁc (i.e.,is a concept associated to a entity performing a speciﬁc service). It should not be associated to a entity as a whole. Therefore, calculating entity-wide trust values is always a delicate approach. It can yield to misestimate the trust values for the entity providing a speciﬁc service, and resulting in a degradation of the TRS performance. However, in some scenarios it might be the only kind of information available, or it can be useful as a ﬁrst estimator in the same way that we discussed before about categorization.
Some works in literate analyze in detail this topic. Marsh [107] deﬁnes three types of trust: dispositional trust, the trust of an entity independent from the possible cooperation partner and the situation; general trust, the trust of an entity in another one, independently of the speciﬁc situation; and situational trust, which describes the trust of an entity in another one in a speciﬁc situation or context.
• Dynamic: obviously, trust can increase or decrease with new experiences or observations. In addition, it may also decay with time, and new experiences are usually more important than old ones, since old experiences may become obsolete or irrelevant with time.
• Non-transitive: trust is not transitive due to the fact that it is a subjective concept. The dissemination of trust information allows an entity to use that information to calculate new trust values, but this dissemination do not imply at all that the disseminated trust
35

3. Architecture and Methodology to Analyze TRS
has to be directly assigned to the receptors of that information. In fact, this would lead to a severe malfunctioning and a degradation of the TRS applicability.
• Asymmetric: trust is not always symmetric due to the fact that it is a subjective concept. In fact, trust is typically asymmetric. An entity may trust another entity more than it is trusted back. However, when both parties are trustworthy in the long term, they will converge to high mutual trust after repeated interactions. Conversely, if one of the entities does not act in a trustworthy manner, the other entity will be forced to penalize him/her, leading to low mutual trust.
• Asymmetric Hysteresis Trust Loop: even though it is not a compulsory requirement, most real-life Trust Calculation Algorithms present a sort of asymmetric hysteresis loop in their calculated values. Trust values tend to increase slowly but they can decrease to zero almost immediately. It is important to identify the behavior of the algorithm in this sense. Usually, the behavior of the TRS will be more conservative, the more asymmetric the algorithm. And the behavior of the TRS will be more tolerant, the wider the hysteresis loop. This topic is related with the concepts of trust as a self-reinforcing and event sensitive value. Trust is usually self-reinforcing because entities act positively with other entities whom they trust. Similarly, if the trust between two entities is below some threshold, it is highly unlikely that they will interact with each other, leading to even less trust. And trust is usually event sensitive because takes a long time to build, but a single high-impact event may destroy it completely.
3.3.4 Disseminators
The trust values calculated by the observers can be used by other observers or can be used to calculate reputation values. In order to allow this transmission of information some entities in the TRS can have the capacity of relaying trust and reputation information messages.
The main features we could identify and analyze in a TRS regarding disseminators are:
• Features such as Number of disseminated sources/observers, dissemination range, dissemination time, etc. are completely analogous to those described for the observers. They should be analyzed in order to know if they can determine the behavior of the TRS.
• Information conﬁdentiality: disseminator could have access to the retransmitted information. There are not too many advantages derived from disseminators accessing to retransmitted trust information, but the fact that if they are observers too, they can use this information to feed their Trust Calculation Algorithms. The main drawback is that disseminator can become target of attacks against the TRS because they have read-access to an important asset (the calculated trust information).
• Information Filtering: disseminators can be completely transparent regarding the retransmitted information, or they can modify it in some way. If they can modify the trust information the system can be beneﬁted from processes such as error checking algorithms, or any kind of information sanitization (in a information level, not in a data level). However, disseminators can become target of attacks against the integrity of the TRS because they have write-access to an important asset of the system.
• Reliability: as we detailed before, when dealing with information we always have to know the reliability of every component processing that information. We should identify if the disseminators can lead to information loss. If so, we should model it, and analyze the impact on the TRS performance.
3.3.5 Dissemination Process
Transmission of trust and reputation information carried out by the disseminators is based on the existence of a speciﬁc communication protocol that is commonly called dissemination protocol.
36

3.3. Methodology
Actually, the dissemination process do not have any special feature compared to a generic communication protocol. Thus, the main features we should identify and analyze in a TRS regarding dissemination protocol are topics such as: connection oriented vs. connectionless protocols, computational complexity, point-to-point vs. broadcast communications, conﬁdentiality and integrity of the transmitted data, etc.
3.3.6 Reputation Servers, Information Sources, and Calculation Algorithms
Most features we could identify and analyze regarding these topics are analogous to their equivalents related to observers and the calculation of trust. Thus, we will not detailed them again and we will only focus on reputation-speciﬁc features, or features of special signiﬁcance in this context.
• Number of reputation servers: a TRS usually has a number of observers but it is possible to ﬁnd scenarios where there is only one reputation server, or even none.
Scenarios without a reputation server are also known as trust-pure TRS. They are used when calculating and disseminating reputation values do not add value to the underlying system because: i) most, or all the interaction are local or subjective; i) the reputation calculation and dissemination process has a higher cost then the beneﬁts for the observers to use that information in their Trust Calculation Algorithms.
Scenarios with only one reputation server are common when there is a special entity in the underlying system with resources above the rest. Thus, it is suitable to implement more complex processes or to store more sensitive information. Anyway, the calculation and dissemination of reputation information is a expensive computational and communicational process. Therefore, reputation support should be implemented only when this global and objective concept can improve the behavior of the TRS based on the dynamics of the underlying system. We will analyze this topic in detail in the next Chapter.
Scenarios with several reputation servers allow to deploy TRSs over larger underlying systems. The main drawback is the growing complexity of keeping information coherence between reputation servers. Hierarchical reputation servers can be implemented to cope with this complexity.
• External vs. Internal reputation systems: the reputation server is one of them main architectural elements of a TRS, but we can ﬁnd scenarios where reputation information acquisition and calculation are performed by external or uncontrollable agents. This scenarios tend to be simpler than those implementing reputation management processes. However, due to the fact that this reputation processes are uncontrollable, they can yield to erroneous behaviors. The external reputation server might not have any feedback from the underlying system. Therefore, if it does not reﬂect correctly the reputation of the entities it can lead to a degradation of the performance of the TRS.
• Reputation Information Sources. Most common sources of reputation information are the disseminated trust information of every entity) within the system, and reputation values previously calculated by the reputation server itself. Other sources of information can be used such as reputation values from other services. As we said before, this can lead to a misestimate of the reputation value assigned to the service under study. However, it might be useful to accelerate the calculation of initial reputation values.
• Publicity of the reputation values. Trust information is very often internal to the TRS (some times, it is even private and accessible only to the observer that calculated it). However, as we have described in the previous topic, reputation information can be used for third parties. Therefore, we can identify and analyze if a TRS allows public, restricted or private access to the reputation information. This feature does not have a great computational impact in the behavior of the TRS. It could only demand more resources from the reputation server to manage and disseminate the reputation information to external
37

3. Architecture and Methodology to Analyze TRS
systems. However, it is important to remark the fact that information belonging to entities of the underlying system would be accessible for external systems. Obviously, this could impact the privacy of those entities.
3.3.7 Underlying system requirements
Besides of analyzing these architectural elements and processes we should take into account how the TRS is conditioned by the underlying system. The key topics subject of study in this area are:
• Timing. Trust information acquisition, calculation, dissemination, etc. are vital processes in any reputation system environment and when they happen can modify and determine the features and effectiveness of the reputation system. The three basic timing schemes are: periodic, event oriented and periodic adaptive. Periodic underlying systems usually lead to more complex TRS: the existence of a global trigger is usually required and the transmitted information is higher than in other approaches. Event oriented underlying system optimize the communication resources. TRS processes are executed only when there is new TRS events that actually require to be processed. Periodic adaptive is a trade-off scenario where a periodic polling approach is execute, but its period can change if the number of TRS events is to low or to high. In this way, it tries to optimize the communication and computational resources of the system.
• Topology. Related to the dissemination protocol we ﬁnd that the topology of the underlying system is a key factor. We can ﬁnd as many topologies as in a generic distributed system: client-server, multi-agent systems, ad-hoc networks, etc. Advantages and disadvantages will be those commonly associated to these topologies in a generic communication scheme regarding to: transmission times, reliability, transmission ranges, etc.
• Limitations of the underlying system. Before designing any TRS we must take into account all the possible limitations the underlying system can impose: communication or computational resources, storage capacity, power consumption, etc.
• Requirements and goals of the underlying system. TRSs are but a way to improve the underlying system performance in a number of speciﬁc tasks. Therefore, the most important thing we have to take into account in the TRS analyzing process is to identify if all these requirements and goals have been achieved and up to what point. We will discuss this in more detail in Chapter 4.
3.4 Conclusions
The main goal of this chapter was to provide a methodology to identify and describe the architecture and the dynamics (components and processes) related to any kind of TRS, and predict its behavior.
The compilation of knowledge about Trust Management Systems presented on Chapter 2 has given us a wide perspective of the common elements of these models, their special features, the processes involved in the different dynamics, etc. This global knowledge has allowed us to deﬁne a generic architecture for TRS.
The architecture is as simpler as possible but without loss of generality: it is composed of four components: Underlying System, Observers, Disseminators, and Reputation Servers; and ﬁve processes: Trust Information Gathering, Trust Information Calculation, Trust and Reputation Dissemination, Reputation Information Gathering, and Reputation Calculation.
Based on this architecture, a methodology to analyze TRS is presented. The methodology is based on checking the presence of every component and process of the proposed architecture, identifying their main features and analyzing the consequences of all those features in the behavior of the individual components and processes and in the system as a whole. To facilitate this task, we provide a checklist with the main features to be analyzed.
38

3.4. Conclusions As main objection to this approach we could mention that we cannot claim that the checklist of features presented is complete. However, this checklist has not been presented as it has to be complete at all. The essential process behind this methodology is to identify every component and process of the proposed architecture into the TRS under study. Speciﬁc TRS could require a more in-deep analysis of some elements of the architecture, where others could even omit the analysis of some topics. The proposed checklist is just a guide to help the analyst through the process, pre-identifying the most common and usual features that can determine the system behavior. Finally, it is important to remark that the TRS architecture and the methodology presented in this chapter stand as one of the main contribution of this Ph.D. Thesis.
39

4. TRS Design Methodology
4.1 Introduction
After identifying the ﬁelds of application of TRS, the state of the art in the literature, the main challenges this discipline faces, and describing a methodology to analyze TRS, we will propose a methodology to design TRS in order to bring TRS technologies closer to real-life scenarios.
Following the analogy presented in the previous Chapter, as we have already described a methodology to cope with the description, and prediction of the behavior of any kind of TRS, now is the turn of moving on to the next stage. Therefore, the main goal of this chapter is to provide this basic but fundamental tool (a methodology) to control the architecture and the dynamics (components and processes) related to any kind of TRS in order to achieve a speciﬁc improvement in the performance of the underlying system.
In the Section 4.2 we present the main guidelines of the proposed design methodology. Next sections will provide a more in-deep analysis of main phases of the methodology: characterization (Section 4.3) and mapping (Section 4.4). Then, we present some topics related to the designing process in Section 4.5. Finally, in Section 4.6 we draw some conclusions about the application spectrum and the limitations of the proposed methodology.
4.2 Methodology
As we described before, the main goal of this chapter is to provide a methodology to control the architecture and the dynamics (components and processes) related to any kind of TRS.
Therefore, the designed TRS has to achieve some speciﬁc improvements in the performance of the underlying system.
The methodology is actually simple and straightforward. It is based on:
• Identify if TRS are a suitable approach to cope with the goals or requirements of the underlying system. TRS are not a universal solution for any kind of problem. They perform especially well when dealing with some speciﬁc types of issues.
• Identify the main limitations and restrictions of the underlying system. The designing process tries to bring TRS to real-life scenarios. Therefore, it is critical to adapt them to the actual limitations and resources of the underlying system.
• Deﬁne the concepts of trust and reputation by associating them to some speciﬁc features of the underlying system. Not every underlying system works directly with the concepts of trust and reputation, but we can propose analogies between trust and some subjective and local features of the entities in the underlying system, and between reputation and some objective and global features. This mapping from the application-problem domain to the TRS domain is essential.
• Deﬁne which elements in the underlying system will assume the roles of the components of the TRS. i.e: observers, disseminators, and reputation servers.
• Identify data and information in the underlying system that will constitute the sources of information for the Trust Calculation and Reputation Calculation Algorithms.
41

4. TRS Design Methodology
Figure 4.1: Design process. Iterative loops
• Propose and validate how the processes of the TRS architecture (i.e.,Trust and Reputation Information Acquisition and Calculation Algorithms, and Dissemination process) will be implemented over the underlying system.
As shown in Figure 4.1, the ﬁrst two phases of the methodology deﬁne the characterization process, and they will be detailed in Section 4.3. The next four phases deﬁne the TRS mapping process, and they will be detailed in Section 4.4.
As we will analyze in this Chapter, some of this tasks can lead to re-evaluate previous phases if the results are far from the expected performance or functionality. Therefore, we will get to the ﬁnal design and implementation through a iterative process.
4.3 Characterization
The ﬁrst phase of the proposed design methodology is to identify if TRS is a suitable approach to cope with the goals or requirements of the underlying system.
As TRSs are not a universal solution for any kind of problem, we have to identify the main criteria that allow us to evaluate the performance of a TRS. Based on this criteria we can check if they are suitable to be applied to a specif problem because they are aligned in their goals and required performances of the underlying system.
4.3.1 Basic Criterion
As we have already presented in this chapter and as we will detail in next sections, the knowledge about the trust and reputation of the entities of an underlying system can be used in a number of different ways, depending on the purpose of the TRS.
However, regarding previous works in the literature, we ﬁnd that TRS usually had a simpler approach: they were focused in utilizing TRS as a mechanism to make decisions in complex and distributed scenarios.
In these scenarios, the basic criterion to rate the performance of a TRS is the accuracy and precision of the estimated trust and/or reputation values regarding to the actual trustworthiness and/or reputation of those entities. Thus, the more accurate and precise the estimations, the more accurate and precise the decision will be.
Even though it might look like a simple approach, this criterion yield to the use of TRS in a wide number of practical applications as we presented in Chapter 1: decision-making, ranking engines, suggestion engines, etc.
However, from the point of view of this Ph.D Thesis this is an insufﬁcient approach. The study of the main ﬁelds of application of TRS presented in Section 1.2.3, and the compilation and analysis of Trust Management Systems presented in Chapter 2 has given us a wide perspective that enables us to identify and propose a wider range of applications where TRS can be extremely efﬁcient.
These ﬁelds of application are based on extended criteria that go beyond the basic criterion of improving the accuracy and precision of estimated trust and reputation values.
42

4.3. Characterization
4.3.2 Extended Criteria
The essential idea behind the proposed extended criteria is based on analyzing trust and reputation as ratios that allow us to compare entities.
This comparison goes beyond just using this information to sort the entities from the highest-rated to the lowest-rated ones. It is focused on identifying groups of entities with similar trust and/or reputation values. This leads us to be able to identify anomalous entities (not belonging to any group) or even to identify anomalous groups of entities (groups different from the majority of groups).
Hereinafter, for the clarity of the explanation we will call both anomalous or ill-behave to this entities or groups of entities.
Therefore, if we focus on this new approach, we can identify the following criteria:
• Response time. It is the elapsed time since an anomaly behavior started until it is detected, i.e., the trust/reputation of ill-behave entities begin decreasing below a speciﬁc threshold.
• Isolation capacity. It is the portion of ill-behaved entities that are detected as anomalies.
• System degradation. It is the portion of well-behaved entities detected as anomalies.
4.3.3 Typology
Regarding the basic criterion previously presented, we have already identiﬁed that TRS are a good approach to cope with some speciﬁc underlying systems: those that are based on trying to achieve precise and accurate values of trust and reputation in order to make decisions, generate rankings of entities, suggest recommendations, etc.
The analysis of the extended criteria yield to a new set of applications where applying TRS can be an suitable approach to cope with the requirements and goals of an underlying system.
Therefore, we will explain in more detail the importance of each of them and the way they can be useful for presenting a typology of suitable TRS applications.
• Minimization of the Response Time: It is the determining factor for all those applications where the TRS is being used as a detection mechanism: attacks, anomalous behaviors, etc.
Typical examples of applications that can deploy a TRS to minimize this factor are the Intrusion Detection Systems, both Network Intrusion Detection Systems and Host Intrusion Detection Systems.
• Maximization of the Isolation Capacity: It is the determining factor in all those applications where few elements can make a lot of damage to the system. The damage can be twofold: they can have a negative effect on other entities, either in degrading their performance or even rendering them completely useless; on the other hand, these elements may provide critical information or critical functionality and their incorrect functioning can highly degrade the performance of the complete system.
Typical examples of applications that can use TRS to minimize this factor can be a system for contingency against DoS or DDoS, where we TRS can prevent further propagation of the damaging effects of the attack.
• Minimization of the System Degradation: It is the determining factor in the cases where it is more important as many entities functioning properly as possible. This added value can be found in three different types of scenarios: the entities provide a higher data throughput to the system, the entities provide higher processing capacity to the system, or the entities provide stronger validity to the information generated in the system.
Typical examples of applications that can use TRS to maximize the performance can be auto-healing or even load-balancing system, both highly deployed in every kind of distributed systems such as WMN, ad-hoc networks, WSN, etc.
43

4. TRS Design Methodology
This typology of applications, based on the extended criteria previously presented, opens a new range of ﬁelds of applications where TRS can be a good approach to achieve the goals of the underlying system, or to improve its performance in a speciﬁc way. This topology overtakes the idea of a TRS as a simple decision-making mechanism and presents TRS as a suitable technology to implement detection and isolation systems, auto-healing and loadbalancing policies, etc.
In order to validate this hypothesis, a number of TRS applied over real-life scenarios will be presented in the chapters of Part II of this Ph.D. Thesis.
4.3.4 Underlying System
Once we have identiﬁed if the requirements of the underlying system can be fulﬁlled or improved by applying a TRS because they are within the scope of application of this systems (i.e.,decision making, detecting anomalies, isolation anomalies, minimization of system degradation/maximization of system performance/throughput), we have to identify and analyze the main limitations that the underlying system can impose to the TRS.
We do not have to forget that the goal of the proposed design methodology is to bring TRS to real-life scenarios. Thus, it is essential to know the limitations and restrictions that a speciﬁc underlying system can set.
The key topics subject of study in this area are:
• Resources: the main limitations of the underlying system might come from available resources of the entities: communication or computational resources, storage capacity, power consumption, etc.
• Reliability: besides the quantitative quality of the entities’ resources it is important to analyze their qualitative quality. Therefore, we should identify topics such as the guaranteed availability of the entities, the reliability of the information managed within the system, etc.
• Topology: TRS usually works over complex and distributed systems. Thus, we can ﬁnd any topology: client-server, multi-agent systems, ad-hoc networks, P2P networks, etc. Regarding these topologies we should identify and analyze the limiting and conditioning factors of topics such as: transmission times, transmission reliability, transmission ranges, etc.
• Dynamism: temporal and spatial variability of the entities within a system can be decisive in order to effectively apply a TRS over it. Thus, we should identify some relevant rates such as: number and rate of entities in-to/out-of the system, the spatial distribution of those entities (i.e.,density), the range of location of every kind of entity (i.e.,mobility), etc.
Based on this main topics we should create a more precise image of the underlying system regarding the possibility of applying a TRS to improve its performance. All these features will be taken into account in the mapping phase, and in the implementation and deployment phases.
4.4 TRS Mapping
From the point of view of describing the design methodology, this is the most speciﬁc phase regarding TRS. The result of this phase will be deeply determined by the designer’s knowledge about TRS advantages, characteristics, and limitations. Besides, as in any other design methodology, the knowledge about the ﬁeld of application is essential.
However, the goal of this methodology is not to create a playbook with the best designing choices for every scenario, but to identify all the processes involved into applying TRS to the improvement of an underlying system. Thus, the designer will have a systematic methodology to face this task.
44

4.4. TRS Mapping
After identifying if a TRS can be an appropriate approach to cope with the underlying system, and analyzing its main limitations, the next phase of the designing process aims to translate terms belonging to the ﬁeld of application of the underlying system into the TRS architecture proposed in Section 3.2.
If we achieve to do that, we can apply all the knowledge, tools, and beneﬁts derived from the use of TRS into a completely different ﬁeld of knowledge.
Although we will delve into this idea, we will give a short case of use to clarify this approach. Let’s imagine an hypothetical scenario based on a backbone network routing trafﬁc to enable some kind of information transmission service. This scenario do not know anything about trust and reputation, but about transmission rates, round-trip times, etc. However, we can create a direct association between this problem-speciﬁc concepts and the proposed TRS architecture. We can identify that the best routes are those managed by those routers of a specif model, or those handling with a speciﬁc amount of trafﬁc, or those having short routing paths that yield to short round-trip times, etc.
Thus, we can assume that the trust of a router in its neighbors is related to those problemspeciﬁc terms. Therefore, we model trust as a new variable derived from processing those Trust Sources of Information by a speciﬁc Trust Calculation Algorithm. TRS do not know anything about transmission rates, round-trip times, or router’s models, by they are very efﬁcient at detecting and isolating trust anomalies.
Therefore, by detecting and isolating anomalies in trust values that are actually based on essential problem-speciﬁc features, the TRS now becomes a efﬁcient tool to detect and isolate anomalies in the underlying system: over-utilized routers, not optimal routing paths, malfunctioning of routers, etc.
This simple approach can be extended as far as needed: routers communicate their trust information to other routers, we deﬁne different behaviors based on extreme situations (infrautilized/over-utilized routers), the routers store previous interactions with other routers in order to use historical information in their routing decisions, a central or distributed service provider initial values of router’s reliability to other entities within network, etc.
How we can systematically apply this mapping process to real-life underlying systems is described in the next sections.
4.4.1 Trust and Reputation
The ﬁrst step of the mapping process is to deﬁne the concepts of trust and reputation by associating them to some speciﬁc feature or to some speciﬁc measurement of performance of the underlying system. This mapping from the application-problem domain to the TRS domain is essential.
As we have previously mentioned, we can propose analogies between trust and some subjective and local features/performance measurements of the entities in the underlying system. And in the same way, between reputation and some objective and global features/performance measurements.
The association between an underlying system feature and the concepts of trust and reputation has not to be strict. Trust and reputation can be associated to a complex feature (a feature resulting of processing several features).
An additional characteristic of this resulting values of trust and reputation is that they have to allow us to sort and group entities. The ability to sort entities will allow the TRS to use the concept of preference in its algorithms. The ability to group entities will allow the TRS to use the concept of difference in its algorithms.
Finally, it is important to remark that not every underlying system has relevant features/performance measurements for both local and global concepts. Therefore, it is not compulsory the mapping process yields to an architecture having always the concepts of both trust and reputation. An TRS dealing only with trust is usually known as trust-pure TRS, and a TRS dealing only with reputation is called reputation-pure TRS.
45

4. TRS Design Methodology
4.4.2 Architectural components
The goal of this step of the mapping process it to assign the roles of observers, disseminators, and reputation servers of the TRS to speciﬁc entities or types of entities within the underlying system.
Observers are the key architectural component regarding the concept of trust. Therefore, they usually have a local scope and are close or have an easy access to the selected sources of trust information.
They must count with the communication and computational resources required to implement the processes they are responsible of (trust information gathering, trust values calculation, etc.)
Obviously, if the concept of trust is not needed in this scenario, the observers as architectural component of the TRS will not be needed either.
Disseminators are the key architectural component regarding the transmission of trust and reputation information throughout the system. They must count with the communication and computational resources required to implement the selected dissemination protocol.
Reputation Servers are the key architectural component regarding the concept of reputation. Therefore, they usually have a global scope and have an easy access to the selected sources of reputation information (calculated trust values, etc.). They must count with the communication and computational resources required to implement the processes they are responsible of (reputation information gathering, reputation values calculation, etc.)
Obviously, if the concept of reputation is not needed in this scenario, the reputation servers as architectural component of the TRS will not be needed either.
Finally, it is important to review the main responsibilities and features of this architecture components as they were described in Section 3.3. A systematic analysis of these responsibilities and features will allow us to identify if the proposed architectural components comply with the expected responsibilities, and will allow us to characterize the their expected behavior.
4.4.3 Sources of Information
In the ﬁrst step of the mapping process, we proposed a mapping between some feature or measurement of the performance of an entity providing a service, and the concepts of trust and reputation. This mapped feature or performance measurement is usually based on processing several basic features of the underlying system.
An important, and not simple task when mapping TRS, is to identify and choose the most appropriated features that will allow to calculate accurate and precise trust and reputation values.
This task is deeply application-problem dependent. Therefore, it is not possible to give a comprehensive list of sources of information for a generic scenario. However, based on the Trust Information Acquisition Process described in Section 3.3.2, we can systematize the process of identifying them by following the proposed taxonomy of sources of trust information. This taxonomy identiﬁes perception, communication, memory, categorization, reputation, and reasoning. Based on this approach, the designer has to analyze the underlying system and try to identify if any of this sources apply to the studied scenario.
4.4.4 Architectural processes
Selecting and implementing an speciﬁc Trust Calculation Algorithm is one of the most complex tasks when designing a TRS. However, once we have chosen the Trust Information Sources and the meaning of the concept of trust for our speciﬁc problem, the process of generating a valid Trust Calculation Algorithm basically becomes and algorithmic problem. i.e: we have to ﬁnd the best way to obtain a behavior in an output metric by processing a set of inputs.
Actually, most of the Trust Management Systems described in Chapter 2 are focused on this process. Therefore, it might be useful for a designer to know the ﬁeld of application of those algorithms.
46

4.5. Related Topics
Anyway, as we described before, the goal of the Trust Calculation Algorithm is to provide a trust values that allow us to sort and group entities. Thus, we can try and evaluate any algorithm providing this two features.
A common approach when designing Trust Calculation Algorithms is based on previously deﬁne the Asymmetric Hysteresis Trust Loop (as it was described in 3.3.3), and then try to ﬁnd a function that ﬁts this loop. Concepts such as trust update and trust revocation are common in the literature regarding this designing Trust Calculation Algorithm approach.
In order to evaluate if an algorithm is suitable for the designed TRS, the speciﬁcation of a performance test-bench is suggested. This test-bench has to identify the expected outputs associated a different scenarios. These scenarios can be speciﬁed through the deﬁnition of ranges of variation of their input values, changes in the architectural components, the presence of external elements that can modify the normal behavior of the underlying system, etc.
The same reasoning applies to the process of selecting and implementing a speciﬁc Reputation Calculation Algorithm.
Regarding the dissemination process, the steps to select and implement an speciﬁc protocol do not differ from those used in the process of implementing a generic communication protocol. It will be determined by the topology of the underlying system, the communication and computational resources of the entities chosen to be disseminators, etc.
4.5 Related Topics
In order to offer a comprehensive view of the process of designing, implementing, and deploying a TRS into a real-life scenario, we will present some topics regarding the last phases of this process.
4.5.1 Implementation and Deployment
The characterization and mapping phases are essential in the process of creating a conceptual framework for designing a TRS to improve the performance of an underlying system. However, this process is not complete until all the proposed components and processes are actually implemented, tested, and deployed.
To optimize the required time and the expected results of these phases we propose an iterative approach. In fact, we differentiate two kind of optimizations: ﬁne-tuning optimizations, and a global T&R approach.
• Fine-tuning optimizations: these optimizations have to do with the implementation of the processes proposed in the TRS architecture. They are related to these tasks of the mapping stage: selection of information sources, and implementation of the calculation algorithms and the dissemination protocol.
Some times the selection of the architectural components can be correct, but the implementation of the related processes can be sub-optimal. In this cases, an iterative approach is suggested. A performance test-bench or, at least, a set of minimum quantiﬁed performance results, has to be deﬁned. Progressive iterations over the conﬁguration, the implementation, and the utilized sources of information have to be carried out until the requirements are ﬁtted. Restrictions on communication or computational resources, time of executions, etc. have to be taken into account.
• Global T&R approach: these optimizations have to do with the most general and fundamental topics of the mapping process: the mapping of the concepts of trust and reputations, and the assignation of the roles of the TRS components (i.e: observers, disseminators, and reputations servers). In some cases, a ﬁne-tuning optimization is not enough to cope with the requirements of the underlying system because more deep and fundamental decision have been incorrectly made. In these situations, the relevant features of the underlying system are not correctly reﬂected into the concepts of trust and reputation. Therefore, trying to optimize algorithms based on wrong premises is useless.
47

4. TRS Design Methodology
This situations usually reﬂect a lack of knowledge about the speciﬁc ﬁeld of application. To cope with these issues, a reformulation of the problem is suggested: recharacterizating the underlying system, and acquiring a deeper knowledge of its components and dynamics.
4.5.2 Security
Regarding TRS security, we cannot forget that the act of trusting is associate to the act of delegating a speciﬁc responsibility. When we deal with these concepts, the idea of risk is always present. This refers to the risk of generated expectations not being accomplished or being accomplished in a different way we anticipated. Therefore, any system using a TRS to improve its behavior is especially vulnerable if the premises it is based on are attacked.
Thus, one of the goals of a TRS is to ensure that trust and reputation values correctly reﬂect the actions taken by the entities in the system and cannot be manipulated or accessed by unauthorized entities.
All the components and processes of a TRS can be attacked, and those attacks can degrade the performance of the TRS, and even compromise the conﬁdentiality, availability, integrity, etc. of both the TRS and the underlying system.
Due to the importance of these issues, we will dedicate the Chapter 5 to analyze the security of TRS.
4.6 Conclusions
The main goal of this chapter was to provide a methodology to effectively apply a TRS in order to improve the performance of an underlying system in a real-life environment. The methodology is actually simple and straightforward.
First, we have to identify if TRS are a suitable approach to cope with the goals or requirements of the underlying system, and identify its main limitations and restrictions. We have called characterization phase to these processes.
Then, we have to deﬁne the concepts of trust and reputation by associating them to some speciﬁc features of the underlying system; identify and select which elements in the underlying system will assume the roles of the components of the TRS architecture, identify data and information that will constitute the sources of information for the Trust Calculation and/or Reputation Calculation Algorithms. Finally, we have to propose and validate how the processes of the TRS architecture will be implemented over the restrictions of underlying system. We have called mapping to these processes.
Finally, we have presented some related topics such us an iterative process to implement, validate, and deploy the designed TRS, and some security considerations.
As main objection to this approach, we could mention that we do not offer a complete pattern-based design methodology.
Being able to identify a number of generic features or parameters which would allow us to characterize an application based on the requirements imposed on a TRS, would make it easier for us to identify patterns of standard-applications. Thanks to this pattern-based depiction and modeling we could create a knowledge foundation. This knowledge could allow us to face the resolution of new situations in an easier way and without the need of carrying out any initial work. Finally, having a model or a pattern for a speciﬁc type of problem would allow us to apply previously proposed solutions to solve similar problems in other ﬁelds of application.
However, design patterns are an advanced designing topic and we have considered that a complete analysis in this area would go beyond the limits of this Ph.D Thesis. Actually, it alone could be considered as a research line for a complete Ph.D Thesis work.
Finally, it is importance to remark that the methodology presented in this chapter stands as one of the main contributions of this Ph.D. Thesis.
48

5. TRS Attack Taxonomy
5.1 Introduction
One of the goals of a TRS is to ensure that trust and reputation values correctly reﬂect the actions taken by the entities in the system and cannot be manipulated or accessed by unauthorized entities.
For example, this is not achieved if entities can falsely improve their own reputation or degrade the reputations of others [140]: misbehaving entities might obtain unwarranted services or honest entities can be prevented from obtaining those services.
Regarding TRS security, we cannot forget that the act of trusting is invariably attached to the act of delegating a speciﬁc responsibility and, when we deal with these concepts, the idea of risk is always present. This refers to the risk of generated expectations not being accomplished or being accomplished in a different way we anticipated. Thus, we can see that any system using trust to improve or enable its behavior, because of its own nature, is especially vulnerable if the premises it is based on are attacked.
However, even though the importance of this matter, a taxonomy to identify TRS attacks has not been yet proposed. Different approaches in the research literature enumerate some of the most common attacks against TRS but none of them tries to provide a holistic analysis.
In this Chapter we will present the tools and the analysis framework that will allow us to deﬁne such taxonomy.
To achieve this goal, the rest of this Chapter is organized as follows: Section 5.2 explains the basis of security taxonomies and the most studied security topics regarding TRS. Section 5.3 presents a generic framework to analyze the security assets and potential attacks against any kind of system. Based on this framework, Section 5.4 presents the proposed taxonomy of TRS attacks. In Section 5.5 we present a case of use where the taxonomy is applied to a real-life scenario. Finally, in Section 5.6 we draw some conclusions.
5.2 Related Work
As we said before, we cannot ﬁnd any holistic analysis of TRS security in the literature. Common approaches identify some features that allow us to classify TRS attacks and some of them offer lists of interesting attacks.
On the one hand, two of the most important feature vectors that allow us to classify the different kinds of attacks are:
• Passive attacks and active attacks. A passive attack occurs when an unauthorized agent gains access to a resource of the system but does not modify its content. Passive attacks include eavesdropping and trafﬁc analysis, among others. An active attack occurs when an unauthorized entity modiﬁes a resource of the system.
• Insider attacks and Outsider attacks. If an agent is authorized to access system resources but employs them in a malicious way, it is classiﬁed as an insider attack. On the other hand, an outsider attack is initiated by an unauthorized or illegitimate user. They usually acquire access to an authorized account or entity and try to carry out an insider attack.
49

5. TRS Attack Taxonomy
Furthermore, the most popular attacks against TRS in literature are described bellow:
• Sybil attack: malicious agents can use multiple network identities [141].
• False information or false recommendation: malicious agents may provide false recommendations/information to isolate good agents while keeping malicious ones connected. It has three main variants: Bad-mouthing attack, where attackers manipulate reputation of surrounding agents by falsely decreasing it [90], [142]; ballot-stufﬁng, where attackers manipulate reputation of surrounding agents by falsely increasing it [143]; and self-promoting, where attackers manipulate their own reputation by falsely increasing it [142].
• Incomplete information: malicious agents may not cooperate in providing complete information.
• Initial Window: if agents rely only on their own experience in evaluating other agents, they are vulnerable until they ﬁnd other trustworthy agents, because they do not have enough information to identify and avoid cheaters [144].
• Re-entry: if attackers can create new identities freely, this presents the opportunity to remove bad reputation by creating a new identity [144].
• Whitewashing: in some systems, attackers can repair their reputation completely by using some system vulnerability [145].
• Exit: attackers planning to leave the system have no further need for keeping their reputation. Thus, they can cheat freely without consequence.
• Value Imbalance: in some TRSs, all reviews are weighted equally, regardless of the importance of the action reviewed. This presents an opportunity of attack: an entity can honestly execute minor actions, then use the reputation gained to cheat on very important ones [144].
• Selective misbehaving attacks: agents can behave badly but selectively to other agents, or they can alternatively behave well and badly to try to stay undetected, or they can even behave differently to nodes in different groups to make the opinions from the different groups conﬂicting, and lead to non-trusted relationships between them.
Besides, some attacks, although they are not speciﬁc for this ﬁeld, are usually analyzed when dealing with TRS: loop attacks, wormhole attacks, black-hole/gray-hole attacks, packet modiﬁcation/insertion, replay attacks, DoS attacks, etc.
In this way, we can see that there are a diverse set of attacks but there does not exist a holistic framework to analyze them. Thus, to offer a holistic approach to TRS attack identiﬁcation, we propose a new taxonomy in Subsection 5.4.
The purposes of any taxonomy are diverse. A taxonomy allows for previous knowledge to be applied to new attacks as well as provides structured tools to identify such attacks. Finally, a taxonomy also provides a holistic approach to classify attacks.
The features required to deﬁne a good taxonomy are [146]–[149]: accepted, it should be structured, so it can be generally approved; comprehensible: it has to be able to be understood; completeness/exhaustive: it should account for all possible attacks and provide categories accordingly; determinism: the procedure to classify attacks must be clearly deﬁned; repeatable: classiﬁcations should be repeatable; mutually exclusive: it has to categorize each attack into one category; terminology: existing terminology has to be used to avoid confusion and to increase previous knowledge with it; unambiguous, based on the deﬁned categories, there is no ambiguity with respect to an attack’s classiﬁcation;
Anyway, a taxonomy could not necessarily meet all the requirements identiﬁed above. It depends on its speciﬁc goals.
50

5.3. Proposed Security Framework
Related to the evolution of attack taxonomies, two of the ﬁrst taxonomies in the security ﬁeld were the Protection Analysis (PA) [150] taxonomy and the Research in Secured Operating Systems (RISOS) [151]. They were focused on vulnerabilities instead of attacks, but they provided a solid background used by later taxonomies.
Bishop made important contributions to the ﬁeld of security taxonomies. In [152], he presents a taxonomy of Unix vulnerabilities in which the underlying ﬂaws or vulnerabilities are used to create a classiﬁcation scheme. They are classiﬁed based on six axes: the nature of the ﬂaw, the time of introduction, the exploitation domain (what is gained through the exploitation), the effect domain (what can be affected by the vulnerability), the minimum number of components necessary to exploit the vulnerability, and the source of the vulnerability. Bishop and Bailey [153] also performed a complete analysis of other vulnerability taxonomies, such as PA or RISOS.
In [154], Howard presents a taxonomy of computer and network attacks based on factors such as the attacker motivation and objectives. In this way, it can be considered a processdriven taxonomy, rather than a classiﬁcation taxonomy.
In 2001, Lough [155] proposed VERDICT (Validation Exposure Randomness De-allocation Improper Conditions Taxonomy). It is based upon the characteristics of attacks, namely: improper validation (insufﬁcient or incorrect validation allows an unauthorized access); improper exposure (a system or information is improperly exposed to attack); improper randomness (not enough randomness in the system behavior); improper de-allocation (information is not properly deleted).
Hansman and Hunt [156] proposed a taxonomy based on four dimensions that can be applied to cover both network and computer attacks. The ﬁrst dimension is the attack vector, the second dimension identify the target. The third one consists of the vulnerability classiﬁcation based on Howard’s taxonomy [147], and the fourth describes the payload or effects involved in the attack.
In conclusion, there exists a high number of identiﬁed attacks against TRSs and some attack taxonomies in the literature, but a generic security framework to identify all viable attacks against TRSs in a holistic way has not yet been proposed.
5.3 Proposed Security Framework
In this section, a security framework based on well-known security topics is presented. Together with the TRS architectural analysis performed in previous sections, it will be the other key element of our proposed attack taxonomy.
This framework will be presented in a historic way, beginning with the CIA triad. For over twenty years, information security has held the CIA triad (conﬁdentiality, integrity and availability) to be the core principles of information security: conﬁdentiality was addressed by LaPadula and Bell in 1976 in their mandatory access control model for Honeywell Multics [157]; integrity was addressed by Clark and Wilson work in 1987 [158]. Anyway, the CIA triad is a very simple model with narrow application, that cannot adequately describe many important security objectives. Thus, there have been attempts to augment the CIA triad with more fundamental concepts. The most relevant augmentation could be the one made by Parker [159], that he called the six atomic elements of information (commonly known as the Parkerian hexad). These elements are conﬁdentiality, possession, integrity, authenticity, availability, and utility. However, this model is also limited and more topics have been considered later, such as accountability or non-repudiation.
First of all, to carry out a complete analysis of possible attacks to TRS, we will identify the relevant topics that we should take into account from the viewpoint of security. In order to do this, we propose a holistic security framework, based on the augmentation and redeﬁnition of the CIA triad and the Parkerian hexad.
The framework is divided into basic entities and topics. The topics are divided into: wide scope topics, that affects to all the other topics; primary topics, that are necessary and sufﬁcient to perform any security analysis; and derived topics, that can be deﬁned as combination of
51

5. TRS Attack Taxonomy
Figure 5.1: Security Framework
primary topics. Derived topics are included in this framework due to its importance in the literature and because they can be very useful to carry out a deeper and detailed analysis if these sub-topics are especially relevant in the different scenarios analyzed. All the topics are conceptualy organized as showed in Figure 5.1. The meaning of every element is shortly described bellow.
The basic entities of our framework are:
• Agent: agent means an entity trying to perform an action within a system.
• Resource: resource means the entity used to offer a feature within a system. Data, information, knowledge, any kind of physical resource, etc. are examples of resources.
The only wide-scope topic is:
• Accountability/Activity logging: Accountability is assurance in tracing all activities within the system. It can be applied in combination with any of the factors detailed bellow.
The primary topics of the framework are:
• Authentication: Authentication means the processes related to check if an agent can fulﬁll a challenge-response process. The challenge can consist in login/password/PIN prompts, bio-metric constant analysis, or any kind of requirement, or combination of requirements, that an agent has to fulﬁll within the system. The classical concept known as Identiﬁcation could be expressed in this context as a speciﬁc type of authentication. Identiﬁcation means the act of determining who someone or what something is. It should be based in speciﬁc features of the agent uniquely associated to it. Thus, from the viewpoint of the system, the agent and the set of selected features are exactly the same. In an optimal identiﬁcation, the values of the features should be unique for each agent. Moreover, identiﬁcation can be applied to identify resources as well. It is important to mention that identiﬁcation and authentication are not exactly the same process. They are usually confused, though. Identiﬁcation can be considered as an strict authentication method where the challenge consists in providing enough credentials to identify the agent uniquely within the system compared to other agents. Attacks to authentication are usually called credentials theft, and attacks to identiﬁcation are referred to as impersonation, man in the middle, etc.
• Authorization: Authorization process shows what resources an agent is permitted to access and what processes it will be allowed to perform after it has successfully been and authenticated. The access control mechanisms are usually deﬁned in policies. Attacks against authentication are usually called privilege escalation.
52

5.4. Trust and Reputation System Attack Taxonomy
• Availability: Availability means having timely access to the utility/process (as described bellow) whenever it is required by an authorized agent. The Parkerian element possession can be expressed as a speciﬁc type of availability where physical access is required. Attacks to availability are usually referred to as Denial-of-Service (DoS), and attacks to possession are usually known as robbery
• Utility/process: Utility means usefulness. It means that the action an agent wants to perform over a resource could be carried out properly. Utility is often confused with availability, but it is important to understand that availability is focused on an agent (when it is trying to access a utility), and utility is focused on the process itself (that should be carried out correctly).
Finally, the derived topics are:
• Conﬁdentiality: Conﬁdentiality refers to limits on what agent can access what kind of information. This process is usually associated to cryptography, although it is valid for any method used to protect information from unauthorized access. It can be considered a combination of the authorization and utility (access) topics, dealing with the resource information. Attacks to conﬁdentiality are usually called eavesdropping, snifﬁng, spying, etc..
• Integrity: Integrity means the act of being consistent with the intended state of information. Any unauthorized modiﬁcation of data, whether deliberate or accidental, is a breach of data integrity. It can be considered a combination of the authorization and utility (modiﬁcation) topics, dealing with the resource information. A special case of integrity is Temporal Integrity where the aspect of the information that is modiﬁed is time: when it has happened.
Attacks to integrity are usually called manipulation, and attacks to temporal integrity, delay and re-transmission.
• Non-repudiation: It means that one party of a transaction (agent-resource) cannot deny having received a transaction nor can the other party deny having sent it. It can be considered a combination of the identiﬁcation, utility/process, and accountability topics.
All these factors constitute a security framework proposed to analyze the security of any kind of process: services offered by a web server, access to a ﬁle system, operation of control and monitoring systems, etc.
In this work, they are applied to TRSs in order to identify an attack taxonomy composed of any possible security threat against their basic processes and resources. The description of this taxonomy is provided in the next section.
5.4 Trust and Reputation System Attack Taxonomy
Our taxonomy is based on the TRS architectural model proposed in Section 3.2 and the security framework proposed in Section 5.4.
In order to identify all the different attacks against TRS, an analysis of the four agents (entities, observers, disseminators, and reputation servers) and the basic processes related to TRS (trust and reputation information gathering, calculation, and dissemination) will be performed from the viewpoint of each topic considered within the security framework.
The results of this analysis are presented and described below. In the following tables viable attacks to the different processes of TRSs are presented, and a measure of attention received by the research community has been included (from ﬁve stars: #####, assigned to the most studied attacks, to zero stars $$$$$, assigned to attacks without any research work in the ﬁeld of TRSs). No previously cited attacks in TRS literature have been marked with (*).
53

5. TRS Attack Taxonomy

5.4.1 Attacks against gathering T&R information
In terms of the security framework detailed in the previous section, the process of gathering T&R information could be described as follows: observers from the TRS architecture are the agents, the process they try to carry out is to gather information from the resources, in this case, entities or other observers. The results of this analysis are presented in Table 5.1.

Topic Authentication Identiﬁcation Non-repudiation Authorization Availability Utility/process
Conﬁdentiality Integrity Time Integrity

Gathering T&R information Credential Forgery Man in the Middle, stolen identity, Clone, Sybil, Re-entry Entity/observer Misbehavior, Confusion Gathering-based Privilege Escalation (*) DoS against entities and observers Bad-Mouthing, Ballot-Stufﬁng, Incomplete information, Null information, Selective information, Entity Malfunction Information and Behavior Eavesdropping Second-Hand Information Manipulation Second-Hand Information Delay/Re-transmission

#$$$$ ####$ ##$$$ $$$$$ ##### ###$$
$$$$$ ###$$ ##$$$

Table 5.1: TRS Attack Taxonomy. Gathering T&R Information

Attacks related to authentication, identiﬁcation, and non-repudiation rely on the fact that the identity or the authentication tokens of the entities might be broken in some way. In TRS most attacks of this group are focused in identiﬁcation. In this way, we can ﬁnd popular attacks such as man in the middle attacks, stolen identity attacks, clone attacks, or Sybil attacks. But there are more subtle attacks included in this group, such as re-entry attack (if identity generation is a replicable process for an attacker). Pure authentication attacks are less common in TRS, but they could include the forgery of categorization credentials, so an attacker can pretend to belong to a speciﬁc category within the system. e.g.,a passport can pre-assign some rights to an agent based on its nationality. Thus, forgering a false credential (i.e.,the passport) could be considered a break into the security of the TRS system known as foreign affairs. Finally, attacks to non-repudiation in TRS include all kind of misbehavior/confusion attacks (entities that offer different information to different observers). These attack can be carried out only if the accountability of the system is inadequate.
Attacks against authorization rely on the fact that an observer could obtain more privileges in the entity than just observing speciﬁc T&R information. Sometimes, the work of the observers is completely passive, but if an action is needed to get this information from the entity, the observer can abuse this access. This kind of attacks regarding TRS has not been studied in detail in the literature.
In TRS, attacks against availability and possession are focused in this ﬁrst topic: DoS attacks against the availability of entities and observers. However, there is no speciﬁc knowledge about DoS in the area of TRS. Regarding to possession, robbery attacks are included in this group. In TRS, they mean to physically steal the entities or observers that generate the trust or reputation information, but they have not been studied in detail in the TRS literature.
When an observer effectively accesses to the T&R information of an entity (i.e: the entity is available), the next step in our analysis lead us to study attacks against utility/process. In this process of gathering trust information, common attacks are; bad-mouthing and ballot stufﬁng attacks (entities provide false information), incomplete information attacks (entities do not provide all the information available), null information attacks (entities do not provide information at all) or even selective information attacks. This group also includes true entities malfunction.
Regarding conﬁdentiality, the T&R information that observers obtain from entities can be the subject of eavesdropping attacks. Its important to mention that this analysis do not include only information, but behavior too. Both of them can be subject of unauthorized access.

54

5.4. Trust and Reputation System Attack Taxonomy

Despite their importance, these attacks have not been studied in detail in the TRS literature. Attacks against integrity or temporal integrity are uncommon when dealing with the pro-
cess of gathering ﬁrst-hand T&R information because observers usually access to it directly. Thus, attacks such as trust information manipulation or trust information re-transmission have not been studied in detail. The exception resides in attacks based on relayed information. In this case, second-hand T&R information can be manipulated. Actually, this kind of attacks are very common in different areas of knowledge such as social relationship or corporation environments.

5.4.2 Attacks against T&R calculation

In terms of the security framework detailed in the previous section, the process of T&R calculation could be described as follows: observers from the TRS architecture are the agents, the process they try to carry out is to calculate new T&R information, and to do that, the resources are the T&R information they previously gathered. The results of this analysis are presented in Table 5.2.

Topic Authentication Identiﬁcation Non-repudiation Authorization Availability Utility/process Conﬁdentiality Integrity Time Integrity

T&R Calculation Forgery of credentials to access T&R information (*) Stolen/Clone Observer Identity (*) T&R information Authorship Rejection (*) Calculation-based Privilege Escalation (*) DoS against observers Initial Window, Whitewashing, Observer Malfunction T&R information Eavesdropping Whitewashing T&R information delay/reuse (*)

$$$$$ $$$$$ $$$$$ $$$$$ ##### ###$$ $$$$$ #$$$$ $$$$$

Table 5.2: TRS Attack Taxonomy. T&R Calculation

Attacks to authentication, identiﬁcation, and non-repudiation are not very common dealing with T&R calculation, because this is often an internal process. Observers do not usually have to identify or authenticate against himself to access its own information (e.g: human beings do not need to prove their identities to access to their own memories or sensor devices to access its RAM memory, etc.). However, in some TRS, the algorithm to calculate the new values of T&R and the T&R information can reside in different agents. In these cases, dealing with authentication, identiﬁcation and non-repudiation becomes a matter of great importance (i.g: cloud computing systems). In the same way, attacks to authorization are not common when dealing with T&R calculation. At the present time, all these topics have not been studied in detail in the TRS literature, but they are a promising ﬁeld when dealing with TRS in cloud-computing or high-distributed systems.
Attacks against availability and possession are focused on DoS attacks. A DoS attack against the observers can frozen the T&R values, since they cannot calculate them. Attacks to possession are a threat only in the aforementioned high-distributed scenarios where T&R information and T&R calculators (i.e: observers) are in different agents.
Most of the attacks against T&R calculation are those against utility/process. For example, we can ﬁnd initial window attacks or whitewashing attacks (based on exploiting the calculation algorithm). Any kind of malfunction or bug in T&R calculation, although they are not attacks, can be classiﬁed within this group.
Attacks to conﬁdentiality consist in snifﬁng attacks against the T&R information used in the calculation process and inverse engineering against the calculation algorithms. Anyway, despite their importance, these attacks have not been studied in detail in the TRS literature.
Regarding attacks against integrity, the main threat is the manipulation of the T&R information used to calculate the new T&R values. This can result in a whitewashing attack (based on exploiting T&R information instead of exploiting T&R calculation). Finally, attacks
55

5. TRS Attack Taxonomy

against temporal integrity can only appear in high-distributed systems, where delay or retransmission attacks might be a real threat.

5.4.3 Attacks against T&R dissemination
In terms of the security framework detailed in the previous section, the process of disseminate T&R information could be described as follows: disseminators from the TRS architecture are the agents, the process they try to carry out is to distribute T&R information throughout the TRS, and the resources are the messages with that information. Due to the fact that T&R dissemination is basically a routing process, most of the attacks shown bellow are not speciﬁc of TRS, but they are important to identify all threats that can affect to a TRS. The results of this analysis are presented in Table 5.3.

Topic Authentication Identiﬁcation Non-repudiation Authorization Availability Utility/process
Conﬁdentiality Integrity Time Integrity

T&R Dissemination Routing credentials forgery (*) Man in the Middle, stolen identity, Clone, Sybil, Re-entry T&R messages Routing Rejection (*) Routing-based privilege escalation (*) DoS against disseminators Loop, Black-Hole, Gray-Hole, Wormhole, Misrouting, Disseminator Malfunction T&R messages Eavesdropping T&R messages manipulation Pulse Delay, T&R message re-transmission

$$$$$ ###$$ $$$$$ $$$$$ ##### #####
$$$$$ $$$$$ ###$$

Table 5.3: TRS Attack Taxonomy. T&R Dissemination
Attacks related to identiﬁcation rely on the fact that the identity tokens of the disseminators might be broken in some way. In fact, these attacks are rather similar to those regarding gathering T&R information but the subjects of the attacks are disseminators instead of entities. In this way, we can ﬁnd attacks such as man in the middle attacks, stolen identity attacks, clone attacks, Sybil attacks, re-entry attack (if the disseminator identity generation is a replicable process for an attacker).
Authentication and non-repudiation attacks are very rare in the TRS dissemination process and we could not ﬁnd any example in the literature. Anyway, these attacks could be carried out only if the accountability is inadequate.
Thus, authorization attacks are unusual because the only action that disseminators perform is relaying those messages. Attackers could try to carry out a privilege escalation attack against the disseminators through the sent messages but it is very unlikely that they could do this in most TRS. Anyway, we have to know that it can be a possible threat against our TRS.
Attacks against availability are basically DoS attacks. A DoS attack against disseminators can frozen the T&R values, since the calculated new T&R values are not propagated throughout the TRS. Attacks regarding possession are robbery attacks, where the T&R messages are stolen from the disseminators.
Most of the attacks against T&R dissemination are those against utility/process. In this group, we can ﬁnd loop attacks, black hole attacks, gray-hole attacks, wormhole attacks or misrouting attacks, and, although they are not attacks, any kind of malfunction or bug in disseminators, can be classiﬁed within this group. These attacks are quite popular in TRS literature, even though they are not speciﬁc of this ﬁeld.
Attacks to conﬁdentiality are classical network eavesdropping/snifﬁng attacks. But, despite their importance, they have not been studied in detail in the TRS research works.
Regarding integrity, manipulation of the T&R messages is the most dangerous threat. It is a topic analyzed in depth in generic communication scenarios, but it has not attracted the attention of TRS researchers despite its importance. Finally, regarding temporal integrity, we can ﬁnd two classical TRS attacks: pulse delay attacks and T&R message re-transmission attacks.

56

5.5. Case of study
5.4.4 Taxonomy-based Analysis Conclusions
Based on this analysis, we can identify two main deﬁciencies of the state-of-the-art in TRS security literature. First of all, there are some potential threats that have not been previously identiﬁed, such as credential forgery to access T&R information, deny of T&R information authorship, privilege escalation attacks against all the processes of a TRS, and T&R information reuse attacks. And secondly, there are some identiﬁed attacks that have received few attention from the TRS community despite their importance, such as attacks to the conﬁdentiality of the T&R information sources, the T&R information utilized by observers, and the T&R information disseminate throughout the TRS.
At the same time, all these deﬁciencies are new opportunities for TRS researchers to increase the available knowledge about security regarding TRS.
5.5 Case of study
In this section, the proposed taxonomy is applied to a real-life scenario. In this way, we can describe the beneﬁts derived from its use, and we can validate the approach.
The selected real-life TRS environment is the Journal Citation Report, as a measure of the relevance of a scientiﬁc journal.
Journal Citation Report has been selected as our ﬁrst example because it is a well-known TRS for all the research community. Besides, because of its simplicity, it allows us to clearly illustrate the use of the proposed taxonomy.
5.5.1 Journal Citation Report
As Thomson Reuters says in its website: Journal Citation Reports offers a systematic, objective means to critically evaluate the world’s leading journals, with quantiﬁable, statistical information based on citation data. By compiling articles’ cited references, JCR Web helps to measure research inﬂuence and impact at the journal and category levels, and shows the relationship between citing and cited journals.
From the viewpoint of TRS, and based on the architectural model presented in the Section 3.2, we can identify the following subjects:
• In order to simplify our model, the entities of the TRS will be all the published journals.
• JCR is a pure-reputation TRS (it does not deal with trust). Thus, there is only one observer, and it is Thomson ISI (Institute for Scientiﬁc Information). There is not any disseminator, and Thomson ISI is itself the reputation server.
• The reputation algorithm is the well-known Journal Impact Factor (IF). It is a measure of the frequency with which the average article in a journal has been cited in a given period of time. IF is calculated based on a three-year period, and can be considered to be the average number of times published papers are cited up to two years after publication. For our purpose, IF will mean reputation.
There are more agents involved in the scientiﬁc publishing market, such as publishing companies, authors, reviewers, chief editors, etc. But for our analysis we will focus only in the agent journal. There are a number of reasons for a journal to try to obtain a high IF. Anyway, we will not describe all those reasons and we will just work with the premise that this fact is true.
Now, we can analyze JCR from the viewpoint of the proposed taxonomy. In this way, we could identify all possible attacks against this speciﬁc TRS.
5.5.2 Gathering T&R information
What makes a journal different from another one is its name and its publishing company. Thus, we assume name and publishing company are the identity of a journal. In this way, we
57

5. TRS Attack Taxonomy
have to check if this identiﬁcation mechanism is prone to some of the aforementioned attacks. Firstly, we can see that Man in the middle attacks, confusion attacks or misbehaving attacks are unfeasible.
However, clone attacks (or semi-clone attacks) are viable: a journal can create an identity similar to the identity of an existing journal. With this technique, a journal can try to clone the reputation of the attacked journal by attracting authors to publish on it. Although it is not a fast and effective attack, it is easy to ﬁnd some examples in the publishing market. A variant of this identity attack consist on creating appealing identities. This means to create journals that are susceptible to be referenced by other journals just based on their identity (i.e: their names). Journals devoted to tutorials and surveys are clear examples of these attacks.
Related to the fact that it is easy for an attacker to create new identities, we can ﬁnd examples of re-entry attacks. If a journal is not well considered it can be re-created in order to clear its reputation.
Regarding to authorization and availability there is no viable attacks. Thomson can always access the required data (the references between articles) and always has enough resources to perform this process.
Regarding utility we can ﬁnd the most popular and dangerous attack against JCR: it is a collaborative attack where some journals improve the IF of other journal. It is a classical ballot stufﬁng attack, and the only thing needed is that a set of journals artiﬁcially reference articles of a speciﬁc journal.
All information handled by Thomson to calculate the IF is public. So, we do not have to take care of conﬁdentiality.
Regarding integrity, all the information used to calculate the reputation is eventually controlled by the editors-in-chief. This means that there is no way to ensure the integrity of the journals (i.e: integrity means that the papers published in every journal actually deserve to be published). Each editor-in-chief can decide what papers are or are not included in the journal. So, they control the information managed by Thomson to calculate the IF: they can add or remove references to others journals just by adding or removing speciﬁc articles in their editions. This is a big security hole for all the publishing system and the Thomson’s IF.
Finally, regarding time integrity, we can ﬁnd re-transmission attacks. An author can send the same article (or almost the same article), to different journals. If they are published, the IF is suffering a classical re-transmission attack, with duplicate information. Although this could be detrimental to the author’s reputation, it is a viable attack against the JCR system.
5.5.3 T&R calculation
Regarding T&R calculation, the analysis is simpler. Due to the fact that Thomson is the only entity that calculates the IF based on public information and with its own calculation resources, authentication, identiﬁcation, non-repudiation, availability, utility/process, conﬁdentiality and temporal integrity are not subject of any of the identiﬁed attacks.
However, we are in presence of an insider attack, where the reputation server (Thomson) can decide what information will be include in the calculation of the IF and what will not. This decision can be expressed as an integrity attack: the information the reputation server handles can be deleted (not included). It might look like something that would never happen. But, due to the importance of the IF factor, Thomson can arbitrarily decide what journals are included in the JCR and what are not. And this has dramatic consequences in all the publishing market, affecting authors, publishing companies, etc.
5.5.4 Gathering T&R dissemination
Finally, attacks against T&R dissemination are not possible, because the information is distributed in a wide and public manner and subvert this information completely is an almost impossible task for any attacker.
58

5.6. Conclusions
5.5.5 JCR Analysis Conclusions
As we have demonstrated, the JCR system has many important deﬁciencies in the processes of gathering T&R information and calculating new reputation values (i.e: IF). In this way, we have identify re-entry attacks, clone attack, appealing-identities attacks, ballot stufﬁng attacks, editors-in-chief attacks, re-transmission attacks (i.e: multiple paper re-submission attacks), and excluding-journal-from-JCR attacks. Anyway, all of them have been easily detected with the proposed taxonomy.
5.6 Conclusions
Due to its nature, TRSs are especially vulnerable to attacks if the premises they are based on are subverted. There exists a high number of identiﬁed attacks against TRSs in the literature, but a generic security framework to identify all possible attacks against TRSs in a holistic way has not yet been proposed.
To achieve this goal a security framework has been presented. It is based on an augmentation of classical models such as the CIA triad and the Parkerian hexad. The topics identiﬁed in this framework are: accountability, authentication, identiﬁcation, non-repudiation, authorization, availability, utility, conﬁdentiality, integrity and time integrity.
Thus, the presented taxonomy is based on the TRS architectural model and on the security framework: in order to identify the different attacks against TRS, an analysis of all the agents and processes related to TRS is performed from the viewpoint of each topic considered within the security framework.
Based on this analysis, we can identify two main deﬁciencies of the state-of-the-art in TRS security literature. First of all, there are some potential threats that have not been previously identiﬁed, such as credential forgery or privilege escalation attacks. And secondly, there are some identiﬁed attacks that have received few attention from the TRS community despite their importance, such as conﬁdentiality attacks. Anyway, these deﬁciencies constitute new opportunities for TRS researchers to increase the available knowledge about security regarding TRS.
Finally, the proposed taxonomy is applied to a real-life TRS: the Journal Citation Report (JCR). In this way, we can validate the beneﬁts derived from its use. The result of this analysis is a complete list of viable attacks against this TRS.
59

Part II
Cases of study
61

6. Detection and isolation: Anomalies in Data
Centers
Reliability is one of the key performance factors in Data Centers. The out-of-scale energy costs of these facilities lead Data Center operators to increase the ambient temperature of the data room to decrease cooling costs. However, increasing ambient temperature reduces the safety margins and can result in a higher number of anomalous events.
Anomalies in the Data Center need to be detected as soon as possible to optimize cooling efﬁciency and mitigate the harmful effects over servers. In this context, TRS can provide a signiﬁcant improvement for these systems.
In order to take advantage of TRS we will follow the analysis and design methodologies proposed in Section 3.2: identify architectural entities, trust and reputation information sources, functional and non functional requirements, dissemination algorithms, etc.
This analysis allow us to choose the constitutive elements of a TRS. Therefore, we can reduce the detection time and improve the isolation capacity of anomalies in Data Centers.
6.1 Introduction
During the last few years, there has been a rapid increase in the number of Data Center facilities over the world. Data Centers provide the required infrastructure for a wide range of traditional applications (social and business networking, Webmail, Web search, etc.) as well as new-generation applications such as e-Health or Smart Cities. Advances in the underlying manufacturing process and hardware design technologies have continuously made possible the constant increase in computing capacities.
However, the increase in computational capabilities has not come for free. These facilities consume huge amounts of electrical power, accounting for 2% of the total USA energy budget [160]. They also generate a tremendous amount of heat that has to be extracted to ensure the reliable operation of server and other computational (IT) equipment. The energy consumption needed to cool down servers accounts for around 30% of the total energy cost of the infrastructure [161]. Even though increasing the Data Center room temperature has proven to be a way to save cooling energy, there are some important concerns regarding reliability, which is one of the key performance factors in Data Centers.
The American Association of Heating and Cooling (ASHRAE) [162] describes that the inlet temperature of servers should be kept below 30ºC to avoid CPU redlining [163]. Failures in either the room or the server cooling systems could lead to reliability issues that would reduce the Mean Time To Failure (MTTF) of IT equipment [164].
Temperature anomalies in the Data Center, as well as any other type of anomaly that might affect the reliable behavior of IT equipment, need to be detected as soon as possible to mitigate the harmful effects.
To this end, this chapter describes the usage of clustering-based outlier detection techniques coupled with a TRS to detect anomalies in Data Centers.
Clustering-based outlier detection approaches [89] offer numerous advantages for detecting insider attacks, such as high adaptability, ﬂexibility, possibility to detect unknown attacks, no restrictions on training data, etc. Data center anomalies exhibit a similar behavior, making
63

6. Detection and isolation: Anomalies in Data Centers
clustering techniques a good candidate for their detection. Within the scope of clusteringbased approaches, we encounter different deployment possibilities: i) k-means or k-Nearest Neighbor (k-NN) techniques, or ii) topology-preserving competitive methods, such as Selforganizing maps (SOM) or Growing Neural Gas (GNG). Topology preserving techniques are very convenient for our application scenario, since one of the main parameters that reveal the presence of outliers is the average distance of a cluster to its closest neighbors.
The remainder of this chapter is organized as follows: Section 6.2 describes the related work on the area of detecting anomalies in Data Centers. Section 6.3 analyzes in detail how TRS can improve the system, focusing in the typology of anomalies (Section 6.3.2), the available trust information sources (Section 6.3.3), and the algorithms proposed for this scenario (Section 6.3.4). Experimental results are shown in Section 6.4. Finally, the most important conclusions are drawn in Section 6.5.
6.2 Detecting Anomalies in Data Centers
Next-generation applications, such as the ones found in Smart Cities, e-Health, Ambient Intelligence or Weather analysis, require constantly increasing high computational demands that can only be provided in Data Centers [165], [166].
Several techniques to reduce energy consumption in Data Centers are based on increasing the supply temperature of air conditioning units to reduce cooling costs. However, increasing the inlet temperature of servers has some drawbacks. A report by the Uptime Institute [167] showed that for every 10ºC degrees of temperature in excess of 21ºC in the inlet temperature of servers, long-term reliability could be reduced by 50%.
Even though recent research [168] shows that the effect of high temperatures on reliability is smaller than what had been assumed, as the ambient temperature increases the safety margin for the server thermal shutdown is decreased. Moreover, the temperature distribution in a Data Center is not uniform and tends to have hot spots, which are areas signiﬁcantly hotter than the average. To prevent server thermal shutdown, the highest CPU temperature limits the maximum Computer Room Air Conditioning (CRAC) air-supply temperature.
Thus, it is important to be able to detect and localize any anomaly taking place at the Data Center. Anomalies can be due to failures in the cooling system, in the servers, or misbehaviors in the workload assignment, that affect the thermal conditions of the server and room.
There is much research in the area of anomaly detection in Data Centers. Some approaches try to model and estimate the temperature conditions with Computational Fluid Dynamics (CFD) simulations [169]. CFD is time and cost expensive, and results are not robust to changes in the Data Center. Other works use regression models with historic data [170] or thresholdbased anomaly detection [171].
All the previous techniques rely on considering static Data Center layouts. However, Data Center environments are subjected to constant changes in the placement of servers and racks. Learning and training techniques based on fuzzy control have been previously used by Sedano et.al.[172] for temperature control in buildings to maximize energy efﬁciency. For the particular case of Data Centers, machine learning approaches based on Neural Networks (NN) aim to ﬁnd relationships between the thermal features. Other works use Self-Organizing Maps (SOM) [173] but only to discover network attacks in the Data Center, not as a methodology for anomaly detection.
6.3 TRS and Anomaly Detection in Data Centers
As we describe before, in order to improve the behavior of other anomaly detection techniques we only have to analyze this kind of systems from the point of view of the proposed TRS methodologies. Thus, we can identify the elements that are not being used by other approaches and propose the most suitable sources of trust information and trust algorithms to achieve the goals of the underlying system.
64

6.3. TRS and Anomaly Detection in Data Centers
6.3.1 Underlying System Analysis
Following the structure showed in Section 3.3.7 we can identify these topics about the underlying system.
• Description of the underlying system. Without loss of generality and for the purposes of this work we describe a Data Center as system that is composed of a resource manager/workload allocator, a number of servers equipped with different kind of in-server sensors, and a parallel cooling system that is made up of air conditioning units and environmental sensors deployed through a WSN.
• Requirements and goals. Data Centers have to detect any kind of anomaly and isolate them as soon as possible to avoid any of the drawbacks described previously in this chapter. Based on section 4.3.3 this is a paradigmatic example of a Minimization of the Response Time and Maximization of the Isolation Capacity. Due to the importance of this topic, it will be discussed in 6.3.2.
• Topology. A number of different topologies can be implemented in a Data Center. However, due to the high connectivity between all the entities in the system it will not introduce any limitation or restriction to the design of the TRS. The only relevant issue regarding this topic is the fact that all the entities in the system are static and they will have a ﬁxed position.
• Timing. There might be a global clock to trigger whole-system sensors and actuators behavior, but its presence is not compulsory. Thus, the system can be both event oriented or polling oriented.
• Limitations. Most, or all the entities have a permanent energy supply, and a permanent communication link to each other. The main limitations might be the computational and storage resources of some of the sensors or actuators.
6.3.2 Requirement and Goals: Taxonomy of Anomalies
In order to deﬁne our TRS architecture, therefore, it can cope with the previously deﬁned goal of detecting and isolating anomalies in Data Center, we propose in this section an anomaly taxonomy according to their causes:
• Data room cooling: caused by failures in the cooling equipment of the data room. Their impact depends on the number of CRAC units failing and the nature of the failure.
• Server level: refers to failures in the electronic components of the servers. The effect is local to the server (i.e. thermal redlining in the CPUs). However, local effects can also have an impact on the room dynamics.
• Workload execution: workload is allocated to the computing nodes via a resource manager. Failures can be understood as tasks assigned to a certain computing node that aborted or did not complete properly. Their effect is local to a server but can be extended to the nodes absorbing the unattended demand, which might become potential hot spots.
• Information sources: caused by failures in the environmental or in-server sensors used to gather information to detect anomalies. Malfunction can come because of batterypowered sensors running out of power, environmental sensors being moved by data center operators, server sensors providing random incorrect values, etc.
A last category would be attacks on the information or networks of the data center. The scope of these attacks can be very broad, but they are generally related to gaining access to the computing nodes to retrieve sensitive information. The aim of this work is not to detect anomalies due to foreigner attacks on the data center, which falls under the area of security, but to discover anomalies inherent to the data center.
65

6. Detection and isolation: Anomalies in Data Centers
6.3.3 Trust and Reputation System Analysis
If we review the elements and processes of the proposed TRS architecture, we can identify the following ones:
• Observers. Every sensor, server, and the workload allocator can provide some useful information about the status of the system. Therefore, they can be an observer in the TRS.
• Trust Information Sources. Current Data Centers are constantly monitored by a large number of sensors to enable overall IT and cooling management. All the information gathered in the data center can be used as trust information source. Generally speaking, it can be classiﬁed as follows:
– Environmental sensors retrieve relevant thermal characteristics of the data room. In a real-life scenario, these sensors are: i) temperature sensors to measure the inlet and outlet of servers, ii) data room relative humidity sensors, iii) differential pressure sensors for raised-ﬂoor air-cooled data centers and iv) CRAC air supply temperature sensors.
– Integrated server sensors: these sensors are embedded in the electronics of the servers during their manufacture, and can be polled without performance overhead. The most relevant sensors are: i) CPU, memory and ambient temperature, ii) fan speed sensors, and iii) server power consumption sensors.
– Server workload information: this information is obtained directly through the OS of the server (e.g. CPU and memory utilization, disk accesses, etc.).
– Workload allocation: the resource manager provides information about the particular workload allocation to each node, i.e. number of tasks assigned, execution time, start and end time, etc.
• Disseminators. Every observer in the underlying system can act as a disseminator in the TRS. Due to the communication capabilities of every entity, we do not have to take any special consideration regarding the functionality or performance required by the disseminators.
• Dissemination Protocol. All communications in the system are sensor-to-sensor, sensor-toserver, server-to-server communications. They have place in a local network or even in a dedicated link.
• Reputation Server. For the purpose of this work, we do not need to specify where the Reputation Server logic has to be deployed. We just need to know that one of the highcomputational-resources entity within the system will assume this role. However, the resource manager is the perfect candidate to assume this role.
• Trust and Reputation Algorithms. Because of the topology, complexity, and communication capabilities of the underlying system we will evaluate a combination of a local-area trust algorithm implemented by observers deployed throughout the system and a reputation algorithm implemented by the workload allocator. It will allow us to cope with both local anomalies and wide-area anomalies. Because of the special importance of this matter it will be discussed in detail in the next section.
6.3.4 Trust and Reputation Algorithms
Introduction
Most of the anomalies that take place at the Data Center have a direct impact on the thermal behavior of the data room.
66

6.3. TRS and Anomaly Detection in Data Centers
Due to the fact that the anomalies demonstrate themselves as spatial and temporal inconsistencies, no matter what their source is, we ﬁnd that SOM or GNG clustering techniques yield to high quality results in detecting and isolating anomalies. This theory will be validated in the section 6.4
The explanation on the next subsections applies both for SOM and GNG, as both algorithms follow the same standard steps. They only differ in the fact that the size of SOM is ﬁxed from the start, whereas the size of GNG grows during the training. Fixed size can be a limitation, as it might not possible to know the optimal number of clusters from the start, leading GNG to perform better in some scenarios where SOM does not obtain adequate detection and isolation rates. Due to space reasons, the reader is referred to [174] and [175] for a deeper explanation on the SOM and GNG techniques used in this paper.
Feature Extraction and Model Formation
Following the idea of temporal inconsistency in the presence of anomalies, we provide the data model that captures these properties and allows us to deploy machine learning. For the case of sensed values, we follow the idea presented in [176] based on extracting n-grams and their frequencies within different time windows.
We give a short example for a boolean sensor. Let the sensor give the following output during the time window of size 20: 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0. If we ﬁx the n-gram size on 3, we extract all the sequences of size 3 each time moving one position forward. In this way we can observe the following sequences and the number of their occurrences within the time window: 111 - occurs 6 times, 110 - 2, 100 - 2, 000 - 6, 001 - 1, 011 - 1. Thus, we can assign them the following sequences: 111 - 0.33, 110 - 0.11, 100 - 0.11, 000 - 0.33, 001 - 0.05, 011 - 0.05.
In our model, the sequences are the features and their frequencies are the corresponding feature values. This characterization is performed in predeﬁned time instants and takes an established amount of previous data, e.g.,we can perform the characterization every 20 time periods based on previous 40 values. As the extracted feature vectors are not of the same size, we calculate the distance function using the approach presented in [177], which calculates distance between sequences.
The same solution is applied to a continuous magnitude by normalizing the values to a ﬁxed range (e.g.,from 0 to 5) and quantifying the sensor values to reduce the amount of ngrams without losing relevant information.
Anomaly Detection
Our goal is to detect unknown behaviors which have not been seen during the training phase, thus, we aim to detect outlying data that belongs to non-outlying clusters.
For this reason, we calculate the quantization error (QE) of each input as the distance from its group center. The deployed distance function [177] is equivalent to Manhattan distance after making the following assumption: a feature that does not exist in the ﬁrst vector while exists in the second (and vice versa) actually exists but occurs with 0 frequency. In this way, we get two vectors of the same size and the distance between the center and an input is between 0 (when they are formed of the same features with the same feature values) and 2 (when the features with the values greater than 0 are completely different). Similarly, if the set of the features of one is the subset of the feature set of the other, the distance is between 0 and 1.
During the testing, n-grams not seen in the training appear when a sensor starts providing data signiﬁcantly different than before. When this happens, the distance (i.e.,the QE value), between the n-gram and its corresponding center is greater than 1, showing evidence of abnormal behavior in the sensor or the data room.
Sensors are arranged in areas according to the events they report information about. All sensors providing information about the same observation (e.g.,a thermal anomaly in a certain rack or room area), are assigned to the same area. The sensors in each area are examined by one or more independent observers. Observers are trained separately and execute the clustering algorithms. The system is complemented with reputation server that assigns a value o reputation to each sensor.
67

6. Detection and isolation: Anomalies in Data Centers

For our purpose, the trust and reputation values of the sensors are used in two different ways: i) individual sensor trust reﬂects the level of conﬁdence that other sensors have in this sensor, and is used to detect sensor malfunctioning. On the other hand, ii) area-wide reputation is calculated as the average trust value for a speciﬁc area, and reﬂects the global-spectrum anomalies occurring in the Data Center (e.g.,CRAC malfunctioning).

6.3.5 TRS mapping

After analyzing the components and processes involved in the design of a TRS to cope with detection of thermal anomalies in Data Center, we present a complete speciﬁcation of all the decisions taken in Table 6.1.

Component/Process Underlying System Entities Observer
Trust Gathering Information
Trust Calculation

Feature
Goals/Requirements Functionality provided Timing Topology Limitations
Observed Service
Area of inﬂuence Deployed in...
Observed entities
Observation time Range of observation Internal vs. external
Perception
Communication Memory Categorization Reputation Nature of information Reliability Redundancy Scope Base algorithm Calculation Time Computational Resources
Nature of information Required information

Detection time and isolation capacity Thermal Anomaly Detection System NR NR - ﬁxed Sensors: computational and storage capacity Enviromental Sensors Server Sensors Workload Allocator Environmental Sensors: Sensed values Server Sensors: sensed values Workload Allocator: allocated workload Local Environmental Sensors, servers, workload-allocator Environmental sensors: 1 Server Sensors: n (1-5) Workload Allocator: 1 NR NR Internal
Environmental Sensors: sensed values (temperature, humidity, differential pressure) Server Sensors: CPU, memory, and ambient temperature. Fan speed. Power consumption. Workload allocator: task manager information. Yes Yes No No Quantitative 1 Server Sensors: Yes Situational SOM, GNG NR Environmental Sensors: limited Server Sensors: NR Workload allocator: NR Quantitative Last polling

68

6.4. Experimental results

Information consumption No

Scope

Sensed values

Dynamism

Yes

No-transitivity

No transitivity

Asymmetry

Yes

Histeresis Loop

Logaritmic update function

Disseminator

Deployed in...

NR

Disseminated observers

NR

Dissemination Range

NR

Dissemination Time

NR

Conﬁdentiality

NR

Filtering

NR

Reliability

NR

Dissemination protocol Base algorithm

NR

Connection/connectionless NR

Point to point/broadcast NR

Conﬁdentiality

NR

Integrity

NR

Reputation Server

Deployed in...

Workload Allocator

Nr.of reputation servers

1

Topology

Central server

Internal vs. External

Internal

Reputation Gathering

Information

Trust

Yes

Reputation

Yes

Other sources

No

Public vs. Private

Private

Information

Reputation Calculation Base Algorithm

SOM, GNG

Calculation Time

NR

Computational Resources NR

Observed entities

Global

Nature of information

Quantitative

Required information

Trust, Reputation

Information consumption No

(NR) Not relevant.

Table 6.1: TRS and Anomaly Detection in Data Centers: system

speciﬁcation.

6.4 Experimental results
In this section we show the experimental methodology used for the experiments performed to validate the approach proposed in this chapter.
All data has been collected from a data room belonging to the research group. For the purpose of this chapter, we restrict our experiments to the enterprise servers in one rack. The rack contains two types of servers, different in terms of architecture and power consumption: i) SunFire V20z with 2 Dual-Core AMD Opteron CPU and 4GB of RAM and ii) Fujitsu RX300S6 servers with 1 Quad-Core Intel Xeon processor and 16GB of RAM. The servers are arranged in three different partitions: i) one containing all Intel servers, ii) one containing one half of the AMD servers and iii) a last one containing the other half of AMD servers.
All servers execute a controllable workload consisting on different tasks of the SPEC CPU 2006 benchmark [178], each requiring a different amount of CPU cores, arriving with a Poisson statistical distribution. The workload is assigned via the SLURM resource manager [179]
69

6. Detection and isolation: Anomalies in Data Centers
Figure 6.1: Simulated environment
that distributes workload across partitions. Thus, each partition exhibits its own workload proﬁle. A WSN developed by the research group is deployed in the Data Center to measure the inlet and outlet temperature of all servers as well as per-server power consumption. Internal server sensors are collected via the Intelligent Platform Management Interface (IPMI) tool that enables us to obtain, for each server: CPU, memory and server ambient temperature, and average fan speed.
Our experimental setup allows full controllability on the data room environmental conditions, as well as on the workload execution, enabling the generation of normal and abnormal training and test sets, in a fully controlled way. In particular, we generate different conditions in the Data centers that lead to two different anomalies:
• Anomalies in the data room cooling due to a CRAC fan failures • Anomalies in the workload execution.
Moreover, these anomalies take place together with anomalies in the sensing infrastructure of the Data Center, i.e. malfunctioning sensors. Anomalies are detected with the TRS simulator described in Appendix A.
The next subsections describe how each type of anomaly is generated, which are the information sources needed to detect and isolate them, and how random sensor failures can be detected within this scope. To systematize this analysis, we provide results on detection ratios, detection time, and isolation time.
6.4.1 Anomalies in the data room cooling
In our experimental setup, during the normal operation of the air conditioner, the inlet temperature of the servers varies between 16ºC to 23ºC. CRAC anomalies can be generated by suddenly turning off the air conditioning unit for a certain time.
For these experiments, we simulate a CRAC failure in a real raised-ﬂoor air-cooled real Data Center environment composed of three racks (R0, R1, R2) with servers at three heights (H0, H1, H2) that are cooled via 2 CRAC units. Figure 6.1 shows the simulated rack and CRAC distribution in the data room, and the failing CRAC unit, whereas Figure 6.2 shows the inlet and ambient temperature sensor for a server in the middle height (H1) in all three racks.
The information provided by inlet and ambient temperature sensors of servers at the same rack and height is highly correlated, comes from two different information sources (WSN and internal server sensors) and is sufﬁcient to detect and isolate CRAC failures. We arrange data in areas according to their physical position in the data center and run TRS simulator to test the anomaly detection with SOM and GNG algorithms, both when all sensors are working properly and when some sensor malfunction exists during the testing phase.
The best results for both cases are obtained with SOM, using a training set of 300 ticks (each tick representing 1 minute) and an n-gram size of 3. Usually, n-gram size varies from 2 to 5.
70

6.4. Experimental results
Figure 6.2: Server inlet temperature with time under CRAC failure.
(a) CRAC failure detection in three different racks (b) Sensor malfunction around ticks 550 and 600 for rack (R0)
Figure 6.3: CRAC fan failure detection and isolation with individual anomalies in sensors.
Higher n-gram sizes give more sensibility to anomaly detection but, at the same time, increase the false positive rate [84]. An n-gram size of 3, provides the best trade-off between detection and false positive rate in our setup.
Figure 6.3(a) shows the results provided by TRS-SIM (see Appendix A) for SOM with a CRAC failure starting around tick 500 that highly affects rack 0 (R0), moderately affects rack 1 (R1) and does not affect rack 2 (R2) at all. Red and purple colors represent low reputation values and yellow color represents reputation values near 100 percent. In the horizontal axis, information source IDs are represented for the different racks are presented. CRAC-failures are calculated by averaging the reputation of sensors in the same area. If reputation is below 40, we consider that an anomaly takes place.
Figure 6.3(b) shows the malfunction of two sensors in Rack 0 (one in H2 and another in H0) around time instant 550. Regarding individual sensors, we consider that a sensor is malfunctioning when its reputation drops below 60 whereas the reputation of its neighbors if stable. Around tick 800 all sensors have a drop in their reputation. Because all sensors provide the same values, our system detects a CRAC anomaly around tick 800, instead of a sensor malfunction.
For our experiments, we obtain a CRAC failure detection rate of 100%, with a false positive rate of 0%, a very low detection and isolation time of 2 and 5 ticks respectively.
6.4.2 Anomalies in the workload execution
Detecting anomalies in the workload execution in a heterogeneous Data Center is not an easy task mainly because of the temporal variation usually exhibited by the workload. Power consumption gathered via the WSN shows different proﬁles depending on the workload under execution and the server architecture (AMD vs Intel, see Figure 6.4(a)). CPU temperature is correlated with power consumption and gathered via the internal server sensors, making these two metrics good candidates to detect anomalies. Because the SLURM resource manager as-
71

6. Detection and isolation: Anomalies in Data Centers

(a) Power consumption for AMD (blue) and Intel (red) nodes with time

(b) Workload misconﬁguration detection

Figure 6.4: Power proﬁle in two different architectures and workload misconﬁguration detection with individual anomalies in sensors.

signs the incoming workload to three different partitions, to detect and isolate anomalies, we arrange the sensors depending on the partition they refer to.
In this case, GNG techniques with a training set of 300 ticks and an n-gram size of 2, outperform SOM in terms of false positive rate. Figure 6.4(b) shows the detection and isolation of workload anomalies in a rack composed of 9 servers belonging to the three previously described partitions. Around tick 400 servers in AMD2 partition start having an abnormal behavior that extends to more servers around tick 500. When the behavior of the server workload changes partially its reputation drops. To avoid false positives, however, we only consider that an anomaly exists when the area-wide reputation drops below 40.
For our experiments, we obtain a workload misconﬁguration detection rate of 100% and again immediate detection and isolation times, as in the previous case.

6.5 Conclusions
In this chapter we have presented a clustering-based detection methodology based on SOM and GNG coupled with a TRS to detect and isolate cooling and workload anomalies.
Following the methodology proposed in Chapter 3 and Chapter 4, we selected the most suitable algorithms and trust information sources for the designed TRS in order to improve the detection and isolation times.
By making use of sensor topological information and arranging data in different areas we differentiate between individual sensor trust and area-wide reputation, splitting CRAC and workload data center anomalies from anomalies due to the malfunction of information gathering sensors.
We show how SOM provides better results for CRAC anomaly detection, yielding detection rates of 100%, in training data with malfunctioning sensors. We also show that GNG yields better detection and isolation rates for workload anomaly detection, reducing the false positive rate when compared to SOM. It is important to note the very low detection and isolation rate, that allows rapid actuation upon a Data Center anomaly.

72

7. Throughput Maximization: Social Odometry
The improvement of odometry systems in collective robotics remains an important challenge for several applications. Social odometry is an online social dynamic which confers the robots the possibility to learn from the others. In this context, TRS can provide a signiﬁcant improvement for the coordination capabilities of this robot networks.
In order to take advantage of TRS we will follow the analysis and design methodologies proposed in Section 3.2: identify architectural entities, trust and reputation information sources, functional and non functional requirements, dissemination algorithms, etc.
This analysis allow us to choose the constitutive elements of a TRS so we can maximize the throughput of the underlying robot network in adverse, unsupervised and complex environments.
7.1 Introduction
Robots are individual sensors highly efﬁcient, equipped with sufﬁcient abilities, that can be exploited jointly. The collaborative swarm is a group of entities that work together to achieve a common objective. They make intelligent decisions to achieve a foraging goal which requires some mechanism of collaboration by means of social odometry. In social odometry, each robot is a sensor for the other robots of the swarm. The importance of social odometry lies on the fact that the swarm (the collectivity) allows the robots to collaborate to achieve a common objective because the individuals are working together.
Many robotics applications require the robots to be localized to achieve different tasks. Different solutions to the localization problem have been implemented. Among these, odometry is probably the most used as it provides easy and cheap real time position information by the integration of incremental motion information over time. Unfortunately, this integration causes an accumulation of errors during the movement of the robot, and this can be a great drawback in some robotic applications, such as foraging, where the robots have to ﬁnd, select and exploit resources from unknown locations.
Different approaches have been implemented to deal with this complexity; however, those solutions have a number of different limitations: i) they are power consuming in terms of computation [180], [181], ii) some robots are not allowed to move or they have its mobility limited [182], iii) robots must maintain visual contact at all times with the rest of the group [183], and iv) in some cases robots have to communicate with a central device to update or download maps of their environment, synchronize movements, or update positions [184], [185].
Social odometry [186], [187] is a novel solution that exploits self-organized cooperation in a group of robots to reduce each individual location error.
Each robot location knowledge consists of an estimate of its own location and an associated conﬁdence level that decreases with the distance traveled since the last know location. In order to maximize its conﬁdence about its estimate, each individual tries to update it by using the information available in its neighborhood. Estimated locations, conﬁdence levels and actual locations of the robots co-evolve in parallel in order to guide each robot to the correct objective.
Without loss of generality, in this chapter, we will work with a classical swarm foraging scenario: a number of resource items (usually called prey) are randomly scattered in the arena. In this context, robots search and retrieve those resource-items back to a speciﬁc place (usually
73

7. Throughput Maximization: Social Odometry
called nest). The performance of the robot network in this kind of foraging systems can be measured as either the resources-items collected by unit of time, or the time robots need to exhaust the resources.
Actually, as we said before, social odometry already uses a simple TRS based on the distance travelled. However, from the point of view of TRS techniques, foraging robot network scenarios have more valuable trust information sources that have not been used at all in previous works.
With the use of the systematic analysis, design and deployment TRS methodology proposed in previous chapters we will identify all these valuable resources and we will evaluate the performance improvements we can achieve in complex and unsupervised scenarios.
The rest of this chapter is organized as follows: section 7.2 explains how social odometry works in detail. Section 7.3 analyzes in detail how TRS can improve social odometry robot networks, and in section 7.4 we present the experimental results. Finally, in section 7.6 we draw some conclusions.
7.2 Social Odometry
7.2.1 The odometry problem
Odometry is probably the most used localization method. It provides easy and cheap real time position information through the integration of incremental motion information over time without the need for any other device.
In all the odometry techniques a travel path is derived from sensors computing the movement of the robot. However, the accuracy of odometry measurements strongly depends on the kinematics of the robot. Typical sensors for robots with a differential drive system are incremental encoders. Incremental encoders are mounted into the drive motors to count the wheel revolutions. A robot can perform odometry using simple geometry equations.
Odometry errors can be classiﬁed as either systematic or non-systematic errors [188]. Systematic errors can be modeled and corrected, while the non-systematic ones cannot be corrected and many classical techniques have been implemented to cope with them.
7.2.2 Learning from others
Social odometry is a previously deﬁned technique [187], [189] which is not based on any maplike algorithm, and despite being inspired by the Kalman Filter [186], [190], it does not require any explicit model of the movement errors. On the contrary, a relationship between the distance traveled and a conﬁdence level allows the robots to select the closest resource site on a foraging-like scenario.
The key aspect of social odometry is that robots within the swarm act as virtual landmarks to the others and exchange their knowledge about the position of goal areas. Nonetheless, they have to deal with two main issues: i) the robots only know estimated locations, not the real locations, and ii) the more the robots travel the worse those estimates are.
Figure 7.1 shows how information about the estimated location of area Y is transmitted from robot i to robot j. In a ﬁrst step, robot i transmits its estimate of the distance dyi and direction φi of area Y to robot j. For the direction, the value transmitted is the angle α, obtained from φi using the communication beam as reference axis: α = φi − γi. In a second step, robot j transforms the received data into its own coordinates system using simple trigonometric equations.
At this stage, robot j has the opportunity to adopt the estimate of the neighbor, to keep its own or to produce an updated location based on both. Given that estimates get worse with distance travelled, the robots use the inverse of the distance travelled as a conﬁdence level of their estimated location. This conﬁdence level, denoted by i for robot i, respectively j for robot j, is part of any communicated location and informs about the reliability, or quality, of the information.
74

